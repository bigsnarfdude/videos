Engineering science at U.S. San Diego is the director of the National Reserve for Network Biology, the San Diego Center for System Biology, and the Center and the Cancer Cell Map Initiative. So Dr. Ide had an influential research in genomics, trace photomics, and proteomics analysis. He's advancing the theory and practice of systems biology and the use of genome-scale measurements to construct networks models of several processes and disease. He founded and maintains the Cytoscale Network Analysis Platform. Cytoscale network analysis platform and created the Android epigenetic plot, which is the first to measure human aging rates using DNA methylation. Today's going to talk about building a mind for cancer. Thank you so much, Tray, for being here. My pleasure. Thanks for the invitation. Can everyone hear me okay? Yep. Okay, great. Okay, so the motivation for my talk today, as you can tell from the title, it's related. It's related to interpretable machine learning for cancer in particular. But I think, as you'll see, and as I've already seen at this conference several times, cancer provides an excellent proving ground for some of the technologies that I think that are developing and being developed by people at this conference. So, as we at this conference know, machine learning techniques hold immense promise for tasks like, in this case, cancer diagnostic. Case, cancer diagnostics, prognosis, prediction of drug properties. And today I'll focus on this last goal: prediction of drug response of a patient, given their genomic and other molecular features. The challenges of machine learning techniques in these fields are exactly the same, or at least. Exactly the same, or at least mostly the same, as in other fields. And those relate, as this conference knows, to lack of interpretability. And I'm also going to touch at the end of my talk today on a related concept, lack of transferability. And both of these problems are particularly salient in high-risk applications such as precision medicine. Anytime you're Anytime you're using a machine learning system to make a decision about someone's life, that certainly classifies as a high-risk application. So that is an area where we particularly need to make sure we build trust in the machine. And the challenge of transferability comes because often the data that we have for training these models are mostly in models. Are mostly in model systems such as cell lines, mice, and so on. Whereas, of course, we want these systems to work in patients, and they therefore must be sufficiently general or able to extract general information that's present in the cell line and mouse training sets for transfer to patients. Also, a huge problem these days is overfitting a model to a particular cohort of individuals. To a particular cohort of individuals, such that it, such that, for instance, a model that makes good predictions of drug response in one race or ethnic group fails to do so in another. And this is also, of course, a lack of transferability problem. But shown in the graphic here, of course, is the current black box approach to translation or conversion of patient information. Or conversion of patient information into, in my case, predicted drug outcomes. But there's many applications, or a number of applications that can go here at the output. And so the main approach I'm going to talk about today is an interpretable approach, which is explicitly interpretable because the non-linear machine learning systems we're going to build. Linear machine learning systems we're going to build based on deep learning are explicitly tied to models of cell biology in cancer. And we call that visible machine learning for biology. The names of approaches we've published in recent years are D cell and drug cell, and I'll be talking about those. And then in the transfer learning part of my talk, I'll talk about a few shot approach called TC. Approach called TCRP that we published last year. And I'll also have allusions to unpublished work. So, first, let's talk about the visible, what we've called visible machine learning and cell biology with these D-cell and drug cell approaches. So, these are deep neural networks for prediction of general cell responses where the architecture of the neural network is guided by a hierarchy. By a hierarchy of known systems that have been mapped for the particular cell type in which you were making predictions. So here, let's just think about the most or a very general genotype to phenotype translation engine shown over here at the left. And that's exactly what this really is. It's a general genotype to phenotype translation engine. Of course, if you know something about genetics, course, if you know something about genetics, you'll appreciate that really much, perhaps all, but certainly much of genetics boils down to translation of genotype to phenotype in different contexts. So those are your inputs and your outputs. Genotype is the inputs features, and output is prediction of some phenotype. Now, of course, there's many variations that'll fit that mold or that template. In the original D cell paper, which is shown down here, this is the Ma Ma Uadal Nature Methods paper. We used a toy system based on Sacromyces cerviciae. That's a budding yeast cell, where the advantage of that toy system is that already biologists had made every single gene disruption experiment and every double gene disruption experiment. Double gene disruption experiment, and even many, many, as in hundreds of thousands of triple gene disruption experiments that can be made into the genome of that organism. And in response to each of those perturbations, the simplest possible, one could argue, phenotype was measured, and that's how fast the cell grows or the amount of cell proliferation. So, with about 5,000 genes in yeast total, there were then 5,000 single gene disruptions for which we had a Single gene disruptions for which we had an outcome of cell growth, as well as 5,000 shoes, two pairs of disruptions for which we had a cell growth, which a phenotype, which is about 12.5 million training examples. And then, like I said, we had a number of triple gene deletions as well. Now, in constructing a deep neural network to translate which genes were deleted. Translate which genes were deleted to what the growth rate will be, we built our neural network on top of an ontology or knowledge base of components in the cell. And if you've studied cell biology before, it won't take you much thought to appreciate that there are thousands and thousands of components that make up cell biology. You can think here Here, in terms of top down in this diagram, individual nucleotides, which are the scale of say nanometers, are embedded, of course, or sequences of those make up genes. Those genes produce proteins, which don't act alone, but form small molecular machines, which here I've denoted as small complexes and subunits of larger protein complexes. Those larger Protein complexes, those larger protein complexes form metabolic and signaling pathways in relation to one another. Those take place in organelles like the mitochondrion, nucleus, or the peroxisome, or the cell membrane. And those organelles, of course, unify under the entire body of the cell. And so these ontologies, you can think about it here. Bottom up would be to factor the cell into many parts. Top down is to slowly assemble those parts into a To slowly assemble those parts into a complete cell. But all of this is well represented by an ontology. In the original paper, we looked at two or at a variety of different knowledge bases or ontologies for guiding construction of the neural network. And the one that most people use and that we use is called the gene ontology. So that's the source of, in this first publication, the Source of in this first publication, the source of the information. And then what you do is you, for each component of, say, 2,000 or so components in this hierarchy, you embed into that component, or I should better say, represent the state of that component with a bank of neurons. So for instance, somewhere in the hierarchy is a component that maps to the process of DNA repair. DNA repair is represented by a bank of neurons here. By a bank of neurons here shown by these small circles, and whose off-on states, that vector of off-on states for DNA repair, would essentially model its state under an input genotype, giving rise to a predicted cell proliferation phenotype or cell growth phenotype as you model, and that's what's going to happen here, as we model the genetic flow from genotype to phenotype through these components. Now, DNA. These components. Now, DNA repair and this hierarchy factors into going up the screen here, factors into subcomponents, such as double-strand break repair, basic scission repair, mismatch repair, and there's others. This is not an exhaustive list of the daughter systems of DNA repair in the ontology. Each of those have their own bank of neurons representing their states. And importantly, during training of this system, we're going to only allow non-zero weights. Allow non-zero weights to be learned that connect, if they connect, the subunits of the system to that system's neurons. We do not allow non-zero waste to be learned from other systems in this hierarchy that do not funnel into DNA repair. And so that's quite a large constraint on the architecture of a neural network as it's built. Otherwise, It's built. Otherwise, this deep neural network is going to look a lot like other deep neural networks. The original one had about 12, I believe exactly 12 layers because of, you can see there's a funnel-like or a funneling of information through this hierarchy. And so you have fewer neurons in the last layers at the bottom here than you do at middle layers, which are fewer than at the top, and so on. Fewer than at the top, and so on and so forth. And all with the particular constraint that these are not hidden, or these are not exactly like normal hidden neurons. They are explicitly assigned to cell biological processes. Now, I already told you how we trained this model for yeast. In the examples I'm going to show you, I'm going to pivot to, just in interest of time, the companion paper that came out two years ago. Companion paper that came out two years later, where we trained a very similar system, but for human cell cancer, cancer cell biology. And that is this cancer cell paper by Kooncey Park at OW. Here, rather than model how gene knockouts, gene perturbations affect cell growth, we modeled how gene perturbations or the genotype or the mutation profile, these are all equivalent terms, the mutation profile of a tumor. Profile of a tumor plus a drug, okay, how does that translate into a predicted cellular response, again, as measured by cell growth? Now, that was a natural bridge from the budding yeast model to the human cancer cell model, because we had a very good data set for training this human cancer cell biology. Human cancer cell biology response. And that's, and so drug cell is the name of that model. And the training data set was a set of about a thousand human cell lines, I should say, human tumor cell lines. Each had a complete genome sequence available, which means we know the exact, or at least with to a first approximation, one can argue about how exactly you know, but to a first approximation, we knew what genes were mutated. Approximation, we knew what genes were mutated in a given cell line. And we also knew, and each of those cell lines had been exposed to each of about a thousand drugs. And so we also knew that this set of mutations was in the context of a given drug. And what had been measured experimentally was the outcome, which was how fast a cell proliferates under. A cell proliferates under that drug condition, given that set of mutations. It turns out this was far less data than we had for budding yeast, but we still, you know, as you can see, it's still a data matrix between half a million and a million training samples. If you multiply the rows by the columns here and subtract out a few missing ones, a few missing cells in the matrix. um so that's that's the result i'm going to show you next is training these these these uh these visible neural network models to predict drug response given uh given the input uh mutation pattern and and a drug uh and the training this is all at that point uh uh everything works just like a conventional neural network with back propagation and training the system over over a series of epochs one one final concept before i move One final concept before I move to the results. The system really is quite similar in a way to a convolutional neural network, where instead of the areas that are being integrated by the next layer being organized spatially in two dimensions in the image, here those areas of features are organized in spatial cell biology by these different systems. And so rather than sort of So rather than sort of do convolution over a two by two grid of pixels or what have you, here we're integrating over the subunits of a component in the hierarchy. But otherwise, it's in spirit quite similar to what is being done by convolutional neural networks in image analysis. So, okay, that's enough talking for now. Let's go to some results. Results. So first, we checked that the predictability or the predicted performance of this model was at least equivalent to standard models in the field. So the drug cell visible neural network model is shown on the y-axis here. The x-axis is a competing straw-mann model, either elastic net over on the left or a matched nerve. left or a matched neural network model on the right where we simply where we've scrambled the labels on the individual component or on the I should say we scrambled the the connections between the input features and and the hierarchical structure so then every point is a particular looking at the particular ability to predict of response for a drug and so it's like one Drug. And so it's like one, if the drugs are the columns of that matrix of data, it's one column's worth of data. And you're looking at over all the cell lines, over all the tumor cell examples you had. You're making predictions for what their growth is going to be in that drug context. And then you're looking at how that compares to the actual measurements using here a simple spearmill correlation. So, what you can see just to orient us in this plot is 0, 0. The origin is right in the middle. So, these are drugs that. In the middle. So these are drugs that were poorly predicted by both models on the Y and X axis. Up here in the upper first quadrant, way out along the diagonal, we have drugs that are well predicted by both models. And then you can kind of convince yourself that there may be a few drugs that are better predicted by the drug sell approach than by the competing model in both cases. But I won't really make a point of that here. I think that the concern mainly was. I think that the concern mainly was to make sure we do no harm as we build out these visible neural network models. So what's more important, of course, especially as the topic goes for this conference, is the interpretation. So now the idea is we can go back and look at what are, you know, the devils are in the details, but intuitively, what you want to do is having now. Intuitively, what you want to do is having now trained the model, find drugs that are well predicted by, you know, so drugs that are above, say, a threshold of 0.3 or 0.5 in Spearman correlation, above a sort of horizontal line in these plots. And then for those drugs, you become very interested in the model interpretations. And so you'll simulate those drugs in terms of what across your cell lines and looking at the responses. And as you do, And looking at the responses. And as you do, you basically watch the neurons that are assigned to each of the different components. And intuitively, you want to choose those that are the most important for the response. And it turns out the way we do that is still in, I think, an open research question, but we've had pretty good luck with approaches related to the Lyme interpretability method. Essentially, all of, I think, the basic interpretability. Essentially, all of the basic interpretability methods, most of them apply, can be pushed back through the circuit of the neural network into internal to look at internal states and which ones are most important. And that's essentially what's going on here. So let me just show you an example. So this is Paclitaxol, a drug that is first or is certainly standard of care in several types of cancer, certainly including breast cancer. Taxol is thought to work by Is thought to work by binding the microtubules in a cell and stabilizing them inappropriately. So it kind of mucks up the works of the cytoskeleton of a cell. And for that reason, retards cell proliferation. Now, many who study Taxol have debated, there's this sort of an ongoing debate about is that the real mechanism of action of Taxol or is it in Taxol, or is it interacting with some other circuit of tumor cell biology? So, what was very interesting as we began to interpret the response to Taxol using the drug cell model, we did find microtubules as important. That is to say, that bank of neurons was important for the taxol response. But as important were the three pathways shown here, starting at the right. Starting at the right, response to glucose, response to cyclic AMP, insulin secretion involved in response to glucose. And so the common theme to us for these three sets of components was glycolysis, was glucose. So what the first author of this study was a collaboration between the first author, who was a pharmacologist, pharmacogenomics person, and that was Brent Cooncey and G. And that was Brent Kooncey, and Jisoo Park was the machine learning person. And so here, Jisoo made this plot and this readout, and Brent took it into lab and said, well, if the model is correctly captured something here, which is to say that mutations that affect glycolysis are somehow modulating the response to Taxol. If that's true, then maybe if I That's true, then maybe if I directly drug glycolysis, then I'll see the same effect. So here he's using a tool compound known as 2DG, which stands for 2-deoxyglucose. And what he's showing us in this plot at the right is that in the first column, if he applies paplitaxel at a certain concentration, he dials the concentration of paplitaxel alone so that you get a slight depression of cell viability. This is in, I believe, A54. This is in, I believe, A549 lung cancer cell line. So this is just one of the thousand cell lines. Okay, you can do it for others. He then gets a suitable dose in the same fashion of 2-deoxyglucose, drugging glycolysis, or mucking up. Basically, 2DG looks like glucose, but it's not. And it feeds into the system and then mucks everything up is the way to think about 2DG's effect on glycolysis. But now in this third column, what he's doing. But now, in this third column, what he's doing is combining the two and trying to convince us that, in fact, you see a large decrease in cell viability when you drug, when you expose the cell to both drugs simultaneously, as could have been anticipated by this modeling result over here at left. Now, that's certainly very anecdotal. And so, to further explore this concept, Brent did some further experiments. Brent did some further experiments. But first of all, to be clear, what is the concept? The concept is that you have this deep learning system whose neurons are explicitly tied to cell components. And when you find using that system, you can find the neurons and thus the cell components that are most important for the response to a drug. And the implication is it's those components that are integrating mutations, perhaps across. Mutations, perhaps across many genes. And in fact, if you further interpret the model, I'm not going to show the slide here, but you can further interpret the model to look at exactly what are the genes in glycolysis, say here, that are affecting drug response. And it turns out it's dozens that are being integrated essentially above these systems shown here. So you're mutating dozens of genes, and those mutations are similar in that they model. They are similar in that they modulate the drug response to Taxol. So, using that general, or if that principle is general, then the thought would be for any drug, you should, or the algorithm would be, for any drug, find the most important pathways for that drug response and drug those using a second agent as a way of combination therapy in cancer. And if this result with two deoxygenos. this result with with 2-deoxyglose impact with taxol is any any um um any guide then you're going to have that that combination therapy would be uh significantly uh more efficacious than either agent uh alone and so that's exactly what brent continued to do here and um and and you can read his paper to see more examples of this these are expensive experiments both time and money um and and and sort of technique so we have a couple of more anecdotes i i you know at least in this in this paper and here's one Know, at least in this paper. And here's one. This is another class of compounds such as trimetanib, which target, supposedly, they target the protein family called MEC or MEC. MEC is a signaling protein and a signaling pathway that tells the cell to grow and, in the case of cancer, inappropriately so. And so, here, the top five pathways to The top five pathways to uh in the response to a mech inhibitor, trimetonib, were the five shown here. Each, of course, contains many genes. And so what Brent and Jisu did is they repeated this kind of experiment where they perturb the drug target itself here, MEC1. Okay, and here they're doing it not with the drug as a small detail. They're using this CRISPR guide RNA to do it, using the CRISPR technology. Guide RNA to do it using the CRISPR technique. And then they come in with a second CRISPR guide RNA and disrupt one gene chosen essentially arbitrarily at random from these top five pathways. Okay. And then they do it again with the second gene chosen at random from these top five pathways. And they do that a few dozen times. The first perturbation is always to the drug target, MEC1, and the second perturbation is sort of the second perturbations are sprinkled throughout. Second perturbations are sprinkled throughout these top five pathways. So, what you see over at the right here is the result of that experiment. On the left, you're looking at what those combo therapies did to cell growth. And on the right, you're comparing that to a negative control where the second guide RNA, the second perturbation is chosen at random from the entire human genome, not just these, in fact, excluding these top pathways. These top pathways. And so here you can see that not every double perturbation taking out a system in the top five pathways produces a depressive effect on cell growth, but many do. And it's very significant. And you can just easily see the effect in comparison to random combinations. So we think, you know, this is one other anecdote. These are expensive experiments, but we think we're. Expensive experiments, but we think there may be a more general principle at play here. And in the paper, there's maybe two other anecdotes. So please do look at that. And the general principle would be quite useful for design of combination therapy, which is something of high interest in tumor drug development at the moment. Let me end this part of the talk by showing you an example in In patients, though, because I mentioned the need, of course, these are all experiments in cell lines where you have all the training data, but I mentioned, of course, the need to translate these experiments efficiently into actual cancer patient scenarios. Now, with any advanced model of drug response, it's going to take years. Years, hopefully, single-digit numbers of years to get these vetted for clinical applications. And we're working on that with, for instance, the molecular tumor board at Morris Cancer Center here in San Diego. And there's an armada of increasingly large armada of companies trying to do this, again, in consultation with different cancer centers. But nonetheless, what one can do now is look retrospectively. Is look retrospectively at previous outcome data from the clinic and see if the model would have gotten the answer right. This is not nearly as strong of a validation. It's a prospective clinical trial making predictions in the future, but nonetheless, it's worthwhile and it's all we have now. So this is a study of, and even for retrospective trials, I should say, there's really not a lot of data. It's not like we chose. Chose. So, the good thing is, what I can tell you is, we did not look at 10 data sets here and choose the one that worked the best for this presentation. There's only one we had to look at. And interestingly enough, we got some interesting results. But it's anecdotal. That's the problem. It's not like we're optimizing anything here. So this is the AACR Genie project. This was a retrospective trial published in 2020 of breast cancer patients who were ER positive. Breast cancer patients who are ER positive, that's estrogen receptor positive, and are metastatic. And in that case, these are end-stage patients where essentially to have progressed to this point, we really need some creative thinking and exploratory. This is the time when exploratory analysis with new drugs is appropriate. And so in this trial, they're comparing. Everyone, by the way, gets because they have this estrogen receptor, they get Have this estrogen receptor, they get an estrogen receptor antagonist, fluvesterin. But then the question is: if you add in combination an inhibitor of some other point in the circuit, is it going to have an effect? And here the goal was to try out Everolimus, which inhibits this mTOR protein. Now, let me give you the cheat sheet to the mTOR circuit that's shown here where my cursor is. It's a famous or infamous cancer proliferation pathway where this. Pathway where this protein, this signaling protein PI3K, activates the protein AKT, which activates mTOR, which activates tumor progression. So there's no negative effects in this particular pathway. It's all just positive amplification of the signal down this cascade of proteins. Now, it had been thought that if your drug is going to inhibit mTOR, then the patients that are going to particularly respond. That are going to particularly respond are those that have inappropriate activity or activation of upstream components like AKT or like PI3K. In the plot on the left, this is from the original Genie paper by Smith et al., they're showing a negative result. If I activate the AK for patients that have an activating mutation, this E17K and that's an activating mutation in the AKT protein, compared to patients who don't have that activating mutation, I see no. Activating mutation, I see no difference in survival under this Everolemus mTOR inhibitor. Okay, now we retrospectively, and these patients had genomic data available for their mutations, not genome-wide, but they had what is measurable these days in the clinic, which is about four to 500 genes on a panel, and we fed those as features to the drug cell model. Cell model, and used those features to get a cell proliferation continuous value prediction out of the model, which we thresholded into what we call here on the right drug cell positive patients and drug cell negative patients. The positive patients are those that are predicted to respond to this drug, and the negative patients are those that are predicted to not respond. And you can see here we do get a significant separation of survival as the model expected. As the model expected, or what follows from the model's prediction is that the drug cell-positive patient population should live longer, and they do. That's as shown by a median survival difference of about 15 months, which is, if that could be shown in a prospective trial, that would be a very big deal. In a retrospective trial, it's nonetheless interesting, I would say. So now, because the model is interpretable, we open up the hood of the model and we ask, okay, what are the Model, and we ask, okay, what are the components of the model in which neurons are the most important? And it turns out it is looking at AKT mutation as that feature, but only in combination with mutations shown in the pathways and components over here to genes like CDH1, TP53. Like CDH1, TP53, ESR1, RENX1, and so on and so forth. So, what you essentially have is a complex biomarker. It wasn't as simple as AKT, as a single gene biomarker, as clinicians think about these days. Lots of drugs in the clinic have single gene biomarkers that indicate a response or non-response. But this model is essentially enabling and advocating a move to compound biomarker responses where you have a collection. Where you have a collection of mutations that you want to examine. Okay, so that's the first part of my talk. And let me just quickly say a word about this knowledge base or ontology on which you're building into which we're building these deep learning systems, because that's going to be critical. Clearly, if you're constraining the way that these layers are interconnected, that's a pretty strong constraint. That's a pretty strong constraint, and you better be right. And I think that there's a number of possibilities for, I think, what should be done in the future. One is to allow some flex in that learning. And the other is to directly incorporate measurements of structure, not just of input-output function, and provide that for learning at the same time. And so that's the direct. Same time. And so that's the direction that I'm going to talk about here. And we've gone in most recently. And it's really just kind of an experimental aside in the middle of a machine learning talk to build out these maps of cancer cell biology in a data-driven end-to-end pipeline in a sort of way, in a closed sort of way. We have been operating with funding from the NCI, National Cancer Institute. National Cancer Institute, which supports the center called the Cancer Cell Map Initiative. Nevin Krogan and I direct this center. Nevin is up at the moment at UCSF, but it involves a cadre of about a dozen faculty, six of whom I show here on the left, and of course, many, many, many postdocs and graduate students, some of whom I'm going to show over here. Some of whom I'm going to show over here on the right, because I'm going to show their work in just a slide or two here. But here's the goal of the Cancer Cell Map Initiative. It's to provide data to these machine learning models, not just about the functional translation of what is the outcome and prognosis, diagnosis, and drug outcome of a patient with. Outcome of a patient with such and such mutations. That's the functional translation, but to provide an orthogonal data set on, or a set of data, I should say, on tumor cell architecture, the architecture of the machine that in real biological terms is performing that translation. And once you've done this, I think the future opportunity and challenge would be then to build machine learning systems that can incorporate both in the correct or in In the correct or in the most optimal way. And I think that much of that research is, of course, yet to come as we develop these maps. But how does the mapping work? We apply two workhorse technologies. We apply protein-protein interaction mapping with affinity purification tandem and spectrometry, which draws these big network graphs of what proteins physically bind, which other proteins. And then we also apply. And then we also apply imaging, confocal microscopy of fluorescent, of the same fluorescent proteins to look at their locations in a field of cells against the backdrop of common stains like nucleus, cytoplasm, and endoplasmic reticulum. With these two complementary data sets, the biochemical mass spectrometry and the microscopy imaging, we integrate those into these ontologies of cell. Ontologies of cell components for different diseased applications. And then these ontologies would then be used to guide machine learning systems. And whether or not you pre-build the ontology and then feed it to the model, or you actually, or really the modeling begins over here and actually learns the structure and function of the system simultaneously, I think remains to be determined. Certainly, thus far, we preordain the structure and then we give it to the neural network. And that I've already shown you, but let me quickly show you how we integrate or at least point you to where you can read more about how we integrate these two main data streams of microscopy on the left and protein-protein interaction mapping with mass spectrometry on the right. So, the key insight here, and this is a paper that came out about six months ago by Yu Chen. Six months ago, by Yu Chen, who was one of the faces on that CCMI slide. She's a grad student in my lab who's about to graduate. Her key insight was that both microscopy and protein interaction mapping are ways of positioning proteins in some space. One positions proteins relative to other components that you can see in an image of cell biology, and the other Cell biology. And the other positions proteins, in mass spectrometry, you grind up the cells. So there's no imaging, there's no two or 3D spatial information that's preserved. But what you can exquisitely read out is what are these sort of immediate interaction partners. And so this is positioning a protein relative to nearby proteins. So they're both positioning proteins. And what she then does is she, you can then think about with that insight, embedding. With that insight, embedding those proteins using either source of data, but then ultimately co-embedding both types of data into the same embedding. And here we're just looking, I'm moving very fast here. You can look at the details in the paper. Here, we're just showing most or two dimensions. We're using UMAP to just display two dimensions of that embedding. But here, the points are proteins, and proximity of two points means or indicates that those proteins are close. Indicates that those proteins are close, both in their imaging, okay, with support from imaging and with support from proximity in the protein interactome. And so then, and then we can cluster these. You can look for community structure in these embeddings, and that's how you start to build out those ontologies. And so we're starting to do this. I think I'll skip through this, but we're starting to do this for cancer cell mapping experiments. Cell mapping experiments, and I think there's going to be a lot more to come. It's going to take us a few years here, but we're well, you know, these experiments are well underway to come up with data-driven ontologies of tumor cell structure, which can then be available to these machine learning models. And here, like I said, I think I'll just skip over a lot of this, but please do check out this paper. Do check out this paper by Zhengadao, a former postdoc in the group. This is our best data-driven ontology of cancer cell components using these data-driven methods. This is mostly based on mass spectrometry at the moment, not imaging. The imaging is going to have to catch up, but it's there and it's available for consumption now. So let me, you know. Um, so let me, you know, and here, and then this slide simply shows that we're now beginning to use. Uh, this is unpublished data, but it shows that we're beginning to use these models in deep learning systems, just as I showed you before, like DrugCell. This is a deep, this is, so now I have sort of an end-to-end system where I generate the structure and the function of the model from experiments performed de novo or systematically in a controlled, unbiased fashion. In a controlled, unbiased fashion, I guess is the better way to put it. And so here's an example. The red systems in this model are those that are important for the response to another drug here, palvociclin. Okay, so now I just want to take, I think I have maybe just, well, depends if you give me an extra few minutes for getting started late. But regardless, I think I'll try to take less than five minutes. I'll take, like, I'll try to take less than five more minutes and wrap up, and hopefully, we'll have time for at least a couple of questions. Um, so I just wanted to briefly mention at the end of my talk here: uh, this is not a conference on transfer learning, it's a conference on interpretation, and I've covered that bit. But I wanted to briefly mention a second area that we're working on that we think is going to be really important for to go hand in hand with interpretation, which is methods that allow for models that generalize. Models that generalize well across related but distinct contexts of learning. So, just to read, starting from the second bullet point here, few-shot learning is a particular type of transfer learning. And just, you know, I suspect much of the audience is familiar, but if not, transfer learning is a field that postulates that prior knowledge acquired in one domain can be reused and applied to solve a different but related. Applied to solve a different but related domain. Linguistics certainly has provided the prime example of transfer learning where if you already know, say, a Latin language like French, you're much better off at learning another Latin language like Italian or Spanish than if you don't know a Latin language, if you've learned English and German or Chinese. And of course, the opposite is true. Is true staying within those language families. So that's sort of the idea. And the core idea, really, if you look for the core mechanism for achieving this idea, I should say, is rather than optimize for maximum. So the loss function of the model usually is simply optimizing for maximum accuracy during training in a single data set. Here, what you do is you optimize for maximum transferability between contexts. Between contexts, from one context to another, using that loss function. And again, there's no time here, but I'm just going to show you a couple of results that'll hopefully, if you're interested, motivate you to read the paper here by Ma et al. came out about a year and a few months ago in Nature Cancer. This just shows it's the same problem, prediction of drug response. And now we're averaging over many of the drugs, you know, as I showed, we have about a thousand drugs. You know, as I showed, we have about a thousand drugs, and we're averaging over many of them here in this plot. But it just shows what happens. This is, and this is now, there's no interpretable modeling here. This is TCRP, it's a neural network trained using this transfer learning technique versus a conventional loss function in comparison to these other TCRPSR approaches, in comparison to these four straw man approaches. So you can see, and here the And here, the toy problem is going to be to take what you've learned about drug response across different tissue types, but now I'm going to present you with the tissue you've never seen. So maybe you've done your learning in tumor cells drawn from breast, lung, and liver cancer. And now I'm going to give you tumor cells from brain cancer. How well do your predictions do? How well do your predictions do in that challenge context? Well, it turns out none of these models do very well out of the box. So, correlation-that's the performance metric on the y-axis here. Pre-training is how well models do when they first are exposed to the new context, like brain cancer. But now, look at what happens with the few-shot learning approach. Each additional sample, you so now. Sample use so now you give each of these models some number of samples from the new context, but just a few. So, here, for instance, we're giving them one, the first sample of brain cancer, two, two samples of brain cancer, and so on up to looking at 10 samples from that new domain. And you can see what happens with the transfer learning approach is it rapidly learns to get better at predicting in that domain, whereas Whereas non-transfer learning approaches get slowly better because what they're doing is they're just putting that first, second, and third new samples into the pool and they're retraining. And so, of course, slowly that training data set will begin to absorb and help the new context and help generalize, but it takes a long time. So, that we thought was a pretty interesting result. And so we've continued along these lines to show, to look not just how well transfer learning can help transfer to a new tissue type, but how well it can help you transfer to patients, shown over here on the left, and mouse models or patient. They're actually, it's what's what called, this is what the lingo of the field calls patient derived xenographs or PDSs. But rather, I'm out of time, so please just do look at. So, please just do look at the paper for that. But I do think transfer learning fits in well with the way clinic can operate. So the idea would be that you would initially pre-train these models using the wealth of data one can generate in high-throughput screening in cell lines. These kinds of screens go on all the time in academia and the pharmaceutical industry. You'd have these pre-trained cell lines that now you would begin to. That now you would begin to tailor to certain contexts. You can do it first in mice and these PDX models, and then ultimately you were ready to look at patient outcomes as the final step where you have the fewest data available. So with that, I will summarize. What I've shown you and spent the bulk of my time on today is the idea of performing a convolution. Of performing a convolution-like operation. But instead of the convolution being simply dictated by the two-dimensional array of pixels in an image, that structural information is provided by the structure of cancer cell biology or the domain you're interested in here. It's cancer cell biology. The methods for doing that from my lab so far are the D-cell and drug cell methods. I would also, in passing or in ending here, call your attention. Passing or an ending here, call your attention to this nice paper by Ellie Van Allen at Harvard MGH and the Broad Institute called PNET. And this is based on the D-cell model, but extended in some very nice ways to make predictions about prostate cancer metastasis in patients. I've also shown some indications for not only how interpretation helps build trust in these models because it makes sense to humans, but how those interpretations But how those interpretations can be used to design second chemotherapeutic compounds that synergize with the first. And then finally, I've shown how we think at least transfer learning is going to go really well with interpretation in helping ensure that you not only have an interpretable model for the clinic, but also that it can maximally use the data, the wealth of data in cell lines without overfitting. Without overfit, okay. Thank you very much for your attention. So questions from the audience here and virtual. So you can also raise your hand virtually and make questions. So go ahead. Yes, please, Thomas. Thank you for your talk. My question is about the network in your first project. Network in your first project. How do you incorporate the drug information in your network architecture? Yes, great, great question. And I glossed over it completely. So I drew the parallel between the two papers, but that's, of course, the difference. And so we had a embedding, we embedded a drug compounds using what's called a smile string. And there's And there's several methods that are emerging for how you can embed drugs in some space, low-dimensional space. One is the easiest really is smile strings. There's also graph embeddings of the actual structure of the drug that are coming along. For our purposes, we just needed some way to embed the drug into a bank of neurons, and then those neurons could be put together with the. With the neurons that represent that embed the genotype. So you sort of have two branches of the model. I have since become less enamored by that approach, and I'm happy to talk about that later. But that's how we did it. Thanks. Thanks for the talk. In the first project, so when you work with ontologies and you fit them to the model, so Feed them to the model. So you manually presume the ontologies, or the model learns that third time paths are not useful because you use the full ontologies. Sorry, sorry, I didn't get the question. Can you ask? You can just try again. Yes. In the first project, when you use the ontologies, do you fit them to the model? Do you manually pre-own the ontologies because they are too big or the model, you choose the full ontology? The model to use the full ontologies and the model decides that so you mean in with respect to like the gene ontology, the go, did we use the whole go or did we filter it in some way? Or in the data-driven part, do we use all components we find of cell biology or do we filter it in some way? And the answer in both cases is we filter it in some way. Although the ontology is still quite large that we used in. That we used in both cases. So, this is a longer conversation, but the problem with the gene ontology is it has been constructed by humans, you know, from, you know, it's a human literature curated ontology. And their goals are different from the goals. They're not exactly in conflict, but they. They're not exactly in conflict, but they certainly have not had any thought in mind or effort to optimize this ontology for a machine learning system, right? And so, what happens is you get these crazy, I'll just simply call them uninformative paths, where if I have, you know, a, let's say I have a component of 100 genes, they will do crazy things like factor that component into two parts. One has 99 genes and one has one gene. Genes and one has one gene. And I'm going to factor it again: 98 genes and one gene. And maybe there's some significance for why that gene should be pulled apart. But more often than not, putting on our biology knowledge hats, we can't figure it out. And so one kind of general purpose filter, and there's others that we could talk about that we use, and it's a very ad hoc thing, is we compute essentially an entropy-like measure. Essentially, an entropy-like measure for every split in this hierarchical ontology. And so, a high or conversely, how much information content is in every split? And a split that has a lot of information content would, of course, take a 100 gene bag. And if I split that into 250 gene bags or 425 gene bags, that's a high information split. Kind of like playing 20 questions. You wanted to ask questions that equal. To ask questions that equally divide your answer, the space of all possible answers, not leave them all together. And so, anyway, maybe feel free to contact me offline. But I think that's a general takeaway. Okay, thank you. I have a question related to also the visible neural network, especially the application to the drug sensitivity prediction. I was curious to ask: the drugs that this The drugs that display the lowest accuracies, like the ones that you predict worst, basically. Like, do you think that this is because maybe there is a lack of information about those traps? Could it be? A lack of information in terms of the structure of the model, that's one way. Exactly. Right. Yeah, absolutely. So the answer is I don't know, and I think it's a good question. Let's think of some other reasons why. Another reason why. Reasons why. Another reason why is simply that there's a lack of information from the actual experiments. So, in other words, cells don't differentially respond. So, you know, if I poison every cell in the same way, let's say my drug is to heat cells up is to boil my cells alive, right? Every cell is going to have no growth, and there's no information that the model can hope to catch. There's no information that the model can hope to capture. So I think that, you know, generally poisonous drugs across cell lines that don't have, there's no particular configuration of input features that can save the cell, if you like, is another reason. And those we've tried to filter out, but there's reasons why we may not have filtered that out. It's difficult to filter that out completely. But that would be another reason is there's simply the biology. There's simply the biology doesn't actually have any kind of differential response. I see. And then I have another question. This is about the cancer product interaction that you reconstruct using mass spectrometry and imaging. And I'm just wondering, like, if there is an actual gain of it, like, how different are those protein-productions that you reconstruct using both information compared to the ones that you reconstruct using individual? Using individual data. You know what I mean? Yeah, so we're writing a paper on that right now. And it is, I would say, weekly. So in terms of how different. So let me, so the easy thing to show is that it's very useful to do in terms of knowledge of cell biology. So if you put the machine learning aside for a second and just look at the map and ask how different is it? Map and ask how different is it from the literature curated map? The answer is quite different. To me, you first want to make sure it's similar in that you capture well-known systems in both maps, and you do. But then you start to get structures that are unexpected. And there's two ways the structure can be unexpected. One is it's entirely a novel component of cells that has never before been discovered. Cells that have never before been discovered. And we think there's some of that. But another way in which you get an unexpected structure is to recombine known proteins in ways that were slightly unexpected. So maybe the people thought about the system in one way, but the actual data disagree, right? So it's not, no one's hugely surprised that this collection of proteins, say, is involved in the process of apoptosis, but it's exactly how. Okay, but it's exactly how that organization comes down in the ontology that can differ a bit with the data-driven model. And the hope is that that difference is going to is because it's been collected from the exact same cell population in which you're going to make the functional mutation drug response measurements, it's going to be more consistent between the structural and functional data than some literature-curated ontology, which has been curated. Anthology, which has been curated over 30, well, I guess going on 20 years now, by teams of people without a cancer focus. I mean, it's general. This is supposed to be a general ontology of knowledge about biology. So it's that context, I think, that is important, not just for the functional prediction, but the structural prediction. Now, all of that should translate to better learning when you move. Better learning when you move to the deep learning. And we have a paper we're writing right now, and in our hands, thus far, it does, it's not a super strong result, it's there. And anyway, I'm happy to talk about it. Hi, so great talk. Thank you very much, Folly. So, coming back to the question you have.