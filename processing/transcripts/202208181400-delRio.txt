Introduce Rafael de Rio from UNAM. He will talk about singular random perturbations. Please. Okay. Well, good evening, good afternoon. First, I want to thank Monica Winkel-Maya for the kind invitation to give this talk. Invitation to give this talk. Can you all hear me well? Yes, yes. I cannot see you, but I hope you can. Yeah, yeah. Yeah. Yes, do you hear? Do you hear us? Yeah, I hear you. Okay. I don't see you, but I hear you. Okay, please continue. Okay. If there is any problem with the voice. If there is any problem with the voice or whatever, please let me know. Yes, yes. Okay. Well, I have been working for some time in round one perturbations. So the main thing is to have some properties of a self-adjoint operator. And to ask what properties or which properties will be preserved if I introduce some kind of perturbation to this operator. And the simplest perturbation in some way is the rank one perturbations, perturbations which the range has dimension one, so rank one. Okay. Did you hear me well? Yeah, yeah, okay, perfect. Okay, I would like to see you in some way. I don't know how can I see you, but well. How can this be done? Well. Nice to see us. That's fair. Wants to see us. That's fair. We want to see us. Well, actually, we can't see you because your camera is off. My camera is on. We can see you. So maybe you can try log out and log in, but you can. Okay, well, I'll continue. I'll continue. Yes, you can see us. I think your Zoom is broken. Is broken or something because actually the camera is on, but okay, but you can see the slides. Yes, perfectly. Okay, very, very good. So I continue with this. Yeah. So I'm going to talk about rank one perturbations, but singular ones. So by that, what I mean is the following. So we have a Gilbert space, and we have an operator which may or may not be bounded. Normally we'll have this domain. And we consider a linear functional which is defined in the domain of the operator. It's going to be a linear a linear a linear function and we consider or I consider the restriction of the operator A to the kernel of the functional. So this number one equation, it says that the domain of a dot is Is the restriction of the functions which are in the domain of A and are in the kernel of phi. The kernel, of course, is a set of points or set of functions in this case, set of vectors for which the function alpha vanishes. So phi of psi. vanishes. So phi of psi is equals zero. So I'm going to consider this restriction of eight dot because random perturbations which are formally defined as it is written there is A sub alpha. It's going to be A plus alpha. Then I have phi I have five scholar product and five. These five scalar products is just the application. Okay, I can write that straight. This thing is just phi of something. It's an notation. It's not really scalar product. It's just the way to denote. We are applying phi to. applying phi to something which which which is going to enter in this in this place so if i consider my operator a and i make and we make this kind of perturbation it is somehow easy to see that if we are in the kernel In the kernel of the functional phi, all operators a alpha are going to coincide, are going to be the same operator, because in the kernel of phi, this is going to vanish. Is that clear? Yes. So in some way, all operators A alpha Alpha are extensions of A plot, which I do is a restriction of A. All operators A alpha extensions of A, not of A, of A restrict. A of A restricted to the kernel of phi because this perturbation doesn't cease points in the kernel of i. And what we want is self-adjoint operator, so we're going to define these A albas as self-adjoint extensions of the symmetric operator A dot. A dot. So, this is a way to introduce singular perturbations. It is not the only way. You can introduce it using four methods and using the scale of subspaces. And there are several ways to do it. But the easiest way that I found for me at least, the easiest way to understand this round singular round one perturbations. Singular round one perturbations were to understand the perturbations as self-adjoint extensions of a symmetric operator because we have a well-established theory of self-adjoint extensions. The so-called Fon Neumann theory of extensions. Well, there are other theories like the theory of tripletis. I don't know how to say that in English, tripletes. But how do you say tripletes in English? Triplet. Triples. It's a very useful theory, triplets due to cobayashi, I guess. Kachube. Kachube. Thank you, Liz. With von Neumann, this develop another theory. And since we have a way to construct separation extensions from a symmetric operator, this gives us a way to construct singular random perturbations of separate operators. So I'm going to talk a little bit about how How this way of constructing self-adjoint extensions is done. And then I'll talk about some properties, spherical properties that are preserved when we introduce these kind of perturbations. Am I explaining myself? Yes, yes, yes, yes. Everything is okay. Yes. Everything is okay now? Okay. Okay. Well, very good. First, I want to discuss this lemma one, which to me was kind of a surprise. I mean, when one studies hilbert spaces, Hilbert spaces, one comes across the Ries representation theorem that says that every continuous functional in my Hybrid space is a scalar product. So if we have a, I'm going to write where I'm going to, well, let me do something. Do something we have if we have a functional phi which is in the dual space of H, that means phi linear e continuous. Then we know by the Then we know by the Rhys theorem, Frederic Ries' theorem that phi of X can be written as some Y phi. Okay, there's a very important theorem which characterizes all continuous. Continuous linear functionals defined by the Hilbert space H. But I have not found a book which states this kind of theorem, this characterization, the characterization of lemma one. Lemma one says that the functional which is Which is in fact defined in D, where D is a dense set, D could be the whole space. But the lemma says that if phi is discontinuous, then the kernel of phi, that is the points, the vectors where the functional phi vanishes, is dense. In fact, In fact, the assertion is if and only if a functional is continuous, if and only if the kernel is dense. One direction is very easy to see. This direction is very easy to see because the kernel of phi, if phi is continuous, the kernel of phi is the orthogonal. Is the orthogonal space to the vector to the vector y so phi and this is a closed space and since it is closed it cannot be the whole space because otherwise the kernel would be the whole space so kernel That's a way to see it. Do you agree? Okay. That's one way to see it. Other way to see it is there are several ways. I mean, another way is to observe that in a Hilbert space, two orthogonal vectors are always at the distance. Always at the distance square of two, I mean, you're using that x minus y is of course if the Hilbert space, I mean if The Hilbert space, I mean, if I develop the square of this, then we have x times x, y times y, and then the terms a x, y, which vanishes, and then I get two, and then whenever I take the square root, I get this. So, two vectors which are orthogonal in a space are. Are always far away. So I can take a ball, a small ball around and don't get any vector in the orthogonal space of y. So the kernel is not dense. That's another way to see it, but maybe the basis ways to see that the kernel is close and cannot be dense because otherwise it would be. And cannot be dance because otherwise it will be the whole space, then the functional would be the functional zero. Okay. Okay? Yes, okay. Only Luis is going to say only Luis is following. Okay, very good. Well, I'm going to to go. Going to go through this proof because it's very simple. And it will show that a functionality is continuous if and only if the kernel of the functionality is dense. Okay, then the proof is using. Is using is using nothing. It says, since phi is continuous, there is a sequence. Well, that's one of the main points. Since phi is continuous, there is a sequence in the domain in D where the functional is defined such that the norm of xn is one and phi applied to. Phi applied to Xn the absolute value of the model. Well this absolute value goes to infinity as n goes to infinity. This is just this comes almost immediately from the definition of discontinuity because Discontinuity because a linear function is continuous if and only if it's bounded. I think it's clear for everyone. Well, I don't know. Is there any question here? No, it seems to be all fine. It's almost direct from the definition of. I mean, if we have a bounded function which is linear, is called. Function which is linear is continuous, and if it's continuous, it's bounded. Okay, okay, then this sequence is going to be important in the proof. Okay, take Y in D and just add and subtract this term phi of y divided by phi of xn times x x n. Looks the same. So subtract phiy phi x when x when and add the same thing. The trick here is that the first summando, so sumand, the first term in the sum is in the kernel of phi. That's very easy to see because if we apply phi, we have we apply phi we have phi of y minus phi of y times phi of xn divided by phi of xn which cancel so these things in the kernel of phi okay everyone has agreed since i don't see the face and i don't see i don't see you i don't know who is following or who is not following yes okay yes okay okay you you you you let me know always please yeah yeah okay then since that is in the kernel then we go to the line where we multiply x with y we take the scalar product of x with y since this first term of the sum is in the kernel of i Of phi, and we are assuming that x is in the orthogonal of the kernel of phi, then x times y is just x times the second term in the sum because we are taking x in the orthogonal to the kernel of phi. Of i and then we use Cauchy Schwartz inequality and get that x times phi y divided by phi x when x x x n is less or equal than the norm of x times the absolute value of phi y divided by phi x n times the norm of x n, which is one. Norm of x n, which is one. But this goes to zero as n goes to infinity because this goes to infinity. It's right, yeah? Yes, then we have that y, which was an arbitrary point in D. Is in the orthogonal to the orthogonal of the kernel because x was in the orthogonal to the kernel and y is orthogonal to x, which is an arbitrary point in the orthogonal to the kernel. So, y, which is an arbitrary term in D, is in the kernel perpendicular, perpendicular. Perpendicular, perpendicular in the double perpendicular to the kernel of I and this double double perpendicular thing is equal to the closure of the of the space because kernel of i is a subspace and if we take twice the perpendicular space we get the closure Okay, do you agree, or there is any problem? No question. Everything is very clear, yeah? Yes. Okay, since D is dense, the closure of D is equal to my Hebrew space, but the closure of D is The closure of D is contained in the closure of the kernel of I. So we have that the closure of the kernel of I equals the hero space H. So the kernel is dense. And the proof is over. So we have a characterization of discontinuous linear functionals. Okay, well, there is no questions. I really like this lemma because I was not expecting this characterization of density of the kernel. The density of the kernel of a functional is equivalent to the discontinuity of the functional. Of course, we're talking about linear. Of course, we're talking about linear functionals. Okay. Okay. Okay. Now we need this lemma. This lemma has a little bit longer proof, but it's also a key lemma. So, assume phi is at least continuous functional. Phi is defined in the domain of A. A is as above, is a self-agent operator, and A dot is the restriction of A to the kernel of the functional file. If I'm saying that phi is continuous, of course, this will respect to the norm, to the metric generated by the norm of the Hill space H. Okay, now we are going to consider another functional which I call L. L will be a functional from H to C, which is defined as the composition of phi. composition of phi with a plus i to the minus one psi so l of psi is phi to the apply to the vector a plus i to the minus one psi since a is self-adjoint since a a the operator a is self-adjoint the point the complex point i The complex point i is in the resolvent set of a and the operator a plus i to the minus one is defined in the whole hero space and takes the whole hero space to the domain of a so the function an L is defined in the whole Hilbert space H just because Just because A is self-adjoint, and then the point, the imaginary point I is in the resolving set of my operator. And the dilemma says that if this function L is continuous, then the operator A dot, which is the restriction of A to the kernel, To the kernel. These are densely defined symmetric operators with effect indices of deficiency indices 1, 1. Remember that we need the deficiency indices to apply the Fournoiman theory of Servagon extensions. So here is the continuity of a functional, the continuity of the functional L, which implies the density of the symmetric operator. Operator and implies that the indexes, the defect indices of the deficiency indexes are the same and are equal to one. Is the statement of the lemma clear? Yes. Okay, perfect. Okay. The proofs are taking a little bit longer. Would I want to sketch the proof? Okay, I'm going to explain a little bit how it is proven. And the keys in this line, I mean, if gamma is in the candidate of L, if L of gamma is zero. Of gamma is zero, then a plus i to the minus one gamma is in the Kerala of Phi. Why? Because of the definition of L. If phi or gamma is in the kernel of L, this A plus I to the minus one phi is in the kernel of phi. So, this should be clear. Now, this kernel of phi, since phi is defined for vectors in the domain of A, is exactly the domain of A dot, which is the restriction of A to the kernel of phi. And that means that gamma is in the range of A dot plus one. Why? Why because this operator is sending a vector gamma to a point in the domain of A. So the So if I since A plus I minus one to gamma IC is in the domain of A, if I apply A dot plus I to this vector, I obtain gamma. So gamma is in the range of A dot plus I. In the range of A dot plus I. Do I explain myself? Is that more or less clear? Yes, I think yes. Yes. It's just because this thing is in the domain of A. If I apply A plus I to this vector, I obtain something, I obtain gamma. That means gamma is in the range of that vector. So, what we have is that the kernel of L is equal to the range. That's the first step in the proof. Here, the observation is made that DZ is closed by the continuity of L. Remember that any linear operator which is continuous has a closed kernel. And the kernel is different from L. The kernel is different from L because if the kernel of all I mean the kernel of L is different from H because if the kernel were all H this would be equal to H. equal to H and here I mentioned the basic criterion of self-adjointness. This basic criterion, which is a particular case of the von Reumann theory of self-adjoint extensions, says that we have a symmetric operator such that the range of a dot plus i equals h and the range of a dot minus Dot minus y equals h, then the break reserve adjoints. So, analogous to what we do here this here, we can do it with minus i. And we would have the range of a dot plus minus i equals h. And we would have that a dot is self-adjoint. And therefore, since a is a self-adjoint extension of Since A is a self-adjoint extension of A dot, because A is self-adjoint and A dot is a restriction of A, we would have that A dot is equal to A. But that would mean that the kernel of phi should be the domain of A, because remember that the domain of A dot is a kernel of I. Phi and therefore, phi would be a continuous operator. In fact, it would be the zero operator, would take any vector of the domain of A to the zero, which is a context of the positive because we are assuming that phi is discontinuous. So we are applying the basic criterion of seba jointness. Criterion of seba joins to the operator a dot plus i plus here I should apply also to minus i okay okay okay okay then we have that the kernel is equal We have that the kernel is equal to the range of a dot is one, and that the kernel is not all h. Okay, now we're going to apply Rule's lemma. Since L is continuous and linear, that's what it's our hypothesis that L is continuous, we apply the Rislema that we mentioned at the beginning. Apply the Rislem as we mentioned at the beginning. And there exists a vector H, such as the functional L equals H, dot. That's the representation theorem for linear functionals, continuous linear functional of Frederick Ries. Okay. Okay. Then the range of A dot plus I is close. Why is it close? Because equals the kernel of L and the kernel of L is closed because L is continuous. Continuous. Okay, since it is close, it is equal to this kernel. In fact, there is a very important theorem, very elementary, but also very basic, important theorem, which I'm going to show, try to show. Let me see. Um no well I want to show you is this theorem, which is very basic. The proof is just the definition, is just just the Just the definition is just the definition of the joint. Buddhist says that the kernel here n denotes the kernel. The kernel of the operator theta joint minus the conjugate of set times the identity i equals the orthogonal to the range of t minus set i. Or in another formulation, if we take orthogonals to If we take orthogonals to both sides of this equality, we have that the orthogonal to the kernel of the adjoint minus the conjugate of z times i is equal to the double orthogonal of the range. And the double orthogonal is the closure of the range. So the closure of the range of operator P minus Z equals the kernel of the operator T at. Equals the kernel of the greater t adjoint minus z conjugate. Okay, this is a this is identity which is used in many places. And that's why I didn't want to show it. Okay, let's okay, okay. So the range of A dot, which is a symmetric operator plus I, is close and therefore it equals following the theorem. Following the theorem that I just mentioned, equal the kernel of A dot adjoint minus I orthogonal. Okay. Then we have the kernel of L, which is which are the vectors which are orthogonal to H equals the kernel of A dot adjoint minus I orthogonal. So, what do we have that eight that gamma is orthogonal gamma is orthogonal to H and the double orthogonal what am I saying? What am I saying? The gammas, he hears this line the gammas which are orthogonal to H which are orthogonal to here I have double orthogonal gamma is orthogonal to H because Because gamma is such that h times gamma is zero. Here we have it. But I'm taking the orthogonal. The orthogonal to the orthogonal here, here, since it is closed, here I don't have orthogonal anymore. And the orthogonal to the orthogonal of H is exactly the multiples of H. The multiples of H. Maybe that's not so clear, but I don't know how clear is that, but that means that the kernel of A dot at joint minus one has dimension one. This kernel is a defect space, and the dimension of the defect space is the defect index. And since I And since A dot has L Bayon extensions, the defect indices are equal according to the normal theory. And therefore, the dimension of the kernel of A dot adjoint plus equals one. Well, please tell me something. It's all okay. It's all okay? Yeah. Okay. Okay, yeah. Okay. Well, we have the two main lemmas. Okay, we have the two main tools that we need to develop the theory of round one single perturbation. So I'm going to give an example. How much time do I have left? I think 15 minutes. 15 minutes, okay. Okay. I'm going to consider operators generated by, for example, this differential expression. The maximum operator t corresponding to tau is defined through this differential expression tau and this is the maximal domain f. In L2, which shows that F and the derivatives are absolutely continuous in the interval, and such that tau of F is in L2. And with the help of this maximal operator, we construct self-adjoint restrictions. The way to construct The way to construct self-running decisions is imposing some kind of boundary conditions according to the vial alternative. Here I define the Lagrange bracket, which is this thing. And well, the way to define the operators here, I just wrote the vile alternative, which says. The bile alternative, which says that we have either limit circle case, which is when all solutions are all solutions of tau minus z are in L2, the limit point case, which is the case where at least one solution is not in L2, but in the limit point case, there is always one solution in L2. And if we have this alternative, we can construct these operators H, which are separate. operators H, which are Seban John operators. This operator H of F is defined as tau of F, and the domain is F in the maximal domain, in the domain of DT, but we may need to introduce these conditions here. Just if we have the limit circle case. If we have the limit point case, there is no condition needed. Here it is. There is no condition. So, I'm going to try to apply the lemmas that we use so to this kind of operators. Okay, it's okay. Yes, yes, it's okay. Okay. Okay. Well, let's define the Green's function. Well, let's define the Green's function. This W is the Brownscan. W is the Brown scan, which is constant for solutions. U sub B and U sub A are solutions of this equation here. Solutions equations such as satisfy the conditions at A and at B. At me. And it happens that the inverse of h minus z is exactly this integral operator. This is the integral from 0 to a, from excuse me, from a to b of g x y z g. So we have a very clean way to write the inverse of the paradox. To age, we can construct the green function using solutions with the boundary conditions at A and B. Okay. I won, okay? It's okay. Yeah, yeah, it's okay. I don't know how long you need to read it, but Okay, okay, then we are going to take a particular functional, which is called the delta functional. Our phi above is going to be the phi which is defined in the domain of h. Remember that the domain of h are functions which are continuous. In fact, the derivative is also continuous. The derivative is also continuous or as well continuous. So it makes sense to apply phi to f we have the evaluation of phi to f is just f evaluated at some point. And it happens the following. It happens the function alpha is not continuous. That's what we need. That's what we need, and the functional L, which is this one, is continuous. The proof is very elementary. Maybe just I give the idea the proof. Take, for example, a sequence of functions, which are one here, and this goes narrow and narrow. Narrow or narrow. So in this case, you have this sequence of functions, F of X and zero. This will be always one. Suppose that here is X and zero. And this cannot be the norm of F n. norm of fn since this the base of these triangles is going to zero the area below the triangle the triangle is always smaller and smaller so this makes that the norm in l2 goes to zero so we cannot have this functional bounded because this is equal to one always but this goes to zero so this functional To zero, so this function is not boundless. That's what is written here. In geometrically, is more or less that. Okay. Okay. So I'm going to skip this. And the continuity of the functional L L can be easily seen here. L of f L of f equals this by definition. With this, using the Green's function is this thing here, and using the Cauchy Schwarz inequality, we have this. So L is continuous. So we have what we need, we have this continuous functional phi and a continuous functional. And a continuous functional L. So we get that the restriction of the operator H to the domain, which is a kernel of I give us a symmetric operator. Operator with effective instances 1, 1. Remember, this operator has defectiveness 1, 1 and is essentially defined if phi is discontinuous and dL is continuous. In fact, the self-adjoint extensions of which I denote by t sub theta of the symmetric operator H dot are given by this thing. Are you in by this thing? This von Neumann domain is G's J G, which are in the domain of H dot plus C C plus plus C e to the i theta psi minus minus. When we apply tau to theta, we obtain these equations where these are vectors. These are vectors which are in the kernel of h dot adjoint minus plus i, which is the defect space. It's okay. Let me go back a little bit. Is there any questions? Maybe I didn't emphasize. I mean, I just mentioned this lemma one and lemma two, but Okay. Remember this lemma too, which says that if phi is discontinuous and L is continuous, where L is phi applied to A plus Ai to the minus one, then A is densely defined symmetric operator with affecting this one. That's what this lemma is what we apply. It's a particular case where we have operators generated by differential expressions with the delta gene, okay. Is everything right now? Or there are some questions or some remarks? No questions. No questions. Very good. Well, something that really called my attention a lot was the following thing. These functions psi plus minus. Plus, minus these functions, which are in the defects of spaces, can be chosen to be the Green's function. That was to me a big surprise. This is lemma four. Because these functions appear magically in the theory of Neumann says, well, okay, the effective spaces have dimension one. Spaces have dimension one, so there is a function psi plus or psi minus minus which generates that space, but it's a very obscure obscure function. It's not explicit, but in this case, this obscure function which appears in the fundamental theory has a face and a very pretty face. Pretty face is just the green function, and I think this is not a coincidence, this should have some deep reasons. I mean, two objects, which are important, are the same, and the proof is very easy. You just take the phi applied to h plus i to the minus one j is just this thing here because we're using the green's function and the phi just evaluates the green function in the point remember that the phi in this case is a delta function then we take the conjugate twice conjugate of the green's function and conjugate here conjugate i minus i to obtain this To obtain this, so phi applied to h plus i to the minus one j is equal to the scalar product of the Green's function evaluated at x sub n zero times our scalar product with g. Now for g which is in the domain of h dot we have that this is zero. This is zero. This applied to this because of this equality is exactly phi applied to this. Here instead of j where we're taking h dot plus i applied to j. But this is just phi of j because here we have h plus i to the minus one. H plus i to the minus one, we have h dot plus i and phi of j is zero because j is in the domain of h dot and the domain of h dot is a kernel of phi. So the Green's function is orthogonal to the range of h dot plus i, which is but by what we mentioned above. By what we mentioned above, exactly the kernel of H dot adjoint minus one, and the same happens with the other. So this I have not seen written in any in any place. And since it's, I consider, I consider it an important formula, I think many people Many people knew it, but somehow I haven't found it written in some good book or even in a paper. Well, to finish, just let me say two things. If F is in the domain of one of the self-adjoint extensions of the operator, Of the operator H dot, which are denoted by tes of theta, and that the F's in the domain of this operator have this jump, the relative jumps, and this alpha has to do with this theta. In fact, there is a one-to-one correspondence. I have the proof here, but I don't have time to give the proof, it's very easy. To give the proof is very easy. I don't have to go in the proof. And I want to mention another fact that it also requires a proof. This theorem 2. It reads, assume E is an eigenvalue of one of the self-adjoint extensions, which I denote by T sub beta, where beta is a point, a fixed point in the interval zero pi. Then we have the alternative, the following alternative. So one of the following. Alternative. So, one of the following options happens. Either E is an eigenvalue of T sub theta for all thetas, or E is not an eigenvalue of T sub theta for theta different from beta. So the eigenvalue is only survives for T sub beta. But if we move beta, the eigenvalue disappears. So So if we put this in random perturbation language, it says that singular random perturbations either preserve the eigenvalue for every perturbation, for every single perturbation, or for any similar perturbation, the eigenvalue is going to disappear. Well, I guess my time is over. Yeah. Okay. Thank you very much for your attention. I'm going to stop sharing. Yeah. Are there any questions? Sibriana Angel, Serio Morayanu, Emily Drigen. Well, at least I can see your. Well, at least I can see your names. I hope some things that I mentioned here could be useful for you because it's a quite elementary talk. I'm not telling anything very complicated, but there are basic facts that were not well known to me. For example, the density of the kernel of a linear functional is equivalent to the discontinuity of the functional. Discontinuity of the functionality. Also, the functions appearing in the form member extension theory are exactly the Green's functions. So that's why I choose to talk about these things because they're quite elementary, but to me, at least with some surprises. If there is any comments or questions, I will be glad to address them. No, it seems to be. No, it seems to be that there are no more questions. So, well, let us thank again the speaker.