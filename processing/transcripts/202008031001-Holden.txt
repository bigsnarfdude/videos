By Thomas Hatchcroft. So, the course this week and next week will both be Monday, Tuesday, and Thursday for about one hour each. As a reminder, these lectures are being recorded and live streamed on YouTube and Bears. So, if you do not wish to appear online, then please turn off your camera and keep your microphone muted. During the talks, we will. During the talks, we will actually have everyone's microphones muted, but we do encourage discussions and questions. So, if you have any questions during the talk, please ask them on the chat. The talk will be roughly one hour long, and there will be some additional time for discussion afterwards. There will be a short break in the middle also for discussions. So, we have with us also Matthias Lemkuller, who will also be helping answer questions on the chat. Be helping answer questions on the chat as they rise. So that's if you have any questions, please do ask. After the talk, there will also be a breakout room. And if any of you wish to have any informal discussions, you can also join the breakout room afterwards. Finally, there is also a Zulip forum. So if you have any questions outside of the Zoom meeting times, you can also join the Zulip forum and ask there, and someone will certainly answer. Will certainly answer. So, with that, we'll pass the camera to Nina, who will give this week's course. So, if you could share your slides. So, the slides, by the way, are also available on the website if you wish to download them and follow along. Thank you, Nina. Yeah, thanks, Omer. Can you see the slides now? We might make it full screen. Yeah, is it good now? Yeah. Yeah, this looks good. Okay, yeah. Okay, so first I would like to thank the organizers for arranging my nice courses this summer and also for giving me the chance to give a course. So this course will be about Schram-Lebner Revolutions or SOE. So in the first two lectures we will be studying SOEs via what is called Leubner giants. What is called learner chains, and I will give the definition of SLE and present some basic properties of SLE. So, in the third lecture, we will be studying something called imaginary geometry. So, this is giving a very useful alternative perspective on SLE. The third lecture will be rather independent from the first two, so it's possible to follow the third lecture, although you haven't followed everything in the first two lectures. Lectures. The first two lectures will be mostly based on a book by Lawler on ISOE and also on some lecture notes by Berystici and Norris, while the third lecture will be based on the imaginary geometry papers of Miller and Sheffield, in particular the first one, but also a little bit from the later ones. And as Omer mentioned, I can also repeat that Matis Lemkuller will be answering. This Lemkuller will be answering some questions that might come up during the talk. So he will be sitting in the chat and he might also interrupt me if something should be addressed in front of everyone. Okay, so SLE curves, they are curves that arise as a scaling limit of discrete models, and I will show you a few examples of this. But first, we will be looking at an even more well-known scaling limit result, which is Is which is that the simple random walk is converging to Brownian motion. So here we have a girl who's doing a simple random walk on Z2. So after she's taken one step, her path looks like this. After about 15 steps, her path looks like this. After a few thousand steps, her path may look like this. And then it's a well-known result that when we make the lattice finer and finer and we send time to infinity, then the path of this girl is converging in long. Path of this girl is converging in law to a planar Brownian motion. So, the Schram-Deubner revolution is arising as the scaling limit of other discrete models. And one example of this is what is called the looperized random walk. So, the looperized random walk is closely related to the simple random walk. So, again, this girl is doing a simple random walk on Z2. So, at some point in time, So, at some point in time, her path will make a loop, for example, like this. And every time her path is making a loop, she's erasing that loop. At this point in time, her path has made a loop again, and again, she's erasing it. And then it was proved by Lawler, Schramm and Werner that when we make the lattice finer and finer and we send time to infinity, then this looper is random walk is converging to a Schrammel revolution. A Schramm-Lernrevolution is always associated Ramlear evolution is always associated with some parameter kappa, and in the case of the looperized random walk, this parameter is kappa is equal to 2, which is why we call it an SLE2. So in the result I described here, we considered a simple random walk on Z2, but Lolish-Ram and Werner also proved that if we consider the looperized random walk on some other lattice on which the simple random walk is converging to Brandon motion, then this looperized random walk is still converging to assolution. Random walk is still converging to SOE true on that lattice. Okay, so SOE is also rising as the limit of a completely different model. So it's rising as the limit of critical percolation. So yeah, so here I have chosen some arbitrary simply connected domain, which happens to be this rectangle. And there are two fixed points, A and B, on the boundary of this domain. I've also considered I've also considered the triangle lattice restricted to this box and I've colored one boundary arc between A and B blue and the other one is colored in yellow. So in the setting one can draw a unique interface between blue and yellow. And it was proved by Stanislasmurnov that if we keep the size and shape of the box fixed and we make the lattice finer and finer, then this interface between blue and yellow is converging in the scale moment to merging in the scaling limit to an SLE. And this time it will be an SLE with parameter kappa equal to 6. So then a third example is the uniform spanning tree. So again we consider some arbitrary simply connected domain and we have which again is a box which happens to be a box and then I have here I have considered a spanning tree on this. Considered a spanning tree on this graph. So, a spanning tree is a subset of the edges which is spanning all the vertices, so it covers all the vertices, and it's also connected and it contains no cycles. So there are finitely many such spanning trees, and I choose such trees as spanning tree uniformly at random. In this picture, I have chosen two marked points, A and B, at the boundary, and I require that all of That all of the edges on the arc between A and B are part of the spanning tree, but otherwise, I've still chosen the spanning tree uniformly at random. Okay, so then it's possible to draw the piano curve. So the piano curve is a curve connecting A and B, and which is tracing around the boundary of the spanning tree. So this is the same picture again. This is the same picture again, but where the lattice has been made finer. And then it was also proved by Lohlerstrom and Werner that in the scaling limit, this piano curve is converging to an SLE. And this is an SLE with parameter kappa equal to 8. And they prove this by using a close relationship between the loop raised random walk and the uniform spanning tree. Okay, so we're not going to. Okay, so in order to introduce strum learning revolutions, we will need quite a bit of complex analysis. And I start by recalling what a conformal map is. So a map, so we have a map F, which is defined on some open domain D in the complex plane, and which takes values in a domain D tilde, also in the complex plane. So this map is conformal if F is bijective and if the derivative of F exists. Of f exists. So, in the literature, there is actually also another slightly different definition of conformal map. So, sometimes one will see a definition where f is not required to be bijective, but where one instead requires that the derivative of f is non-zero everywhere, and that alternative definition is weaker than the one we are considering here. So, it's possible to show that if f is conformal, then it satisfies the Cauchy-Riemann equations. So, identifying the complex So identifying the complex plane with R2, we can view f as a function from a subset of R2 to a subset of R2. And by using that the derivative of f exists, it's possible to show that the coordinates functions satisfy the relationships shown in the lemma. So Schram-Goebner evolutions are what we call conformally environmental. We call conformally invariant, and I will explain later what that is, but first I will explain what it means in the setting of planar-Brandian motion. So we let W be a plane Armbrainian motion started from the origin. Then we assume that D is some domain in a complex plane containing the origin. And we let tau sub D be the time that this branch motion is first exiting D. First, exiting D. Then we let F be some conformal map from D to some other domain D tilde, which is fixing the origin. Then we let W tilde be the image of W under this map, where we run W only until time tau sub D. And then in this setting, conformal invariance means that W tilde has the law of a Klein-Arbrainian motion until it first leaves D tilde. Detail down. So, in this result, we are viewing curves, modulo time reparametrization, which means that if we have two different curves and we can get one from the other by reparametrizing the curve, then we view the two curves as the same curve. So, this theorem is saying that this path W tilde, there is a way to reparametrize it such that it has the law of a Brownian motion. Motion. So it is necessary to state this result: modulo reparameterization of time, because we can formal map locally it looks like a composition of a translation, rotation, and a scaling. But this scaling will be different in different parts of the domain. So in parts of the domain where we do a very big rescaling, small sum scales on small set to a very big set, then the Brownian motion will move very fast in these regions, while it will move slower in regions where we're down. Slower in regions where we downscale the domain. Okay, so this figure illustrates the theorem. So in the left figure, we have a random walk on Z2. And in the right part of the figure, we have the image of the left part of the figure under a conformal map. So if we look at these two figures from a distance, Look at these two figures from a distance, we see that they are maybe not so different. So, if we just zoom out and we ignore the small details of the paths, then it's not so easy to see which path is a random walk on Z2 and which one is a random walk on the modified lattice. And in the scaling limit, these two paths will have the exact same law. So, both of them will be planar Brown and motions. So, in the right figure, the path will move faster in Path will move faster in regions where the lattice is big and slower in regions where the lattice is smaller. But modular time reparameterizations will be the same in the scalar moment. So the proof of this theorem, conformal invariance of Brownian motion, is just stochastic calculus. And I've left most of it as an exercise. So to prove it, you can first define the coordinates function. You can first define the coordinates functions w1 tilde and w2 tilde of w tilde. And then it's possible to show by using Ito's formula and the Cauchy-Riemann equations that these two functions, that they are local martingales. One can show that the quadratic variation of these two functions are the same. And one can also show that the quadratic covariance is equal to zero. So from these three properties, Three properties. One can use standard results in stochastic calculus to deduce that the process must be a planar Brownian motion. So one can use a characterization result, sometimes known as Levy's characterization of a Brownian motion. So from the first two bullet points, one can get that W1 tilde and W2 tilde, that each process is a time-changed Brownian motion. Brown in motion. From the second bullet point, one also gets that the time change is the same for the two processes. And from the third bullet point, one gets that these two processes are independent of each other. Yeah. So that's all I wanted to say about the planar brain in motion for now. And the next goal will be to give a definition of SLE. But before doing that, I need to do quite a bit. Doing that, I need to do quite a bit more complex analysis. So, I start by recalling the Riemann mapping theorem. So, the Riemann mapping theorem is saying that if D is some simply connected subset or simply connected domain in a complex plane, which is not equal to the full complex plane and which is not empty, then there exists a control map from D and to the unit disk. So, this control map is not unit disk. So, this control map is not unique. And roughly speaking, we can say that when we choose this control map, then we have three degrees of freedom. For example, we can choose three points, A, B and C, on the boundary of D, and then we can require that these are mapped to plus minus i and 1. So the reason we have these three degrees of freedom is that if we look at the set of conformal maps from the unit disk to itself, then this space of conformal maps can be parameterized by three real numbers. By three real numbers. Okay, so now we assume that eta is some curve in the upper half plane which starts at the origin and which ends at infinity. So for example, eta can be a simple curve such as shown in the left figure, so a curve which never visits the same point twice. It can also be a non-simple curve as in the right figure. So in the right figure you see a curve So in the right figure you see a curve which it's hitting its past multiple times, but every time it hits it past it's jumping off again without crossing the curve. So for now I will not put any more restrictions on Ada, but later the curves Ada we're interested in they will typically also satisfy some other constraints. So then we're defining a set K sub T to be the sets which are disconnected. To be the sets which are disconnected from infinity by the curve at time t. So, one way to define the set, one alternative way to define the set k sub t is to first run that curve up until time t. So, when we do this, we will get then the set age minus the curve will consist of one or more connected components, and then there will be a unique unbounded component. And we define k sub t. And we define k sub t to be age minus this unbounded component. So in the left figure, k sub t will simply be the curve run until time t. In the right figure, then k sub t will be the union of the domains that are disconnected from infinity at time t. And then it will be the union of these domains and the curve itself. Okay, and then so the set H minus K sub T, that will be a simply connected subset of the complex plane. And by the Riemann mapping theorem, it follows that there exists some conformal map from H minus K sub T and to the upper half plane. And we also require that this And we also require that this conformal map, which we call g sub t, that it sends infinity to infinity. So in the figure, I've illustrated this in the setting of a simple curve. So what you can imagine is that you have the upper half plane, you take up a scissor and then you cut the curve and then you cut along the curve. So you make a slit in the upper half plane starting at zero, then you cut along the curve until you reach the point eta of t. eta of t. So this will give you a slit domain where the curve has been removed and this slit domain is what you are mapping to the upper half line via this map G sub T. So it's possible to argue that in this setting then the tip of the curve can be is mapped to unique point on the real line. So this map G sub t that I just defined it extends continuously to the tip of the curve and is mapped to some unique The curve and is mapped to some unique point on the reline. It's also possible to show that g subt is extending in a certain sense to the curve itself and also to the real line. So if we look at the left part of the curve, then that is mapped to some interval on the real line, which is lying to the left of the image of the tip, while if we look at the right side of the curve eta, then that is mapped to some other interval on the real line, which is to the right of the image of the tip. Of the tip. So these two intervals are shown in red on the figure. Okay, so yeah, so that's the default. So that's G sub T. So we can look at the expansion of this map, G sub T around infinity. And I claim that it has an expansion on the Sean form. So I will not give a full proof of why. So I will not give a full proof of why we have such an expansion, but one way to prove it is to look at the map G tilde sub t that I have defined below. So this map G tilde sub t, so that will send the upper half plane minus some slit to the upper half plane. And since g sends infinity to infinity, then g tilde sub t will send zero to zero. So then it's possible to argue. So then it's possible to argue by something known as Schwartz reflection that this map G tilde sub t extends to some conformal map which is also defined in some neighborhood around the origin. And it's also possible to show that this extended map it maps points on the reline to points on the reline. So by using that we have such a that we have a map which is defined in the neighborhood of the origin we can consider the table origin we can consider the Taylor expansion of this map and we also see that all the coefficients in the expansion has to be real since points on the real line are mapped to points on the real line. So now we can by using the expansion that we have for g tilde around zero and by using the relationship between g tilde and g then we can get that g sub t has the shown expansion. So then we can fix g sub t by We can fix g sub t by requiring that the first coefficient in this expansion is equal to zero and the second is equal is equal to one and the second is equal to zero. So roughly speaking, this is uniquely determining the map G sub D because I said earlier that we have three degrees of freedom when we choose the map G sub T. So the formal proof that this is uniquely determining G sub T is maybe done in a slightly different way, but heuristically speaking, these three degrees Speaking, these three degrees of freedom is the reason that this uniquely determines G sub T. Okay, so the map, so the set K sub T, we call it the hull at time T and we say that G sub T, we call that function the mapping out function at time t. So one small remark is that at this slide I considered a collection At this slide, I considered a collection of sets, k sub t, indexed by time. I also considered a collection of functions, g sub t. So they're also indexed by time, but the time parameterization is not really important for anything that I've done on this slide. So we can define a compact HL to be a bounded subset of age, such that the complement is open and simply connected. And if we have an arbitrary compact HL, then it is possible to associate it with a mapping out function G in a similar manner. G in a similar manner as I did on the compact on this slide. So the fact that we had the time parameterization was not really important for the definition of the objects on this slide. Okay, so then we have, we recall from the previous slide that we have a function g sub t which is mapping the complement of k sub t. complement of k sub t to the upper half line and the expansion of this of this map around infinity is looking like z plus zero plus lower order terms so the first coefficient here that I have not fixed is the coefficient a minus 1 in front of 1 over z and it turns out that this coefficient is very important and that it gives a natural way to measure the size of the set k sub d. of the set k sub t. So I define the half-plane capacity of k sub t. I define it to be this coefficient a minus 1. So I'm claiming that this coefficient a minus 1 is a natural way to measure the size of k sub t. But in order to justify that this is a natural definition, this half-plane capacity needs to satisfy some natural properties. For example, in order for it to be a natural definition, it's necessary that if we Definition is necessary that if we increase the set K sub T, then the southbound capacity is also increasing. And such a monotonicity property is given by the next lemma. So the next lemma is giving an additivity property. So it says that the half-plane capacity at time t plus s is equal to the half-plane capacity at time t plus the half-plane capacity of the set of the remainder of the curve. Remainder of the curve, which we see after mapping out at time t. So, in the setting of the figure, we can look at the curve on the left picture. So, the lemma is saying that the half-plane capacity of this curve is equal to the half-plane capacity of this initial blue segment plus the half-plane capacity of this red dashed curve, which is shown in the middle figure. So, here the left and the middle figure. So here the left and the middle figure are related by the map G sub T, which is mapping out the initial segment K sub T. So the proof of this lemma is following from the picture. So to get from the left picture to the middle picture, then we map out with a map G sub T. Then to get from the middle pic, Then to get from the middle picture to the right picture, then we map out again by mapping out this red dashed curve. So if we look at first look at the control map G sub T, then the expansion of this map will be Z plus A minus 1 times 1 over C plus lower order terms. And by the definition of Half-Link capacity, the coefficient A minus 1 is the Half-Link capacity of K sub. Half-line capacity of k sub t. Similarly, we can look at the second time we map out. So we can also expand this map around infinity. And now we see that the coefficient b minus 1 in front of 1 over z, we see that that gives us the half-line capacity of this red dashed curve in the middle figure. Okay, so we have these two, we are mapped out twice. We can also look at the composed map. We can also look at the composed map. So we compose these two mapping out functions and then we look at the expansion of this composed map around infinity. And what we will see is that it can be written on the form z plus 0 plus plus a minus 1 plus b minus 1 times 1 over z. So what we can observe now is that this composed map is actually also on the form of a mapping out function. Out function. And it is a map which sends the complement of the original curve to the upper half-line and which has the expansion around infinity, which is characterizing a mapping out function. So this composed map is actually the mapping out function of the original curve. So by using this, we see that the half-plane capacity of the left curve is actually The left curve is actually a minus 1 plus b minus 1, because this is the coefficient of 1 over z in this mapping out function of the curve. Okay, so then another natural property that this half-bank capacity is satisfying is that it also satisfies some scaling property. So if we have some set and So if we have some set and we rescale it by R, then the half-bank capacity is scaling like R squared. So the way to prove this lemma is that we can define some function g tilde sub t to be a rescaled version of the original mapping out function. And then we can observe that this function g tilde sub t, that is the mapping out function of this rescaled set. So, you can ask, how can we see that this function g tilde sub t is the mapping out function? So, we can see this by expanding it around the origin. And then we see that it has the expansion of a mapping out function since it starts with z plus zero and then it's followed by lower order terms. We can also see that g tilde it maps the That g tilde it maps the complement of the rescaled set to the upper half plan and it maps infinity to infinity. So it satisfies all the requirements of the mapping out function of the rescaled set. So therefore it has to be the mapping out function of that set. So now if we look at this expansion of g tilde sub t around infinity, then we see that the coefficient of 1 over z and will be r squared. will be r squared times the corresponding coefficient of the original map g sub t. And this tells us that r squared times this original coefficient is the half-plane capacity of the rescale set and this gives us the lemma since this coefficient is the half-plane capacity. Okay so now I have spoken for approximately 30 minutes. Approximately 30 minutes, so then I think we can take a short two-minute break just in case someone has any questions, or if people want to look again at some previous slides. Yeah, so then I can just stop the sharing. No, you can leave the shares out. Thank you. And there is a comment for Mathis on the chat. On the church. Okay, I will put an intuition for the half-plane capacity. If there are any questions at this point, please feel free to ask on the chat. Yeah, so what yeah, so what Matis is saying is a very, yeah, that's also a very, that's an alternative way to define the half-plane capacity, which, yeah, which is also Yeah, which is also very different and it's often gives some other intuition and it's also often very useful to use in proofs, this alternative definition that Matisse is giving. Okay, so if there are any questions, ask on chat. If not, we will continue in a couple of minutes. If not, we will continue in a couple of minutes.   Should we start should we? Should I start again now or should we do a few more minutes? What do you think? Okay, I can't hear anyone now. I think everyone is. Yes, I think things are fairly clear. Okay. Yeah, okay, then I'll continue now. Okay, so yeah, so we have seen on this slide that this half-plane capacity is giving an It's giving a natural way to measure the size of some set k sub t and because it satisfies these two natural properties, additivity and scaling. And when we look at curves in the upper half-plane, then most of the time we will assume that it has been parametrized by half-plane capacity. So by that, I mean that we parameterize the curve such that the half-plane capacity of the set K sub T Of the set k sub t is given by 2 times t for any t. Okay, so here in the next slide I will introduce two very important objects. So the first object I will introduce is what I call the driving function. So yeah, so on this slide I will also assume just for simplicity that eta is a simple curve. Simple curve, but much of what I'm saying is also working for more general curves. So as you remember that when the curve is simple, then it's possible to argue that when we apply this map, G sub T, then the tip of the curve is mapped to a unique point on the real line. And we denote this point by W of T. w of t and it turns out that this that w t when we change t then it's changing then it is a continuous function okay so the second the second object I want to introduce is the Lohmer equation so the Lohmer equation is the differential equation shown on the slide so as you can see for each point Z For each point z in the upper half-line, then it tells us how the image of z under the map g sub t is changing when we vary t and here I am using when I write a dot over the letter g, then I mean that we take a time derivative. So you can see that for each z we have an ordinary differential equation which Which describes how this point Z is mapped when we vary T. And we can define tau sub Z to be the set, to be the time and to be the first time, or the infrim of times at which Z is contained in K sub T. And it turns out that this differential equation is well defined exactly until tau sub Z. For many points, tau sub Z. For many points, tau sub z could be infinite, but for some points it will be finite. So what happens when t is equal to tau sub z is that then the denominator on the right side of this differential equation will be equal to zero. So then the derivative is no longer well defined. Okay, so I want to show you a simulation of this Of this Leubner flow. So, yeah, so I have that here. So, this is a simulation which was made by Henry Jackson, who used to be a PhD student in Cambridge. So, in the left part of this In the left part of this figure, you can see the upper half-line and the curve. And in the right part of this figure, you can see what happens when we apply these mapping out functions, g sub t. So it's illustrating g sub t when we're varying t from infinity, not from zero, to some large number. So if we can fix the video at some time, so we assume. Fixed at some time. So we assume that the conformal map at this point in time is given by g sub t. So then if you look at the left part of the figure, then the curve until time t is shown in blue and the rest of the curve is shown in black. Yeah, so what you can see, so we can go back to the starting point. So at time zero, So at time zero you can choose some point in the right part of the figure and then when I start the video again you can see what happens with this point. So what you will observe is that the point you chose that it's that it's flowing downwards and the differential equation which is describing how this point is moving that that so the movement of that fixed point is exactly described by this Leebner differential equation. So as you remember for each So as you remember, for each fixed point z, we have such a differential equation. Another thing you can look at, so you can look at the intersection between the curve and the real line in the left part of the figure. Yeah, so that's not so visible now, but if I go back a little bit in time, then you can see that the point of intersection between the curve and the real line is oscillating up and down. And this point of intersection is exactly given by, so this is exactly. Given by so, this is exactly described by this driving function w of t. And in the example we see here, then this driving function is actually a constant multiple of a Brownian motion. Another thing you can see is these times tau sub z. So in this case, for almost all points of the domain, tau sub z will be infinity because this learner flow is well defined for all times. Defined for all times. But for those particular points which lie on the curve, then tau sub z will be finite and tau sub z will be given by the point that the curve is hitting the point. So tau sub z will be equal to the time that the curve is hit. Okay, so I think that's all I wanted to say about that. That's all I wanted to say about that simulation. So then we can go back to the slides. Okay. Yeah, so here we have now I've introduced the driving function and the learner equation. Yeah, so then we will go to Schrum's idea. So, when Schrum introduced SOE, then he was interested in understanding the scaling limit of discrete models such as the Rupert's random walk perpolation and the uniform spanning tree. And so he assumed that these models had scaling limits and he looked at properties of the limiting curve. So we assume now that eta is represented. So we assume now that eta is representing the scale limit of one of these discrete models. So one of Odo Schramp's realizations was that instead of studying the curve eta, one can equivalently study this driving function w. Because if we have a curve eta, then we can get a family of functions g sub t, which again gives us a driving function w. Or conversely, if we have the driving function w, then we can re- Then we can reconstruct the curve eta. So, what Odeschram did, so he looked at the properties that this conjectural limiting curve eta is satisfying. And he looked at what those properties tell us about properties of W. And what he realized is that if W, now if eta describes the scaling limit of the discrete models he was interested in, then W actually has to be a constant. W actually has to be a constant multiple of a Brownian motion. Because he saw that from properties of the discrete models, it was natural to believe that eta would have properties which imply that W has IID increments and which satisfies Brownian scaling. And from these two properties, we know that the unique process satisfying these properties is a constant multiple of a Brownian motion. Okay, so finally we are ready to give the definition of SLE. So to define SLE in the upper half plane, then we start by choosing some parameter kappa and then we let b be a standard Brownian motion. Then we set w equal to square root of kappa times b and then we solve the Lebner equation where the driving function is given by function is given by W. And then we let K sub T be the set of points in the complex plane such that tau sub Z is less than or equal to T. So K sub T is the set of points in the complex plane for which the Logan differential equation is no longer well defined at time t. And then we let eta be the curve which is The curve which is generating k sub t. So, what does that mean? So, what it means is that eta is generating k sub t. So, that means what I have described in the first of the smaller bullet points. So, we see and then we say that we define an SOE in the upper half plane from zero to infinity to be a curve eta which has been sampled in this way. So you can see that this procedure for sampling eta is also illustrated in the Sampling eta is also illustrated in the lower figure. We start with the random motion. This gives us conformal maps G sub T, which again gives us the set K sub T, which finally gives us Ada. So the first two steps I have described here are quite straightforward in the sense that it's not so difficult to see that these are well defined. But the third step of this procedure, getting eta from K, is not so straightforward and it's not so. Straightforward. And it's not so straightforward because it's not so easy to see that these sets k sub t are generated by a curve. So there are many possible ways to define growing sets in the upper half plane, which have not been generated by a curve. And it's not obvious that if we solve the Lebanon differential equation with the driving function given by this Brownian motion, then the resulting sets k sub t will be generated by a curve. Will be generated by a curve. But it was proved by Rod and Schrum that the sets k subd obtained in this way, that they are generated by curves with probability one. So Rod and Schramm, they proved it for kappa not equal to eight, and then in the case kappa equals to eight, then it follows from the work of Lauder, Schramm and Werner, who proved that SOV8 is arising as the limit. SLE8 is arising as the limit of the uniform spanning increase. Okay, so this is the definition of SLE in the upper half plane, connecting zero and infinity. So in general, if we have some general domain D, we assume D is simply connected, and we assume that A and B are fixed boundary points on D, then the slide here gives the definition of SOE in this domain. In this domain. So to define SLE in this domain, then we first let eta tilde be an SLE in the upper half-line connecting zero and infinity. Then we consider a map F, which is conformal and which sends the upper half-line to D, and which sends zero to A and infinity to B. And then we say that, and then we define eta to be the image of eta tilde under this control map. And we say Under this control map, and we say that eta is a curve which has the law of an SLV in the domain D with marked points at A and B. So when you see this definition, the first thing you may ask is whether this is well defined. And the reason that this is a good question is that this map F, which is appearing in the definition, it's not unique. So if you So if you did a rescaling of the upper half plane before applying this control map, then you would still have a control map from the upper half plane to D, which sends zero to A and which sends affinity to B. Yes, you can ask whether this SLE that we just defined, whether it depends on this choice of a conformal map. But it can be argued that SLE as defined here is well defined, and the reason is. Defined and the reason is scale invariance in law of SLE in the upper half plane. And I've left the proof of this as an exercise. So we let eta be some SLE in the upper half plane from 0 to infinity, and we let R be bigger than 0. Then we define a new curve, which is a rescaling of the original curve. And then the exercises to show that this rescaled curve also has the law of an SLE. Also, it has the law of anSLE in the upper half plane. So, I've also written a hint. So, one hint is to let eta tilde denote this rescaled curve, then define g tilde sub t to be the mapping out functions of this rescaled curve, and then argue that g tilde sub t is satisfying the relationships which are shown. Relationships which are shown in the indented equation. So, where g sub t is representing the mapping out function of the original curve eta. So, the first thing you can notice is that the rescaling of the curve eta tilde has been, so when I defined eta tilde, I also rescaled time by r squared. And by the by the scaling properties of the half-plane capacity, it follows from this that eta tilde is also parametrized by half-plane capacity. Have plane capacity. So, what you can see is that in the indented equation, you see that g tilde is also satisfying the Loebner equation, and you see that it satisfies the Loebner equation with a rescaled version of the original driving function W. But now, in order to conclude the proof, you can observe that this rescaled version of the driving function. That this rescaled version of the driving function that that also has the law of a Brownian motion, and this follows by Brownian scaling. So by using this, you can see that g tilde sub t is also satisfying the Dromin equation with Droving function given by a Brownian motion. And then you can use that to conclude. Okay, so now So now we have the definition of SLE. So yeah, I will say a little bit more before I finish. So as I mentioned before, Odotram, he introduced SOE while he was studying scaling limits of several discrete models. And he realized that if these And he realized that if these discrete models have scaling limits, then these scaling limits would have two properties in common. And these properties are conformal invariance and the domain Markman property. And these are the properties that I will introduce before I finish. So we assume that the D is some simply connected domain in the complex plane with With boundary, with two distinct points, A and B, on the boundary. And then for each such triple, we assume that mu sub d comma a comma b is a probability measure on curves in D which is connecting A and B modulo time reparameterization. So it means that we have a probability measure on curves, and again, we are identifying two curves. If we can get one. Two curves if we can get one from the other by reparameterizing time. So, in the first bullet point, I just considered arbitrary probability measures, but in the second bullet point, I introduce one more constraint. So, I assume that if we take eta and we sample it from the probability measure defined in the upper half plane with marked points in zero and infinity, then this curve is almost surely generated by a learner chain. So maybe. So, maybe you ask, what does it mean that a curve is generated by a Loebner chain? And by that, I mean that eta is obtained by a similar procedure as what I have described here. So I say that eta is generated by a Leubner chain if it can be obtained by solving the Lohmann differential equation for some driving function w. We're not anymore requiring that the W is a Brownian motion. And then we solve G sub T, then we get that K sub T. then we get sets k sub t and then finally we get eta by saying that eta is the curve generating k sub t. So I assume that eta is obtained by a similar procedure to this. And then I say that these probability measures, that they are conformally invariant, if the probability measure in n domain D is related to the probability Is related to the probability measure in D tilde by a conformal map. So it means that if we sample a curve eta from the probability measure in D and then we compose it with some conformal map which is from the domain D to some other domain D tilde. Then the resulting curve in D tilde will have the law of a curve sampled from the measure in this domain. In this domain. Okay, so then we also have the domain markup property. So to define the domain markup property, we assume that we run the curve eta until some stopping time tau. And then we condition on this initial segment of the curve. And then the domain marker property is telling us, conditioned on the initial segment of the curve, what is the conditional law. Curve, what is the conditional law of the rest of the curve? So, the figure is illustrating this in the setting of where the curve is simple. So, in this setting, we let k sub t be the curve run until time tau. Yeah, we let k sub tau be the curve run until time tau. And then we see that the set D minus k sub tau is simply connected. And when we also see that eta of t and b are two marked points on the boundary of this domain. So therefore we know that we have some probability measure mu which is defined in this domain with the two marked points. And then the domain marker property is saying that conditioned on the initial segment of the curve, the rest of the curve has the law of a curve which has been Of a curve which has been sampled from our probability measure in the slit domain obtained by removing the initial segment of the curve. So these are the two properties. So then Odotrum was proving that these probability measures, they are conformally invariant. measures they are conformally invariant and satisfy the domain marker property if and only if a curve sampled from one of these measures is an SLE curve. So we prove that SLE curves they are conformally invariant and they satisfy the domain marker property and conversely if we have a family of measures satisfying these properties then they have to be SLE curves. And this theorem is exactly what was motivating him to introduce the SLE curves because The SLE curves, because he realized that many of the discrete models he were interested in, they were believed to be conformally invariant and satisfy the domain marker property in the scaling limit. So by this theorem, the only possible scaling limit are SLE curves. Okay, so yeah, so in the next slides, So, in the next slides, I wanted to give you some more intuition for these two properties, conformal invariance and domain marker property, in the discrete setting. So, I think I will maybe be doing conformal invariance before I finish. So, the measuring u sub d, a, b, it's typically representing the scaling limit of some discrete model. Discrete model in the domain D with marked points A and B. For example, in the setting of percolation, then we can consider percolation restricted to the domain D, where A and B mark the points at which the boundary data change. And then mu sub d comma, B is representing the scaling limit of the interface of the discrete model in this domain D. So then we can So then we can do this procedure for two domains d and d tilde and then conformal invariance. As I stated on the previous slide, conformal invariance means that these two probability measures mu one defined in D and one defined in D tilde, that they are related by a conformal map. Okay, so I think that now I will finish the presentation for today and then yeah. And then, yeah, but before we end, I can ask if there are any questions. Maybe, yes. So we will have time for questions afterwards, I guess. But I think at this point we will unmute everyone so that we can show our appreciation to Nina. Thank you, Nina. And at this point, we will stop the live stream and recordings so that people are more free to ask questions. And you should all be able to unmute yourself at this point if you want to ask questions. want to ask questions