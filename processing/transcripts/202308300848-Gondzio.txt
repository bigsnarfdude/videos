Right, you see the title of my talk. I'd like to convince you that IPNs, which is an abbreviation for interior point methods, and I will use it occasionally, can solve some sparse approximation problems and can go further in this direction and also solve some discrete optimal transport problems efficiently. It's a joint work with a group of colleagues. You can see quickly I have certain inclines. Can see quickly, I have a certain incline to the south of Europe because the names indicate that these are either Italians or Greeks. Very well-trained people and fantastic researchers. Stefano Cipola, Valentina DeSimone, Daniela Di Serafino, Spiros Gugarchiotis, Marco Viola and Filippo Zanetti for my collaboration. You've got them all. Sadly, one of my colleagues with whom I had the pleasure to work with, that is Professor Daniela Di Serafino, passed away last year. She fought a long battle. She had a long battle with cancer. Unfortunately, the illness was stronger than that. It's a big loss. She did a lot of interesting things and then a lot of myself. Right. Moving on to the talk. There are lots of problems in which can be formulated as one of those three very basic classes of optimization. That is either LV or QB, quadratic programming or semi-definite programming. Here it's a slightly different thing because the object is a matrix, which is a positive semi-definite matrix. So the scalar product is a trace between C. The scalar product is a trace between C and X transpose. Here we have a linear operator and non-negativities. And wherever you have non-negativity constraint, you should use interior point method. I hope no one who leaves this room will ever question this text. And this is the the right way to treat them is through logarithmic barrier function. And this is somehow counterintuitive. And this is somehow counterintuitive. How do you replace a linear constraint by a non-linear function? Do you know in mathematics many examples of doing non-linearization of the linear problem? There are not that many. But in case of optimization, it works. So for simple images. Shock capturing, by the way. Pardon me? Shock capturing. Okay. Well, thanks. For the For the simple inequality like that, x greater than or equals zero, if you just draw a logarithmic barrier function. If you have a more complicated inequality like this one, which defines a cone, speaking Italian once again, gelato a limone, and you have the ice ice cream cone. So that's described by such an inequality, and what do you do? You throw the logarithm on the on this entry which should be positive. And three, which should be positive. That's it. For positive semi-definite matrices, if you want x to be positive semi-definite, it means it should have all non-negative eigenvalues. So how can we handle this? We say logarithm of the determinant has to be positive. By the way, logarithm of the determinant, which is a product of eigenvalues, would give you what? Would give you the sum of logarithms of eigenvalues. So we will be coming back to the sum. So, we will be coming back to the sum of logarithms here. And that's exactly what I want to show here. If you have a polytope and you'd like to be in the interior of the polytope, then you could use this function to keep you there. Because this function penalizes for any of the x's approaching zero. See, if x one gets close to zero, minus in mi uh minus logarithm should stay infinite. And minus logarithm should stay infinity. So, to minimize this function, we should come somewhere here, which has a name of the analytic center of the polytope. Generally, to be close to optimality, we should stay somewhere in the interior. And this is a good tool to say, whenever you have an optimization problem, let's delay the optimization by using such a function. And let us throw here a little parameter. A little parameter, the Greek letter me. You are talking to me, said Robert De Niro in one of his famous films. So that's the Greek letter which controls the force of this Mogarthic barrier. Because if you're now trying to optimize this function, and you should go in a direction like this, that is to come to this specific vertex, then of course you have to. Vertex, then of course you have to allow it, and to allow it, you need to reduce the barrier. So reducing the barrier will move the balance to take more of the objective of the function into account, less of the barrier function into account. That's IPM in a nutshell. This is the beautiful logarithmic barrier function which repels the x. The x from getting too close to zero. And then, if you use this sum of logarithms and go to the minimum, which here is at the bottom, then you will have to stay somewhere in the center of the polyton, far away from the boundaries, until the very last moment when you really approach optimal. While logarithmic barrier, it is a self-concord line. It is a self-concordant barrier, so the third derivative of this function cannot go wild. That's how I would rephrase self-concordance. It's mildly non-linear, and because of that, Newton method will have a large region where it converges quickly. And it also transforms a difficult equation which is called complementarity in optimization and in PDEs. That is In PBEs, that is this condition which says one of these two variables has to be zero. And how do you solve such an equation? Normally you would say, oh, it's fantastic. One of them has to be zero. But actually, this is the source of non-polynomiality in any kind of active set metal. So this one is removed by the magic button. It is removed by integral point idea, by the logarithmic variant, because then zero is replaced by a small zero is replaced by a small perturbation and this perturbation is gradually shrank to zero. If you look at the computations in interior point method, then for LP case, the easiest of cases, you quickly come down to Karush Kuntaker conditions or uh half of the of the of the group here would call it subtle point uh system, of course. System, of course. So, well, the same thing, which in linear case has this shape of looks like weighted least squares, where the weight is the matrix theta and it originates from interior point. That is, component-wise, it is a division of primal variable by the dual slide. This is inevitably ill-conditioned, because don't forget, some of the x's have to approach zero at optimality. So, inevitably, some elements of this theta will be very, very. Elements of this theta will be very, very small. The other elements we will be dividing by something close to zero. So the other elements will explode to infinity. And here, the linear algebra, the person will probably say it's a disaster. Of course, it's a disaster because the condition number of this matrix goes to infinity. It's an inevitable price to pay for the advantage of using interior competence. Whether you use augmented system or you reduce it to normal. Augmented system, or you reduce it to normal equations, that the thing is the same. It will be the conditional number of the matrix goes to infinity. But the linear systems are not that complicated, and they can still be solved to sufficient accuracy in the subspaces in which the security has to be recovered. To finish this quick introduction on internal point methods, I'd like to say that they do have certain amazing ability. Amazing ability of aggregating information from all constraints that the other methods don't have. And because of that, they are able to spot where the part of active set is, which constraints are really relevant, which variables will go to zero and can be eliminated, sort of, which variables do not go to zero. So we are able to detect this, what I call. To detect this, what I call an essential subspace, something very, very different from active set pattern. And if I could once again come back to this picture, it's sort of understandable because the logarithms are always present. Even if you move from this point closer to optimality, maybe here or maybe there, you will still have a little influence of all the X's. So you have the aggregated information about what's going on with the constraints. Something that is absent in activists. That is absent in active set methods. And now let me move to sparse approximations. It's the area where which, well, to focus on one specific problem, you could think of that. We have to minimize certain function f, which is usually a convex, maybe linear, maybe nonlinear, but you'd like to have a solution which is sparse. Solution which is sparse directly in terms X is sparse, or maybe sparse in some other dictionary. This could be total variation or something else which originates from your application. Such problems appear everywhere. They certainly appear in computational statistics, but also in compressed sensing. We had a talk yesterday which mentioned compressed sensing or in spark portfolio selection. Or in sparse portfolio selection where you would like to have the portfolio but you do not want it to be spread in every possible asset. You'd like to have five assets or six assets but not more. Or image processing, classification models in functional magnetic resonance imaging, lots of applications that can be framed as this. From optimization point of view, it could be NLP or QP of NLP with some linear constraints and a little bit of difficulty Constraints and a little bit of difficulty with this norm one, which, as we know, is a non-differentiable function. So everything looks nice, but the non-differentiability is a little bit of an issue here. So what do you do with non-differentiability? If you are a non-mathematician, an engineer, just ignore it. But if you want to have a proper mathematical approach to it, you could either split a very Split a variable into its positive and negative part. This blows the dimension of the problem to two. It replaces an x with two non-negative variables. But now, what is the best method to handle inequalities? I ask this question. Interior point methods. That should be your quick answer. Next time I ask about it. So of course we would not worry about it. Another option is some smoothing when you have a cast. Is some smoothing when you have a cask and non-differentiability, you could smoothen it. And well, it's not by chance that I also use here the parameter me, because if this me is sufficiently small, the function will be almost the same, only here at the very bottom, will be small. Right, so these two options are available, but then we would need some form of continuation, some form of homotopy to guarantee that if we replace the Guarantee that if we replace the problem with a sequence of other problems easily solvable, that the solutions of these easier problems will converge to the solution of the problem we are interested in. So, one example of such monotopy is interior point method. And I will use it, but I will not comment on it much more. Another would be to use the pseudo-Qber regression and use another type of smoothing on this parameter mean. It can also This parameter. It can also be done in a provable way, mathematically clean way, to guarantee that such a process delivers. Questions are naturally about the theory and practice, but you know very well being good lecturers that the question like this would never appear on a slide if there was no positive answer to it. So, yeah, the theory of it has been done and it will still work like this. I would also like to make this comment that. I would also like to make this comment that I often go to conferences and there's this community of first order methods, people who do not want to use Hessian to formulate it, to solve equations with it, and they typically say something like this quotation. Computing or using the second-order information is too expensive and don't go there. I cannot completely agree with it. It is expensive, but you could use a little bit of the second-order information and capture a little bit. Information and capture a little bit of the curvature of the function and go much, much faster to normality. So I'd like to convince you that this general criticism is a little bit too harsh. It is strictly based on unfair comparison because some specialized first-order methods, specialized to a given problem, are compared with general off-the-shelf second-order methods. And that's, well, the general method may not be able to. May not be able to catch certain specifics. Okay, I'd like to convince you that the specialized second-order methods and interior point methods in particular can be really very competitive and frequently outperform first-order methods. So, how to specialize in the orbital methods? First of all, the very basic thing is use inexact Newton method. Because the exact Newton method would require formulated Newton method would require formulating the Hessian and solving an equation with the Hessian. In Dense case, it's a disaster, computationally very expensive thing. We can't allow ourselves to do it. So build efficient preconditioners for iterative methods. Try to use as much as possible matrix-free mechanisms to avoid formulating the matrices, but use only multiplications with matrices. Think immediately of the fancy applications from signal processing or image processing. Signal processing or image processing, where you know how to perform matrix vector operator times the vector action because FFT can be used to deliver it quickly. You should not formulate things as matrices in such case. How to exploit the expected sparsity of solution? So, maybe I should first say a word about what I mean by sparsity of solution. I mean you have a vector which is possibly of dimension 1 billion, but there is 1 billion, but there is only a small fraction of entries in it, which is only a million entries are non-zero, while the remaining entries are zero. I would say that such a vector is sparse, and I'd like to argue, to convince you, those who are unconvinced, many of you are already convinced, that lots of applications require such solutions. Look for such solutions. So, if we do have such a situation, what does it mean? Situation, what does it mean? I have a vector of length 1 billion, but only 1 million entries are relevant and should be non-zero. It means that for 999 millions, I will perform modifications with some value of the entry. Complete waste of time, isn't it? It shouldn't be done that way. It should be done by building up information where non-zeros are and finding the solution. So we would ignore this. So, we will ignore this very long matrix. We will not update all variables. We will use something which, in optimization, is well known, is called column generation approach. By the way, I give a few references here, which address some of the background. So, the first one analyzes what happens when inexact Newton directions are used. The joint work with Spyros and John Nielsen is about designing preconditioners for the variable. Designing preconditioners for the methods. And my fantastic Italian PhD student, Vidi Pozanetti, almost out the things about when to stop grid of solvers. That's a very interesting thing, because you typically launch a Kridoff solver having a fixed requirement on accuracy, saying, Oh, I'd like the three-digit exact solution to be found, or six-digit exact solution to be found. Exact solution to be found. It's actually a wrong criteria in the particular situation of interior point. Maybe it's a wrong criteria, generally speaking. Because what you are really after is to find a direction that is suitable to deliver something. And we have designed such stopping criteria to say you you can stop much, much earlier because the Krilov Nethod already delivers the useful information to make progress in optimisation. to to make progress in optimization. But right. The main tool will be inexact Newton method. And that's very easy. That's well known since 40 years now since the work of Denbo, Eisenstadt and Seichal. We replace exact Python method, which comes from the solution of this equation with an inexact one. With an inexact one, admitting certain error on the right-hand side. And the theory for inexact Newton method says that as long as this error is only a fraction of the right-hand side, the inexact Newton method delivers almost the same features as the exact plot. But you can deliver the solution much faster. Particular when using iterative methods. Stefania Penavilla was the first. Stefania Panavilla was the first person to notice that this is that because interior point method relies so strongly on interior point, then it actually will benefit from this. Indeed, it does. The question about theory, will it work? Yes, it will work if you use standard so-called small neighborhood, that short-step integer point method, which is known to deliver the best complex. Known to deliver the best complexity result. It is also known to deliver very poor performance, practical performance, but from a theoretical point of view, it's the best complexity result. So what I actually could prove is that you could allow yourself to have error in Newton up to 30%, which is quite a lot when you think of it, without any loss in the complexity result. Is it surprising? It shouldn't be when you think of it. Be when you think of it. Because whether the neutral direction points exactly at Aretha or changes a little bit and I alter it a little bit, I can still make a good step towards optimality, on a long path to optimality. For this more practical neighbourhood, which is a symmetric neighbourhood, we have to be a little bit more demanding, but still up to five percent error in the direction is harmful. Direction is harmful. May I make a couple of questions? First, an observation about what you just said. So, if my step is very long, the distance will be much larger. So, you assume that you have short steps? Not necessarily. I'm just assuming I'm still so far away from optimality that if I go to it like that and then turn to the right, or like that, and then turn a little bit to the right. Or, like that, and then turn a little bit to the left, I will still have plenty of time to recover from potentially my tiny error at this particular step. And as long as the step delivers reduction of the duality gap, that is, improves the measure of distance to optimality, I'm fine with it. Okay, any question? Because in the previous page we talked about stopping criteria. So, this is a typical position of stopping criteria for in disguise. In disguise. Oh, absolutely, because the slide is a sort of textbook. My question was a curiosity actually. The quantities on the right in your norm of R less than ton of kinetic. So the norm of the gradient, is this going to decrease as the outer iteration or increase as the territorial? Iteration or increase. Yes, it decreases. It decreases. So you're always requiring a more and more accurate solution. Let me put it this way. Right-hand side here, roughly, I hugely oversimplify, but roughly speaking, is in the scale of me, the barrier parameter, this. So it goes down. It goes down and It goes down, and me very close to zero means optimality. But also, many entries here will go down. And also, steps go down. So, somehow, I'm sorry, I'm very imprecise now. But everything scales down together with this mean. And in a way, a relative accuracy is relevant here. But in this relative But in this relative accuracy, you can allow yourself up to 30% error or 5% error without observing any harm to the practical behavior of the method. So would it make sense to have a variable eta that changes as you approach? In reality, we will not do it in that change. We will not do it in that general way. We will do it in a slightly different way by looking at a much bigger form of this equation, analyzing the errors in specific subspaces, pretty much like you did in the paper with Matiatani and Benedetta. Looking at what happens in primal space, in dual space, and in centrality, and once Centrality, and once we see the following, the direction already delivers good progress in reducing primal invisibility, in reducing dual invisibility, and in reducing duality gap. We're done. We interrupt a lot better. Thank you. Yep, I think it's very basic, but this is a residual, like Valeria said. And you use the term error there, but the Use the term error there, but the delta x is eventually what you want, I think, to be small, right? No, not necessarily. Delta x is a Newton direction. Oh, I saw that. That's an unfortunate notation for us. Okay, because that's what's confusing. Apologies that I chose a note that that's the way the residual grand. Calling the residual error is a yeah, it's a lot of confusing. We had this discussion yesterday, but I just want to say that there is nothing magical about 0.3, right? No, there is nothing magical. But you could parameterize on eight at least. Yes, yes, you could. And the 0.05 when you said you have to polarate less, simply the constant will become larger. Indeed, right? Indeed. I mean, common sense says that you would never. Says that you would never be able to accept ether very, very close to one. Because what this would mean, this would mean that we are not solving the system. There is no phase transition. So there are problems if you're at the optical science, especially when you have a phase transition. Should you exceed a particular eta, there is nothing you can do. So there is nothing like that. No, no, there is nothing like that. Just problems. Right, now let's go to sparse approach. Now, let's go to sparse approximations. I know before we go to sparse approximations, a quick comment about these long problems. So, think of the linear programming problem that has the Fomali matrix. It starts here, column 1, column 2, and finishes here. Okay? Well, you don't want to solve it by doing silly multiplications. Silly multiplications of a very long matrix time a very long vector full of zeros. The column generation, a well-known technique and mostly used in combinatorial optimization, comes as the answer to that. Because it means replace the big problem by taking only a subset of comments. Maybe it's a little bit unusual annotation to put n bar being a subset of n, but you have to stick with me on that. You have to stick with me on that. So n bar is smaller than n. Here. And we will do the summation on a smaller set. We will solve this problem, which has a name of restricted master problem. So you pick up a few columns from a long matrix, you solve the problem, and then you find out, well, I'm missing something. What do I miss? The dual information will tell me what I'm missing. And the columns, which are the most promising, The columns which are the most promising, which has the largest reduced cost, will be appended to create a new restricted master problem. Then you solve the new restricted master problem, you do the loop like this, boom, it converges to optimized. But the advantage of it is that you will never ever use some columns from this long matrix will never be present in any of these restricted masters. So if your problem has dimension 1 billion, the largest restricted master will have a dimension. The largest restricted master will have a dimension 1 million, which is exactly what we need for sparse approximations. How interior point metal can be specialized to sparse approximations. Well, ignore the long matrix, work with the short variant of it. Use simplex-type pricing mechanism to judge which of the columns left out really need to be appended later on. Simplify no. Simplify normal equations. If you write normal equations as a sum of outer products, you immediately see this is the summation over j from 1 to n. So if we shorten the summation, we have a very quick gain resulting from it. Moreover, this is likely to be significantly denser than this. So there will be also a gain in sparsity of the matrix. But we do not want to solve But we do not want to solve these equations, equations with this matrix directly, because we still look for a preconditioner for normal equations matrix. It's not deterministically aspect, right? I mean, what you've written there essentially is sub-sum in some sense. You've done it probabilistically as you have used major concentration. You could, but you you yes, but if you do it uh probabilistically, then uh unless you guide somehow this probabilistic process. This probabilistic process to deliver it an understanding of where the problem originates from, you wouldn't gain much. So you didn't have good probability spaces to shift. Exactly. While if we know where the problem comes from, where the matrix A comes from, and I will talk about discrete optimal transport soon, then you know how to generate the starting set of columns, for example. If we want to use Use to interior point in sparse approximations. Our approach to this was the following. Let's take several very different applications of this, which have been solved very successfully by first order methods, like Sparta Portfolio with BINPREGMA. Classification models for MRI, it is solved by FISTA or ADNN very successfully. Total variation-based Poisson image. This is solved very successfully by Primal Dual Automatic Lagrangian. By primal dual automatic Lagrangian method of shambling box. Or linear classification and machine learning things. So we have taken these problems and we decided we will develop interior point method for all of them. And we will then perform comparison with these best first-order methods for all of these applications. And that's written down in the paper and Samry. I wouldn't have time to cover all of it, but I'd like to quickly comment on this. But I'd like to quickly comment on this. So let's use the following modeling trick. Let's get rid of norm 1 here and norm 1 there. So let's replace absolute value of x by positive plus negative part of it. And x is of course x plus minus x minus. Well, you blow the dimension of the problem by a factor of 2, you throw some extra constraints on it, because I have to do the same for the... In it, because I have to do the same for this, the result of the operator times x. That is the vector d. I have a bigger problem, a few more constraints, lots of inequalities, but may I ask this question again, what is the best method to solve problems in the problem? Okay, so it can now be eligible to use integer point methods, and that's what we pay for. We use the data, which really comes from. The data which really comes from real applications. So this operator is a discrete isopropy total variation, and the data comes from examples that were studied by experts. That's a comparison. Interior point method or VISTA or ADMM applied to such a problem with different values of these parameters, how you measure. How you measure, how much importance you pay to sparsity. And I do not want you to read the fable, just focus on this red or magenta colored line. We would like the following. We would like the accuracy to be as close to 100% as possible. We would like the corrected overlap to be as close as possible to 100%, and we would like density to be as small as possible. We are looking for sparse solution. Sparse solution. Now, if you use Interior Point, you get that. If you use Vista, you get good quality here, reasonably good quality here, reasonably good quality here. If you use ADNM, you get good accuracy. Really very confused about corrected overlap. Well, here we want sparsity. We have practically dense vector. 97% of entries are non-skew. But it's interesting to see at the evolution what happens when you use these algorithms. So let's have a look at what happens when interview or point is applied, what happens when FISTA is applied to the problem. And as you can see, IPM wastes about eight minutes for learning. What on earth is going on? How to place my point in the center of the polytope? Well, and this is this eight minutes to learn about the influence. To learn about the influences of all constraints. And then, once you've done this, you should optimal it. In a few more minutes, about 15 minutes, all indicators are settled close to optimal and they will not change from now. Vista does something different. Pretty quickly, in about two minutes, gets a rough optimality, but it will take ages to get to a sparse solution. It really saturates. It really saturates here. You cannot see it, you can see only 30 minutes, but it will take 30 days probably to get to the same accuracy as here in terms of sparse. But you do get reasonable solution quick. Why is it going down at the end? It looks like it is. At least. It goes down? I mean, at top, the measures you're interested in. So I suppose these are the things that... Because these are the things of over-solving, where the error confuses the network. Known in computational statistics. I'm not an expert, maybe Arita could comment on it, but there is something known that if you continue too much with optimization, you sort of over-optimize and certain indicators start to worsen. Exactly is the y-axis. The y-axis. Accuracy. It is accuracy, the green line, the density, the dashed blue line, and the corrected overlap. Corrected overlap looks how the voxels are, how accurately the voxels of information are corrected. I prefer not to give the answer rather than to give a stupid answer. Than to give a stupid answer, which means I'm not 100% sure. Because it also looks like it's going down in both cases, which could be over 50 after a quarter. That's how it is based. Could be. Can I provide you some good starting point or the interpoint method? It could. However, it's not obvious how to translate an arbitrary knowledge into a good starting point. And the reason for that. Point. And the reason for that, as much as I'm fanatically in love with interior point methods, it's difficult to find something in the middle. So it might not be here, it might be something over there, and then it would not necessarily be a good starting point for right hand. So it's not that easy to. I know what you mean. Let's start with this. Let's quickly find an approximate solution and then let's switch to this. It's not obvious always. It's not always obvious. Now, let's transport ourselves to optimal transport. Sorry, I need to speed up this. So, optimal transport is a... So you have at least 10 minutes. Okay, we start late. Well, thank you. It's very generous. Right. We have the optimal transport problem, that is, there is a mass distribution. Problem that is, there is a mass distribution in red, we would like to transform it to mass distribution in blue. The obvious thing is to take a little piece from here, bring it over there, and so on. How to do it in an optimal way. Now, you can take a piece from here, bring it anywhere. So you have a complete graph of connections between red points and blue triangles. Do you expect all connections in this graph to be used? No. A sparse solution will be found here. Solution will be found here, which means we will take the mass from here, we will bring a little bit here, a lot of it there, a little bit over there, a little bit over there, and that's it. So, sparse solution is a naturally sought in this example. The problem has a nice formulation, as an L P involving here chronic error products, so it will exactly give you this matrix. Exactly give you this matrix, a very long matrix. A very long matrix because the number of constraints is m plus n, where m describes the initial distribution of mass, n is the dimension of the final distribution of mass, discrete optimal transport. But m times n is the number of variables. So you see number of constraints is significantly smaller than number of variables. A very good example for column generation approach. For column generation approach. And that's what we did to it. This problem can be interpreted in graph. It's a well-known thing in graph theory. It's called a single commodity network flow. But we'd like to have an interior point which competes, ideally beats the network optimizer. So we have a particular We have a particular form of matrix A. It's a no-dark incidence matrix. A column of A has only two non-zero interests: one plus one, one minus one. It's extremely sparse. But A times A transpose gives you a completely dense matrix. So that's a disaster if you wanted to use standard IBM. This is the disaster if one feeds it to CFlex and says, oh, CFlex cannot solve it. Of course it cannot solve it. Well, unless you ask Cplex to use the network simplex method. To use the network simplex method, then it puts on. What can we do in interior point? We should build this matrix by shortening it, and we should solve equations in a clever way, using Krudov method, using good preconditions. Fortunately, people in optimal transport is a very attractive area, I have to say. There was, of course, a long time ago, Nobel Prize for Gunt. Nobel Prize for Gantorovic, but not so long ago Fields met out to Alessio Figali. So it's the area which is very active research one. I have to say, much more complicated optimal transport than this one that I'm presenting here. So many people tried different solvers. Some of them called them rather ambitiously like light speed. So if someone calls the solver light speed, what happens? Over light speed. What happens if someone finds a faster solution? This questions the relativity theory. Anyway, these guys have developed a very nice benchmark of problems and tested several solvers. And what did they find? And actually C-Plex, which is a standard LD solver, is the fastest. The fastest the network simplex. That's why I will not compare with this, I will only compare with Cplex network solver, and actually I will compare with a much, much faster network solver than Cplex, something called Lemon. Once again, Gelato Alemon comes to my. That's a comparison on large problems. Start from 1 million, goes to 10 billion, and you can see black triangles. And you can see tri black triangle is the seaflex, it goes up. By the way, this is logarithmic, this is logarithmic. So if it goes up, it goes up significantly. IPM is the red box here on this picture. This happens for different classes of problems from this discrete optimal transport benchmark. The benchmark consists of pictures and slightly perturbed pictures. So we would like to have a picture one to be mapped. One to be mapped on a picture number two. And do it quickly. Well, this was the case when we had Benz graph and sparse solution. The question is, what would happen if we had sparse graph? That is, the matrix A would not be so disastrously long, but on the other hand, it will be much, much bigger in this dimension. What if you have the problem 10 million by 15 million? You have the problem 10 million by 50 million. How do you solve that one? So, this is the second case where the number of nodes, the number of arcs, is just a little bit larger than the number of nodes. Maybe two times larger, maybe ten times larger. This is a bit like social networks, where connections, where you have a few connections, but not everybody is connected with everybody. I'm certainly not connected to Donald Trump. And why? To don out to Trump. And why? Because I'm not on social networking. Okay. But say, the typical thing in networks is that there are connections to only a few neighbors, not necessarily. Somebody has golf courses in Scotland. Sadly, please don't remind me about that. So we have sparse graphs and we will be looking for sparse solutions. In this case, once again, we will be able to interpret the problem as an optimal transport problem using the fact that the matrix is a no-dark incidence matrix. But in this situation, we'll exploit the Laplacian structure of this matrix because it originates from the graph. And therefore, even if we use the weighted Laplacian, we will be able to well approximate the Able to well approximate the full Laplacian by using only a subset of columns. Here I use the better letter S or a subset of capital N, and then either use this approximation to factorize it directly, or if it's too difficult, to precondition. That is to find even sparser decomposition. The whole point is to do it in such a way that you really never formulate That you really never formulate big matrices and big factorizations. That's the whole thing. It's quite entertaining. So that's what happens when we took sparse graphs from sweet sparse. Some of them are large. Take this one. 16 million nodes, 48 million arcs. Arcs, on average, there are just three arcs emanating from every node. So it's really very sparsely connected. And then you'd like to find the solution of the optimal transport on such a problem. Now we only compare ourselves to Lemon. Lemon is much faster than Cplex. Cplex would be out of this scale. We would have to add another. To add another level, another order of magnitude. This is logarithmic, and here there are the names of the problems. But they are ordered in increasing dimensions, so you can see quickly that the larger the problem is, the better relatively interior point performs in comparison with uh lemon. Here it's about ten times faster. Here it's maybe twelve ma sorry, maybe twenty times. Ma ma sorry, maybe twenty times faster. If we go for bigger graphs, but uh this was done on laptop. If you want to go for big things, yeah, you need a you need something that will be able to store things in memory. That's an interesting thing. It summarizes somehow my experience with optimal transport problems because now we put the results on Put the results on a graph. This is the logarithmic scale for number of edges or r's in the graph. This is the average time, also in logarithmic scale. And then we put the solution times for interior point, which is blue, and for lemon, which is red. You see how lemon scales. If you see the straight line here, it means there is certain parameters. There is a certain parameter which controls how the solution time depends on the size of the problem. So Lemon scales a little bit worse than quadratic. Scale is 208. Interior point is 128. So this was for random graphs. For pseudo-sparse graphs, Shoot sparse graphs, Lemon scales once again a little bit above quadratically. Interior point has a scanning factor of 1.40. What this means is that we can solve the problem of size n in observed complexity n to power 1.4. And I just remind you, this is the inexact Newton method, which is which should be order n cube or a little. Order n cube or a little bit lower than n cube. So that's very, very fast of solving such problems. To conclude, interior point, they enjoy predictable behavior. You never do more than 20, say, 30 iterations to solve a problem of any size. That's quite amazing. They deliver high accuracy. When applied to sparse approximation, When applied to sparse approximations, they certainly compete with or frequently outperform the first order methods. When applied to optimal transport, I would say there are the methods to beat. We will see. Someone will of course come with something much faster, but right now it's not that obvious to be able to beat that. And why this happens? Because they have this amazing ability of very quickly finding out what is active. Finding out what is active and important, what is inactive and can be thrown out of the problem. Thank you. So, um, I don't know, is anybody online? But I can't see you on the screen, which is like well that's that's not to do with uh, that's to do with the live feed. So does anybody online has any questions? You have a chance to ask. Are there any questions? You have a chance to ask one. We had a few questions you would have. I'll take maybe just one question running a little bit late. Just to be sure that I understood correctly, you for the solver on the graph using the graph, you use like the L1 minimization approach where you double the number of unknowns because you say that we have a linear programming with a constraint that is the incident matrix. But the cost functional is the one when you double the number of variables. For optimal transport, I didn't have to do it. For the other sparse approximations, I had to do it, but objectives were always there now. Okay. One comment. Probably. I remember the first time I gave a talk on multi-grid talks about order N and equations and unknowns, we solved it in order N. Unknowns, we solved it in order to work. And then somebody says, Well, why is it possible you maybe can do it less than n, n to the one? So there's still room for improvement, is that what you're saying? Well, I just throw that out there for myself. Thank you. So again, by either serendipity or good programme design, we have a talk which seems to follow along quite naturally from the previous talk. Rico.  Yeah, that's good. I'm a sourcing.