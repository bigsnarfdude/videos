First, to the organizers for organizing this event. Second, to my wife for allowing me to be here. And finally, to the referee of the paper for actually making sure that actually there is no mistake in the paper. And there's a chance that you are here, so thank you. Okay. All right. So let me start by telling you what problem we are going to talk about. What problem we are going to talk about. And everything new I'm going to talk about is joined with Amze Jeffs, who is a postdoc at CMU. So it's about patterns of intersections of convex sets. So I will use C1, C2, up to CN to denote convex sets. Okay, and please, if you cannot read what I write, or it doesn't make sense, or you cannot hear what I'm saying, please. Cannot hear them saying, please don't wait until the very end. Ask questions, make sounds. Okay, so this is convex sets and R to the D. So N will be the number of sets, D will be the dimension, and I'm interested how they intersect. So let me draw some examples. So just okay, three convex sets in R2. So the first way. So the first way to record the intersection pattern is why what's called a nerve. So okay, so I will call this collection C altogether. So the nerve of this collection consists of all those sets sigma. Okay, so this is index sets. So which are in one flow. Which are in one through n. So I will use usual notation bracket n is elements one through n that have a non-empty intersection. So I looked at sets indexed by sigma. I intersect them and I'm asking are they empty or not? And collection of the non-empty intersections. This is called the nerve. All right. As many of you know, this is a wonderful object with very nice anthropological properties. Very nice anthropological properties. It's much can be said, which why will not say. So, this is one way we can record intersection pattern. And actually, this the other way, which I want to mention, even though I will not be talking in this talk, but it's something interesting. And actually, we did actually even work with AMZ about related matters and in different work, one can look at the Look at the call it code, neural code for marketing purposes, I suppose, of C. So this basically says this, I would really call it a Venn diagram. So what it records, it records not only intersections, but also non-intersections. So here is definition. It looks almost the same as that of the north. So I'm intersecting those. So, I'm intersecting those which are indexed by sigma and the complements of those which are not indexed by sigma. So, this is the same thing. So, this, if you think a few moments, records more information than the nerve, because I should know which intersections are also. Ah, thank you. Compliments. I said compliments, I did not. Okay, people are paying attention. Good. All right, so. All right, so I will be talking about NERSC exclusively through this talk. This is much harder to understand. For example, if you've been at a problem session on Monday, I mentioned a problem which basically said, suppose I give you a collection of subsets. Is it a code of some collection of convex sets? And we did not even tell that it's a decidable problem. Okay, it's that bad. Okay, this is easy to decide. Well, in principle, it's. To decide, well, in principle, at least, and we are actually asking now more fine questions. And kind of question we want to know is what, ideally, what is a typical pattern of intersection of convex sets look like? We cannot quite answer, but we can make a kind of fourth step towards that, which is we can count, well, to some degree, how many such things are there. So, let me make definitions so we can actually speak about the problems we're going to work with. So, I'm going to say a complex. I'm going to say a complex K is derepresentable if it's the norm of some collection of n convex sets. And for the duration of the talk, my collections of convex sets will be labeled. So again, the decision is like number one. Label so again, position is like number first, first set, second set is up to n. So they are labeled. It's not going to make much difference, but it just makes life slightly simpler. Yes. Yes. Oh, yes. Thank you, Martin. I should have said that this is actually a simplicial component because it's downwards closed family. And again, its topology is very nice and relates to how the sets are arranged. And I promise not to tell you about it. Promise not to tell you about it. All right, yes. Um, uh, yes, uh, some C, thank you very much in R D. Okay, so this is Hans D representa. All right. Um, and let's one thing which is immediate about About derepresentable compasses, you don't actually need to have something derepresentable or not, you don't need to look at all sets of arbitrary size or faces of arbitrary size, if you want to talk about the terminology, because of the Helley theorem, right? This is the conference about Helley. I suppose I forgot, you know, this is what was said. So Helley says that if If that m more than d plus one convex sets intersect if and only if every z plus one of them do. Okay, that's that's Helley's theorem. Given it's right, I don't even need to at most. D plus one is actually in our words, if I want to tell whether some sigma of size, say d plus two, is here, I don't actually need, I just can just check all the subset of size d plus one. Are they there or they're not? That's Helisten. All right. So what I so that tells me really that I need to look only up of size D plus one. So if I introduce the number, so I'm going to be seeing the number of derepresentable components. Going to be the number of deep representable complexes. So f d of n, I'll define to be the number of deep representable complexes on n points. So Halley would instantly tell us that f of n easily bounded by, well, I will need to. Well, I will need to tell you for each set of size at most d plus one whether it's there or not. So that's a kind of crude upper bound for number of choices. And this is going to be bounded. Well, it's n this by rod n to the power d plus one. Okay, so this is this is an upper part. And the question is: how far is it from truth? How many of them are there? Many of them there are there. All right. So, what is known? I was told I should not write on the blackboard. And so, I will erase and write on the green board. So what's known about this question? Really, the only case with which anything was known before our work, as far as we can tell, is that in one dimension. That in one dimension, so in one dimension, we only need to look at the pairs of sets which intersect, right? By Helley's theorem. So in dimension one, we are talking about what's called interval graphs. So interval graph, so vertices of the graph correspond to intervals, and two intervals are joined by an edge if they intersect. Let's say this is. That's it. And so they were studied and they're counted in various ways. And the best result is by Gabo and Paul from 2008, which were the proof that this is asymptotic to and plus big O and log log. Log, log n, end of parenthesis. So it's an asymptotic for logarithm of the number. The result has since been twice worsened, not improved, worsened, because two groups of people consider the same question independently improved worse bounds. Okay. I will not mention them for obvious reasons. Okay. Okay. Okay. It's a base of the log is the same as the base of the X. It's asymptotic. So it's upper bound and lower bound. And the upper bound, I'll show you right now. So let me just prove an upper bound for this. So upper bound, actually, easy lower bound is this. And let me explain why. So take your Take your n intervals, okay, by perturbing the endpoints slightly. You can assure that the endpoints are distinct without changing the intersection pattern. Okay, I will skip that argument, it's easy. So then basically, your intervals will look something maybe like this. Okay, so I'm just drawing them one atop the other because they're all post on the line. And you're just going to just record. So this is my interval one, interval two, interval three, interval four. I'm going to just record. interval flow i'm going to record in which order this um i if i swift from left to right i see endpoints of which interval so this is the two n endpoints two n endpoints and just i record permutation of these endpoints and there are that many permutations and this clearly determines the intersection pattern of my of my intervals okay this is the upper bound and so really the content of this what they did okay that should it's not the one thing it did in that It's not the only thing it did in that paper, but kind of what they did, what I'm referring to, is they had a construction matching this and matching it fairly well to some other terms. And okay. All right. So what did we prove? We proved an asymptot an asymptotic, if you might say. For this konesotic theorem, this is new myself with AMSI. So, this is theorem one, I suppose, goes to be theorem two. So, this is actually equal to exponential. So, first term, of course, is the same. The second term is minus, sorry, two plus log pi squared over six. Over six and let's be go of log n. Okay. So this is this is the answer for interval growths. And for the kind of some sense of say, I'm not sure, I think it's to me it's more interesting is the higher dimension analog. Well, in higher dimensions, we could not prove. In higher dimensions, we could not prove something so precise and pretty. This one, no, it's a log n. Yeah. Yes. Yeah. So yeah, so this is, this means this is, yeah. So we have determined this thing up to a factor which is polynomial in n. This is maybe a better way to think about it. Right, in higher dimension, we could not prove anything so precise. And I'll explain later why. So instead of to claim that we actually prove some sharp results, we take logs. It's easier to prove sharp results on a log, right? So we have an asymptotic for the order of magnitude for the log. So the logarithm of the number Is sandwiched between two constants times and the log n. So just to remind you, the trivial bound from Halley's theorem was n to the power d plus one. So this is one lower power of d, but it's got a log. And this is the correct answer. All right. Okay. Good. Okay, good. And we even have a theorem three, which I will just say for people who know about this, we have analogous results for de-collapsible complexes. So in some sense, you can think basically a bound for Hallis theorem is basically bound for collapsible complexes. And this shows this is sharp. So log of the number of them, so which is called G, it's this is that bound was correct. So n to the power d plus one. n to the power d plus one okay so i will not talk about collapsible much but again for people who know what those are um this is uh third result all right so let me uh tell you about um theorem two because it's kind of more exciting and then i will make some comments about theorem one etc and then we'll start all right so let me So let me prove theorem 2, which is this higher dimensional thing. Of course, we need to start with dimension 1. So let dimension 1, okay, I showed you upper bound, right? And let me show the upper bound on F1. So this is big. So how does it go? It goes as follows. I will have two kinds of convex sets. Have two kinds of convex sets. So, um, so half of my convex sets are going to be just single points. A single point is a convex set. So, um, so it's going to be n over two points. And then each other convex set, there are also n over two of them, is going to be an interval which is convex of two of these points. Okay? Okay, for example, this, this, and that, okay, etc., and you can easily see with some work that basically almost every choice of these intervals is going to give you a different intersection graph. So, basically, you're going to get a bound which is roughly speaking, again, I'm lying slightly, but this should give you an idea. I'm choosing for each. I'm choosing for each interval. I'm choosing n over two endpoints. Sorry, and choose two, and I'm doing n over two times. So that gives you a factorial type of upper bound. Okay, so if you don't care about this constant, that at least gives you one dimension. Okay, so of course, our dimensions are more interesting. So let's So let's do the upper bound on the number of derepresentable complexes. So just remind you, I have convex sets C1, Cn, and I want to somehow. And I want to somehow efficiently encode the intersection pattern using very little information, very few bits. So what I'm going to do, I'm going to look at d-wise intersections of this convex set. So if I have some mu, which is collection of the indices, I'm going. Indices, I'm going to look at the intersection of the corresponding sets. So this is this definition. And I'm going to project them down. So, okay, here is a picture. Let's just do. So down means I'm projecting to R1. So let me just draw a handful of convex sets, not a big handful, small handful. Handful, small handful. Okay, so there are three convexes in this picture. I'm looking at in this picture, it's these two because it's a flat board, and I'm taking it to parallelize in the station and projecting them down. So here is the projection map pi, which projects to R1. So I'm going to look at sets of the form pi of this. So, okay, so now I'm pretty an intersection. Okay, so now I'm pretty intersection, it's a convex set, possibly empty, but it's okay, it's a convex set. I'm projecting down, I'm going to get an interval, possibly empty, but an interval. So in this picture, I'm going to say for intersection of this and this is going to be this. This is one interval, then there will be some other interval here, and then there will be some other interval here. Here, and then there will be some other interval here, approximately speaking. Excuse my imprecise drawing. Okay, so I got, so I have now this, I have a bunch of intervals, and now I'm telling you that I can now recover my complex from the interval graph of these intervals. So, I'm going to look at the interval graph. Of all of this collection, and I'm saying this gave again, I can recover the nerve of this family of sets. How do I do that? By a simple claim the collection of sets, so C one, C one C. Sigma so is non-empty. So I'm intersecting a bunch of sets, possibly more than D, if and only if whenever I look at intersection of D, many of them, so sigma, sigma, every projection is non-empty. This intersection. At this intersect intersection, so let me just repeat. I look at all detouples of sets. In this case, I have to look at all pairs of sets here. I project, I get a bunch of intervals. In this case, I get these intervals. And I'm saying if all these intervals intersect, then these sets which I start with also intersect. This is the, so that allows me to, so this tells, it gives me criterion when is gives me criterion when is sigma an element of my nerve okay now why is that this true of course one case one case is clear so if the intersection is non-empty right there is a point somewhere here in the intersection is going to be in interest in all of these smaller intersections and therefore projections will intersect so this is Therefore, projections will intersect. So, this is an easy case. What about the opposite case? Suppose all these intervals intersect. By the Helley's theorem in dimension one, there is going to be a point in common. So it's going to be some point which is in all of these intervals. So now I can look at the pre-image of this point under this projection. So it's going to be hyperplane. So I'll call this hyperplane H. So, I'll call this hyperplane H. And I'm now going to look at the intersection of H with all of the convex sets which I just talked about. So I'm going to look at H intersect C1, H intersect C2, etc. So in this picture, these are also just intervals, but in general, H is D minus one dimensional. So it's going to be a bunch of D minus one dimensional convex sets inside H. Inside H. So this is a convex in D minus one dimensional space. And every D of them intersect. So that means by Halley's theorem, again, a theme of the conference, that there is a point in common inside the plane. So therefore, that's it. They intersect inside H. This is the end of this pool. This is the end of this proof. So, this is of the claim. And therefore, what we obtained, we obtained that the number of directors complexes, since we can encode them in integral. So it's at most F1 of N choose D, basically. Okay. Plus, you might need to worry about intersection. Intersections of size bigger than z. So you need to again you need to multiply by two times small lower terms plus bigger of something small because you need to record other sets of size d minus one intersecting d minus two etc but those lower the terms so really it's essentially what we're proving this is at most this and now we can use what we know about dimension one which is um uh Okay, let me just plug it in. So, therefore, f1 of n is going to be at most two n choose d log n choose d plus lower terms. And that's the upper bound. Questions? Okay. Okay. A lower bound is, of course, we need to construct many distinct nerves which are representable. So here's how we do it. So I'm going to give a construction on 2n convex sets. So instead of n, I'll just use 2n for convenience. Again, it just changes variables. It will just for indexing purposes. It will just for indexing purposes, it will be easier. And much like the construction which I showed you in dimension one, which use two different kinds of convex sets, points and intervals, I am going to use I'm going to use two different kinds of candid sets here. So there will be, I'll call them A's and B's. One through n, index one through n each. So that uh and I will all I will also select n n interval graphs. So n interval graphs g1 to g n on the same vertex at one frame. That month frame. Okay, say GI is made of, okay, I'll be in, I'll say, of intervals, which I call I1. So this is, so the I, these are intervals representing that interval graph. Yes, Attila. Sorry, did you need to write log of Fp? Yes, thank you, thank you, thank you, thank you, thank you. You thank you, thank you, thank you, thank you, thank you. F D F D and yes, because this was the bound there and then plug it in. Thank you, Attila. Okay. All right. So I select n interval graphs on the same vertex set. And now I will now construct using those interval graphs two n plus n convex sets. Okay, so first n sets. Okay, so first n sets, which I will call A's, are going to be line segments in the plane, which are arranged in the convex position. So this will be my A1, this will be my A2, A3, etc. These are my A's. They are like analogous to points in the dimension one. Then inside each of these intervals, I'll put a copy of this. I'll put a copy of this interval graph. So they say inside A1, I'll put a copy of G1. So I'll put a G1 here. So in other words, inside this line segment, I'll just put intervals which look like this intervals for G making up G1. So I'll let me draw them. So I'll not draw them all because it's going to be very crowded. So it looks something like this. I just drew two intervals here. And similarly here, similar here, similarly here. Similar here, similar here, similar here. And I also choose some point P here just for convenience. And what does my set B B? So if I'm interested in B J, I'll just take a convex hull of all the intervals each index by J. So here, there is a Jth interval here. Okay, there is also the Jth interval here, Jth interval here, et cetera. So in each copy. So, in each copy, so I'll take a convex half or unions of all of these guys. So, this overall i. And okay, I also just add a point just to make picture nice and pretty, P here. Okay, and so what picture looks like is that I'm just doing this. This is a convex hull of this, all of these guys. Okay, and this is my convex set, BJ. Now, I can now, so from interest, I can recover now my interval graphs from north of this collection of families, because if I'm interested in intersection of the B's inside one of these AIs, so this is non-empty if and only if the intervals corresponding. The intervals, corresponding intervals, intersect. Right, because I'm asking whether it's BJ and BK intersect inside AI. This is exactly. So I can now, so from the nerve, because from the nerve I know whether it's empty or not, I can recover all this and interval graphs. And so this gives me a lower bound on the number of z represented. On the number of z representable, on sorry, two representable in this case, because I'm just showing you picture. So this gives me a bound for f2 of n. It's basically f of 2n. My apology, because there are two n sets. That's f1n to the power n because I'm selecting n integral. Selecting n integral graphs on n vertices. So, this is the lower bound. Again, plug it in, expand, you get it. All right, so that's that's really all. And a higher dimension, of course, as you can see, see, it's going to work exactly the same way. There is none. When you choose the j's interval from each, it doesn't the order doesn't matter. You can order them also. No, everything is labeled, right? The j's one is the one which has labeled j. One which has labeled J. I'm not sure I understand the question. Which one is the J? J has so this memory interval interval graph means it's a labeled interval. So there is a it's a my graphs are labeled. So there is a first vertex, second vertex, zeta. So there is a jth vertex because vertex is labeled. It will change my graph, right? Right. Labeling does not matter too much because at the end, the bound we are getting is x and to the d log d log n. So even if you're going to divide by n factorial, at the worst case, which of course you should, it's still not going to change the symbolic if d is at least two. And for d equals one, you need to check curves separately, but it's okay. Okay. All right. Good. So I think I have a couple of minutes, if the chair agrees, to tell you what happens in dimension one, why we can get their sharper result. And the short answer is because we don't need to do any work. All the work was done before us because the only thing we do, we relate in numeric. We relate enumeration of interval graphs to enumeration of other objects called interval orders, which were already enumerated. So, and that's where hard work was. So, let me just basically tell you what interval order is. And this I'm telling you is because perhaps something similar is going to be helpful in higher dimensions, but I don't know what the appropriate object is because interval orders are clearly better behavior than interval graphs. So, what's an interval order is that if you have intervals, Intervals so these are intervals interval order it's a partial order where the interval one interval is less than the other interval in that order if ij is to the left, completely to the left. The left of the IK. This records more information than just whether they intersect or not. They're going to so if they don't intersect, that either ij is bigger than ik or other way around. If they're incomparable, that they do not intersect. So incomparability graph of the interval order is going to be interval graph. So it has more information. So trivially, so if you do know about So, if you denote by number, say, by H of N number of interval orders, then what we are getting is that since they contain more information, this is upper bounds, the number of interval graphs, trivially. And what we prove, this is really what we prove, that this is We've proven the quality going the other way direction. So we have some kind of injective function which takes an interval graph, does things to it, and spits out an interval order with two more vertices. And then we just invoke the results that you already know. Okay, that's a short story. And I think that's about what I That's about what I wanted to tell you, and thank you very much. Very nice. I have a question. Suppose you have equal our convex set are equal equal both. What happens with that? Okay, so in that. Okay, so in that case, the number is going. So, if convex, let's say, balls, or balls, the number is going to be much smaller. So, say balls, then the answer is going to be factorial type. Okay, I will think what the Kashi constant is, but it's going to be that kind of answer. And the reason is even more true that for your sets are saying this constant will. This constant will depend on the following is true. If you have sets which defined by, say, system of polynomial equations and equality, some algebraic sets of some fixed complexity means there are only some degrees bounded by some constant, okay, then this is going to be true, okay? Again, with constant depending on how complex the bound on degrees and dimension, okay, and this is a consequence of what's called Warren's bounds, okay, so there is. Bounds. Okay. So there is a fairly general bound on the number of sign patterns of the polynomials, system of polynomials. So that's this kind of, and the lower bounds, okay, tend to be easy to construct for this kind of things. And some special case for graphs, you know, this is a general result by Sauerman, which shows that this will get this bounce is overshot. This would work for hyperactive? Sorry? Sorry, hyper rectangles boxes. Well, upper bound, sure. Lower bound, I'm sure. Usually, this can be started out at Saman's results works only for graphs where it's written. So, but yeah. Yes, Pablo. So, yeah, for uh nerves and complex uh of oxygen effects, we know quite a bit. As you mentioned, for colds things are much more difficult. Cults things are much more difficult. Is there any intermediate structure between them that would be interesting to study? None that I know, but maybe you can find one. Yeah, about if you have some weakness, for instance, up to homotopy. Can you say something about homotopy? I don't know, maybe some we have a complexes and because maybe geodes permutation actually has. By how much you mean by uh sorry nobody and its intense or no no no I'm talking about uh nerves that nerve can eventually nerves up to homotopy so you're counting homotopy classes of nerves of uh of the representable complex uh on n On endpoints. How likely is it that they are the same? Oh, very likely, very likely, but how likely? I have no idea. Yeah. But here in some permutation, but not the permutation. No, permutation is not a big deal. It's only factorial. It's a factorial. It's factorial small, but multiple. No idea. Rotations here, but I'm not no idea. Short answer. What about nerves slower dimension than what you are considering? They one skeletons, what for are two? One skeleton. Can you get everything? You can, if you have that complex, right, you have a one-dimensional scale as well. Yeah, I see what you were asking. Yeah, it's like in the nature of a place of point. I cannot answer on the spot. Sorry. Give me until dinner time. So let's post all the questions to dinner for after the next walk. Thanks, Ethan.