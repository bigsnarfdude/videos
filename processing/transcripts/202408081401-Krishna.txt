People who are also participating online. So I think I decided to interpret the prompt for this conference as let me tell you about a like tool or technique that somehow I fall back to constantly, like every day, every day that I'm thinking about math, somehow raised some picture and factoring them in whole ways has sort of become a really important strategy for a lot of things that I've done. And so I'm going to try to give you sort of like a baby toolkit. Like a baby toolkit, if you need to maybe want to implement similar techniques. And so, for me to do that, I sort of need to start at the beginning and tell you a little bit about grades, some of which you'll already know. So, let's recall that Bn is usually how we call the braid group on N strands. And we usually denote this by By, you know, it's a group, so we can write down like a group presentation: sigma 1, sigma 2, all the way to sigma n minus 1, such that you have some relations, which for today I'll just denote by the close and bar relations. And I'll tell you a little bit about what I actually mean by that in a second. But just remember, what you have n strands are all oriented in the same direction down, and these sigma i's are recording. And these sigma i's are recording for you how adjacent strands are passing over each other or whether they're passing like over or under each other. So, for example, sigma i is gonna mean this, where this is strand i, this is strand i plus 1, and sigma i inverse is going to be the same set of strands, but the process has become the negative prostitute. Okay, and so for the remainder of the talk, I'm gonna. The remainder of the talk, I'm gonna, I like get very, it takes me a long time to write sigmas, so I'm gonna introduce some notation, which is that instead of writing sigma i, I'll always just write i, and instead of writing sigma i inverse, I'll write i bar. This is like probably pretty standard, but I just want to introduce this to you if you haven't seen that before. Okay, so now I can tell you what these close and far relations are. So, what are the close? Are. So, what are the close relations? The standard set of close relations are the following. Oh yeah, so you have sigma i, i plus 1, sigma i is this. So, what does this picture look like? You have adjacent strands, and you have, this is sigma i, sigma n plus 1. This is sigma i, sigma i plus 1, sigma i. And this is sigma i plus 1, sigma i, sigma i plus 1. Okay, so these are like, if you ever look up the braid group anywhere, like this is what they're gonna be writing down as like one set of relations. Oh, and this is true for all i from 1 to n minus 2. Okay, but there's sort of another set of close relations which are rarely. Another set of close relations which are rarely written down but are super helpful. So here are some bonus close relations which is implied by this, which is that sigma i, sigma i plus 1, sigma i, but now I have inverses on these two, which is sigma i plus 1. So the inverse, like the, it's like the regular grade relation, but like the inverses got moved to the left side. Got moved to the website. And let me just draw a picture of this just to convince you that this really is a valid grade word, or sorry, grade relation, like when you're thinking about it in terms of isotopes. Okay, ta-da! Yeah. We're all very happy. The crossing just slid down the slide. Okay, so these are some bonus relations that are going to show up a lot today. And then finally, I have to tell you about the Today. And then finally, I have to tell you about the phi relations, which is just that sigma i, sigma j equals sigma j sigma i when i and j are far away from each other, meaning that their distance is at least two. And you know, this is just saying that here's sigma i. Here's sigma i, here's sigma j down here. And you know, you can just do this. Okay, good. So this is probably familiar to many of you, so sorry, but this bonus relation is so useful. And we're going to see it in one minute come into play. Okay. So. So, why should you care about braids? Because you're a low-dimensional topologist, you already do. So, I don't really have to convince you, but you know, there's like the one-two punch of braids and not low-dimensional topology. The first and the one punch is the Alexander theorem, which is like now 100 years old, which says that every link in S3 can be realized as a closure of some braid. And then, how might different braids for different knot be related? That's famously Markov's. That's famously Markov's theorem. So Markov's theorem says that if, oh, I should just, I mean, I think, what is the closure? You draw the braid, and then you just, like, attach the top and the bottom without introducing any new crossings. That's just the closure. That's how you produce a link inside of S3. And so Markov's theorem says that if beta 1 and beta 2 represent isotopic links inside of S3, Represent isotopic links inside of S3, sorry, beta 1 and beta 2 represent isotopic links in S3 if and only if beta 1 and beta 2 are related by three sets of moves. The first being these grade relations, the second being stabilized. Stabilization and destabilization. So, this just means that you take your braid and then you sort of do a randomized your one move to create an additional strand. And finally, you can do conjugation. Okay. Are there any questions about anything I said so far? No. Okay. Okay, good. Okay, so the thing I want to try to convince you of in this talk is that if you are really good at implementing these three moves, you can actually like, it's very helpful in actually proving theorems. And so I want to sort of, as a proof of concept, I'm going to prove for you something that everyone here. Something that everyone here already knows. We're going to prove that the figure 8-0 is antichiral. And we all know this. Okay, but maybe I should say something about this. The thing I'm about to show you sort of didn't happen by accident. I was sort of trying to remember, like, what's going on? I was sort of trying to remember, like, what's the problem? I was thinking about ampichirality for other reasons. And then I was trying to think, like, oh, how do I remember that 4-1 is ampichiral, like, in some sort of diagrammatic way? And the only thing I can remember in that moment was like the proven column Adams of the Mount book, which is very nice. But he has this long kind of complicated sequence of diagrams. And, you know, I was like not anywhere where I had any books nearby. So I was like, oh my gosh, that's horrible. I don't, that's not. And it's also not something I can generalize either. And it's also not something I can generalize easily because I sometimes find like working with actual lock diagrams hard, you know? So the thing about braids is that they kind of help you provide a little bit more structure. And if you're really good at applying more bug theorems, you can actually like, I think it's a little bit easier. Okay, so if you want to prove this, what do I need to do? Well, I know that 4, 1 can be realized as the closure of 1, 2 bar, 1, 2 bar. 1, 2 bar. Okay? And so if I want to prove that it's antichiral, then I need to think about the mirror of this grade. So that's going to be 1 bar 2, 1 bar 2, right? Because I just need to switch all the crossings. And so now what I want to show is that beta is isotopic to its mirror, or that beta and the mirror, by using Markov. By using Markov modes. Okay, so we're gonna do that right now. I feel like I hope no one hates it, you know? Like, there's other ways to prove this, but I came up with this one by myself, so I was like quite pleased on the random two standard or whatever. Okay, so let's do it. Okay, so I have one bar, two, one bar, two, and if I stare at this, I guess I just. And if I stare at this, I guess I just erase some of the relations, but it's not immediately clear what relations to apply. Because I don't see, like what I had before was, I'll just write it here for, you know, I had this. The thing I had just erased was I had this, two what I just erased. I have this to what I just erased. I'm just writing it here for reference. But if you look at this braid word, there's not a clear way to apply that. So, what do you do? You change it, so you can't apply that. So, I'm going to do some creative spacing and underlining in a second. So, if you're taking notes, it's on purpose. So, what I'm going to do is I'm going to change this into, I'm going to have like a one bar one, because those are canceling. It's like a canceling pair. Looks like a canceling pair, but braids. Like this. I didn't change anything. And now what I see. Oh, you know what? I'm so sorry. I wanted to start at the other one. Sorry, sorry, sorry. Oh my gosh, I've already made a mistake. Okay, sorry. I want to start here. Okay, so what I'm going to do is I'm going to do one. I'm going to do that same thing. I'm going to create a one, two, one, one canceling there. One canceled there. And now I see that I can apply the relation that I drew over there. So let's do that. So I'm going to indicate the part where I'm going to apply the relation by underlining it in orange. So what do I get? I'm going to get 2 bar 12, this lonely 1, 2 bar, 1, 2, another lonely 1. And now there's another place that I can apply a grade relation, because I didn't use. A grade relation, because I didn't use this lonely one, so I'm going to use it now. So this is 2 bar, 1 bar, 1, 2, 1. 1 bar, 2, 1. Is spacing working? Okay. We'll see. Okay. I did everything okay, so that meant. Yes, okay, everything is. Okay, everything is. Oh my god, I know how to do this so well. And now I've forgotten everything I've ever learned or ever done in my entire life. Can I remember any Beyonce alerts? No, I can't even do that. Everything is bad. Not bad. It doesn't work. No! All I know how to do is worry! No. Okay, it was worried. I'm so sorry, I did it in the wrong place. Sorry, I did it in the wrong place. I was trying to convince you that I was really good at this by now, but like it's very stressful. Okay, I'm gonna do it here. Sorry, okay. So I'm gonna do two bar one. This two is the same. Two, one, two. Two, one. Okay, this is much better. Okay, why is it much better? Because now I can cancel this 2, 2 bar. 2 bar, 1 bar. Right, this is good. I'm going to do it again. I'm now going to conjugate. I'm now going to conjugate by this 2 bar. 1 bar, 1 bar, 2, 2, 1, 2 bar. So I conjugated that element around the other side. Okay? Okay, and now what should I do? Oh, I'm going to do it again. So now I have this other two bar here. I'm going to find my regulation here. So this is going to be one bar, one bar, two. One bar, two, one, two, one. Okay, and now I'm really happy. I'm going to conjugate again. One bar, two, one, bar, two, one, one bar, and now these cancel. Okay, oh my god, my heart is beating so fast. Okay, we did it. Okay, we did it. That's good. So, again, like, maybe this is a little bit, maybe you think it's a little bit silly, but I think the point of this exercise is that Exercises that, like for me, this is easier, believe it or not, this is easier than doing like isotopy of a knot because I have control and I can keep track without an iPad of like what I move where. I can't do that when I isotope a knot on paper at a time. Okay. Oh, it's so much more stressful. We also did more than three power. I didn't read that sort of rate in. Because I didn't use kind of getting it. Use conjugation, yeah. Well, I used conjugation, but I didn't use stabilization. Excuse me is like closed-brace isotopic. Yes, I did prove that it's closed-brace isotopic. Better. Yeah, just better. Oh gosh. Okay. Wow. Okay, well, hopefully you're like, that was something. So, um, okay, so now for the rest of the talk, what I want to do is sort of show you how. Show you how I was going to say, like being agile at applying these relations and when you see them in the wild can actually be very helpful and sort of give a hint of how it's like showed up in practice for me in some of my recent work. Okay. Do we hate it? No. Yep. I love it, bestie. He loves it. Ty loves it. That's great. Okay. I think we'll lose the best one. That's good. Someone loves it. Okay. I'm going to do another one. It's going to go better. Oh, God. No, it's going to go worse because I just said it out loud. Okay. So, great. Okay, so this is like a little intro. Like, this is kind of going to be a big switch of topic. So maybe some of you know about this kind. So, maybe some of you know about this conjecture due to Ken Baker. So, Baker conjectured the following. He conjectured that fibers strongly quasi-positive knots Represent distinct smooth concordance classes. Okay, and so if you know what strongly quasi-positive means, that's great. If you don't, just think That's great. If you don't, just think braid positive, that's fine. If it does talk. And so another way to say this is that if you have two fibered strongly causing positive knots and they represent the same concordance class, then in fact the knots were isotopic. And so why did he conjecture this? Or like what was some of the motivation? The point is that either this conjecture is true or the slice ribbon conjecture is false. False. And because then, yeah, if you had two fiber strongly causing positive knots representing the same concordance class, but they were different, that would give you a knot which is ribbon but not slice. Okay. Okay. So using this, wait, did I say the wrong thing? Did I say it again? Did I mess up again? I went. Yes, I must try the. I'm on. Yes, I'm at 50. Oh my god! This is the worst. I'm so. I should just like give up now. Okay. It's gonna be okay. I'm gonna redeem myself. So. It's better than that. Oh my god! I was trying to tell you that this now. I mean, like, I did, you know, let's go. It just feels so good. It would be so much work. Encouragers. We're doing cool. Oh, yeah, okay, okay. So. Okay. Okay, okay. So, motivated by, okay, so I wrote this paper with Hugh Morton, like what a guy, the Edm and Humphrey. And we proved a bunch of things in that paper, but one of the things we proved was the following. We proved that. We prove that every L-space naught of rate index 3 represents a distinct concordance class. And so And so, I mean, what's the relationship between these two things? Well, you know, L-space knots are examples of fiber-storming quantum positive knots. And in general, they're kind of very hard to tell apart from each other. So this was one derivative of Baker's conjecture is that L-space knots should represent distinct components classes. And so we proved that for Braden Dix 3. And so I, you know, we have proved a bunch of other stuff in the paper, which I don't really want to talk about. Other stuff in the paper, which I don't really want to talk about, but I do want to kind of mention one cool, one cute corollary of this era. Here's a nice corollary. Oh, I guess the thing to emphasize again is like, you know, if you have fibered, strongly quasi-positive resonance of the same three genus, they're really hard to distinguish in concordance. That's like the theme, and that's one of the reasons. That's like the theme, and that's one of the reasons why this is a conjecture. And that's why one, you know, this is a theorem. But here's a nice corollary. So there exists infinitely many positive frame knots representing, oh, I think that hyperbolic. Hyperbolic positive rate knots representing distinct concordance classes. Distinct concordance classes such that the following hold, such that as g4 goes to infinity, the number of knots, or I'm going to say g here, as g goes to infinity, the number of guns. I'm going to say g here. As g goes to infinity, the number of knots with the four genus equal to that g also goes to infinity. So, you know, as g gets really big, there's like an even bigger family of hyperbolic positive radons that all have that genus, that three genus and that four genus, but you know, are still representing distinct concordance class, and they're also hyperbolic. Okay, so that's nice. So, what I want to do, though, is kind of focus on Is kind of focus on this theorem. And I want to tell you a little bit about how thinking about grade factorization or like factoring grades in big ways was sort of a really essential observation if you're trying to prove this. Okay, oh yeah, so what's the first thing we need to know? The first thing is a theorem of Bafa'i and Li Bafa'i. And what do they prove? They prove that K is an L space naught of break index three. of Brady 63, if and only if K is realized as the closure of some braid, but that braid has a very specific form. It's of the form 1, 2 to the t, 1 to the 2s, somewhere t is greater than or equal to 3, and s is greater than or equal to 0. So this is really important because now So, you know, this is really important because now we have some kind of classification, I guess, of L-space knots of grade unix 3. But again, oh, I guess before erase this, but the theme or the thing I'm trying to emphasize is that if you have fibered, like if you have positive grade knots and they have the same genus, it's really hard to tell them apart. So let me give you an example of a concrete example of two knots with the same, or excuse me, two. With the same, or excuse me, two grades, which are going to be really hard to tell apart. Look at my notes. Okay, so here's just, I think, an illustrative example. So I'm going to let beta 1 equal 1, 2 to the 7th times 1 to the 4th. And I'm going to let beta 2 equal 1, 2 to the 8th squared. And so, you know, And so, you know, it's really straightforward to see like these knots have the same, these grades have the same vibe. And in particular, the 3 genus of a closure of theta 1 is going to be equal to the 3 genus of a closure of theater 2. You know, they're going to have the same 4 genus. And in fact, you can do what I was doing when I was thinking about this. You have your computer open and you have KLO open. And KLO lets you can put things as a braid. And KLO lets you input things as a braid, which is amazing. Oh, that's a. Oh, that should be the reason we care about braids, because KLO lets you input braids and then take links as those closures. It's amazing. It's amazing. Okay, using KLO. I think that might be like Kyle's trip. You know, like, he's really good at using it. He's really good. Shout out to Kyle, who might be here over Zoom. Okay. But in particular, you know, when you use KLO, they can compute the signature. And so you do that. And so you do that, and it tells you that the signature of beta 1, beta 2 is equal to minus 12. And you're like, oh my! I have, wow, so, you know, I have these two knots, they're both grade positive, they have the same 3 genus, they have the same signature. So, like, how am I going to tell them apart? Like, what fancy am I going to have to use? Yes. Well, you're going to get ahead of me, so, like, hold on, let's. You're gonna get ahead of me, so like, hold on, let's go. They do actually have the same alexander hold on, though. Yeah, okay. But, um, but then, you know, and I was like, Joey's boot salon. Oh, I was like, that's going to be, I'm going to find that hard. Okay. So, and then I tried to figure out what do I do now. And then the next day I woke up and I said, you know, let me try something. I actually didn't get a paper doing that. Yeah, that's true. Gage, who are you? You did. I didn't. I can use on your rebranding. Use everything to rebrand, but I can agree with her problems. What am I going to do? What about the SM group? It's going to be the same! We know, yeah, it's going to be the same. So, but you know, one day I woke up and I said, hey, Markov's theorem. And then, bam! I proved that. I proved that. How did I do it? Using braid factorizations. So this time I'm going to try again. And we're going to see how it goes. I'm so nervous right now. Yeah. Uh-oh. There are already classifications of freebirds. Why couldn't you just? Because, okay, that's a good question. Well, because, okay, I was doing them, like, doing some examples by hand, and then I wanted to prove a general thing. A general thing, and maybe, I mean, you know, you have mercedes classification, but it's not always easy to like put something into that form, right? Like, this is something Diana and I talked about with a bunch of people at the Bridge Union conference a couple weeks ago. Like, if you have the Bridge one, two, knowing which one it falls into is actually like, well, I can do it. I did it then. No one was watching me, but then I showed everyone. Anyway, so. It doesn't gel out a public view. Yeah, I do. Because there's all these negatives that come. Because there's all these negatives that come up. Okay, so what I'm going to hopefully try to convince you, well, we're going to prove this. But I'm going to, along the way, sort of introduce like two very useful facts to know about if you're thinking about grades and thinking about factorizations, which if you're working in the wild at home in your office or whatever, then you too should know those things. Okay, let's see if I can do it. So, I'm gonna do it. Okay, so. Okay, I'm going to do it. Okay, so let's prove it. So, what is beta 1? Beta 1 is 1, 2 to the 7th times 1, 1, 1, 1. So, I'm going to write this as 1, 2 to the 6th times 1, 2. Take away the parentheses, I don't really want them. 1, 2, 1, 1, 1, 1. Okay, I didn't do anything. I just like factored out a 1, 2. Now, what I'm going to do is I'm going to start applying. Because I'm going to start applying, I'm going to apply a brain relation here. So this is 1, 2 to the 6th, 2, 1, 2, 1, 1, 1. Okay. And now I'm going to do it again. This one. 1, 2 to the 6th. 2, 2, 1, 2. 1, 1. Now I'm going to do it again. Okay. Here. Next, so two, two, two, one, two, one, one. I want to get it wrong. Okay. Too many ones at the end at the end. There's too many ones at the end. Oh, this is announced. Good to have a lot of ones. Oh, good. And now. And now, oh no, this is where I'm going to stop. Okay, good. Okay, now I know what I'm doing. So now notice I have this like 2, 1, 2, 1. So I'm going to write this as 1, 2 to the 6th, plus 1, 1 to the 6th. 2, 2, 2, 1 squared. Okay, and I'm going to conjugate. You're going to see why in a second. 1, 2, 3, 2, 6. 2, 2. Okay. Because now you see this and you're like, wow, if only the ones in the Wow, if only the ones and the twos were different, then I could combine these back together and get something to the eighth. Wouldn't that be nice? Yes, it would. But you can do that because of the following fact. I'll call this fact number one. The fact is that 1, 2 cubed is the same as 2, 1 cubed. And more generally, so this is called, I'll write it in a second, this is like something about full twists. And so in general, And so, in general, and in general in the N, you have that n minus 1 times n minus 2 times 2 times 1. If I take this whole thing to the n, this is equal to 1. This is equal to 1, 2, n minus 2, n minus 1, 2. And this is called the full twist. And it's usually denoted by delta squared. Okay, so with this fact in hand, what I can do is now I can change how this line looks. So this is by fact number one. So I'm going to get 2, 1. So I'm going to get 2, 1 squared, 2, 1 to the 6th. Okay, good. 2, 2. Okay, so I have 2, 1 to the 8th, 2, 2. Okay. And now you might look, oh, she didn't erase this yet, and be like, wow, if only the twos and the ones were different. The twos and the ones were different, were exchanged, then I would be done, right? Because I have just compared that to what I have over here. And so, wouldn't it be nice if there were a way to switch those? And there is, and it's called conjugation by the Gar side element. So that's going to be factor number two. So the Gar side element Denoted by delta. So whatever I'm about to write down, you'll see like that delta squared is like that delta. So look at this. So who is it? It's n minus one. It's n minus 1 times 2 times 1. It's like the triangle. n minus 2. 2 1. Big product. I'm taking it this way. Okay? Oh gosh, my handwriting is so chunky. Okay. Okay. It's okay. Okay, so I want to tell you two facts about the Garzaite element. So, fact number, or like two sub-facts about the Garza element, I guess. So, the first thing to know is that if you take sigma i times the Gar side element, this is Gar side element times sigma n minus i. And then the second is sort of what I was trying to say before: that delta squared is the full twist. Okay, so now with this fact in mind, what should I do with this? But I left off here, so what should I do? I should conjugate. So I'm going to write this now. Conjugate, find the Gaussian element. And so what I'm going to get is delta inverse 2, 1 to the 8th, 2, 2, times delta again. And now I can just going to start, like, push the elements of the braid, like, Push the elements of the braid like through the Gar side conveyor bone onto the other side. And when I do that, I'm going to end up with delta inverse, delta 1, 2 to the 8th times 1, 1. Okay, and now we're done. Yay! Okay, I did it. Okay. Okay, good. So what was the point of this example or exercise? One is because it was actually useful, because I literally had these nails. Useful because I literally had these and I was like, What should I do? What should I do? What should I do? And I was like thinking about different concordance and variants, they all kept coming up the same. And it wasn't until I tucked a bunch of them that I was like, Maybe they're the same, and I should just see if they're the same. And then I did. And then, of course, like the benefit when you do something like this is that you can generalize it to like a big family, right? Like, you can generalize by putting sprinkling n's and m's, blah, blah, blah, whatever. Okay, so, um. Okay, so I wanted to say one more thing about this example. Oh, yeah, the other thing I wanted to say is that, like, the Lafayette-Lee-Lafay theorem gives me a way to sort of say, like, they have to look like this. But once I had this factorization trick that I had employed, then, deployed, I guess. Then it meant that I could put all those L-space notes. It meant that I could put all those L-space knots of great index 3 into a standard form. Like I could say, it has to actually look something more specific than what they said. And so it allowed us to prove the following proposition. So there are at most the four of Q over three distinct. L-space knots of rate and X-3. But in fact, like a lot more than that is true. Because I had put them into the standard form, that meant that I could actually compute the signatures of, oh, I'm sorry, sorry, I forgot an important part. With G4 being the same as T. Same as T3Q. Sorry. So I can compare, and now I have this very finite list. But in fact, because I had this factorization trick that I had used and that I could put them into a standard form, I could use that standard form to find a really, really nice way to compute the signatures of them using the Goren's matrix. And so, in fact, moreover, Moreover, they have pairwise distinct signatures. And so, you know, they're not actually at most, there are like exactly this many. And because I could compute their signatures, because of the grade factorization I had picked, I could actually do that for all of them. Could actually do that for all of them. And I should say something stronger. It's not that they're pairwise distinct, it's that I can compute it all the nose in terms of that great word. Okay, so I think I have like eight minutes. I started three minutes late. So in that time, I sort of want to emphasize a different way in which brain factorization sort of matters. But maybe before I do that, I should. Maybe before I do that, I should ask her questions. Oh wait, I could have kept that. This is like now a different section. It's going to be completely unrelated. So a lot of people who are here have seen me talk about talk fallations and about the L-space conditions. Todd foliations and about the L-Space conjecture before. And I spent a lot of time thinking about constructing Todd foliations in manifolds and by gain surgery along S3. I'm like, what's the TOD foliation? What's the L-space conjecture? That is like a whole other 50-minute talk. So like, I'm not really going to say much about that. But, oh, but you can have to be later. But, you know, I do want to emphasize or just mention this theorem that I prove, which is the following. So if K. So if K is a positive rate naught, then for all r less than the genus of k plus 1, r surgery along k has a top lesion. So why Why would I approve this? Why would I, you know, what is the, what is the point of this, and what's the top, like, what's, why would you do this? Again, I don't really want to talk about it. But the point is there's some pretty explicit construction that's kind of the bulk of this paper, which goes into studying positive brain knocks and their monodromies and other things. But the thing that I want to emphasize is that, which I never mentioned in talks, is that there's That, which I never mentioned in talks, is that there's a construction in the background, and the construction is sensitive to a brain stackization of k. And so, I want to emphasize that by just giving you like a little example of that. So, here's just an example to demonstrate sensitivity to factors. To factorizations. I'm going to draw a little like schematic. So I think this is enough. I'm going to make it a little bit. So there's going to, you know, there exists a not k, you know, a positive rate not k, like a You know, a positive braid not K, like I was talking about before. So I have my not K, and I can have two different braids, beta 1 and beta 2, and I have that beta 1 and beta 2 are both, you know, different braids representing K. And then, you know, I can apply, you know, the black box. You know, the black boxed construction to these braids. And you could think about what happens in what range of slopes can you construct populations. And if I had chosen beta 1, then I would have gotten them for all r less than 4/3 the genus of k. genus of k. But if I had kicked beta 2, then I could have done it for all r less than twice the genus of k minus 2. And so what is the construction? Like don't worry about it. It's just something. But the construction like in this, for this grade, there's a lot worse than for that grade. And you might be concerned being like, well, what if the genus of K was kind of small? Well, don't worry. Well, don't worry. There exist knots K sub M such that K sub M is in some family fancy K and the genus of K sub M goes to infinity. So this gap can get really, really big. And so one of the things that was very tedious and difficult about pretty much. And the difficult about Purdue's theorem is like you don't have a standard form for all positive grades that's like helpful. And so you really care about the factorization that you picked. And this is what's true for all positive grades. But that's the best you can do if you try to, if you didn't, like if you were handing me a specific one, then I might be able to do much better because I can't over there. But proving something better all the time is really difficult. Is really difficult, I think. And so, what is the key? You know, what's the difference between those two rays? Because the output is so, you know, is quite different. So, the difference, or like here's like a vague, you know, hand wave at the idea for this discrepancy is that, or how do you, like, how do you, what do you do? Is you try to push. Is you try to push crossings into and out of certain columns to I have a specific word I wanted to use. Okay, to make their distribution, to make the distribution of crossings, to make the distribution of crossings unbalanced. Okay, so like, what does that really mean? It's just that I think what I'm trying to emphasize with this idea that I remember. Idea that I wrote over there is that sometimes you're really useful when you're great or you're not half a lot of symmetries. You're like, I want to use those symmetries. Ah! Oh, I knew that was coming. Okay. But, you know, in this case, you actually don't want too much symmetry in the braid because having too much symmetry sort of decreases the construction less effective on that braid. You want to like make it as To like make it as unbalanced. Thank you. Couldn't you tell? That's what I was saying about doing this. Unbalanced as possible. Okay, so the last one thing I want to say is like this idea in general is certainly not due to me. Like I would think that it should be attributed to Sebastian Botter, who maybe used it first, and then also Levio Lichti and Peter Feller used this idea in a lot of different ways in their own work. But it was really important for me for like. Was really important for me for like for this hero. Okay, I'm gonna stop there. So does unbalance mean, like it tells it a word, you're sort of getting rid of as many sigma ones as possible. And then getting, once you've done that, getting rid of as many sigma twos as possible? Is this sort of like you're sort of stacking all the words to one side? Is that that's sort of it. I mean it's a little bit more subtle than that. I mean, it's it's a little bit more subtle than that. What you actually want is, like, to you think of the cop the columns of the brave like parody mod three for some reason. And then you're trying to push and pull things in and out of different columns based on what those columns are, 1, 3. But you're right, you're trying to decrease the total sum of some of sigma 1, but increase it on sigma 2 or something. And there's like, can you, once you've set up what your requirements are, can you, are you effectively getting like some kind of normal form that maximizes how unbalanced this is? Can you plug it into a computer and make it through this? You say that like one more time, so sorry. So I'm just wondering, like, you've got this condition, sort of, you want it, as unbalanced as possible. Yeah. Right? So is there some kind of, given a grade word, a positive one, is there a. Is there a normal form? Like you can put it into. Is there some canonical form that makes it most unbalanced? You can always get to it. There's an algorithm you can do almost with your eyes shut. Yeah, yeah, you can just say, like, for any positive grade you give me, like, there is a form that will be very unbalanced. You can say that. But, like, it's a, but, but I guess the point is, like, unbalanced is not unique. Like, you've got a different. Unbalance is not unique. Like, you could have different braid braids that represent the same knot, but might be different unbalanced ones in some optimal way. But that's okay. I just need to know that there's one. But do you care about actually finding it? Yep! Because in these examples, it actually mattered. My bound was much better. And how do you find it? I factored raise on paper in my office. Right. So could you do this? Like, are you guaranteed to be able to do this for any product? Are you guaranteed to be able to do this for any positive radar? Like, to me, human being? Yes. Great. Okay. I think they've answered our question. Is there a web of understanding of Elsevier samples that we're reading about? Oh, that's a great question. So I think the answer might be no. Oh, we're recording. Okay, well, I think the answer is no. But I think the reason is because, you know, Cameron Gordon had his conjecture. You know, Cameron Gordon had this conjecture that hyperbolic L-space maths were always grade positive. And this conjecture turned out to be false due to work of Baker and Cable, who found an example of a fiber strongly quasi-positive, like four-braid, like four-braid knot that is an L-space knot, but it's not braid positive. And so, like, I mean, you might be able to classify them, but it would be a lot more. Able to classify them, but it would be a lot more subtle because, like, now you're working outside of brain positive, you're working strongly quasi-positive in general, and that's like a little bit more. Oh, I mean, when you find in a more balanced way and you um sort of range of boundary slopes, do you know whether the is there any technique for showing those topologies together the same? Populations that you get are the same as the ones that you get when you get out. I think they're probably the same in every way that you could try to measure. Like, they should have the same homotopy class of two-plane field, you know. Which is maybe the strongest, like, you know, that's much stronger than like Euler class, for example. So, like, I think that you wouldn't be able to. So like, I think you wouldn't be able to tell those apart. Like, I think they're kind of like... They can have different floral limits. But like, okay. Yeah, but I don't think they do. Because if they did, I would be really happy. And I have been thinking about that for the past some number of months, as you know. Yeah, Allison had a question, maybe. Yeah. All these movies. Uh, all these moves themselves preserve the very isotopy type, but is there a set of moves that maybe change the isotopy type but aren't guaranteed to preserve the concordance? Oh my god, see that? Sorry, say sorry. Are there any moves that preserve the concordance class? Break moves, like that break the isotope that keeps on. Oh, well, okay, so I um I don't know if I can do like a super precise answer off the top of my head, but I can say that like you know. Say that, like, you know, Peter has done a bunch of work talking about like cobordisms between Taurus knots, and so that's not a concordance, right? Because I said, because they're not concordant to each other. Taurus knots are never concordant to each other. But, like, I think my instinct right now is to say, like, he, there's definitely some kind of moves that he employs, which I can't, like, reproduce right now. But, you know, he's thinking about them from a concordance point of view. That's a bad answer. That's a bad answer. There may not be a set of children. Is there not a result with Rudolph that you can like raid every basically Basically you've got to put it in a annual time to I and then you have yeah I'll try and remember the paper I think it was Mark Hawaii Market Marks. Mark Hughes. Oh yeah, Mark Hughes has some paper, but braided surfaces. We could braid some surfaces. Oh no it's a maybe free to be on now. Oh no, it's okay, yeah. Oh okay. Hey. Listen. Oh my god. Me? No. I also like this trick, but I've never stabilized and had it do anything for me. Yeah, you know, I have, it's never come up for me either. But I think, you know, anytime someone mentions stabilization, I feel like it's wrong to not mention this beautiful paper of Hugh Morton, where he. This beautiful paper of Hugh Morton, where he proves that there's a four-braid whose closure is the unknot. But you have to stabilize the braid and then do a bunch of stuff and then destabilize it to get to the trivial empty grade. And so I think that paper is really cool. It's really short. It's like two pages, three pages. And I think it kind of is showing you that braids even once are. Is showing you that like raids, even once representing a fixed knot type, can be very complicated. Even if you know the braid index is strictly less, you sometimes have to go up before you could go down. But stabilization doesn't ever come up for me, no. But maybe it will. If it does, I'll tell you. Any further questions for Sue? Alright, next meeting again. 