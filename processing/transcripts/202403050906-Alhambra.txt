It's a bit of a bit of an experiment, I guess. Uh 'cause I was actually asked to do a tutorial and I wasn't sure really exactly on how to do it. I mean I don't particularly feel that I'm the one that knows the most about any topic regarding one computation, but you know basically what I thought then was okay so what how I've been thinking in the last year or so? Basically what I've been thinking was graph proposals because I'm an engineer faculty so what I'm doing at the moment is writing graph proposals. So basically what I'm gonna what I'm gonna what I what I want to kind of talk What I want to kind of talk about now and share with you, and hopefully, also you can share back some ideas and some opinions, is the things that maybe have been puzzling me and have motivated me to write the Gramposta. So hopefully it's interesting. And yeah, I'm just going to start with some general ideas, very, very, very simple. And then actually I want to move on to some actual calculations to maybe motivate uh one of the ideas that I that I want to explain. Um and yeah, I guess this this so this this two kind of thing that David was asking was actually that that one of the grants was successful. Actually, that one of the grants was successful. So, this is the European project that we got together with Fanta and Antaniel and Martin and Titani, who's not here. So, we got some European project, which actually has to do with more or less topics. Trying to understand what's going on with this quantum advantage, quantum simulation, and so on. More or less the motivation. Yeah, we have a nice acronym, so I think that maybe helps us in. So I think that maybe helps us in getting your anyway. So I guess I just want to start with something that you all know, which is, you know, what's the existing, let's say, established experiments on quantum advanced, which has to do with random circuit sampling. So of course this is the Google paper, right? Where the idea is, there's some sort of theoretical computer science argument showing that sampling from a random circuit is difficult, right? And there are very nice complexity theoretical arguments that I don't feel like I really understand. I don't really feel like I really understand very well how integral with polynomiality and p and gapy and so on. So I don't want to enter into this because I actually don't know, I only know very superficially. But anyway, there are some nice arguments justifying this reasonably solid theory for us to believe that there's a quantum advantage. And of course I guess there are some issues with this type of approach. With this type of approach, I guess, no? One that I guess I think is the case is that this type of uh random circuit sampling seems hard to verify. So, the verification doesn't seem to be available, it's more or less what I understand. So, in the Google experiment, they sort of managed to do it because it was kind of the right size to do that. And then another thing, of course, which is which is maybe the main point here, is that the the calculation they do is not necessarily useful in practice. Maybe there's some application for these things, but I don't know. Nothing that I that I know. Nothing that I know. And of course, there are caveats, you know, so this is quantum advantage. So you typically say that it's a moving target. In particular, for instance, in this paper here, they actually move the target for a big term, because they show that there's a polynomial type algorithm when there's actually noise in the circuit. Anyway, yes, well, I just kind of want to want to set the context a little. But now I want to talk about what is kind of really puzzling me. See, what is really puzzling me is something I read What is really puzzled me is something I read here. Oh, I don't know where much else. Yeah, this one. Yeah. So this is kind of a review article. I don't know how many of you know this. It was published not even a few years ago. And it's called Practical Quantum Advantage in Quantum Simulation. It's written by these people here. And if you look at what they claim on the abstract, I find it intriguing. And basically, what I would like to kind of do is to understand. Of two is to understand what's going on here, and to make sense of these claims and to kind of make sense of how far we can go into kind of rigorously establishing the claims that are written down here. And in particular, what's really surprising to me, and I don't know if it will be to you, but if it is and if it's not, please share it with me, is the following. It's a sentence in the abstract, right? And basically, what they say is that the first practical quantum advantage already exists in the case of specialized applications of analog devices. So, what this means is that So, what this means is that there's already some experiments, even like dating like 10, 12 years or so. In particular, I think of called atoms, where they track a lot of atoms and they let them interact, some tracks. And of course, with this, they can explore some phenomena in many other things. And basically, what they claim is that for this type of thing, and for specific scenarios, in particular things like dynamics into dimensions, which is meant to be hard to simulate, then this disadvantage has already been achieved. So, I guess my question is: what does it mean? How rigorous can we make this? Maybe I guess people have different opinions. So, if you have one, then please share it with me. I think James was saying yesterday that he has very strong opinions about this. So, feel free to share also. Yeah. And actually, there's actually a blog that they have that is one of the things I want to explain a little bit because also, the thing I want to bit because also the thing I want to do later in the work is explain a little bit what is maybe the theoretical evidence for this type of for this type of plot or this type of argument. And this is basically plotting the following. So you have system I think is in two dimensions and where you simulate the dynamics and they compare different ways of simulating it. So so so so the the this plot is basically time, so the time the time of experiment, the time that the system is is running for, the simulate the dynamics, versus the simulation error, okay. Versus the simulation error. So there's no systems, actually. And what they see, for instance, is that, of course, this blue curve is obtained with some sort of sensor network, like everything. And what they see is that the system evolves in time, and at some point, there's an exponential. So the error you run into is exponential. And this is, of course, because the, well, intuitively, this is because the entanglement in the system is too large to be captured by the touch network as much. And then you can kind of compare. Um and then you can kind of compare this to to what's happening in analog and and for Toleran vegetables. These are these are actually like numerical calculations that they they do. And here for instance what they see is well they they find that there's um so they have some analog simulation where they basically assume that there's some sort of error and this error propagates. So your simulation time. And the idea is also what I want to kind of explain a bit more later is that this error doesn't propagate very much. In particular, you know, it it goes up with time, but maybe it does so in some sort of like linear fashion. In some sort of linear fashion. Yeah, and then I guess for Frotter and Vigita, which is basically Trotter questions. I don't get how they find the error or analog simulation without simulating it. So I think all you need, I mean, what you need to do, I don't know too much of the details, but basically you assume that you have some sort of coherent error in your Hamiltonian. So you're not implementing the actual Hamiltonian. And so, this may be some extra term or something like this, and this is an error in the Hamiltonian, which also can appropriate into the error in the signal that we measure, the expectation value that we want to measure. And of course, this is kind of growing with time. So, the effect of this perturbation is going to grow with time. So, that's more likely the area. This is actually what I want the calculation I wanted to do later. Perfect time evolution. Perfect time evolution, yes. I believe it is for a I should have checked this. I believe it is for a, okay. I should have checked this actually. I believe it is for a 2D model, but I'm not sure. Maybe just one dimension. Yeah, I mean, I guess you could do similar processes for other things. Somehow, maybe here the commentary is kind of meeting this case. You can understand more or less what is going on. Although actually, I kind of want to claim later, but there's no mathematically rigorous argument for this, actually. As far as I know, I will make it later. What's the vertical axis? What's the vertical axis? Oh, the vertical simulation error. So it's capsuling, right? So basically, this is saying that, yeah, so if you have, so I guess here what is fixed, actually, maybe I should have said this more carefully. What is fixed, I believe, is somehow like the computational cost of your algorithm, let's say. So you fix the computational cost, and of course, the longer you want to simulate, the bigger the error is going to be. So that's why this is kind of going up. And yeah, here, I mean, so then it's very clear what's going on. So so here what's going on is that if they fix the one dimension, and then for a given one dimension, they want to reach an arbitrary time. One dimension, they want to reach an arbitrary time. Of course, the longer the time you want to reach, the bigger your error, right? In particular, at some point, it's going to turn exponential. So, I guess at this point, maybe your tension network is capturing the entanglement of your system, and then at this point, it stops doing so. Do you have an argument for why? No, no, I don't think so. And this is kind of, I mean, I guess this is a problem, no? That in the end, I mean, this is, I don't know if that's my I don't know if that's if my question is for you all is what are these ways you can do it? I mean, this is like moving targets and like you know we have this kind of 2012 comparison of the best algorithm at the time available as a tensor network method, comparing this with a time evolution from Josem Lambache from Marathon, where we outperformed in a sense the classical simulation. But in the meantime, tensor network methods have been developed that go further and strong. And I think now the regime that's very detractable is. Regime that's very detractable has been more or less mapped out as new methods in hands and only this can this can keep growing, no, the classical. I mean, maybe people come up with so many new methods also, no? Yeah, absolutely. I mean, I don't know if what you're doing is basically shifting this to maybe a blue curve to start here or something. So actually, funnily enough, there was a paper today in the archive. I don't know how many of you saw it, and the title is something like what I'm talking about here. And okay, I don't act, I mean, this is recorded, right? Anyway. Recorded that. Anyway. I just skimmed it for like five minutes, and it seems to me that they're doing kind of the same thing. They're comparing their quantum simulation with presumably pretty good algorithms with cancer networks and also with some neural network states. So in that new paper, they also do something similar. The argument is somewhat similar to the one here, also. And any other claiming is correct, right? And I would say probably it is, there's actually a point of advantage here. Advantage here, but I guess I want to understand in which sense it is correct. Maybe the best you can do is just compare with whatever the best method you have. Anyway, this is kind of important. So are there any more comments or questions? Yeah, so I guess, I mean, this kind of this is maybe something I already said. No, is that the This is maybe some something I already said, no, is that of course the the one use for quantum advantage in this in this business of course we I mean I don't uh it doesn't seem to me that we can prove uh sort of a separation between P and B, which is really what we would like to do here now, because of course what this plot is suggesting is exactly that. There's a clear separation between P and B. So I guess I mean, ideally we would like to prove this, but of course I don't think we expect to be able to do this. So, what this means really is that actually the complexity theory that's going on in here behind this type of claim is completely different to one of random circuit experiments. And it's completely different actually in a kind of thing about way because we don't understand the room for making rigorous claims seems to be much smaller, I guess. So, in that case, what does it mean to have this practical quantum advantage? Uh the answer is the answer is I don't know, no, and I also have an another answer which is, you know, maybe we're overthinking it, you know, we shouldn't consider care about this. Once you care about this, but yeah, no. You know, this is a bit of a puzzle, and I don't know exactly how to solve it. Again, maybe it's not really a puzzle, but people are making big claims also. Okay, so maybe just to maybe actually set the problem a bit more. I mean, so what is really what is going on here? What do we want to measure in this experiment? In particular, in these analog simulations of many amino granules. Of course, the species. Many ways I mean dungions. Of course, it's physics problems, and physics problems of particular kinds of systems, which are systems of spins, no, or of strongly coupled spins, or electrons, no fermions, and so on. And basically anything that has to do with quantum materials. So very large configurations of quantum systems. And I would say that maybe one interesting thing that you would like to understand is our phase diagrams. So actually the shift, the the kind of problems that we that we that we interested here maybe they're also a bit different to the ones people tend to think in computer science. People tend to think in computer science, not a decision problem. So that doesn't mean that you can maybe phrase things like that. So a little more specifically, what kind of things are physicists interested in? Maybe you all already know this, and maybe what I'm saying is obvious to you. I kind of want to give very different definite examples. So, what are the flowings of electrons and materials and so on that we care about? So, there's one that is very important, which is the one people always mention, which is the lowering. Always mentioned, which is the low energy phase diagram of the Hauer model. The Hauer model is a system of fermions, so it's a fermionic operators, which are interacting in some lattice. And you have somehow like two fermions per site. And what's special about this model is that it's this term here. Because this term is the one that makes the fermions interact. And basically, what it means is that you have the lattice, and whenever there's two fermions in one spot, this term is somehow a repulsion between them. So this means that at that point, this electron. Point these electrons are somehow repelling each other. This complicates the interaction a lot because if you didn't have this term, then this is a very simple Hamiltonian. It's a very simple Hamiltonian you can do with refermons. But this model, once you introduce this, it gets very complicated. The phase diagram, people are developing like hundreds of different methods of for solving this. And there's and of course there's some reasonably good understanding of of what's going on, but of course there are many important wisdoms. But of course, there are many important questions. And I guess the idea behind this is that this is really modeling how electrons are transporting certain kinds of materials. And for instance, maybe with this, if you understand the phase diagram of this, maybe you can understand things like high-temperature superconductivity. I mean, I think there are a few steps in the middle. But this is the kind of thing that, you know, people think is the killer of this standard of it. And of course, there's other things, you don't know, like one thing that is very nice, of course, is topological. One thing that is very nice, of course, is topological order, which is trying to explore exotic phases of matter in these simulations. And there's others also that I cannot like, because they have to do with statistical physics, which happen maybe more at high energies, at finite temperatures, and so on. And for instance, have to do with the transport of quantities in your system. So you can think that this Hamiltonian, or another Hamiltonian, has conserved quantities like energy and charge and so on. And you want to know how they sort of move around. The dynamics, how does it move them around? And how does that sort of transport? Meaning, you know, sometimes what you see is something like a fluid spreading around, spreading your system, so that you're conscious of quantity, maybe you can even look at it as a fluid. But how is this fluid picture, this hydrodynamics picture that is both, how does it emerge from the microscopic description? This is also a non-trivial problem. And for instance, one thing that people like to understand is the difference between diffusive. Understand the difference between diffusive and ballistic transport now, where there are models in which somehow there are conserved quantities that have some sort of quasi-particle picture and they move very fast. And in many others, like for instance in quantum chaotic and so on, there are quantities like the energy that actually spread diffusively. So it's like a random block. And you want to understand when the difference can happen, for instance. And then apart from that, there's more things. So this is this KPC, which is for instance another type of scheduling, of transport. Of transport, the Cardan-Paris exam, I think it is, which is kind of an anomalous thing that happens also in quantum systems. So, you want to understand the whole picture of the phase diagram of quantum transport. And more in general, of course, you also want to understand the dynamics, which is actually what the experiments are in the one from today, and also the extreme of one of IVM, and also many others. This is kind of also what they're any more questions, comments here? Okay, so it's some considerations about the problems actually, or the phrasing of the problems. One thing that is, I don't know if it's kind of known to you or obvious to you or not, is that typically in this type of context we care about things within the magnetic limit and materials and so on. So a natural assumption to make is that your Hamiltonian extra is invariant. It can also have disorder, but the disorder is kind of. But the disorder is kind of sample in the same way in every site. But basically, somehow, typically in the conditional problems of computer science, you don't want to make this assumption, right? You want things to be different every side, because you want to, for instance, when you have circuit to Hamiltonian mappings and things like this, you don't want this default because you want to be able to encode, for instance, you want to be able to encode computations in the grand state of this model. If you have transit invariance, that seems to be. Of transitional invariance, that seems to be like a lot harder. So, I mean, I guess this is a, but this is a very natural assumption from the physics. We're okay making it, but in particular, also because these models are well-defined, the thermodynamic can go to infinity. And I guess in this type of problem, really what we care about is the approximation error, not really the system size. So we want to make claims about the approximation error of expectation values in the thermodynamic limit of quantities, for instance, like this. Dynamic limiting, quantities, for instance, like this, where n goes to quite large. And the expectation values we usually care about are things like total magnetizations and so on. Maybe things also like correlation functions. And again, also, well, one good thing about this is that, I mean, with this type of thing, maybe what we can do is to actually prove phase diagrams to different kinds, low temperatures, or at high temperatures, and so on. And one good thing actually is that this phase diagram. And one good thing actually is that these phase diagrams, in some sense, I mean, at least if you're away from phase transitions, they seem to be more or less stable to perturbations. And actually, you know, I would say maybe to actually draw a phase diagram, maybe the sort of qualitative results. I mean, maybe you're okay with not knowing exactly what the phase transition is, but you just want to understand the diagram in some sort of qualitative way instead of being very quantitatively precise. So there are some things that maybe you don't necessarily care about as much. And all these things, I guess, are kind of maybe good news for advantages, for instance. So that's kind of what I want to make a bit more well what I'm going to make a bit clearer. And I guess the good news for this is that in this type of simulation experiments, we don't necessarily care about the operation. We don't necessarily care about the error corrections. And one reason for this is actually the, you know, many of the problems have some sort of inherent stability to errors. And maybe it doesn't make sense to you, but actually in the next few minutes, I want to kind of write it down a bit more specifically what this means. So yeah, and there is a physical reason behind this that local quantum systems are stable in what seems to be the right sense for this type of thing that we care about. And actually what this means is that the error rate in your experiments, so for instance, the error, the error. Rate in your experiments, so for instance, the error in how you predict the punion is directly proportional to the error in your signal. This is typically what happens. Which, if I understand it correctly, I mean, without error correction, this is not what happens, quantum computing. And quantum computing, you have very small errors, and this destroys the whole computation. But here, because we're not doing actually kind of generic quantum computations, we're doing something else, it seems that maybe we can do the better. And again, also, because maybe if you have some small errors and we can, and we have, we have. And we have this kind of thing. We're definitely going to get qualitative information. So even with this type of errors, we might be able to more or less approximate this face diagram. Okay, and actually now what I want to do is kind of have a bit of theory, do some calculations about what all this means. And hopefully with this, I'm able to more or less explain a little bit the plot from the beginning, with the exponential version of the other one. And what I want to do now. And what I want to do now is basically talk about the coherent errors. And now let's use the button. There's also a light for the blackboard at the end. Yeah, so since this is a tutorial and I'm not here to talk about my work, I'm going to talk about other people's work. And there's a paper actually that is maybe relevant for this type of discussion. Basically what I'm going to be the calculations that I'm going to be reproducing here. And the paper is this. And it's by uh And it's by uh Tribendi and Theor. So people in EMPQ in Match Blank in Darkin. And really the point I'm making here is basically what I was saying, that somehow many of these systems are stable to errors in the right way. Okay. So what does this mean? Okay, so what it means is that we have some Hamiltonian, which is the one we care about. We care about is a local Hamiltonian, right? It's zero. And because our experiment is imperfect, what it means is that, you know, for instance, our laser is still not some frequency, but of course the frequency is not completely correct. Errors like this, no, so coherent, not the coherence. And in this case, what you're going to implement actually in your experiment is another Hammer V, which is not the right one. It's the right one, plus possibly some perturbation, something called V. And this perturbation V, typically what's going to happen is that this V is. Typically, what's going to happen is that this read is this parameter here, it's actually like another kind of many values on the value. Maybe like a sense of organization, so one local local function. So actually, what I'm going to do is very simple. So if you know about the Robinson bounce, you know what I'm going to do. Okay. So this is what you would call coherent errors, right? And I mean, actually, they're much more common than you could talk about on the same error. I I don't mean the kind of error model that you you care about when it's error in public handler. Something else. But actually these errors are important in these variables. Especially in simulation experiments. Okay, so then what you want to approximate is so you sense you have the overall reservoir. Can you read here? Uh which is also no sorry. Um So, no, sorry. Um you have another observable sorry which is maybe just on a few sites, so a single site operator or anything. And you want to measure the expectation values evolving time in some state. This state could be anything in principle. So the picture is this, right? You have your lattice here in one dimension, always here. Okay. And actually, well, I guess in theory, what I want to make is all I want to make it, I want to make it all actually a single. I want to make it all like actually a sum of these things. But since it doesn't error, I can just do it one by one. And maybe it's actually a sum. That makes sense in the summer. I mean, sort of average. So I'm just going to look at a single one. It doesn't matter for the argument. Okay. So basically, what I want to compare is this, where this is generated by, so this is what I want. This is the quantity that we want to measure, actually. But the one we actually measure is the other one, nice. This is the one generated by the other Hamiltonian. The one we're actually doing in the experiment, right? So, what we want to understand is what is this as a function of this part. And the argument is very simple. And the argument is very simple. So the argument is basically the Libromixon bound. So the Library Mission bound, what it tells you is that both the expectation values are close to, so I'm just going to write it for one, but the same for the other. And this is close to another one, where the Pamiltonium is only supported on a regional sensor. I think Pamelium was supported on a regional sensor. I think Maritoni was supported on origin of size scale. And basically, the distance between these things is exponentially small enough. Like this. Roughly speaking. Right, so basically what this means is that what this means is that this we can upgrade with something like, so we can basically apply the during some here and here separately, and we have the error twice. Here separately, and we have the error twice, so twice the room and error. And now what we have to compare is just this difference, but only in a small region. I've written the same thing too many times, actually. Is this clear? Any questions? What else? I have a comment, another question. Why do you need, like, for all of this, you could also have local dissipation as well? Why do you restrict computer errors? I mean if you if you have a local invalid, you still have the process of the you can make a similar argument there. You can make a similar argument there. But then, I guess you need to make a structure. Yeah, so I guess, yeah, you can make similar arguments. I guess the point is that you want to barely compare this to the digital world, but you chotterize and do the charter error, right? And the error on the gate level. I think it's just a matter of fairness of comparison. Of course, that is totally right, but I mean if you have a limited audience, it's not so easy to compare this with the digital world. I think the point they're trying to make is that the query there is a lot so bad in the analog world. There is a lot so bad in the analog world as in the digital world. Okay, yeah, that's that's that's true. Right. Because you mean because the data in the limb variants is worse or not? It's harder to compare. It's not quite the same thing. Well, at least at the level of like let's say another simulation where we're not doing anything digital, uh you can make a simple sim the same argument for for Limblanians. I think maybe you need extra assumptions because basically you need that the Limblane evolution is stable. You need that the version is stable, which has to do with rapid mixing, for instance. I think that as far as it's stable, okay, just usually rub me. Yeah, yeah. I mean, for this part, you only need automatically. Right, but but I guess in your idea you don't need rapid mix rapid mixing everything, but yeah. No, just for this to be efficient. No, just for this to be efficient. Okay, yeah, see. Yeah, because otherwise the error if you don't have everything, the errors come down. So, okay, so hopefully you disappear, then we just carry on with the uppercomes. So now what we have is something simpler, no? Because now we have the Hamiltonian only on a region. And actually, maybe it's kind of easy to see that this is upper-bounded by because I'm going to have it from Stebbins. I don't know how different the norm of your servo, times two, I guess, it would be two things, times this difference. This is just from like Hudders inequality, basically. And now, but the good thing now is that these commentations are not solar. They don't depend on the whole system, not just the system. Not just this marriage, but so then you can upper one actually this by basically the difference between the two Hamiltonians times uh time. And this difference in this case is basically the delta. Delta, well it's not delta, no, it's delta times some stuff is delta times time times somehow the number of terms in the Hamiltonian of this region, right? So in the Hamiltonian of this region, right? So so basically um L or L to the dimension. And then times the norm of the individual terms in your perturbation. But this I guess you can just take it to the order one, so that's it's fine. So but now, basically this is the this is kind of the result of it. Because now what you can do is you can also optimize over L and then L basically you take it to be up here. Yeah, so L if we take it to be something like t plus log of one over delta t. And basically what you end up with is that the difference between these two things is something like delta times t to the dimension plus one. And this is the result basically. That comes from basically from just uh kind of minimizing optimizing a warehouse here. Is that clear? Any questions about this? One is that they should. Yeah, you just have to so uh so basically you provide this by what you take derivatives and you uh and you integrate the derivative basically. Okay, I mean I mean yeah, so basically you so so so this is an upper one to the derivative of this function and then you just uh at all at all points in time and then you just so since it's an upper one to the derivative you just multiply by time. So yes so that's really okay. Let me do this more carefully. So you can write it as an integral of the derivative. As the integral of the derivative. This thing from 0 to 1 this, you can have the bound by this, which doesn't depend on time. And then you just integrate on that integral of GST. It's that simple. Can I make a evocative remark? I mean, the same proof shows that this value isn't very hard, right? If you're looking, if I say if you take delta, if you take delta to be a constant and t like also like some constant time, then I just have to look at a constant number of qubits, right? Yeah, certainly, yeah. So good, so that's yeah, I was gonna mention this now, actually. Yeah. Um. Yeah. Yeah, because that's basically how you compare. But this is actually how you get how maybe you get this plot before you go. Can I check back on Kerala's remark? Where do you need the mixing time? The check semi-factorization should work for not here for plural lines. No, no, I mean it's for this quantity to be small, of course. No, so okay, so you are recognizing. No, so okay, so so you are probably missing then maybe you can get rid of time and you have a missing time here. Still the actual time. That's quite quite right. Does that make sense? I think if it's a local advantage, you can get something like this also if it's local. But then if you have a rapid mixing, then since you converge to at some point nothing happens anymore, the error doesn't grow abitral with time if you have a rapid mixing. Yeah, so yeah, because you don't have this time yet. Yeah, so now let's say yeah, so this is so this is the error. So this would be your epsilon, actually, in your experiment. So what does it mean for the computational cost? So I mean I guess this is the kind of thing that I think this type of argument is the one that motivates in the product I showed before, no, and you have this annual simulation cost and it was something like, you know, some function that was kind of. Some function that was kind of growing linearly, but not very fast. I believe this has to do with this, no? Because, I mean, I don't know exactly how you quantify the cost, the computational cost of angular simulation. No, but I'm going to tell you one way of doing it, which is maybe not correct, but one way of computing, of estimating what is the cost, would be, for instance, that the cost of your simulation is time, times something to do with times some function of your error. Because presumably the the smaller the error is, the harder it is to figure out that. Your error is, the harder it is to pick it from that model. I mean, this is just kind of a guess of what could be the estimated cost. And okay, so maybe there's one choice, which I don't know if it's correct, but one choice is maybe the cost of your algorithm is some time, and some polynomial of your delta. And then in that case, uh what you get is that your your your cost of simulation uh is polynomial in time and in in one of your epsilon or epsilon is this. Mono epsilon or epsilon is this and this is precisely this this so this being fixed constant this is what gives you this curve for this so the bound is useful only for short time right how does it compare with the experiment because the error grows linearly with time Yeah, well, because the error grows linearly with time. Well, with time, of course. Yeah, yeah. No, but I think, I mean, this is a good plan, actually, no? Because if you have this type of perturbation, you expect the error to propagate in this way. Okay. But at some point, there's something three of the observable is less than some poly. But they expected that polynomial one or something like that. Oh, I see okay. Yeah. Oh, I see, okay. Yeah, yeah, yeah. Yeah, I guess, okay, I guess, yeah, so this has to be small for this thing to make sense, than what you're saying. Yeah, okay. How does it compare with the experiment? Right. Here. Does it compare? I mean, if yeah, I guess what it seems that a simulation will come and grow arbitrarily fast, not so at some point this is gonna saturate for sure. Um Um I mean I guess that's gonna happen anyway, no? So that's uh I guess what you the what you care about is your time, obviously. So that's that's a good point actually, I think. Yeah, so if you do it well now, it's enough at all. Here's normally the normal the normal observable. That's a good point. Yeah, I don't know how it compares, but I guess what it means is that this works for short times, for smaller Which is personally the regime you care about. I don't think so, no, because well, if you depends on how time you've been running, if you change this with time and doesn't change very much, or if you can change it, not very big, I would say I mean you still have the robot internal. So small you can make maybe the agreement is technically a bit harder, no, but too small is the bounds kind of for a Yeah, I mean I don't know if something happens if you change things very fast, but uh I don't think uh well I mean no your own thing is still yeah, it's fine, yeah, change the average. When you change very things very fast, I think I would say what uh something very fast oscillating noise. I suppose that the situation. Ah, yeah, because things are more stable even, oh, yeah. I mean, that's what happens in like flow systems, for instance, when the frequency is very large, I mean, Tanya and so on. Yeah, so I guess the answer is not very much. Okay, so maybe to regarding Netanyahu's point earlier, so I guess how can we do this classically? And I guess there are, well, I would say there are two ways. So So here for now. So classically, what you do when you want to have some sort of classical simulation algorithm for these things, you want to know the cost, basically. So the simplest thing to do is to look at the Li-Rowing sound bound again. And basically what you know is that for time t, yeah, the region that you have to simulate, so you estimate this specific value. I mean, basically, you just have to simulate you want this. So basically, what you end up simulating is this. And this, you know, what's the classical purpose? Because this is a quantity supported on a region of diameter L. So then the classical simulation cost is the number of qubits in this region. The classical simulation cost is e to the L to the dimension. And from the Levromison bound, you know that L has to be time plus log 100. Not 100. Okay? Just because you want the error to be epsilon, no, in here. And then if you plug this here, what you get is p plus log one over epsilon to d. So one funny thing to note about this is that this is actually not polynomial. Is that this is actually not polynomial in one of our x? For b larger than one, this is actually not polynomial, no, it's also not quite exponential in t, no, it's t to the d. So I don't know how efficient is this actually. I think maybe you can do better. In particular, this doesn't match exponential performance. And one another another way of doing it actually is is uh okay, maybe this is the one time I talk about my work actually. I talk about my work actually. So, we had another algorithm where we don't simulate the Lee Robinson lightcomb, but we do something else. Actually, maybe I read this. I think I have space here. So, in this piece of paper, is this one? So, it's by Dominique Wilden and myself. And here we have another. And here we have another classical algorithm for this type of quantity. For this type of quantity. The idea of the algorithm basically, instead of simulating the whole icon, is that you take a Taylor expansion in time of this thing and you want to analyze how this Taylor expansion converges in time. And you can have some results of how it converges. And then you want to know what is the cost of estimating the Taylor moments. If you know how if you if you know how good how well the Taylor series converges, and you know how to calculate the Taylor moments, you have an algorithm. You have an algorithm where you can prove that that works. Proof that works. And this has to do with these cluster expansions. That's the way you actually do this tailor expansion of this type of plan. Yeah, and then for that, actually, so the result is the following. So we know how a result directly is our cost. So this is the cost of the algorithm or the runtime or however you want to call it. So for us, the cost is the following. One over epsilon, and this was an exponential here in time. And actually, there's another exponential in time. So it's something like this. So it's actually double exponential in time. But for a short time, for times are ordered one, it's actually polynomial, one over X, which is not something that you could get with this. This um right so it's I mean so it's in that sense if for like short times I mean for long times this is variable and this is way worse than you would expect in general but at least for short times we we recover the polynomial of one agreement that we expect actually. Maybe I can say a couple of words about this. Actually the reason why we have this double exponential that we leave is because this is uh this applies to systems that are more general than the ones that have Lee Robinson bounds. So for instance, this it's algorithm. So this one is o only works if you have Lee Robinson. So that means that your system is analytics. So that means that your system is anodic. This one also works if your system is k local, it's not anodic, so something like a spander graph. But in spander graphs, actually the way information is expressed is very fast, you know, and the summary the way it expresses is actually kind of public points or in time. And I don't have a proof of this, but this is kind of, I think, a reasonable justification of why we get this. So I believe, like, from as far as let's say mathematically statements of classical simulation of this type of thing, this is what we have. And this isn't, and there's no And this isn't, and that's an open question. And I would like to know if you think this is possible or not. The open question is to have an algorithm whose cost is exponential in time by polynomial in one over exponent. Maybe assuming that you have the original bounds or something like this. So, I mean, I don't know if anyone can think of an argument of why this this is not possible. Uh to me it seems like it is, no, but I don't know exactly how to prove it. Um To prove it. I think I already told some funding agencies that I know how to prove it, but I mean I will try. Yeah, I don't know if anyone has any ideas of any argument on these lighting. There's this old letter edible argument for hastings for the states, so for this one. Yeah, it was but it uses geometric deficit for headless. Was that right? In the sense of lattices, or but this is uh so is this the one the way you the way they construct the MPOs for the gift states or so on that one? Um right but I'm not sure uh they they get errors under control using these that is animal bombs. Yeah, yeah, yeah, I mean this is the simulator. Yeah, yeah. Yeah, that's the signal to signal to what we're doing here. That's basically counting the subgraphs of the clusters. Yeah, but there you are not using the geometric locality of the graphs. No, I mean actually for this we're using the K locality, not the geometric locality. But then there are installed as animal methods too. Plus those hastings are. Okay. Does that work? Maybe I don't know if that works. I mean you should be using those techniques on the Usually those techniques don't work uh yeah uh don't work for like um expander and things like this. Um okay maybe we can hit write this once and maybe I find it all okay. Okay, so maybe that's simple answer actually. Um I mean maybe that makes sense actually. I didn't think of that also. Um yeah so maybe this is the kind of the open question uh. Um Um so this uh then you this is bad news, right? Isn't some step for the claim of bad? No, I think so because this is I I believe this this scaling is the one that gives you this curve that I mean uh the how do you control the errors in the in the simulation? I mean this doesn't mean that uh as well other people remarked this this bound restricts you to Mark this this bound restricts you to small times like yeah. Eh well, but if you have a very small error node, you can go to kind of one time. So I guess if you want to go to longer, you have to go to but then things are polynomial, so if you want to go to past your error and already have one time. So, actually, I wanted to, I have another thing that I wanted to show, but I don't think I have time. Maybe I'll just mention it. Basically, so this type of argument that we run into mouse that works for expectation values of time evolution, you can also make it like, like they were saying, you can also work for like invariants and things like this. And it works for many other quantities that have to do with the local expectation value. So maybe just close with uh uh two-line argument. To lay an argument of why this argument stands to other things, and in particular the thermal expectation values, actually. Yeah, so now we want to compare. I mean, I'm basically I'm going to kind of maybe more or less repeat things that I already said, but in a slightly different context. And now we want to compare transpectation values of server. And this is the one that we made, and this is the one that we want. And basically, you can do similar arguments. So there's something called the local indistinguishability that tells you that the expectation values more or less coincide with the ones that you evaluate on a smaller plateau. So you it's kind of like a Lirones thing, like that. Roman sense thing, right? So you can look at the thermal state in a smaller region and look at the expectation value in the middle of this region, and this is a good approximation to the global one. There are some assumptions here, in particular, the assumption is that in your given state, you have a decay of correlations. But I mean, this is probably a necessary assumption. And then basically, what you need to do is the same thing as over there, no? You have to know what is the error between these two things, considering what is the difference between these two. Considering the voice difference between these two points. And this, I mean, I don't want to do it in full because I'm basically done with time pretty much. And this is, I mean, it's not just this simple step, there's like a couple more steps that are more standard, but they're a bit more involved. And I'm not going to do it in five minutes. But basically, under some conditions, in particular, holding in conditions that typically hold in, like, for instance, in 1D systems and also high temperatures. In one systems and also high temperatures, you have also stability arguments for these things. And basically, what you can show is also something like this. The error here, the error here, again, under some conditions, it goes like beta times for like, and this has, and this holds also for very small dead times. So I'm making some, I mean, of course, I'm putting things under the rubber here, but basically the idea is that for this type of problem, you also get. But basically, the idea is that for this type of problem, you also get similar things. I mean, if you want to know the full argument, we can talk about it afterwards. And also, for instance, if you have states of a gap system, so if you're like in the same phase and you move around this phase, you can use this tricks of phase things, this possibility continuation and things like this to have similar things, for expectation values in the ground state. And also for the implants, so for a variety of things. So as long as, you know, so I guess what I'm saying is. So as long as you know, so I guess what I'm saying is that there's many quantities that you care about and there are actually stable into errors in this sense. Basically that the error in the signal is proportional to the error in the your experiment, let's say. Again, seems to be necessary for good for quantum advantage. I had a question from earlier. Typically the arguments you use with the stability analysis also make things that I should be sticking with you kind of approximate the I guess, yeah, but uh yeah, so that's uh yeah, that's true. Well, maybe high dimensions isn't so easy, but uh like the intention level to dimensions, that's already um so that's that's true, yeah. So again, so maybe just to repeat Martin's point, which is important, is that actually sometimes the same reasons that allow you to make these arguments are the same reasons that allow you to have classical simulations. Yes, it's definitely a concern, but I mean I guess that means that you know at least you have some ideas of what. I guess that means that at least you have some ideas of what to find interesting routines. I mean, personally, maybe you can find things where it's like a switchboard. And maybe that's actually the thing you want to find. And then you want to go to these people that have experiments. And this is the Swiss port, I believe, is the one you should look at. So maybe that's kind of a target to look for. Yeah, I'm basically I'm I'm I'm I'm basically done with this. Thanks for it. So we didn't know recently I was trying to find some results as to like when do we know that the redrawments files are tight, like which amalgamant or so on. so on or like how how do we know that for these systems maybe the the information spreading is even maybe slower or so on do we know anything about this I mean probably the answer is very complicated because it depends a lot on the quantity you're looking at because the answer in the end is always about the the norm of this the norm of the thing of the observable yeah but probably the actual the actual expectation value of the state probably matters a lot is the only family Isn't the only family of Hamiltonians for which is known that the parameters and bounds are tight? Just three fermions and bosons, where the group velocity of the ratio propagation comes for hopping is really the e-parallel velocity. I think that's it. Yeah, I can imagine this earlier. Martin, you can put it back. Might be a nice research project to try to prove hardness to evaluate better equipment. But I think that's a good development. I guess. But for free fermions, it's quite fun. Because for instance, like I said earlier, there's cases where actually things, when these transfer and start sometimes from the way things move in the system, it's not linear. It's actually less than linear, no? But for this to happen, you need a lot of things to happen, like you need Hamiltonian to be specific, you need the state to be specific, you know, and so on. So I mean, there's really a lot of different cases. Yeah, I was just wondering if if in the context of these experiments people Experiments that people expect this to be more or less tight? I mean, I guess in some cases, probably yes, no, but I guess you have to do a bit more physics, not to do minor lessons. Have people originally brought this in MBL? I have done something similar, and there's also others. I mean, like for time-dependent factories, you get the logarithmic cone. You can really tune from a ballistic cone in the static case to a logarithmic cone. And also, in some disordered models, which are static, you can get a logarithmic cone. I mean, there's also a notion of zero velocity bounds, but this you will get for Endless localization, which is non-interacting. Which is non-interacting, otherwise, you will get a level of information which is going slowly, but not with zero velocity. I think usually you have some assumptions in these curves which you cannot trigger? Well, yeah, sure. I mean, what I said on the Nanda-Slocalization was it's a particle hopping on a line. That's a strong assumption, that's the Near model. But for those, you can really show a zero velocity bound. It it really grows and stops. It it never goes. You wait for ten thousand years, it will not propagate. 10,000 years, it will not propagate at all. Just because many body looks doesn't exist. Exactly. Thank you. Exactly for other unique assumptions because thanks for saying that. I mean, understandable designation does exist, right? So this is a strong statement, but the the lock cone things you you can also only get with assumptions. That's right. But but the but the slight cone is compatible with the MBL being a prethermal phase one, so yeah so some hope to prove it. No more questions than I guess we can go for a half hour coffee break. I'm not sure if I should be able to rest but no, I mean I have to have this analogy. I'm not sure if you can make it crazy, because even if it doesn't exist, what if you have topical space? So what is the difference between three?  I don't know if you can use a way of maps. Oh, but then I'm stellic projects. That's fine. Okay. Nice. Which is good because I have to give a talk soon on like a meditation talk on analog versus this. Meditation talk on analog versus digital versus classical simulation. I mean they don't really care about the everything about computer science arguments. I mean of course most people I mean these people might, but some people don't. I mean I once I get given a um I mean I want to have given a um a uh this is not open switches of um because um i think i would just say i'm sure it's what's going on uh the guy we didn't have but  Oh, really? I'm talking about this one. So, what do we have lines of code for these two sets? Is it? Yeah, fuck this game, man. It's absorbed. You know about this. I saw something. I saw somebody. I hadn't heard of this thing and I saw somebody playing it on the plane that my TV wasn't working. So for movies, so I was just a bit. So but like you can play PLF first. Surprisingly efficient algorithm, it's not so much. It's like you load down this time, but you just have to make that one kind of product. Surprisingly for size. Have you solved it? You know how to solve it? I think that's love. I think the substrate is a little bit more. Yeah, maybe you can call it actually. Yeah. If I charge one or two, I just take that one. I guess you can just extend I to like a maximal concentration. Take this to be considered something different. I think that'll be the whole graph. But if you have a sum over a state level, how can we balance it by the state level? Is he only doing one out?  This part is kind of saying that on file is a fully computed set. It has some reasonable reliance on this much. That'll give us a case versus an inner. I mean, the the only non-trivial thing that can solve that is both physically. I didn't mention that so both is where I was once here. This was not squared in the V D. Did you guys gain that type? It wasn't trained summons. Oh, okay. Yeah, that's the Steve Laker. Yeah. Anyway, so that's how you get the plugin this inequality to here. I've I've managed to for a long time to start rental here. It worked. No, I think it's easy to spend the model. It's more like a tilt. And then you can say, well, suppose that our contractor is again. This is a lower bound for the regular command. Back though it's the lower bound for the fractional profane. So now we're gonna assume our predictor is true. And then it has the following statement about sigma I don't I have not seen anywhere. I've not seen anywhere. So it kind of says that if the stabilizer fidelity, like if the number of vertices in this graph is large, so is the stabilizer fidelity. Yeah, it makes sense, but like, you know, so I ran through an example of like probably You know, so I ran through an example of like product state. Like this, this is a pure state. And then what do we expect the value? Take like what is n epsilon? It's the sum over all k epsilon through the k. Epsilon is like the thing that n epsilon in this case is 1 over epsilon squared. Is one over epsilon squared. Opposite of like stable edge, like a stable edge. And you can take epsilon to be one. And then this is like the opposite to be. And epsilon is this is certainly always true. Well, well, the stability is always at least one over two. In this case, you just get a low boundaries that's always at least pushed on.   So I mean I think this is a pretty so I was I was basically looking through Petrospreakus because he proves a number of things that are like kind of related to these types of types of violence but that are not. One of the new tools that we use is this a difference. So I was looking into like does that form a fractional, right? I do love it, but it's like upgrade a bell sampling or something. Yeah, you you do two bell samples. Uh that distribution is undual. I'm using the word dual key, like take a sum. He has all these identities, like you take a sum over a commuting, like you say, the sum over a subspace operator, it's typical of Q, proportional to the sum overpowers, and those are all the operating. So there's some funny things going on where Q is dual to P.  I guess maybe another way of raising the question is could we tell the So we work today. That's a big computation. I don't really have any other stuff. I was going to say about it. I think the same thing. This card always says that holder doesn't kill these guys are not completely all those games. As an approximation, let's just kill all the games we're in less than we like. 