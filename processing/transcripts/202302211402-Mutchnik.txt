And a common way of constructing structures inside the Tay-Mathematical Universe is to start with some literature. Take the class of generic or, so to speak, random examples of models of code theory. And hopefully that'll have hopefully that'll. Hopefully, that will be actually the size of it. So, a more specific way of doing this is you start with some theory in a smaller language with desirable properties. You expand the language with new symbols, and those symbols Those symbols are interpreted in a way that is generic or random. So, the goal of this talk will be to introduce a new class of generic expansions associated with a definable relation in an underlying theory. And in the case where the underlying theory is stable. Underlying theory is stable, and the relation is what one might call a candidate for being the graph of a definable rate pointing group upreach. I am going to discuss a result that shows that there's a generic expansion whose complexity, which will be beyond the level of Level of stability, but maybe still simple or much farther beyond stability. I will detect the presence of a type-defined little group that is associated with this relation. And this group will be given to us by geometric stability theory, but not Stability theory, but not generalizations of geometric stability theory to unstable theories, but rather old school geometric stability theory in the underlying stable theory itself. In particular, I'll be using Khushovsky's group of the So let's discuss this generic expansion figure detail. So So Trachidakis and Pele introduced the generic expansion of the theory with quantifier elimination. The smaller language, the underlying theory will always be assumed to have quantifier elimination in the smaller language. The expansion of the theory with quantifier elimination and elimination of existing infinities expand by a generic predicate. So what you do. Generic predicate. So, what you do is you start with theory eliminating existence. You add a unary predicate to the language. And Prasadakis and Pele showed that if you take the theory just expanded by this predicate simple, not by any new axioms, so it's the same theory at the level of the axioms. So, if the predicate is interpreted as an arbitrary substance, then this theory. Then this theory has a model computing. And earlier on, Winkler showed that the generic expansion by scolar functions also has a model computing in this setting of elimination of existence. So very few demands on the underlying theory. And then Nick and Alex showed that you can expand in this setting by a This setting by a generic function in any number of variables. And it follows that you can expand thy generic equivalence relation, if you think of an equivalence relation as a function to some extremes. So that's the basic back rows. Now, we might ask what happens when What happens when you add new axioms to this expanded theory before trying to take them all away? Now, if you just allow yourself any new axioms, then this might be difficult because you can encode too much. For example, you can encode just by expanding a generic credit case in an interpretive theory. In the interpretive theory, by new axioms, by expanding a predicate, adding a predicate to the interpretive theory and by new axioms, you can encode, say, automorphisms. The theory of generic automorphisms, even at the level of the existence of the model itself. This is its own area of research altogether. So we might get something more protestant by restricting our axioms to Our axioms to those of a particular form. So let's introduce a certain kind of universal axioms. So we start with a theory. We assume it is quantifier only relation. We make no additional assumptions yet. And we fix a definable NERI relation R in this theorem. In this theory. And then we have one option for what we can do. And this isn't the actual preprint itself on which this talk is based. But I also have another variation of this that's in some ways more interesting. So in the first version, the predicative, we add the axiom. So we expand by a predicative symbol, a unary predicate symbol, and we add the axiom that That so this the domain of this predicate will be a set of singletons, and we have the axiom that if we take n of these singletons and turn them into an n-tuple, then n-tuple will be in the domain of this n-o-re relation. And the equivalence relation version will be somewhat similar, except we're expanding now by a binary relation. And we ask that any M singleton. Any m singletons from the same equivalence class, rather than from the unary predicate, from the same equivalence class, when we form the n-tuple of those, that is going to be in the domain of the any relation R. And if this model companion exists, so the universal theory will be called T subscript R, and if the model companion exists, we'll get a generic We'll get a generic structure, T sequence. So, what do we have to say about this generic structure? So, if we make additional demands of the theories here, so first of all, we demand it has elimination of exists infinity. If it has limited of exists infinity, there's a certain kind of relation, an algebraic ternary relation. Algebraic ternary relation. These negations can be thought of as the complements of surfaces in three-space, or going back to what I introduced this talk, they can be viewed as candidates for being the graph of a range-like group operation. And so if it eliminates existing fissions, and this model contains algebraic ternary relation, I would Algebraic ternary relation, I will define it. So if we eliminate existing finity, and already we have existence of the model pre-pandemic, as long as the relation R is the negation of the algebraic term. In addition, if we have weak minimality, we, already having answered the first question of when the model containing exists, can move on to the second question of how complex this. How complex this generic structure actually is. So, first of all, it's going to be, similarly to Alexi Black Group's talk, either very complex or very simple. Either it's going to be simple or it's going to be NSOP4, but strictly so. So it will be SOP3 and TP2. And The question of what levels of complexity this can take. This is not the main focus of the preprint on which I'm basing my talk. This is really more of a result on free email donation, using results from a separate preprint based on Kodiv's work on free email donation theories. The result I want to focus on is not a question of what, but of what. What, but of what. Not what levels of complexity it can take, but of characterizing in terms of the relation itself when the associated expansion takes these levels of complexity. So how this arose was that I asked, you know, I noticed that you you always get the model companion in this situation. And I asked, okay, so is it just going to be simple like the uh Trotskynock's Pele construction? Transnocous Peely construction. And it turned out, no, it wasn't always going to be simple because it was a basic counterexample when R was just the graph of a group operation. Say if we wanted to take the generic sum-free set in a vector space over Fp. And this result essentially is that this turns out to be the only Turns out to be the only counterexample in some geometric sense. So what we're saying here is that the more complex case is going to be exactly that case where you have some parameters over which the sets define. And you have a generic or rank two point of the domain of the complement of the relation. Of the relation, which is going to be an algebraic term of your relation. And you have a type-definable, in the case of a strongly minimal theory, definable rank one group operation. And that is, the graph of that is going to have a generic, you know, consisting of two generics of the group and their product. And these two generics are going to be algebraically equivalent in the sense. Algebraically equivalent in the sense that each of their first, second, and third coordinates are going to have the same algebraic closure. And so that's going to happen in the more complex case, in the less complex case, this is not going to happen. So there's an exact correspondence. The complexity of the expansion well beyond the stable case is going to detect the presence of the group. Presence of the group, the presence of the group corresponding to this relation by means of the graph of this week operation. And then we also have this weakly maintenance case, sorry, this case of an equivalence relation, rarer than a generic predicate, where the simpler case isn't, in fact, actually going to be literally simple at all. It's going to be, most of the time, strictly NSOP1. So where it's not the graph of a group operation, you're going to get an NSOP1. Griffin, you're going to get an NSOP1. Otherwise, you're going to get an SOP3. So you're straddling either side of this NSOP1 versus SOP2 problem. So I have some results on just the model companion existing in general. So that's going to be equivalent, you know, for just a general relation. We're not looking at an algebraic term relation to the underlying theory of an FCP. Theory in FCP. There's a result, there's a model-cutting existence result for algebraic ternary relations in the context of the main theorem of this talk, supplant space. So let's define what an algebraic ternary relation is. Again, you can think of it as a surface in free space. And so it's going to be a Ternary relation. And for any point in the domain of this relation, Any point in the domain of this relation, each of the coordinates is going to be algebraic over the other two coordinates. So. You can take them as two colors? Tellering means three. I mean, telora. You can take three tuccos or oh no no, three uh just three single tips. It's gonna be in you know uh the the cube of the model. The cube of the model theory. So that's why you get only rank one. Yes, in a weekly minimal theory, it's going to be rank two, so the group's going to have to be rank one. The graph of the operation is going to be rank two, and so it's going to be rank one. So you can think of graphs of group operations as examples of algebraic terminal relations. And we have a model companion existence result that makes much. Result that makes much fewer demands of the ambient theory. Now you're only making the basic demand of elimination of exist infinity, but you're requiring that the relation be an algebraic ternary relation, and our result is that this model containing is going to exist, now corresponding to an algebraic ternary relation. And so this allows us, no longer assuming NSCP, to upgrade our results from strongly minimal to weakly minimal. Available to weekly. So. Can you go back? Yes. Only elimination of existing fit. And there's stability or anything. Sorry? Stability or? No, for the model companion in existence, stability is not yet required. Why do you need NSOP? When do you need NSOP? Well, NSOP NFC. And a FCP. Oh, and FCP? They ask if you want to look at any relation rather than an alternate tornado. Okay, okay. Yes. So going back, so we've talked about simple NSOP1. Let me just define some of the more complex classes of the stability. Classes of the stability theoretic hierarchy. So NSOPN, so we're interested in NSOP3 and NSOP4, those are going to be, NSOPN is just going to be the existence of a relation that has infinite chains, but there's not going to be any end cycles. So a strict order will have infinite chains, but no end cycle. Change, but no end cycles. It requires a bit more, but here we're just requiring the absence of M cycles. So it's open whether NSOP2 equals NSOP3. And there are results mainly from the main work of which is done in New Connect's paper and in this paper. Conan's paper and in this paper on generalized free amalgamation, giving partial results on the NSOP1 versus NSOP3 question. And like all known NSOP4 theories, these generic expansions will satisfy the free amalgamation-like properties required for these partial results. So, first of all, they'll have So, first of all, they'll have symmetric conant independence. Just to review what conant independence is, is that instead of being witnessed by, instead of the conant dividing being witnessed by any invariant, by some invariant Morning sequence, as with Kim dividing, it's going to be witnessed by any invariant Morning sequence. So, essentially, you're forcing Kim's lab onto Kim independence to get coming. What is a model sequence in this context? Just an invariant model sequence. Model sequence in any biotype? Yes. So one of the properties that these expansions have is symmetry for coherent independence. So coincidence independence could be thought of as Could be thought of as you're trying to develop a theory of independence beyond NSOP4. And for these theories, as with all known NSOP4 theories, it's symmetric. These theories also satisfy the strong witnessing property, which can be thought of as a variant of free amalgamation. And if a theory has these two properties, it all known in its OP4 through this gap. All known as OP4 fields they have, and which in particular these generic expansions have, then it turns out this is going to be either NSOP1 or strictly NSOP4, and it's going to be either TP2 simply. And this is based on work of Conant in the setting of what he calls freedom elevation theories. He calls freedom elevation theories, and then it's you know it's generalized to allow possibly NSOP strictly NSOP1 structures in my preprint on generalized free avalidation. So what's important is that all the generative expansions have the free evaluation properties, symmetric coherence independence and the strong witnessing property required to make this classification theoretic dichotomy hold. So now we have to ask ourselves whether it's Whether it's going to be in this strictly NSOP1 case or in the strictly NSOP1 case or the strictly SOP4 in TP2 or simple case. In the predicate version, we additionally get the strictly NSO, sorry, the strictly SOP4 and TP2 case. And in the predicate version, if we get NSOP1, we also get SIM case because We also get suitcases because the came independence is what we want. Scott, it jumped away very quickly. Could you remind me what the strong witnessing property? Oh yeah, the strong witnessing property, it says there is a sufficient, there's a monster model lying in the variety model, so that when you take some subset of that model, its type over the actual monster model is Monster model is going to be an invariant type that's minimal in the king divided by so now let's take a look at the actual connect independence in these genetic expansions. It's going to be a natural independence. A natural independence relation. In the case of the predicate version, it's just going to be inherited from the underlying forking independence in the original statement theory. In the equivalence relation version, it's going to be this underlying forking independence plus this additional independence criterion on On the equivalence relation. And seeing as we know what the coniant independence is, whether we're in the simple case, or in the strictly SOP1 case, or the more complex case, is going to depend on whether the conance independence, which we've already characterized, satisfies Satisfies the independence theorem. This is the Kim-Pele criterion for NSOP1 developed by Kaplan and Ramsay. So we know the more complex case is going to be a failure of independence theorem for Kony. A failure of independence theorem for cognitive independence. We know what cognates independence is. Now it remains to characterize this in terms of the underlying stable structure and the fixed relation that we use to define the expansion. So we end up showing that there's this configuration that looks a lot like the failure of the independence theorem in the underlying stable theorem. Stable theorem that gives us a point of the complement of the relation. And that's going to be equivalent to the failure of independence theorem and therefore to the more complex case. So we've gone through our step of characterizing the more complex case of the expansion in terms of the geometry of the underlying state theory. Now let's explore this geometry. This geometry that gives complexity and expansion in greater detail. First of all, as in Leo Jimenez's talk, we can follow this strategy of reducing to the minimal case when we're in a weakly minimal theorem. So we can get every piece of this, we can get every piece of this geometric configuration to be rank one over the base. And now we finally get to our payoff, which is applying the, so this is the result I'm getting is getting the AI to be grateful over A, the AI being the pieces of this configuration. And now we get to our payoff, which is applying the group configuration theorem. So the group configuration theorem says that if you have these six points, Have these six points, and the diagram tells you what the conditions on these six points are. Any three non-collinear points are independent, while any point on the line is algebraic over the other two points on the line. And there's a natural way of producing this configuration from a stable group. And Fruschotsky proved that, you know, in a stable group. That in a stable theory, if you have this configuration, then it actually does come from a group, a definable group, a type-definable group, in a natural way, in this natural way that allowed the group configuration to fall out of the group. And the upshot is that now that we have this geometric configuration where everything turns Configuration where everything turns out to be rank one. The fact that we got everything to be rank one allows us to show that the three pieces of this configuration, as well as the A1, A2, and A3, that give us a generic point of the complement of the relation. Those turn out to form the group configuration. To form the group configuration. So we can just apply the group configuration to characterize concretely the configuration giving complexity. Yeah. Sorry? Oh. I was going to ask, should be AJ union AK there? Sorry? AI is an ACL of AJ AK minus AJ union AK? Yeah. And is R the algebraic thing? And is is R the algebraic thing or not not R? Yes, not R is the algebraic thing. Not R is the algebraic thing. Yeah. So that's what we did. We went from the complexity of the expansion to the independence theorem for Codiant's independence to this geometric configuration to the rate one geometric configuration, which turns out to be the group configuration. So we apply the group configuration theorem to set. Theorem to say what the relation actually is up to this point, this coordinate wise constants. So I'd just like to conclude with some discussion of the advantages of going from the predicate version to the equivalence relation version. First of all, you know, NSOP1 theories, they've really been studied in the past five years, where we've come up with some examples. And coming up with examples of strictly NSOP1. Up with examples of strictly NSOP1 theories is still an active area of research. And it turns out that the direction used to show that when you don't have the group GV reached, when you don't have the graph of the group, equivalent to not offering, that's going to be NSOP1. That direction of the characterization is going to be the one that uses Ruchan. Is going to be the one that uses Krushchevsky's group configuration. So we're actually using Krushchotsky's group configuration here on to construct new strictly NSOP1 theories. And second of all, we have this open problem of whether NSOP1 equals NSOP3. This is well beyond the level of stability. It's even outside the simplicity of this. It is. And when we and these and we're able to characterize the complexity of these equivalence relation expansions on either side of this open dichotomy via the geometric stability theory and the underlying stable theory. So rather than just an analogy with stability theory, this tells us that Geometric stability itself in the stable context allows us to control classification theory well beyond, even beyond simplicity, the stable region of the model theoretic map. Thank you. So, do we have more questions? What if you take a tennering correspondence with but with two poles? Like uh yeah, so if you do that uh you okay, so if you do with if you do with tuples, uh can just look at the underlying theory, you know, as the palmer of theory. You know, is the palm of the original theory. And so you're just really, the only thing that you're losing is the weak minimality. And that lets you get existence for the model of the weak minimality is really used in this reduction to the reduction to rate one for the geometric rate. Geometric for the geometric configuration. So yes, the model company will exist, but you might lose the main result, which is the actual characterization of the complexity. Yeah. What people call beyond generating like 40%? Yeah, it's the surprisingly, the proof of Surprisingly, the proof of the existence of the model container. This is actually going to use something special about the ternary nature of the relation. So maybe you can get it for an early relations, but I'm not sure how. So it is pretty serendipitous that we get the existence with minimal assumptions on T. And we also happen to get this sort of statement. Used to properly terminate the bucket error? Oh, pretty. The methods are pretty elementary. You're basically dividing this up into the case where you're basically expanding the structure. So extending the structure and just adding all the points here. You know, all the points you need to get the existential formula realized outside of the model. And then just asking, trying to define when this is actually going to be a model of this universal theory. And you break it up into three cases. And, you know, the case of three points and one point, those are only the. Points and one point. Those are going to be pretty basic. But the case of two points is we're going to be using something interesting about the fact that it's a terminal. Yes. Well, that's, thanks, Scott, again. And probably good in five minutes. Alright, uh, you can see that we work on the sound.