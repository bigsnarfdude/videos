Let's start with some little summary of the Bern-Krossover formalism. So, here I probably don't have to explain how one calculates amplitudes in string theory. Basically, you do it by calculating a Polyakov parse integral over Parse integral over all embeddings of the world sheet into space-time. And then you have to calculate the sum over topologies, the integrals over metrics, the integrals over embeddings. And external particles are represented by vertex operators. And yeah, we used to be interested in this as a fundamental theory, but more recently we look about. We look about string theory as a nice Uber Bauer as a nice generalization of quantum field theory. And in particular, if we go to the infinite string tension limit, we can get new representations of field theory amplitudes from string theory amplitudes. And the ones who actually were pushing this around 1990. This around 1990. Well, you have attempts by sightly in before, but bring etc. But Donald Kosovo around 1990 made a real systematic effort to get formulas for one loop and Luon amplitudes from the infinite string tension limit. It took them about three years. And from And from set limits, they extracted a set of rules for the direct construction of those integrals. And shortly later, Born, Dunbar, and Shimada got a similar set of rules for the n-capital number. Now, most people will have seen this, probably. I am not going to bother to talk here about the parse integral. I just write down directly the master formula. Directly, the master formula. So the master formula gives you the n-glural amplitude in terms of a global color factor. Ah, no, no, it's coming again. So we see the global color factor here, then there's a proper time integral for the loop, for the loop particle, which right now is a scalar, then every gloon has its own integral, and then you have this Koper-Liversian type exponential, which is slightly formal because we still have to expand and take. Because we still have to expand and take the part that's linear in possibleizations. And the basic integral is made up of these Pins functions that are limits of world sheet Pinz functions. The important thing is to note that they have absolute value and sine functions, which will be important in the abelian case later on. Okay, this is as it as it stands just a skipper loop, which is the one you're not interested in in Q C D. And QCD. But Bernard Kosovo found algebraic rules that converts the scalar and the fermion or gluon. And they have another rule that allows you to go from one particle irreducible to one particle reducible. And Sensei did use this to do the first calculation of the five gloul amplitude, but Sensei abandoned it. And almost at the same time, Strassler, who was then a PhD student of Preskin, actually managed to get not completely, but a big part of the Bern-Krossover rules using directly this Boltline Parsendic will, which in that context we consider as a kind of. As a kind of string tension limit of the polyag of parsing equal. And actually, here we start from a parcel representation of the effective action, which has also the advantage that it shows everything is valid off-shell. It was not clear from Bernard Kosova. And actually, there's an integration by parts implied in the Bern Kosovo. Implied in the Ban-Kosovo formalism. Before you apply the rules, you have to get rid of all second derivatives of the Walt-Ban-Kreen's function. And Strassler also investigated a bit more that integration by parts and noted that it has also a relation to Gauge invariance. In fact, it makes abelian field strengths also appear in the bulk. And he also investigated boundary terms and found that. Terms and found that it all fits together to make up non-abelian field strength tensors. So we see the emergence of gauge invariant tensor structures at the integrant level, which I then followed up a couple of years later. I have the least found an algorithm that preserves the full permutation symmetry. It works for any number of gluons or photons. And it leads to an unambiguous result, which we call the Q representation. So we start from the P representation, where you still have second derivatives of the Green's function around. After the integration by parts, they are only first derivatives. And after the integration by parts, also you can go from scalar to spin. From scalar to spinner, say by using one of these Bern Kosovo replacement rules. This is called the cycle replacement rule. So Bern and Kosovo were interested in this only to apply the rules, only for applying this rule, but in fact, the other interesting point is that the integration by parts arranges not only creates all these. These field strength tensors, but also absorb them into traces, and that usually reduces the number of terms in the indegrin. Yeah, in fact, you can write down very compact formulas by introducing the product of what we call a Lorentz cycle and the tau cycle. Tau cycle. For example, the indegrand of the one loop for gluon or one loop for photon amplitude in this notation fits on a few lines. In reality, if you write it out fully, you will have about 700 terms. But it's nicely organized in terms of these cycles and what tails, whatever doesn't fit into the. Whatever doesn't fit into a tail, into a cycle is called a tail. And yeah, there's a tail, the tails have a length, involve a certain number of the polarization vectors. And yeah, this is the only thing you actually have to calculate. There's no need to ever do the integration by parts, except for calculating. So every time you add on one gluon or photon, Add on one gluon or photon, you have to add to actually calculate one new tail. Yeah, that is the only job left to do here. Yeah, and then when you apply this on shell, as I said, this is true on-shell and off-shell, but if you apply it on-shell, then you have to get also these irreducible parts where wreaths are going out. Parts where wreaths are going out of the loop. And then there are the Bern-Krossover binch rules that tell you you fix the color ordering and then you look just at these where you have two adjacent legs. And then whether these two legs can be pinched depends solely on whether you can find a factor of g dot in your integrand with the corresponding. Integrand with the corresponding indices. If you find the factor g dot linearly but not higher, then you just replace it by this factor here and you pinch together selects. You have the amplitude with those two moments I have actually now unified. And that can be conveniently described as a spinach operator here. Now, this is very old stuff. Now I come to very recent things. The Bank of Formalism, since it tells you essentially how to put trees onto a loop, obviously calls the full information on all the tree level gluon amplitudes with one leg off shell and all the other. Off-shell and all the others on shell, you know, because that's just what we are what we have to put on the loop. The lex that connects to the loop has to be taken off shell. And this is just what Beren Skiele introduced in the 80s, and what we call a Beren Skiele current, and they're also important for the perdobener approach and an important building blocks for amplitudes. In the color climatics duality, which was mentioned yesterday. Moreover, Berlin Zegler already had the idea that one should actually introduce multi-particle polarization tensors and multiparticle field tensors. So those are heavily gauge dependent, and they become particularly useful if you can write them in PC. You can write them in BCJ gauge, which here means that we should have these generalized copy identities. And yeah, in fact, a few years ago, my former student, Christian Lopez, Harkos, just said, well, let's get this information on these parentski currents must be somewhere in here. So let's find a way of. Let's find a way of harvesting these currents. And in fact, it turns out that what you should do is you use the Bern-Kosova rules. And actually, you look at the only Bern-Kosova diagram, which usually is discarded. That is the one where actually all the pinches are on one side. In the end, you have just one bubble hanging out, which is normally just renomerization. But here it can be used precisely. But here it can be used precisely to harvest all that current here. And it's extremely easy. You just have to apply the pinch operator successively in the n minus one of the n lex. And what you get is the Berens-Giller current. And then it turned out we got lucky because it out. All we got lucky because it automatically comes in BCJ gauge, but we had to actually work to find out why it is. And it's actually because the Burn-Crossover-pinching procedure itself guarantees this generalized Jacobia den DVDs. It has just this is the right nested packeting structure to. Jacobi identity. So, this is nice, but not really my main topic here. I want to really talk more about the Belian case, which is much more interesting. Why is it more interesting? Well, not many people apparently know that when Feynman actually derived the Feynman rules for quantum. The Feynman rules for quantum electrodynamics, he used actually parcel declared first. Feynman invented parcel declars in 48. Non-relativistically, in 1950 and 51, he applied them to relativistic quantum electrodynamics. And he actually showed, he said, well, don't look for this in Feynman papers, but Feynman papers, but essentially he says that the He says that the S matrix and QED can be constructed by writing down one pass integral for each open electron line or closed electron loop and then linking them up in all possible ways with photon insertions. And from this he got the Feynman rules and then he apparently saw the Feynman well the Feynman rules are much more efficient and he forgot about all this. And he forgot about all this, but in reality, looked at from today, one can actually see that this parcel construction has two huge advantages. First, because it avoids the breakup of scalar or spinner lines into individual propagators. This is like in string theory, basically. Any photon emission is represented by a vertex over. Is represented by a vertex operator that's moving along on a line or loop. So you don't have to break, you don't have to introduce individual propagators for all these metapropagators here. And even more importantly, nothing forces you actually to fix the ordering of the photons. So this formalism leads. So, this formalism leads actually to integrals which are valid for any ordering of the photon legs along the line. And this, of course, has a huge potential because the main reason for the proliferation of Feynman diagrams in QLD is that there are so many ways of putting photons in different ways on a line alone. In different ways on a liner loop. Like if you didn't have this, for example, the for loop G minus two would just have a dozen finite diagrams instead of 4000. The whole proliferation comes really from this. So in the abelian case, the master formula looks like this. It's almost the same. Important thing is that now all the integrals go along. Now, all the integrals go along the loop. So they're not altered anymore. There's no color factor, of course. And actually, this formula you find already in Polyakov's book before, but Polyakov presents it as a toy Polyakov parcel. And this scalar QED formula, yeah, for Formula, yeah, for polygon spin can be done by various ways, but nowadays we always do it by an additional Crasman parcel integral. That's one thing that Peiman obviously could not do and might explain why he lost interest in this. But basically, even if we decide to use a custom parse integral, there are still two options. There are still two options. We could actually use it in a workload super parcel, or we can use these replacement holes. It depends on the case. We are actually using both options. Now, in the following year, we'll talk a lot about the QD beta function at higher loop orders. Now, we just mentioned t minus 2. You might wonder why we spent years. You might wonder why we spent years working on the Bider function and not on the much more important G minus 2. That is actually because, until very recently, we did not have a good parse integral for open fermion lines. Feynman had something very sketchy, but it's not really what we want to use. For scalar open lines, it's easy, but that's only. Easy, but it's only four years ago that we actually found the really nice parse integral representing open fermion lines. So essentially, what you see here is the important thing comes here. Here you have a Gaussmann pars integral, which involves a Gusman function in the constant Gassman spinner. And basically, the integral has to be done over the psi of tau. And the leftover etas then eventually are converted into gamma matrices and give you the external spin information. But the things that we achieved and what we had wanted in this way is that we can completely avoid long direct races. Yeah, basically, the parse integral projects you directly into the Clifford algebra basis. So, no matter how many photons you put on the fermion lines, you never have to do this tedious thing of introducing commutators and anti-commutators to reduce long direct phases. So, yeah, but I won't talk. This is now going to be applied soon to the G minus two, but right now we. Right now, we have to stick with what we actually have already calculated. So just to take home message is that we are now really in a position to do any calculation in QED in such a way that we write down a pass integral for each scalar or fermion line. And keeping this advantage of not having to split lines or loops into propagators and also not to go back here. Yeah, let me very shortly discuss the first advantage because that is the one that is. Course, set is the one, set is relevant for strong field QED. Why is that so? Because in strong field QED, but definition strong field QED is when you have a field that is so strong that you have to treat it non-perturbatively. If you treat it non-perturbatively, that means you have to use Feynman rules where the propagator solves the exact Dirac equation in the field. This we can do, for example, for constant fields and for plane wave fields. But the propagators are so complicated that, for example, right now, strong field QEDs are still stuck at the one-loop frequency level. Nobody has been able to do a calculation involving more than three direct propagators in a constant field after more than 50 years of work. So, a few words about strong field QED and then I will go back to the vacuum and actually talk about higher loop. What do you do when you have an external field? The fact that the Dragon equation in a constant external field can be solved actually tells. Field can be solved actually tells you that in the Wautland formalism, it should be possible to absorb information on the field explicitly in the Green's functions. And this is quite easy to see. In fact, here set menu is the external field times the global proper time. So basically, in the Bosnian formalism, Formalism. Whenever you go from Bachium to the constant external field case, the only thing you have to do is to provide some determinant factors. Your parse integral determinant changes. It depends on the field. And you have to replace the Wordland King's functions. So there's much more continuity here than in using Feynman diagrams. So for example, the mass. So for example, the master formula for the n-photon amplitudes in scalar QED, when you put on an external field, they look almost the same like Polyakov's formula, only that now the Wordland-Green's functions have become Lorentz matrices. So that's why they now appear sandwiched here. And you have this determinant factor, which by itself would be just the Vacuum amplitude, that means the Hol Eisenberg. Amplitude that means the old Eisenberg by a scopper function. So, this has been an industry. Yeah. Is it clear that I get the same result as working without background and putting one, two, three exponent photons? Yeah. Of the world by formula, or does it at the mathematical level require a lot of tails? Well, well, okay, let's see you want to calculate the photon ambulatory. The photon amplitude in a constant background field. Well, okay, you can, well, we can do two things here. We can actually calculate the and photon amplitude in, or we can all, any, the background can also be converted in the low energy photons. Yeah. Yeah. So the formula is good for both. The formula is good for both. In fact, well, I think I will answer it along the way because we are coming to this anyway. Yeah, anyways, this has become an industry calculated photon splitting. The most recent one is Aquinas. Precisely the CN photon. There's an totally explicit formula for. Totally explicit formula for the n-photon amplitudes in the low energy limit in the constant field. This is a really complicated object, which would be a lot of work to calculate in any other way. But we can get it very simple here, simply here. Any helicity component. Also, two-loop-all Eisenberger functions, which I have no time here, unfortunately. Have no time here, unfortunately. Also, this has been extended to include gravitons. We have calculated proton-graviton conversion in a magnetic field, was never done. This was never done using Feynman diagrams. Also plane wave backgrounds, which for a long time were a puzzle. As I said, whenever you can solve the Dirac equation exactly, which is in fact the case for plane-wave backgrounds, you think that. You think that there should be a way of incorporating them into the Watson-Green's functions, but this essentially means that you can manipulate the pass integral into Gaussian form. And a priori, it doesn't look at all Gaussian. In fact, it's only a few years ago that we found a nice trick actually to rewrite this capacity as a Gaussian. Caparse integral and a Gaussian one. Then we could apply also machinery. Yeah, now we let's come to the second point. The second point that we do not have to fix the ordering is immensely interesting for multi-loop calculations. And in fact, this is the reason why I keep working on this all and all for 30 years. Because if you start writing down the four-photon amplitude in this Down the four photon amplitude in this formalism, and then you saw together two legs, you get the two photon propagator, but you get all the diagrams in one go, all the topologies with in just with the correct statistical statistical weight. Same at three loop, and anybody working on QLD knows that it's precisely this kind of diagrams which lead. Which lead to huge cancellations between terms. And in fact, this is something in 1995, there was this multi-loop work for Aspen, where it all was about the quenched QED beta function. At that time, what was known is that the three-loop beta function was pinned QD. function for spino qd is still rational even so individual diagrams give set of set of threes which cancel the for loop beta function is still rational even so zeta three and zeta five appear and cancel and david rogers just had calculated the zoo beta function for scalar qd and also found that zeta three cancels so at that time everybody believed Everybody believed that the quenched QED beta function was rational, and that ultimately somebody would manage to calculate it. But then in 2012, unfortunately, the Carlsrue group actually calculated theta5. And then it turns out that in that case, theta3 doesn't cancel anymore. So, it leaves us in a very bad situation because these cancellations are not complete. And on the other hand, there's still no much of an understanding why they happen. Now, at around the same time, actually, with Michael Schmidt, we actually found a nice way of using the parsitical representation. Pars integral representation at the Tulu level to actually recalculate the two loop beta function without basically without ever calculating any integral, just pure algebra. You do integration by parts until almost everything has cancelled and you have a single global property integral left. And this was nice, but actually bad because it missed. It misled us to actually afterwards. We spent years trying to make this work for higher loops, and it never worked. Yeah, and it actually what we should have done with this time is probably start working on what nowadays we call the fundamental problem of workload integration. You really want to use the workload formalism and make advantage of. And make advantage of this property of combining diagrams, you have to solve a non-standard integration problem. You have to be able to calculate an arbitrary integral over, well, we can always scale the tau integral to the unit circle. We can always get rid of second derivatives. So at the end, what you have to do is to calculate an integral with an arbitrary number of first derivatives. Number of first derivatives of the Green function with an exponent where you have the Green function itself. If you can do that, you are business. But the problem is nobody will help you with this. You look into the literature, you find integrals. Yeah, where do you find integrals which involve absolute values? Well, there are a couple of famous examples like the integrals of Selberg. Integrals of Selberg, our motto, meta, but these are never quite what we need, actually, unfortunately. Also, mathematical is of limited help. Actually, until version 12, it was no help at all. Suddenly, from version 13, it sometimes actually can do something useful with integrals involving signal and absolute values. Anyway, Anyway, what we have managed to do over the years is to calculate these cycle integrals, which appear very naturally. And we will see below. They're actually just giving the Bernoulli polynomials in the corresponding fermionic cycles, get Euler polynomials. And here is a formula that completely settles the problem. The problem at the polynomial level. So here you have an arbitrary monomial in factors of g dot with n variables and one variables that's integrated over. And the formula does that integral and rewrites the result in terms of the g dots or in the remaining variables. Or in the remaining variables. So this formula actually is totally sufficient, for example, if you want to program any abelian heat kernel calculation. In principle, all you have to do is to program this formula. In the heat kernel, you never get anything but polynomial factors of the Bolantines function. You never have the exponent. So now, what are the Bernoulli polynomials doing here? Well, the thing is, when we calculate the pass integral, we have to fix the center of mass. That means the actual integration is happening in the space of biotic functions orthogonal to the constant functions. Now, in this space, In this space, the ordinary derivative actually becomes invertible, and its ends inverse actually is the Bernoulli polynomial. However, with these absolute values and sine functions, and there's something special if you go in the zeros order of the derivative, actually. The derivative actually is not just minus one, which the minus here is conventional, but sorry, normally you would think it should be the delta, but here's the minus one. That's the zero-mode subtraction. Now, the funny thing is that if you restrict your the integrand to be between zero and one, you have a formula which was already known to Euler. Which was already known to Euler, and you can find in any book. However, if you do that, you are missing all the signal and Zelda stuff, and you're missing actually the opportunity of constructing a nice algebra of integral operators in that Hilbert space H prime. In fact, in the 90s, when we understood this, we assumed that this must be known to mathematicians, but mathematicians never used. Mathematicians never use this Hilbert space, apparently. Very, very strange. They will always use the full Hilbert space of periodic functions, where derivatives are not invertible, of course. Yeah, now there's some nice things that you can do here. If at one loop, you can. You can one advantage of the integration by parts procedure is that actually it also homogenizes the integrand. All terms have the same powers of momentum. And that actually means that if you want to take the low energy limit, it just means getting rid of this of the exponential factor. And then it turns out that we need. And then it turns out that in your integrand, yeah, here you have the terms with cycles where we applied this ban-Kosova rule and they are terms with tails, but then all the tails actually become total derivatives. You can even see it with the naked eye. Here is a variable four, and you have a derivative. And once the exponent is not anymore here, you don't have anymore. Here, you don't have any more occurrences of the variable tau four. So, this actually indicates to zero. Actually, you remain just with what we call pure cycle terms. The pure cycle terms, they all can be expressed in terms of the Mooley numbers. And without any real work, you can actually write down a one-line formula for the one-loop n-photon. N photon amplitudes, yeah, just any number of photons, actually, still valid off-shell. Mind you, that at full momentum, you know, that the photon amplitudes have been calculated only up to six photons, and the low energy limit, it becomes extremely simple. And when you want to go on shell, it turns out that you can actually absorb any fixed number of photons and fixed helicities. You can absorb the whole information on polarizations and momenta in some invariants, reduce everything basically to numbers. And this can even be done in two loops. In one loop, everything is linear. At one loop, everything is linear in the Berboulli numbers. At two loops, you have also these folded sums of Berboulli numbers appear. And actually, I want to discuss a little bit mathematically because we were actually these calculations we were actually doing in various different ways, particularly one direct way and once using the two-loop self-tool or Eisenhower. Using the two-loop self-stull or Eisenberg function. And we got actually two results involving folded sums of Pandoli numbers, which we were not able to identify. And then we asked Richard Stanley, who informed us that this is actually Miki's identity, which at the time was considered the most non-trivial identity involving Bernoulli numbers. And around the same time, actually, Faba and Panderiband did a calculation on topological string theory, where they got a similar identity from Hodge and Deagels. And actually, we then wrote a paper on this where we actually where we provide a proof that applies for both the Miki and Faba. For both the Miki and FABANTA Riband Sagi identities. And moreover, it shows that in some sense the relation is like spin zero and spin one half. And then we generalized them at the quadratic level and we even amused ourselves going on to the cubic level. And we actually gave a recipe for constructing even higher order identities. My order identities. Unfortunately, as far as I know, nobody so far has really done it. But it's on this radar physics. So basically, we are good at the polynomial level, but we have to now think about how to do integrals that really involve this nasty. Yeah, you have the Green's function, which has a quadratic part. Which has a quadratic part and which is not ordered, but you have this nasty absolute value here. So we want to, but we yeah, now if once I'm not returning to x space because in x space, we have actually found something very nice way of doing this. In x space, what you in this simple abelian case, you can Case you can easily switch back and forth between the amplitude and the effective action itself. The effective action basically has the same exponential, but now the momenta have been replaced by derivatives acting on the scalar field. And the thing what you usually want in X space. Usually, one in X space is the heat kernel expansion. And in the heat kernel expansion, you are ordering in, you are normally grouping together terms of E equal mass dimension. And it makes sense to calculate individual terms in the effective action. Now, if you did this directly, you would have to calculate something that very much looks like a multi-dimensional Selberg indicator. Like a multi-dimensional Selberg integral. But it is still too hard to do. Well, individually, any such integral is trivial, but you have to do it in a way which allows for a closed form dependence on your parameters NH. And the way to do that is the following. We can actually make a very non-trivial change of basis. Change of basis, we rewrite the exponential of a border and Green's function as an infinite sum of those integral kernels that we introduced before. So here we have like the quantum mechanic, this is quantum mechanics on the circle. You have the propagator. Propagator for the two n's derivative to go from a point UB to a point UA on a circle. And the bar means that we subtract the coincidence limit. And there's some kind of completeness here that guarantees you that actually any function of the Waddler and Greenst function can be expanded in infinite series like this. And it's a hard. And the hard problem is really to get the coefficients, and they turn out to be Hermit polynomials. Remember, those involves the Bernoulli's, and in fact, curiously, this formula gives already a new, apparently new representation of the error function. It gives you the representation. If you integrate this, you get already something new. Already something new, you get the representation of the error function as an infinite sum involving Bernoulli numbers and Hermit polynomials, which we have not found in the mathematical literature. But anyway, what do we do with this formula? Let's say you want to calculate the heat kernel expansion at the three-point level. So you have three factors with this. Factors with this nasty G lines function, you expand them out like this. And once you have it like this, actually you can just use completeness. For example, if the term where you combine all these three terms here is just an integral. An integral, a three-fold integral over integral kernels. So you use completeness in the quantum mechanics of the circle, and you just get the trace of an inverse derivative, which is the Bendoli number. And yeah, in this way, you get a closed form, closed form. closed form closed form expression involving three point also for all the three three point heat kernel coefficients purely in terms of Bernoulli numbers and mind you said of course these Bernoulli numbers you would get in any other approach but in any other approach you would wonder where they come from yeah in fact this is Bernoulli numbers appear in perturbation theory all over all over the place All over the place, but it's often a bit mysterious where they come from. If you would do this in any other way, you would also get the Benoli numbers, but they would come in pieces, because you would have to order your external X and send some over crossings, and basically you're hacking into pieces your Bernoulli numbers. Yeah, and these coefficients H come from the Hermitage polynomials. And this can be, well, at the next level, but here you have just to use completeness. At the four-point level, you have to do a bit more because you have actually integrals, whereas integration variables appear in three greens functions. And now, curiously, And now, curiously, well, you can do here. You can apply an integration by parts. Actually, you integrate, say, in K you reduce index k and you hike up i and j until k goes to zero. And remember, set the delta zero is just a delta function. Delta zero is just a delta function. 0 is just a delta function. It's just a delta function minus one. So if you use the delta function, you have already you have already you have already killed the integral. If you use a one, you have one propagator less. After that, you can use completeness. And this works to all orders. Orders. In fact, we haven't really pushed this, but we could use this to calculate the scalar heat kernel to much higher orders than not presently known. Yeah, here's just how the integration by bath goes in at the next level. And I also have no time for this. Another mathematical diversion that 20 years ago, actually, with Uber Müller, we made a toy model just for calculating identities between multi-supper values. The basic observation is that the Green's function g if you If you do it as a as a four-year-old, you can use the same thing. Basically, as a story beyond the circle, the Keene's function is the ordinary second derivative on the circle. The circle, you can calculate it in Fourier space, and that gives you the Nulli numbers and the Nolly polynomials. Actually, at one point we noted that actually if we make this chiral, so if we just if we take only the positive ends here, so we do a chiral version. So, we do a chiral version of the workload formalism. Then we are also getting, yeah, we are, yes, this you sum over all, and you get only theta two, theta four, etc. If you restrict the n positive, you can get also theta three, theta five. More generally, if you go to multiple integrals, you will get multi-theta values. So, we made the we made. So we made a model where we actually where we actually introduce again the propagator for the ordinary derivative, inverse ordinary derivative for any power, but now in the chiral half space. And then we wrote down a set of Feynman rules where each multi-set Where each multi-setter value actually can be represented by what we call a C-shell Feynman diagram. And then exactly this integration by parts algorithm could be used to rederive any known identity between multiple sets. Anything which you normally can get by shuffle or stuffle relations. Scuffle relations. And in that model, you can get by indication by parts. Well, this is a true generalization. This is a toy model. Well, you could also speculate maybe one. You could use it for something else, but this was specifically. This was specifically a toy model just to derive relations. Well, this kind of thing like theta one, two equal theta three, etc. I don't remember the stuff anymore, but we actually both. actually wrote down some very general general identities but the curious thing is that exactly the same integration but this integration by parts that worked in the toy model now really works for our real physical model the heat kernel in phi cube Yeah, it also gives you an easy explanation to see why there must be such identities. Anyway, this is very good for Z kernel. For amplitudes, we have a problem because we end up with series that involves Bernoulli numbers. And Hermitian polynomials, and we have not the slightest idea at the amplitude level, we are basically forced to resume these X-Is, yeah? And we know what we should get. We should get hypergeometric functions of two or three arguments, but there are no known formulas that would expand such functions. Well, for the dialogues, there's a well-known formulas. Well, for the dialogues, there's a well-known formula where the Berlini numbers appear. But there's no formula for the function 3 at 2. Let's say, or for much less for the Sarang, Laurichella Saran function. Nobody will give you a formula in terms of the Lully numbers and factorials. Well, it is clear that these formulas must. It is clear that these formulas must exist. We could perhaps eventually use the formulas to derive them, but right now nobody knows them. So let's for the amplitude level, we really have decided to do something different. We have recently recent years practiced a lot on for photon amplitudes. Of course, that is very easy stuff for stuff for people here. But the thing is, we want to do the four photon amplitudes the hard way. We want to do them always in such a way that we never fix the ordering of the proton legs and we never break permutational values. For example, look at this here. Yeah, if you what you see here is the exponent of this Taylor. Is the exponent of the scalar of the ordinary standard four-point scalar box on shell written in the worst line variables? And moreover, we keep st and u not to break the permutational variance. So you have this in the exponent, and now you want to integrate out one leg and you. Leg, and you want to do it without actually fixing the ordering of the remaining three legs. And you want to write the result in a permutation invariant way, so that's what you get. In fact, that is fairly easy to do. And we have whole tables of indegral with various vectors. Once you go to the photon case, you have. The photon case, you have you need such formulas with various vectors of g dot. Of course, for the one loop for photon case, this is all overkill. But the thing is, we want to then actually show off two photon legs and go to two loop, where this becomes a quite different story. In fact, how much time do I still have? Recording, but it's great after that. Okay, yeah, but I will be fast. Yeah, so our latest thing is actually 30 years ago we calculated with Michael Schmidt two Lobida functions in scalar and spinner QD. Now we are actually back at this to calculate the full self energies. And here And here, yeah, all the time I said we do that by sewing, but that's actually not the most efficient way of doing it. In fact, a much nicer way of instead of starting from this and then sewing off two legs to go to here, it's actually much nicer. Much nicer to start with this and then actually use a modified green function that has the information on one internal photon propagator. So, what you see here is a Green's function which is just doing this. So, you put two. So, you put two photon vertex operators here, and instead of propagating straight from here to here, there's the option of using this bridge one time or two times. You can actually construct the Green's function. It's a two-loop level as a geometric series over how many times basically. Times basically the propagation is using the inserted propagator. So you sum a geometric series and you are ending up with this. That we did in the book in 1994. And a couple of years later, actually, Roland and Sarto checked, this should actually be the infinite string tension limit of the corresponding Volt Sheet Greens function, which Holari. Function which Holand is altogether checked. And we can do this with any number of propagator insertions. When you do this to all orders, actually what happens is, well, for simplicity, let's look at the let's say you want to calculate the Wacom amplitude with any number of. You would with any number of bottom propagator insertions. Now, the Woodland formalism will give you a formula which already has all permutation, which includes all topologies. And it actually parametrizes them in variables. Well, if they're n propagators, you have basically n pins functions that refer only to one individual propagator, and then for any two propagators, you have. You have a variable Cij that depends only on these two propagators, nothing that depends on more than two propagators. Okay. That is this general structure, and here is what you get if you want, yeah, of course, the two loop. Yeah, of course, the two-loop mark compolization and scalar QED. You have only this variable C, which connects the two. Well, you have one external propagators, one internal one. So the G34 is actually the internal one. There's G12, that's external one, and then there's the variable C that connects everything. And there are a few. There are a few integrals to calculate, which involve. Yeah, this is just one example here, which actually we do by pure experimental mathematics, just something like 20 or 30 hours of fiddling around have done into calculating this. Maybe somebody here can figure out a can point. Figure out, we can point out a better way of doing this. But it turns out that you want to have this integral, but for any k. If you wanted to do some specific k, Mathematica can actually do it. But Mathematica won't tell it for arbitrary k. But that's what it is for arbitrary k. You get two terms in terms of the hypergeometric function. Hypergeometric function 3F2 and yeah, the remaining variable is this x is actually g dot one two square was external propagator. Anyway, I'm running over time, but yeah, since this formula, the important thing is that here you already have you already have two sectors. Two sectors, this formula solves the problem of combining these three diagrams, these two different topologies. Of course, at the two loop level, this is again a huge overkill. This is an easy calculation. In fact, Lorenzo Dancredi, I told Lorenzo Dancer, he said, can you do this? Can you do this calculation? Because this is not in the literature, actually. Nobody ever calculated cisposcalar QD. So, Lorenzo Dancredi, actually, in just one day, calculated it using all this powerful technology. So, again, it's complete overkill what we are doing. But the thing is, once we know how to do it at two loops, I think I'm already overcome. Given that we're into the break, maybe if people have questions, Pakistan, you can ask while you're having some coffee, and we'll be back for the next talk at 11.