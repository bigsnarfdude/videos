The University of Warwick now, and she will talk about Branian motion condition to have trivial signature. Thank you very much. So the problem I want to advertise during this talk is essentially exactly the title of the talk. What happens or what do we end up with if we condition Brownian motion to have trivial signature? And just for completeness, I'm gonna For completeness, I'm gonna give the definition of a signature of Brownian motion. And the nice thing is that if you care about the signature of Brownian motion, you don't need to refer to the theory of Woff path. If you have the Stratonovich differentials at hand, you can simply define it as the collection of all iterated integrals you can form when you start off with a Brownian version in Rd. And do notice that you're integrating over a wedge here. And usually, you write it as an element in this non-commutative algebra. And in particular, when you're asking for the signature to be trivial, the main reason is that by convention you have this one in here. So trivial signature means that all those iterated integrals vanish. So essentially the question is: what happens if Brownian motion is conditioned to have vanishing iterated integrals of all orders? And now the reason. And now, the reason why this could be interesting to look at is that the signature of a path actually encodes a lot of information of that path. So in 1957, 1958, Shen has studied the formal series of iterated integrals of paths which are piecewise regular. And he showed that the signature characterized those paths uniquely up to obvious. Uniquely up to obvious, like elements of non-uniqueness, which the signature can't pick out, which are like translations and reparameterizations of the path. Then the result was extended by Ben Hamley and Terry Lines in 2010 to path of bounded variation. And there, the statement is that if two bounded variation paths have the same signature, then they agree up to tree-like paths. Tree-like path. And now, for a tree-like path, basically, what happens is that you do simply have to retrace your path completely, except that you conform leave. So you sort of start off, then you might go back, but at the end, you eventually have to fully retrace your path. That's a tree-like path. And if you just write down or compute the signatures, you notice that through this retracing your path, the signature is just going to be trivial so that you. To be trivial. So you can check that completely. So again, you're not expecting the signature to pick up on three-like pulse. And then it was extended further by Terry Lines and his students in 2016 to cover so-called weak geometric PROF path, but the thing to take away from us is that this was now extended to enough regularity or low enough regularity that it also covers Brownian sample path. Covers Brownian sample path. So that's why if we want to study Brownian motion condition to have trivial signature, we in a way know that this condition process will have to be supported on the tree-like path. And then the question is, what exactly happens? And this question essentially arose when I was doing my PhD and was working on conditioning diffusion processes on the endpoints. And I was talking to Terry Lyons, and then at some point I was talking to Terry Lyons, and then at some point, that question arose. And the very first thing you actually have to make sense of is: what do you really mean with this question? Because even though you have tools of disintegration of measures available to make sense of conditioning on sets of measure zero, this is actually a really bad set of measure zero. So our priority can't even really make sense of it. And to sort of give some meaning, To sort of give some meaning to that question, what you can do is you can actually consider, well, there is also a notion of truncated signature. And truncated signature is the collection of all the iterated integrals up to some order. And if you take this expression, you essentially simply replace this infinity by a capital N. And then you can condition your Brownian motion in Rd to have trivial truncated signature up to order N. Signature up to order n. And then you're interested in studying the weak convergence of those laws as n tends to infinity. So, first of all, the question is: do you have a weak convergence? And then the second question would be, what would be the limit if you do have this weak convergence? And just to add this, so this is basically terminology which I found in Fabrice's Stochastic Flow book, where he uses the terminology of Brownian loops. Of Brownian loops. And the other nice thing is you basically can now rephrase that in a way which maybe some of us are more familiar with without having to use the word signature. So the way he describes exactly what we are looking for is you start off with the Brownian motion in Rd, then you can canonically lift that Brownian motion to a free Carnot group of step N. And then you can, this gives you a hyperbolic. You can, this gives you a hyperliptic diffusion process in that Carnot group, and you can condition the Brownian motion in Rd so that the lifted process is going to return to the origin in the Carnot group by time one. And this gives you these Brownian loops. And so this was something I'd looked at at the end of my PhD and sadly couldn't resolve it. And now the way I would like to advertise of why this problem might... Like to advertise of why this problem might be interesting to look at is by presenting you some results on a project where I was trying to like play as similar of a game of this as possible while staying in the Gaussian world. And the reason why staying in the Gaussian world was like sort of a nice incentive is that one of the problems in here was that, well, you could either make That, well, you could either make sense of the condition process using disintegration of measure, or as Fabries does in his book, using Dube's H transform. But in both cases, you don't really have a hands-on control on the condition process. And that turned out to be like one of the hard bits, at least for me, for this process. But now, if you look at or try to stay in the Gaussian world, then you usually can make sense of the condition process very well. Because in the Gaussian world, you make use of the fact that if You make use of the fact that if you're zero correlated, you're going to be independent, and that's very handy. Okay, if you now look at this, is how can I do something similar and not leaving the Gaussian world? And you immediately notice that as soon as you integrate one Brownian motion against another one, you lose this Gaussianness. So the only way to create iterated integrals and staying in the Gaussian world is by integrating with respect to time. And you can never have a cross- And you can never have a cross-intubation between two Brownian motions. So we might as well simply restrict our attention to a Brownian motion in R, and then we look at the iterated time integrals of that Brownian motion. And making the connection to the previous slide, if you replace this one here by a t, then what you end up with is the so-called iterated chromogorov diffusion. So again, this is a So, again, this is a hyper elliptic diffusion process. The nice thing is that even though you only have a one-dimensional Brownian noise driving this process, for all capital N, this is going to have a smooth density. And then you can make sense on conditioning this Brownian motion on having this value to be zero. And then you use the usual splitting argument that you can write down an explicit expression for this condition process. Explicit expression for this condition process. The only subtlety which arises in that setting is that you are interested in studying the limit as capital N tends to infinity. So you kind of need to come up with an expression which works nice as n tends to infinity. And if you do the brute force way, you can eventually get an expression which holds for all n, but it's not an expression you want to deal with. And then the nice thing. And then the nice thing comes into play if basically, if you notice that all these elements of this signature-like object can be written as linear combinations of Qn, which is a shifted Legendre polynomial on the interval 0, 1, integrated with respect to time. And the way you notice that is that, for instance, if you take this big iterated integral, if you integrate by parts multiple times, then this is. Parts multiple times, then this is simply 1 minus s to the suitable power dBs. And then you can use exactly the same splitting argument as before, and you can show that if you condition this one-dimensional Brownian motion on this signature-like object to be zero, that you end up with this expression. So you take your Brownian motion and subtract the integral of the shifted Legendre polynomial times this random coefficient, which is shifted Legendre. Coefficient, which is shifted Legendre polynomial integrated with respect to Barnum motion. And now, the really nice thing about this expression is that once we have this expression, we can compute the covariance of that process very nicely. So, do you notice that this is still a Gaussian process? It does have mean zero because this thing has mean zero and these things have mean zero. So, to uniquely characterize this process, you need to compute its covariance. And this is where you And this is where you use etters isometry and the fact that these shifted Legendre polynomials are orthogonal. So all cross terms just cancel. And as covariance, you end up with this expression. And basically, once you have this expression, this is kind of the heart of the analysis and it allows you to do a lot of things. And in particular, remember that we cared about the limit as n tends to infinity. Tends to infinity. And while the statement of Mercer's theory doesn't apply to cover that case, you can just go back, see how Mercer proved his theorem, and do the same steps. And you can show that these covariance functions converge uniformly, this is important, on the unit squared to the zero function. And the reason why this is important is that we had our Gaussian process, which was uniquely characterized by its mean and its Uniquely characterized by its mean and its covariance function, but now the means converge because they're all zero as n tends to infinity, and because those covariance functions converge uniformly on zero, one, what we essentially now proved is that those condition process, where we condition on the signature-like object to be zero, they just converge weakly on a suitable path set as n tends to infinity to the zero process. And so that's kind of reminiscence of what we are hoping to do eventually for a Brownian motion condition to have trivial signature. But a few things to point out. So first of all, once you've proven that theorem, you now should step back and notice that what you've actually also established is that you found a polynomial decomposition of Brownian motion, which is given at that, because you Which is given at that because you had like bt minus this sum, and you're now shown that this converges weakly to zero as n tends to infinity. So if you just replace this infinity by an n minus one, you have an approximation for Brownian motion which uses exactly n Gaussian random variables. And a few other things to remark. So this decomposition was also encountered by James Fosteri Lyons. By James Fosteri Lyons and Harold Oberhauser, where they used it for simulating when they were simulating SDEs, and it turns out to be very powerful there. And it was also implemented as a Chapfan example into MATLAB by Nick Trefethen. And for that, there are a few things you need to exploit. So this integral of the Chif de Legend polynomial actually has a really nice expression. So this is a multiple. nice expression. So this is a multiple of qn plus 1 minus qn minus 1. So if you have any program which has the Legend of polynomials implemented, then you don't have to do an integration here. And then this is a Gaussian random variable whose variance is 1 over 2n plus 1. So if you take like a square root of n 2n plus 1 from this and move it into here, you just have a decomposition which uses IID norm as IID norm as zero random variables. And in fact, this is, I've implemented that into Mathematica. It's pretty straightforward once you've had that. And so as I said, if you replace this by an n minus one, you end up with this is n equal to 20, 50, 200, and 500. And you really see that even at low orders, you already have a good idea of sort of overall what your path is going to do. Of overall, what your path is going to do, your Brownian sample path, and then as you increase n, you kind of add roughness to your path. And to me, certainly, that was a nice side result and nothing I sort of expected to end up with when I started off on this, that you end up with those pretty nice approximations for Brownian motion. And in a way, you could now be satisfied because you go, like, well, I sort of. Well, I sort of proved something for those conditions first order, and I ended up with also a nice application for Bernie motions. But then, maybe at some point while you were doing your analysis, you were plotting the actually the covariance functions you computed, the CnST. And this is actually a plot of the V-scale covariance function. And you notice that you end up with this thing where, so this is on the thing where so this is on the diagonal s equals t and you very clearly see this sort of edge popping out and if you just plot the diagonal for more values of n you can quite confidently say that this has to converge to some sort of semicircle like just from the pictures it's a good guess and it's a bit more delicate around here because so you see that's order wise it's significantly smaller than what this edge is doing Smaller than what this edge is doing, but you do have some sort of roughnesses. But if you, at the beginning, sort of cross your fingers a bit, you say, like, well, the pictures clearly say that on the diagonal, I'm converging to the semicircle if I rescale the coberian function by n, whereas on the off-diagonal part, I still stay at zero, even though I do this rescaling by n. And if we now just accept this for now, what this What this tells us for the stohastic processes is that if we take our condition processes from earlier and rescale them by square root of n, and we need to rescale by square root of n to then get a scaling by n out in the covariance function, then these fluctuation processes actually converge in finite dimensional distribution as n tends to infinity, first of all to a collection of independent zero-mean Gaussian. Of independent zero mean Gaussian random variables, and this independent is a result of this convergence to zero on the off-diagonal. And the variances for those Gauss zero-mean Gaussian random variables, Gaussian-Random variables, are given by this semicircle. And a few things to remark here are that, so first of all, you found like that this convergence and finite dimensional distribution is Is a result of you in quotation mark only being able to prove point-wise convergence for this process for this function because of this roughness which you saw especially near the diagonal edge. But then it turns out that, so while you can make sense of this collection of independent zero-mean Gaussian random variables, this collection actually neither has a realization as a process with continuous sample path, nor is it equivalent to a measure. Nor is it equivalent to a measure of process. So you can't even hope for weak convergence. So, in a way, finite-dimensional distribution convergence, which you prove by looking at characteristic functions, is the best you can hope for. And what remains to do is to actually prove this rigorously. And now, this is the heart of this paper, more or less, where we prove this fluctuation results for the genre polymer. Fluctuation results for Legendre polynomials. And when you want to prove that, it makes it easier if you translate the entire statement to the standard Legendre polynomials on minus 1, 1. So this is just this covariance function essentially unshifted to give you functions on the interval minus 1, 1. And then the statement is you again are 0 at the off-diagonal, whereas you get to the Whereas you get to the slightly converge to the slightly different semicircle away from the diagonal, on the diagonal. And the reason why it's nice to do this unshift is that this way you have your symmetry at zero and not at one half, which you have for the shifted Legendre polynomials. And in a way, this statement quantifies this completeness and orthogonality property for the Legendre. Property for the Legendre polynomials. Because if you notice, if you take this Dirac delta, if you formally integrate it from minus 1 to x and minus 1 to 1 to y for like x prime and y prime, you do end up with this watch of the minimum of 1 plus x and 1 plus y. And the way this proof works is you do a moment analysis on the diagonal. You show that these things have the correct moments. Have the correct moments and that they're going to converge the way you want them to converge. And then you need to also establish some uniform bounds so that you guarantee that the limit is actually going to be continuous. And then away from the diagonal, I came up with the Christoffel-Darbu type formula for these integrals. So for Legendre polynomials, there's a well-known Christoffel-Darbu-type formula. Diablo type formula, and you can sort of hijack this one and get something similar for the integrals. And this helps to kind of get some telescoping and certain sums. And then there are some well-known Darbo estimates for Jacobi polynomials, which eventually help you to say that even though you rescale by n, you're still going to converge to zero away from the diagonal. Okay, and before I go back, And before I go back, say a few things about the problem I want to motivate, I just want to make a few side remarks, which are, in case you have a background in random matrix theory and wonder if that semicircle is like in any way universal, I can assure you it's not. Because so for this slide only, B is actually a Brownian bridge and not a Brownian motion. So you can look at the code. So, you can look at the Korean Love expansion for Brownian Bridge, and this is given as follows. And for that one, you can play a similar game as we've done before. You can let this go till n so that you have n terms, subtract this from the Brownian bridge, and rescale it by square root of n. And again, by establishing essentially conversion results for the covariance functions, For the covariance functions, you can show that this time the associated fluctuation processes still converge to a collection of independent Gaussian random variables. So you still have this convergence to zero in the off-diagonal regime. But this time you converge to a one over pi squared, just constant, on the diagonal, except at the endpoints you'll stay at zero. And this is recent work with. And this is recent work with James Foster. And so that's the first statement that the semicircle needs to be arising from something else, and it's not like just universal in this fluctuation result. And the second remark is that, so I certainly completely admit that when I started looking at that semicircle for the polynomial approximation, it was really just because I saw it in the plots. The plots, and I wanted to see if I can actually prove it. But now some features of them actually appear somewhere completely else. Because if you have this polynomial approximation for Brownian motion, you can use it to write down an approximation for levy areas. And approximating levy area is important when it comes to approximating solutions to Approximating solutions to STEs because you only really get the strong solutions if you have an approximation for Levy area. And similarly, you can also use a certain, you can also just write down things in the Fourier series basis and also use that as an approximation to the Levy area. And for this Fourier series, the fluctuations look almost the same as here. So the crucial thing is here are this 1 over pi squared on the diagonal. And what it now turns out is that both of those approximations have like an order of 1 over n as the error. And the constant in front of this 1 over n is exactly given as the area under those variance functions. So for the Fourier series, or the approximation resulting from the Fourier series, your error constant is exactly 1 over pi squared, whereas the approximation for the Approximation for the resulting from the polynomial expansion has an error which is 1 over 8, which is exactly the area under the semicircle. And in that paper, we've also given like heuristics which do explain that this isn't a coincidence, that this is really the area appearing, the area under the limit fluctuations appearing as this error constant. So that's kind of nice that the fluctuation processes or some features of them do appear. Of them do appear somewhere completely else. And yeah, just to close off, so if anyone has any suggestions or any input on studying this problem, I'd be very interested because I kind of looked a lot at this during the end of my PhD and I probably need some new input, a new suggestion. And just to say why I think that whatever happens, it's going to be interesting. Whatever happens, it's going to be interesting. So, I suspect that when you look at this, you're actually also just converging to the zero process. This is just my feeling. SN, you know that the process has to be supported on the tree-like path, and I suspect it's just going to be the zero process. But even if that's not correct, you end up with a non-degenerate canonical measure on tree-like path, which would be interesting by itself. So, in that case, either or. So, in that case, either or something nice should happen. And then the second thing is: this is clearly thinking too many steps ahead. But given what I've shown you for this Gaussian framework, can we study fluctuations for those Brownian loops? What happens in that case? But if we look at that, we need to be aware that even in the Gaussian framework, things already end up pretty rough. So probably weak convergence is. Probably reconvergence is nothing we should hope for here. But yeah, so the question is: also, can anything be said in this regime? And yeah, to close off, first of all, thanks a lot to the organizers for putting this together and also for giving me the chance to speak here. And thank you for everyone who's in the audience and paid attention. Thank you very much. Thank you very much.