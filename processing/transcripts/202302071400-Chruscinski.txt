Okay, for our second talk of the afternoon, we have the pleasure to hear Machil Palhammer, who is going to talk about node approaches for the reliable and efficient numerical evaluation of the Landau operator. Thank you, Mach. Thank you very much. So let me start by thanking the organizers of this nice meeting. It's a pity that I cannot be there, but it's a pleasure to be present. To be present in this virtual format. So, my talk will focus on numerical aspects. So, let's say the focus is quite different from previous talks. So, what I would like are some ideas how to construct a numerical method. And as you see, our focus was on the Lambda operator the homogeneous lambda. The homogeneous Landau equation on the way to more involved problems. And our focus was also on reliability, so preserving physical quantities. And of course, also you have the aspect of having a good accuracy and good efficiency of the numerical method. So let me maybe. Let me maybe also give a link to dispersive equations. So, what is, let's say, a final far future aim is the treatment of equations that are arising in plasma physics. I will comment on some applications in connection with fusion. So, one target problem is One target problem is blast of Maxwell Lambda equations, and as you see, you have also Maxwell equations inside, so you have naturally also some waves, and then you have also dispersion inside these equations. But in order, so let's say our idea would be to develop a kind of splitting approach for these more involved equations, Lazov, Maxwell, Lanois. Equations, Laos of Maxwell Lambda equations. And the first step in this direction was to focus on the Lambda equation. This was, let's say, also my first step, since I was not familiar with this kind of high-dimensional integral equations, also with singular kernels in the most relevant physical case. So, this is, let's say, the first step in. The first step in this direction. And as is the case in splitting, you would decompose the full problem in components, and one of the components would then be the Landau operator or the Landau equation. So, in this talk, I will really focus on this collision integral. And as I already mentioned, And as I already mentioned, on reliability of the numerical approach and also efficiency, of course. So we have two things or two problems in parallel. First, the evaluation of the Landau operator, and then we also do the time integration of the associated Landau equation on the spatially homogeneous case in the sense that we can neglect for Sense that we can neglect for the moment also dependence on position. So, this is joint work with José Antonio Carrillo, and we are now preparing our manuscript. So, let's say, the first inspiration for our work were several contributions, former contributions. Maybe to start with. Maybe to start with the study of a numerical approach by Lorenzo Pareski and Korasos Russo and Toscani. So we are following their steps in a sense. We are also using spectral methods. Fourier spectral methods turned out to be a really nice approach for different reasons that I will explain. So this is a very close setting. Close setting considered in this paper. Then, as I mentioned, splitting more concretely, Hamiltonian splitting is a possibility, a good option in connection with Lazov-Maxwell equations. And we intend to generalize this approach in connection with the Landau equation, also. And then, of course. And then, of course, we also want to compare with other approaches. So, there's a rather recent paper by José and co-authors. They are studying a particle method, which of course has some benefits, but also some disadvantages. And it's just a good starting point to compare with these approaches. And then, maybe also to think even more of decomposition, of splitting. So, it's not only a single equation, it's even systems that are relevant in applications. So, maybe to pick some aspects, some perspectives on the physical phenomena, so we are in. Um, so we are in the following context in the context of kinetic equations, also computational plasma physics. And the Lambda equation itself is a fundamental kinetic equation, so it's also of interest to study itself. Um, what is, let's say, the nature of the equation or the nature of the physical processes behind, so you have the charged particles. So you have charged particles colliding charged particles in a plasma and you want to model these kind of phenomena. So when you go to Lambda equation, you of course also have as a guiding line also Boltzmann equations. So this would be also one of our further objectives. So these are really So, these are really two relevant models. And as you might know or remember, there was a kind of, let's say, particular attention to fusion reactors in the last months, since there was a kind of further step towards the realization of these attempts. And so it's also in It's also in the sense of applications, simulations of important physical processes. It's also a kind of motivation to follow these ideas. What I would like to point out, so we have Lambda equation and then we have different cases, test cases and then the relevant case. So one first test case is the case of Test case is the case of Maxwellian molecules. So, this is a, let's say, really simplified situation. This is quite nice to treat numerically. Also, theoretically, you have some simplifications in a model that make things much easier. But of course, we want to come to the Coulomb case finally. And I will, let's say, also in my talk follow. Let's say also in my talk, follow these steps. So, starting from the rather easy case, develop there our approach and then face finally the most involved Coulomb case. So, the equation, how does it look like? So, you have a time-dependent equation. In principle, you have position, which I would call x, then velocity, which is called v. Velocity, which is called v, and time, which is called t. And you see here, I may, for the moment, yeah, for these applications concerning only the Lambda equation, I may focus on the spatially homogeneous case. So position is somehow there, but it's only pointwise dependence, and it does not affect the partial differential equation in the sense that you have no derivatives with respect to position inside there. Position inside there. So the form of the equation is given here. F is the density function, which is the unknown function. We have on the left-hand side time derivative, so first order in time. And on the right-hand side, we have the Lambda operator defining the Lambda equation. And I will use two convenient. Two convenient notations, namely, the kernel will be denoted by phi throughout. And the most physically most relevant case is the case of Coulomb interaction. And then you have this typical form of the kernel. So you have a similarity of this kind. So you have a strong similarity in the equation. And then I just call an additional term P. So this is a major. P. So this is a matrix-valued term and it's quadratic in the components of the velocity. So the defining Lambda operator finally then has this form. So we have divergence of this integral operator. You see here the kernel depending on the velocity and on the integral variable, which I call w, and then I have this. And then I have this quadratic term, and then I have certain derivatives of the density function and of the density function, so products with the density function itself. In a certain combination such that this singularity is finally not affecting the existence of the integral, since when v approaches Approaches W, or when let's say when V is equal to W, this term vanishes, and then the singularity is not somehow not present or does not affect the solvability existence. Okay, so what are computational issues here? So, first, of course, we are focusing on the bull case of three dimensions. A full case of three dimensions. So this integral then involves finally six dimensions: v, the velocity, and the integral variable w. So this is a kind of numerical challenge how to handle this. And second, we have this singularity. So even though this integral operator is well defined, still you of course feel in a numerical approximation then this singularity. Approximation than the singularity, and how to cope with that. So, here the guideline for the following minutes or let's see, yeah, minutes. So, a stepwise approach. So, the idea is to step by step come to a more general approach and throughout And throughout, when taking all these steps, we continuously validate our approach. Since, as you will see, and I have somehow to apologize for that, I have certain technicalities. Since I finally want to treat the full problem, I want to worry about numerical issues. So I need somehow some tools in order to validate my approach. My approach. So, as I said, we are starting with the Maxwellian molecules case. This is somehow the simplest case since here our integral kernel, which I called phi, is just a constant. So this will make things much, much more easier. And in this situation, I also have an exact solution at hand. It's called the BKW solution. It's in principle defined on the full domain. Defined on the full domain, so on R3, but by truncation of the full domain, since I have a localized BKW solution, I have a good possibility to check to validate my approach. And then I go one step further to regular integral kernels, regular in the sense that I have serious representations. Three presentations of this integral kernel that I may use, and here we developed two kinds of test problems. A first test problem on a bounded domain. And here we see some limitations also of our approach. And finally, this is more than also towards the physical situation, sorry, the situation and also the physical solution. The situation and also the physical solution, a test problem on the unbounded domain, but with a localized solution. And then finally, we are in the case of a singular candle, so in the Coulomb case. Sorry. So here. So when you do or when you develop. When you do or when you develop numerical methods, you have to take care of different aspects. Of course, one aim is accuracy of the results. So this is then nicely confirmed. This is nicely confirmed by test problems. On the other hand, we have to worry about computation times, also about the complexity. The complexity, how to save all, how to store all quantities. So, this is related to the notion of efficiency. One idea was also then to realize time integrations to have some pre-computations that are maybe expensive in a sense, time-consuming, but you do this once and for all, and then you go. For all, and then you go further with the time integration. So, these are some additional aspects that we are taking care of. And then, finally, we have a physical problem. Yeah, so we have some quantities that are of importance, mass, momentum, energy, entropy. We have to take care that these quantities are captured by our numerical approach. Our numerical approach. And of course, we also have to worry about the stability of the numerical methods in velocity and also in time. So this talk is separated in several parts and in this first part, which I call a general approach, I will present first representations of the Lambda operator and also some fundamental. Some fundamental tools regarding the numerical approach. So let's say this was my personal first step, just to write down the Landau operator in full 3D, so in all components. And you see here, just to recall, I have divergence of this integral operator. I have here the integral kernel, which for the moment we can just Which, for the moment, we can just assume to be a constant. And then I have this matrix-valued term, which depends on the velocity components in a quadratic way. And then I have the density function and partial derivatives with respect to the velocity inside. Okay, and so the first step, a very pragmatic. A very pragmatic step approach was to just calculate this by hand, do the full expansion. And then starting from this approach, we finally will go back to a weak formulation. So weak in the sense that we determine these divergence in a weak sense. In a weak sense. Yeah, but let's start with this first straightforward approach. So, and when you do this, what you see is the bilinear nature of the problem. So, what you see is that the density function arises, certain first-order and also second-order partial derivatives of the density function arise. Of the density function arise, and you have here given in red some integral operators that are present. Okay, so this is the basic structure of the lambda operator. And when you look closer to these operators, what you see is that in principle, all of them can. They can, all of them can be expressed by integrals. Of course, since we have an integral operator inside, but in principle, then it's well, then it's less caring, I would say. So we have here some polynomial terms up to order two. So this is quite nice. We have here the kernel, which might be singular. We also have some additional partial derivatives of the singular kernel. So here we have to be a kernel so here we have to be a bit careful and then we have the in the lambda equation unknown density function and some derivatives of this density function so this is the basic structure and when you express then the integral operator by by these sorry i was a bit too fast now yeah so when you express now the integral operators by these basic integrals These basic integrals, then you have, yeah, just let's say a rather involved combination of all of this. Just to point out, so what we see, we have different integrals, different of these basic integrals. We have contributions with respect to these polynomials up to degree two, and we have derivatives of the integral kernel up to degree one. integral kernel up to degree one and also of the density function only up to degree one but all possible combinations yeah so uh so you have a long formula and of course uh it's just a good idea to verify correctness of this uh of this of this long formula um yeah and that's why we took these steps starting from the simplest maxwellian molecules case to the Belian molecules case to the Coulomb case where we have no reference solution at hand. So, the main task we are left with is to compute numerically to approximate derivatives of the density function and to compute approximations to these decisive integrals. And of course, you have several possibilities. Course, you have several possibilities, you can think of many different approaches. And we finally decided to come to the Fouri spectral method for some reasons that I will point out later. So we use Fourier expansions of the density function and where possible. So except at the singularity or except that in a neighborhood of the In a neighborhood of the singularity of the integral kernel, we use these Fourier series expansions. Nearby the singularity of the kernel, we use quadrature approximations. And then we also recognize basic integrals that we can compute exactly. So this was the first approach and what And what was the reason to do it in this way? Well, of course, when you have this Fourier spectral method, you have the fast Fourier transform, the inverse fast Fourier transform at hand. So this is quite nice for efficiency. So this is really a strong tool that you can use. We are also coming back finally to summations along certain directions. Summations along along certain directions. This is also fast to do from the numerical point of view. And when you use the forest spectral method, you come to these basic integrals, you also see then you recognize a reduced computational complexity. So you do not, as you would expect, come to sums, triple sums, you only have double. sums you only have double sums or single sums or even scalars and this makes it finally quite quite nice for the practical realization so some some first considerations and for the moment I will somehow shift a little bit aside this singularity at the origin. Singularity at the origin. So please just for the moment think of this situation that we have a kernel that has large values or even very large values. But let's just for the moment close this singularity, which would be present at the origin. Okay, so our main tools are Fourier functions. What What we finally decided to do is to leave freedom in all directions, in all three directions. So, maybe to start here, we finally truncate the full domain, but we leave some flexibility so we can choose different integrals or integrals of different sizes in each of the velocity directions. Velocity directions. And this is then, yeah, this freedom or this flexibility is then reflected in a notation of the Fourier functions. So, well, this is maybe not of so much importance. Of course, you have just the exponential, then you have the associated eigenvalues with the associated eigenvalues. Or with the associated eigenvalues with respect to the first derivative, which are given by such quantities. What we also use is the periodicity of the Fourier functions. And from the 1D Fourier function, we build up our three-dimensional basis, Fourier basis. Okay, and then finally, I truncate the index domain set to the three. Set to the three, so the all integers I just truncated in a suitable manner. Okay, so general benefits of the Fourier spectral method, we have high accuracy for localized regular functions. So, as soon as we have a certain regularity of our functions, so density function and integral kernel, as soon as we have a kind of localization. We have a kind of localization of these functions, the Fourier spectral method works very nicely. And due to the fast Fourier transform, we have high efficiency of this approach compared to other approaches, other possibilities. Okay, and within our particular setting, so you see you have this kind of convolution type integrals. integrals yeah so the integral kernel phi of v minus w and then the density function f of w and due to this particular form and the particular properties of the complex exponential we have a very nice possibility to simplify such products of Fourier functions yeah so we can in a sense separate then the variables v and w and then this works out And W and then this works out really nicely. So, this is one essential point, also. Okay, yeah. And then we have our Fourier series expansions. So, you see here, without this singularity, I shifted aside. I just assume for the moment that I have a Fourier series expansion of the integral kernel, also of the partial derivatives, first order partial. Partial derivatives, first-order partial derivatives, and similarly for the density function, which is an unknown function. Yeah, so I will use this representation. And then, in order to determine derivatives with respect to the velocity variable v, I may use the eigenvalue relations. So, I think this is quite well known. And this is what we also use. We also use. I mentioned basic integrals. So, what do I mean by these basic integrals? This is, as you remember, an integral involving a polynomial part and a Fourier function. And of course, just by hand, by partial integration, sorry, in English, by integration by parts, we can easily determine these kinds of integrals. These kinds of integrals. And there is one point which then finally leads to reduced complexity. Namely, we have this special property that these integrals lead to value zero for many combinations of the indices of the Fourier function. Since we integrate over one interval of periodicity, this is the main reason. And this observation then finally explains the significant reduction in computational complexity also for three dimensions. Okay, so let's now come to this first case, Maxwellian molecules case using Molecules case using the BKW solution on the unbounded domain as test case. So I just recall maybe the situation. So this is the lambda operator. Our aim is to evaluate this operator numerically. We have now the case where the integral kernel is just a constant. So we have this simplification here. Divergence of an integral involving a Of an integral involving a quadratic term and then this combination of the density function and its derivatives. And just for test cases, I'm looking at the 2D case and also on the full 3D case. So in this particular situation, it's possible to construct a solution, to construct a solution on the To construct the solution on the whole domain, on the unbounded Euclidean space. In 2D and in 3D, I'm giving here the solution in the 3D case. So you see, I choose a particular constant for the integral kernel, certain exponents, and then such combinations involving the exponential. And yeah, okay. And yeah, okay, so this is this is somehow a Gaussian-like solution, and then I have some additional terms that are given by the exponential and also some polynomial parts inside. Okay, so this is a well-known approach to construct this BKW solution. And for our purposes, it was nice to go one simplification. One simplification step further. So we start from this solution evaluated time zero, and then we just construct the associated Lambda operator in order to test if our numerical approach for the evaluation of this operator works nicely. So this is a perfect situation from the numerical point of view. So what do I do in this case? What do I do in this case? So, I have this representation of the lambda operator that you recall. I have the representation by the Fourier series that you recall also for the derivatives. I have my integrals, these decisive integrals, and I can just relate them in the present case to basic integrals. So, this is an So, this is an exact representation, and for the numerical approximation, I just need to truncate this representation. Yeah, and also the full formula simplifies significantly since, of course, the derivative of a constant is zero, so many terms vanish, and so I'm left with this representation. With this representation of the Lambda operator, finally. Okay, and this is implemented, and then the solution can be computed. Yeah, so the Lambda operator can be computed, and also the associated Lambda equation can be solved. And you see here now the solution profile. So, maybe just to explain these graphics. Graphics. So, this is the Maxwellian molecules case in three dimensions, and this is the solution at initial time. This is the 3D case, a section of the solution close to V2 and V3 equal to zero. So, a section just through the origin. And here you have the projection to the plane where. To the plane where v3 is equal to zero. So this is the initial state, and then you evolve in time, and this is what you would expect. So your solution approaches, then finally, a Gaussian-like equilibrium state. Okay. So now more. More, let's say, more comprehensive numerical tests. So, first, verification of the approach, then some comparisons concerning computation times and also some comparisons concerning accuracy. So, as I said, one idea of us was also to allow more flexibility in the choice of the In a choice of the numerical domain of the truncated domain. So, we are comparing two situations where we have a non-symmetric choice of the underlying domain and also a different number of Fourier basis functions in each of the velocity directions. And then we have the somehow simpler case, which is, of course, then in a sense also faster, more simpler, more. More simpler, more efficient, also, where I have this kind of Cartesian product of a fixed interval and also a fixed number of basis functions in each direction. So usually I'm choosing about 100 basis functions in each direction, so I have 10 to 6 degrees of freedom concerning the velocity in the computations. In the computations, yeah, and what you see here is that the first results are really nice. So, in 2D and also in 3D, 2D to the left and 3D to the right. So, what we see accuracy comparison with the exact known solution is really nice. So, we have absolute accuracy of ten to minus thirteen in two D and comparably also in three D. Comparably also in 3D. What you see, let's say it's a complex problem. So in 2D, it's still quite nice. So your computation time is rather low. But what you see is the increasing computation time in 3D. And this is still nice in the Maxwellian molecules case, but finally we will need about, yeah, let's say some seconds per time. Let's say some seconds per time step, yeah, which, of course, for a long-term integration then finally leads to long times in the simulation. Just ask you, what is the time unit on the axis? So if there is three or is this three? Ah, sorry, sorry. Thank you, Birgit. No, sorry. This is no time axis. This is just different choices of the implementation. Choices of the implementation. So, this is uh choice one. Yeah, this is a bit misleading. Sorry, um, this is a bit misleading. So, this is choice one, this is choice two, this is choice three, and this is choice four. So, these are just slightly different approaches. Yes, thank you for this question. So, this is one implementation and another implementation for the non-symmetric case and here for the symmetric case. And here for the symmetric case, you have better accuracy finally. So, but it's only the choices and not time or any physical parameter. Okay, so and then what I mentioned earlier, of course, also the physical, the conservation of physical quantities is quite important in these kind of problems. So, I'm giving here the So, I'm giving here the conservation of mass. So, you see, mass is just the integral over the density function on the full domain. So, this is conserved over time. Then I'm here displaying energy. This would involve the velocities and the square of the velocity components. This is also conserved. Then, I, of course, have also first moments, which are just Moments which are just then given by integrals over the velocity and the density function, they are also conserved. And then finally, I have an entropy in this equation, namely a decay of entropy is typical here. So you see, entropy is given by the density function and also the logarithm of the density function. So it's not just only conservation, but also positivity of the solution, which is then finally. The solution, which is then finally important and which is a not so trivial numerical task to preserve positivity. So, what we are doing, we are ensuring high accuracy in our solution. And then finally, we have, yeah, let's say we through this high accuracy, we then just take user protection on the Use a projection on the positive values of the solution, and this seems to work quite nicely. Yeah, but of course, this is also an open question for itself. A side remark for those of you who are interested in splitting methods. So for the time integration, we are using a kind of standard approach, a simple approach based on explicit Runge Kuta methods. Explicit Runge Kuta methods. And of course, you have step size restrictions in order to ensure stability of the Runge Kuta method, of the explicit time integration method. And so one idea was also to use a splitting approach. And as I showed you before, so we have the second derivatives of the density function inside. Side. So the stiffness, let's say the main part of the stiffness of the problem comes from these derivatives. So what I was also using is a kind of splitting into several terms, not many, but several terms, and using then a semi-implicit way in order to treat these secondary. Treat these second derivatives. And this seemed to be quite nice in order to stabilize the method, as I will show you on this slide, so here. So stability, this is of course connected to reliability of the computation. So this is an important question. Yeah, so just some remarks here. I'm displaying results for the explicit Euler method in order to compare it with the first-order splitting approach. But the conclusions and observations hold likewise for higher-order explicit Runge-Kutta methods. So I will give you some results later on. We have the expected results for relatively small. For relatively small time step sizes. So, with the 10 to 6 degrees of freedom in velocity, we need really small time step sizes since the problem is stiff, very stiff. And as soon as you go to larger time step sizes, then you really observe these severe stability issues that you would also expect. Yeah, so failure of the procedure. The procedure. And as I mentioned before, a first-order splitting type method seems to be quite nice. So, this, I think, is worth further investigations. And you see here, just maybe the results to comment on that. So, as long as time is quite small and the number of time step sizes is quite high. This is quite high. I have also in 3D the expected result, so order one in time in the time integration. When I go to larger time step sizes or to larger times, yeah, not too large, I mean time unit equal one, that's of course, yeah, let's say we want, of course, to reach this final time in any case. And here, even with much even with a much reduced significantly sorry significantly reduced number of basis functions, Fourier basis functions, so a much less stiffer problem, I have stability problems as you see here. Sorry, this was too fast. So as you can see here, for larger time step sizes, I just have no solution at all. No solution at all, and then I do not have the expected order of convergence of the numerical method. And up to time equal one, I can improve this situation by using a splitting approach, a lead type splitting approach. So decomposing the equation in several components. And here I can then read. Read a reasonable number of Fourier basis functions. Okay, so now what we also have is conversion towards the equilibrium. So this is a further test. So this was before for the exact solution where you have this equilibrium observation and then likewise. Observation and then, likewise, for the numerical integration method. Now, with the adaptive explicit Runge-Kutte method, the standard ODE for 5-Solber. You see here, still I have quite nice accuracy then finally in approaching, approximating the equilibrium. Long-term integration here, what's about mass by our first approach. By our first approach. Yeah, so we have, let's say, a good conservation, but not perfect conservation of mass. And also likewise for energy. So here accuracy is high, but we do not conserve energy perfectly. And this we can reach. So conservation of mass we can reach by a rather simple modification of what we are doing. Simple modification of what we are doing so far. Energy, this is also a task for the future. So, there are some recent ideas by Lorenzo Bareschi and co-authors, and what we would like to understand if it's possible to use these ideas also in our case. Yeah, and this is just. Yeah, and this is just now for a longer time. So, what I checked here is just a time integration up to time 100, so significantly longer than before. And you see, I have here accuracy, 10 digits here, 10 digit digits concerning mass, and also eight digits concerning energy. So it's not too bad. Okay, so let's now come to the regular integral kernel. So, in principle, we have our path and we follow this path. And the difference is now that we have this additional integral kernel here. I'm assuming it's regular, so I'm assuming I may apply also a Fourier series expansion for the integral kernel. That's what I do. Do yeah, and what you see, I showed you this relation for the Fourier basis functions before. I can, um, by using this Fourier series expansion of the integral kernel and likewise for the density function, as I did before, I can use then the product of the Fourier basis functions and I can simplify this so in the sense that I can separate variables. So, the ideas that I presented to you before. Presented you before, they can just be carried over to this current situation here. Formulas get a bit longer, but in principle, we have the same quality of our approach in this case of a regular candle. Maybe here now to point out once more what is the computational effort. So, what I need are matrix multiplications, summations along certain directions, and mainly inverse fast Fourier transforms. So, that's the main part of the computational effort. And as I said before, due to these basic integrals that vanish for certain That vanish for certain indices or for many indices in principle. A crucial observation is that even in three dimensions, I have no triple sums, which would be really expensive. So everything finally drops down to single and double sums. Okay, so I go back to my Maxwellian molecules case. I have the longer formulas, yeah, I implement them and then I test. Them and then I test again on the basis of the Max Ellian molecules case. And what you see here, it just works as before concerning accuracy. So you remember, I also have my 30 digits. I have now some pre-computations to do. This is still quite nice. So this will be much more expensive or more costly in the Coulomb case, in the final case. Computation time is now large. Time is now larger. As you see, I need just a few seconds per time step. But in principle, it's as before. And now, maybe not too many details on this, but what we also, let's say, wanted to examine is how our approach works in a simple case where you can determine. Case where you can determine principle by hand the Landau operator and the solution of the Landau equation, but where your solution is defined on a bounded domain. So where, let's say, also differentiation based on the Fourier series is more delicate. Yeah. And okay, so our approach works with some model. Works with some modifications, but you see the limitations of our approach. So it's really then finally designed for the unbounded domain, localized solutions on unbounded domains. So this is what we checked here. Okay, so maybe not too many details on this. And then another test equation. So you see here it's like a Gaussian, yeah, Gaussian-like solution. Gaussian-like solution for the density function and also for the integral kernel. So it's a non-trivial combination. So your lambda associated lambda operator has a non-trivial form. So this is a kind of a suitable test problem then towards the Coulomb case. And what are the results here? So still, I have nice accuracy. Yeah, it's not. Accuracy. Yeah, it's not 13 digits anymore, but it's still several digits in 3D. And computation time is comparable to before. And also the time for the pre-computations is comparable to before. So it's consistent results, I would say. Okay, and now finally to the singular integral kernel. And I have seven minutes. And I have seven minutes, I see. So I will just focus on the main points here. So this is now the target problem with this singularity at the origin. So this Coulomb kernel. And here our idea was the following. So we decompose, our idea is to decompose the integral kernel into a The integral kernel into a regular function, like we can just use what we did so far and into a remainder, which is then capturing the singularity at the origin. And we do this in such a way that this remainder is non-zero only on a very small domain. And then we can reduce overall the overall commutational cost. Cost. Since here you remember we have the possibility to use Fourier functions for the kernel, for the density function. So this is quite nice, finally. Yeah, and that's what we do. So we define a small neighborhood of the origin. Then we use a simple interpolation procedure in order to determine the regularized kernel and then for Kernel, and then for the difference, we use numerical purchase approximations. And here, one point is also that we transfer a lot of the computations to pre-commutations that we can do once and for all in advance of the time integration. Yeah, okay, so this is again for the Maxwellian molecule. So we come back. So we come back once again to this simple test problem. So you see, see, this idea implemented works. So it just reproduces the results that we had before. But as you also see, we just need some minutes for the pre-computations. And depending on the size of the domain of the singularity of the sorry, Depending on the size of the neighborhood of the singularity, the computational cost, so the computation time will increase. So you see here 600 for a very small neighborhood and for a slightly increased neighborhood, we have a significantly higher commutation time. But in the during time integration, Integration, we have comparable times. So, and now just to explain this idea of this decomposition into a regular function and a singular remainder. So, let's just think of a regular kernel. So, what we would do, we would just cut here in a neighborhood of the original. In a neighborhood of the origin, yeah, for the integral kernel and also for the derivatives. So we would just use here interpolation. Sorry, I was too fast once again. So then we shrink our domain where we do budget approximations. This is illustrated here. And this graphics are given in order to illustrate how the procedure. How the procedure is done. So, this is a very simple approach shown here. So, we have we define the neighborhood of the origin. We just in principle can cut off the singularity. And then this blue line, this is a regular function in the sense that Fourier series approximations work nicely. And the quadrature approximation is then. Approximation is then only done for this remaining part in red. And also for the derivatives, this works for the derivatives of the kernel. So the similarity increases, but still it's possible to do that. Okay, and just another picture. So that's the regularized functions where I apply Fourier spectral approximations, and this is the The remainder where I use quadrature approximations. Yeah, so okay, we are now ready for the for the Coulomb case. And that's what I'm showing here. So in principle, I have the singularity at the origin, also for the derivatives of the integral kernel. And then I have two possibilities. Either I Either I somehow distinguish the case being at the singularity or not in my commutations, or I also have the possibility just to slightly shift my grid, my velocity grid. And this second alternative is shown here. So, in a sense, this singularity that had to be distinguished, this can be avoided. This can be avoided by just shifting a little bit the grid. Okay, and that's what you see here. This is in principle is that the figures I showed before, just for the Coulomb case. And also here you see this is now for the Coulomb case. I have larger and larger values when I'm approaching the singularity. And that's the procedure I'm using: interpolation, linear interpolation. Linear interpolation in these pictures. Okay, and again, the corresponding illustrations then for the projection on 2D. Yeah, and you see here now the profiles of the numerical computed solutions. So, a similar situation to before. I'm using. To before, I'm using this initial state at time zero, and this is then my evolved solution at time 10. It looks, so the profile looks closely, but you see that the amplitude decreases. So I'm starting here at 0.01, and then I have a much narrower profile of the solution here. Okay, yeah, again with a rather high number of Fourier basis functions 10 to 6. So, and as I'm running out of time, I see, so these are, maybe I just skip this with a few words. These are comparisons with the particle approach considered by José Antonio and coasters, and we have And co-authors, and we have consistent results also with these approaches. And maybe just two remarks on open tasks. What we would like to do is to extend our ideas in the sense that we exploit this. sense that we exploit different approaches that might be um that might be beneficial in in certain situations hamit functions yeah they are connected to the equilibrium states of the lambda equation so this might be nice for this uh for this purpose and um another another point is to explore even more this uh splitting approach yeah and maybe just one for one Maybe just for one very last remark. So the approach in order to construct the numerical method is done in such a way that in principle we know exactly where we have approximation errors. So in principle we also know how to do the convergence analysis of our method. Our method. So, with that, I'm finally finished. Thank you very much for your attention.