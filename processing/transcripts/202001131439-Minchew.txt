The contribution that I could make to the workshop is to talk about observations since I spend an inordinate amount of my time thinking about observations. And I realize it's primarily a modeling session, but all the modelers are just going to have to get over it. So, introduction, of course, start with a statement of the obvious. Remote sensing observations have revolutionized our understanding of glacier dynamics just in the past few years. It's been a fairly Past few years. It's been a fairly significant increase, fairly significant contribution to the field. So we're now to a point where we have near-complete spatial coverage and at least several snapshots in time in general of pretty much any remotely sensed field that we can get. Surface velocity observations, as shown over here on the right-hand side, surface elevation, gravity data from GRACE, a variety of other things, the kind of things that Matthew talked about earlier. In some cases, these data sets are getting good enough that we can get really high. Sets are getting good enough that we can get really high-quality gradients out of them. So, that really means is really high-quality strain rate fields in a lot of places. High resolution, high signal to noise ratio, and the strain rate fields. We do a lot of interesting things with that. So, the key observational challenges going forward because having complete spatial coverage and having at least a few snapshots is pretty well a solved problem from a remote sensing perspective. We'll just continue to collect observations. Continue to collect observations, we stack all these things together, we can beat down noise and this kind of thing. The interesting problems, though, and the key observational challenges as I see them is thinking about the time domain, extending things out to where we can infer consistent remote sensing time series from sparse and irregular data that we get from a variety of satellite platforms, and then taking and fusing multiple data sets together, multiple data sets, multiple data sources. So, different satellites, different types. Satellites, different types of measurements, so interferometry, altimetry, these kinds of things, fusing these all together to have a more consistent understanding of how the ice sheets are changing in time. Of course, the advantages to meeting these challenges, first obvious one is physical insight, the ability to observe phenomenon that we're not able to observe at the moment. We may not even be aware of at the moment. Data assimilation and models, hopefully the kind of thing that we're going to talk about here may be useful in seating discussions for how we may think. Seeding discussions for how we may think about assimilating time-dependent remote sensing observations, and then, of course, as with anything, many, many other advantages, some of which we're not aware of at the moment. So most of my interest in developing these kinds of data sets is really to better understand the rheology of the ice and the mechanics of the bed for the most part. We've already seen these equations before, just the shear thinning viscosity for ice. The exponent tells us about the creep mechanisms that give rise to the deformation of the ice, diffusion, dislocation, creep, gray, balance. Diffusion, dislocation, creep, grain, boundary sliding, all kinds of fun things. Prefactor, function of temperature, interstitial liquid water contents, anisotropy, so on. Mechanics of the bed, Ian showed this before. Just a power law rheology for the bed, so drag as proportional to slip rate of the bed raised to some power. The pre-factor function of water pressure, roughness, bed composition, these kinds of things, as Ian mentioned before. Of things as Ian mentioned before, the exponent is of greatest interest because it really tells us about the mode of sliding. So, if we're able to take observations and infer what the exponent is, so the amplitude and the sign of the exponent in a particular area, then we can really hone in and at least limit the set of admissible physical models that can give rise to the sliding in that area. All right, so simply put, our interests are in testing constitutive relations and calibrating these parameters in the natural environment through observations. Traditionally, it's been a very difficult problem, but it Difficult problem, but we have lots of new opportunities. I like to show this plot. I got it from Twilight, don't take no credit for this. But basically, the story here is the story of the increase in information that we have available to us from remote sensing observations. So, what's important here really is the density of these dots. Each one of these dots represents a measurement of surface velocity taken from satellite observations. So, going back to 2001, I have a dot. These are just three random outlet glaciers in Greenland. Three random outlet glaciers in Greenland. This story could be repeated anywhere. 2001, measurement of surface velocity, step forward five years, get another measurement of surface velocity. You start to get annual measurements here. Terasar X flies, it's a constellation of satellites now. That gives you these yellow dots, so we start to pick up this trend in the velocities. Landsat 8 flies, this is these black dots, optical satellite. We can use to measure velocities. You start to pick up the seasonal signal and these kinds of things, and so on. And these kinds of things, and so on. So, this repeats pretty much anywhere around the poles. And the general takeaway message from this is: at least in the polar regions, more remote sensing observations have been collected just in the past few years than have been collected in the whole history of the field before that. So, we can glean a lot of information out of these new observations. That's pretty much what we're going to talk about today. New information, high-resolution strain rate fields I mentioned before. Today, we're going to talk about the response of fast-flowing glaciers to non-local forcing. In particular, we're going to poke at the In particular, we're going to focus on the propagation of mechanical and kinematic waves through the glaciers that we're now able to observe and constrain with remote sensing observations. The reason that we want to capture these things, of course, is to provide unique constraints on the mechanics of the glacier beds and rheology of glacier ice. Two examples, an older one was published a couple years ago, Rudford Ice Dream in West Antarctica and its response to the ocean tides, and then some new work that we've been putting together looking at Yagosham and West Green. Yakovshaw and West Greenland and its response to calving. The setup in the talk is really, the structure is really built around kind of the methodological progression we've been working on for the past few years. First example, we're going to use a simple set of temporal basis functions that we define based on a wealth of prior knowledge in this area. So we use GPS observations, we're able to constrain how the glacier is varying in space and in time. We use that to inform our remote sensing. We use that to inform our remote sensing observations, and we'll go over that in detail. The approach we use here is a maximum posterior Bayesian framework. It gives us a formal error estimate that's based primarily on the signal-to-noise ratio of the individual measurements that we take in an area. We won't go into that too much in this talk, but I'm happy to talk about it in more detail offline if you want. Second example, this is ongoing work, really brand new stuff in the past few months or so, but it's the first step toward developing a First step toward developing a framework where we can have generalized temporal basis functions that allow us to capture a variety of complex responses and to include robust transient detection methods. So we can take data that are sampled sparsely in space and in time and try to infer periodic and non-periodic transient behavior within that data. We want to do this in a framework that allows us to minimize our need for prior knowledge. So we can take just pure remote sensing observations. Just pure remote sensing observations, we can go to different areas and we can try to infer the time-dependent signature in those areas without necessarily having to have a whole bunch of GBS data or something like that available in that area. We're developing more sophisticated uncertainty quantification for these things, and of course it's a first step toward thinking about data fusion, as I mentioned before. So, the first example, Rufford Ice Stream, West Antarctica, flows along the Ron-Filster Ice Stream, flows along the Elspeth. Fields in our ice stream. It flows along the Ellsworth Mountains. This is some work that we published about three years ago now. It looks at time-dependent 3D, it's the first ever time-dependent 3D surface velocity field over an entire glacier. Still the only one, to my knowledge, as a matter of fact, because we rely very heavily on a special data set to do this. The general strategy that we had in this area, though, is to recognize an outlet glacier that has a very strong response to some periodic forcing, the ocean tides in particular. Forcing, it's the ocean tides in this particular case. We have a ton of prior knowledge of the response from GPS observations collected by Hillmar, and then we have extraordinary data sets to really focus in on this thing. We'll talk about the SAR data set in just a little bit, GPS data that are shown here, that gives us very strong periodic variability to the ocean tides. And we have really excellent observations both abed and the surface topography. So, kind of a key takeaway point from this. So, this is a Point from this. So, this is an interesting feature for a variety of reasons. We won't get into it in too great a detail, but the GPS observations here paint a very interesting picture. So, down here on the bottom, this is the vertical displacement of the ice shelf, so the floating bit of the ice sheet. So, what you can see is this very strong variability at semi-diurnal and diurnal time scales, and then you can clearly see the spring-neep tidal cycle and this 14.77-day beat frequency. That frequency is quite interesting because the That frequency is quite interesting because the long flow displacement, as shown up here, the detrended long flow displacement, shows that that's pretty much the primary frequency of response of the horizontal flow of the glacier. So from an observational perspective, what we did in this area is we took advantage of the Cosmos SkyMed satellite constellation. So four nearly identical satellites that are orbiting Earth. Their orbits are set up in such a way that it can give us very short repeat past times in these areas. So basically the idea there is if I'm So basically the idea there is if I'm standing on the surface of the glacier, a satellite will fly over. It'll observe my position. A day later, another satellite flies over, observes my position. Three days later, another satellite flies over. Four days later, another satellite flies over. And then eight days later, that first satellite comes back. So we have this very dense sampling in time. So the Italians basically turned on the satellite for every single acquisition that we could get in this area. It was collected over eight months. It was collected over eight months. I had a movie over here that was running showing the observational scheme. But the basic idea is that we get 32 unique overlapping flight tracks, and these are collected from both ascending and descending orbits. And that's what gives you this kind of crossing pattern that goes on here, right? This is going to be an advantage because we're able to infer for each one of these patches here, we're able to infer displacement along the satellite velocity vector as well as along the satellite line of sight. So having this kind of crossing pattern gives us the pen. Crossing pattern gives us the ability to measure displacements along at least four unique line of sight vectors. We can use that then to infer the three-dimensional velocity field. We do that by using a method called speckle traction. I don't necessarily need to know too much about this. Speckle is just basically the coherent component of the noise and the radar observations. We can pick up features as well. But the simple idea behind this, this is just an example of a radar amplitude image. Looks like a black and white photo. You can see the shear margin. Like a photo. You can see the shear margins here that stand out very brightly, the shear margins are heavily crevosed, and radar really likes to bounce off of rough surfaces. You can see the mountains over here as well that show up quite well. So you use speckle tracking, these other kind of techniques, the idea is pretty simple. We just take two observations that are collected from the same point in space but at different points in time. We'll pick out a window in one, we'll drag it over the other, we'll calculate the cross correlation, slide, calculate cross-correlation, slide, calculate the cross-correlation, and so on. We'll end up with a correlation surface. We'll end up with a correlation surface. The position of the peak of that surface tells us about the displacement of this point in the time between these acquisitions. Curvature gives us some sense of the error. We repeat this thousands and thousands of times, and we get these maps of displacements. We take all these things. In this particular case, we ended up with 1,600 pairs of observations that we could use and switch together. That was from about 20 terabytes of data, which at the time seemed like a monumental amount of data. And it's a pretty paltry thing these days. Is a pretty paltry thing these days. But anyhow, we get lots of observations. Four plus unique viewing geometries that I mentioned before is able to constrain both horizontal and vertical motion. And that's just because we take displacements along the satellite velocity vector as well as the radar line of sight, which is oblique to the surface. So sensitive to horizontal and vertical. We take all these things, and in this area, we use our prior knowledge from GPS observations so we can write out our simple model for. We can write out our simple model for our displacements. We say that the displacements at any point in space is just given as a sum of secular velocity vectors plus some family of sinusoidal terms. We know the periods of these sinusoids from our prior knowledge and our knowledge of the ocean tides. So we just plug those things in. Our observed observations are simply these displacements over the finite time between these observations and then dotted into the particular line of sight that the observations were collected from. We just chunk all these things together. We just chunk all these things together, and a big inverse problem, which I'm happy to talk to you about before, mentioned before, is just a maximum posterior Bayesian framework to solve this. We solve this inverse problem about 10 to the 8th times, and we end up with a map of all these different components, which we can then turn into a movie, which many of you have seen before. We'll run it forward. So, the panel that's of most interest is in the top right here. This is the variation in the horizontal velocity we observe from the satellites in Brentford, and then this here is the total. In Redford, and then this here is the total flow speed. So, this part is simply this plus the secular velocities that we observe. And down here on the bottom, this is just a simple tidal model. It's going to tell you where you are in the spring-neep tidal cycle because it's the spring-neep tidal cycle. That's the primary period of variability that you'll observe here. Okay, so colors on the top right-hand side, positive values are going with the flow, negative values are opposing the flow. We're running the movie forward. You can see the grounding line here. So, the ice shelf is down here. Ice shelf is down here. We can see variations that occur over the ice shelf, and then we can watch those variations as they propagate upstream. So, we get this fairly strong variability that's leading in phase over the ice shelf. That signal then propagates upstream, propagates to about 90 kilometers upstream in about three days. So, in other words, our phase velocity is about 30 kilometers per day, and we have a decay length scale of about 45 kilometers or so. So, I would argue at this time that changes in buttressing stresses on the ice shelf may be. On the ice shelf, may be the likely driving mechanism for this flow variability. Jerome's going to talk, you're going to talk on Thursday about a different idea about what may drive that. But from an observations perspective, we can go either way with this. Of course, we can set up a simple SSA model flow in a channel, maximal viscoelastic rheology. We can force this then with some longitudinal variability, derive the dispersion relation, so we can get the complex valued wave number of this a function of both the phase velocity. This is a function of both the phase velocity and the decay length scale here. Organize these things. And then we get two equations and two unknowns. The two unknowns are just our stress coupling length scale and then our relaxation time. We can solve these things based on the observations. We can move some equations around and we can come up with an analytical solution for the ratio of the two exponents, so the stress exponent and the constitutive relation for ice, and the exponent and the sliding wall as a function of observable or otherwise tabulated values. Otherwise, tabulated values. So, just the ratio of the secular driving stress to the time average basal drag here. And then this phi term is a big nasty thing, but the takeaway is that it's a function of just observable tabulated values, plug stuff in, get a value for the exponent that more or less tells us that the bed is plastic in these areas. So, yeah, could have done a little bit more of an intro here, but basically, as I mentioned before, the value of the exponent kind of constrains our range of physical models in this area. Models in this area, but I'm going to do it on time. Because this is the most interesting bit. A thing, 500 minutes? 5 to 7 minutes. So the second example on Yakshan, so here we're just going to use freely available data sets. So 555 horizontal velocity fields that are available from GIMP. So this is just Ian Jockin's output product. So all this is produced using the same speckle tracking stuff that we did before, just different satellites. Stuff that we did before, just different satellites, slightly different sampling frequencies, that's not terribly important. Point here is that we can get a generalized temporal basis function. That way, essentially, we're able to infer these time series from some linear combination of polynomials, B spines, and integrated B spines. Integrated B spines are just basically a smooth step function, similar to a tanch function. They're just more, they just work out a little bit better in this particular framework. We can use the least squares procedure. A least squares procedure with a design matrix that's G in this particular case that ends up being highly overcomplete and a non-orthogonal dictionary of displacement functions. We can set this up so that we have regularization, essentially a way to encode our prior knowledge about the observations through our prior model covariance matrix. This is similar to the setup that Hillmar mentioned before. And then we have this sparsity in decent terms out here. Okay, so we have a coefficient out front, and we're basically We have a coefficient out front, and we're basically imposing cardinality. That is, we are penalizing every aspect of our model vector that has a non-zero coefficient in front of it. So we have this over-complete dictionary, but we're forcing the thing to give us a sparse output. What that means, a different way of putting that basically, is that from these observations and from time-dependent surface velocity observations, what we can infer is a reduced set of temporal basis functions. Set of temporal basis functions that do a very good job of describing the time dependence of the velocity field. And then we can take that set of temporal basis functions, a fairly simple set of temporal basis functions, and we can reconstruct the velocity field at any point in time in a relatively smooth fashion, which should be a major advantage in thinking about data assimilation, particularly time-dependent data assimilation, because we deal with a lot of the errors and the uncertainties and the observations. Yeah. Uh Kraski, I presume you enforced that the bas temporal basis functions are both continuous and that's all encoded in our prior model covariance matrix. So we we could chat in more detail about that uh if you want. Uh so anyway, uh another way to put this of course is that it it allows us to decompose the signal into short term and long term components of variability. Components of variability. Alright, that's what we're showing over here. So, surface velocity fields for Yakusham collected three discrete points in this alley glacier, plotted over here, see the time variability in different places. So, these are the total observed velocity fields. I see a variety of observations. Basically, we can break that down then down into seasonal variations and then a multi-annual transient signal that reproduces the tune. Signal that reproduces the two observations. Okay, so of course we can plug this into a movie as well, just for fun, to look at the kind of signals that we're getting. So this is straight out of the observations. So you can watch the time dependence on Jakob Schauman. You can watch these signals, these transient speedups, and you can watch these signals as they propagate upstream. So you get a sense of the date that's going on over there. So strong variability at different times, particularly as we're coming up to 2012, we started getting high amplitude variability. Getting high amplitude variability, high amplitude seasonal variability, as well as an overall speed up in the mean velocities, and you can watch those signals as they move through the system itself. These velocity variations are driven primarily by calving. These periods of variability suggest that the upstream propagation is through kinematic waves, which Jilmar talked about a little bit before. So, from these observations, then we can compute the phase velocity and the decay length scale of these kinematic waves. A couple things that we get out of this, of course, the wave speeds are about two orders of magnitude. Of course, the wave speeds are about two orders of magnitude faster than the waves that we observed on Rutford, likely due to the fact that they're simply due to different sources, kinematic waves versus mechanical waves. A seasonal signal propagates roughly twice as fast as the multi-year signal. Hillmar mentioned this before, so at least in a full Stoics framework, then kinematic waves are dispersive. So in this case, you get kinematic wave velocities that are approximately proportional to the frequency of variability. These phase velocities, of course, are Variability. These phase velocities, of course, are an order of magnitude faster so than the mean glacier flow speed, otherwise, we wouldn't be able to see them. And we have distinct regions of faster and slower phase velocities that we can currently attributing to variations in the ice velocity. And these kinds of things, these phase velocities, decay-link scale, this sort of bit, gives us unique constraints on drag at the bed, geology of the ice, and so on. We can use the same sort of framework then as well to think about time-dependent DEMs and stitch through the variability in these DEMs. Stitch through the variability in these DEMs, changes in surface elevation. This is just a quick example of this. So, Arctic DEMs are very sparse in space and in time, mostly because they come from optical data that are very sensitive to cloud cover. But we can take our knowledge of temporal basis functions that we get from the velocity field, sort of apply it to the surface elevation maps, and then smooth over that. So, we can create time-varying DEMs and velocity. Time-varying DEMs and velocity fields that are sort of have more or less the same time step, effectively. And this is just showing essentially that what we get out of this makes good physical sense. So speed ups and velocity, drawdown, and the surface elevation we infer from the Arctic DEM data. All this as well is to illustrate the direction of work is to extend these methods to 3D as our first step in fusing together multiple data sources in a reasonably coherent fashion. Coherent fashion. So, yeah, two examples, just quick examples: spatial temporal variations in ice surface velocity as well as surface elevation. So, propagation of mechanical waves, propagation of kinematic waves, both cases were able to measure phase velocities, all kinds of fun stuff. The methods presented here could hopefully be useful for data assimilation, and they also inform our nascent work on machine learning methods to see if we can learn the form of the sliding law from data. That's it. That's it. So start with specific questions for Grant. We have a fair value of time for generic questions as well.