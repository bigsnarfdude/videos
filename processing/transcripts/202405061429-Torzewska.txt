Nice conference. So I'm going to talk about a paper called Classification of Charge Conserving Loop Braid Representations, which has worked together with Eric Rowell and Paul Martin. So let's start by talking about the braid category. So we heard a lot about braid groups already today. So this is a category formed by taking all of the braid groups that you All of the Bray groups at each end together. So, what do the objects in this category look like? So, we can represent these objects as just collections of points. So, here we have in mind some kind of topological construction of the braid category. We heard earlier that there's several different choices. But, for example, if we take Artin's original construction, then we've got a specific choice of embedding of a collection of points into the Of a collection of points into the disk. But we're just going to represent them as these collections of points. And we can put a monoidal composition on these objects where we just take the sum of the number of points we have. So if we have two points and we take the tense product with one point, we get the object represented by three points. Now, again, we have some much more complicated topological construction in mind. So, really, what we're doing So, really, what we're doing under the cover here is taking two separate embeddings of points into separate disks and then somehow joining these disks together and doing some homeomorphism such that we get back to our embedding of three points. But this really does all work. And then we end up with a collection of objects that are isomorphic to the monoid natural numbers under. Natural numbers under plus. And then what do our morphisms look like? Well, again, our morphisms are really some topological thing. In the Artian setting, these are embeddings of unit intervals into the disk cross i cross unit interval such that their endpoints meet these embeddings of points. But again, we can just represent these as diagrams that look like these with these crossings. And again, Things and again, we have a monoidal composition on our morphisms which correspond to some topological construction. But we can just represent these by drawing these diagrams next to each other. And then we also have a category composition where we stack these diagrams in the diagrammatic language that corresponds to stacking these diagrams on top of each other. And And to give, so to explain what relations the morphisms in this category satisfy, I can do this by observing an isomorphism to a combinatorial category. So we have a combinatorial category B prime, where this is just the strict monoidal groupoid, which has object monoid, the natural numbers, so generated by one object, which we label one and a plus. 1 and a plus, and it has one generating morphism, sigma, which is a morphism from B prime from 2 to 2 in our combinatorial category, B prime. And this generating morphism obeys this braid relation, which we often see written like this, sigma 1, sigma 2, sigma 1 equals sigma 2, sigma 1, sigma 2. And in each case, so sigma 1 corresponds to the monoidal product of sigma with the monoidal unit. The linoidal unit with the identity morphism, sorry. And then this, I lost the point. This has stopped working. Okay. Maybe, does it have batteries? Maybe it's run up. Okay, maybe we just do it with just do it with the computer. Okay, good. So we. Good. So we have this. Maybe I'll sit down and then I can use the maps in the computer. There we go. Okay, so we have this combinatorial category which satisfies this relation. And then it really is true that we get an isomorphism between this topological category and this combinatorial category, which we get by sending this generating morphism sigma to this crossing the This crossing, the morphism that was represented by this crossing in our diagrammatic language. So then I'm going to define a braid representation to be a strict monoidal functor from this category B into some monoidal category C. And since B is isomorphic to B prime, any such functor is just given by saying where we're going to send this. Saying where we're going to send this generating object and where we're going to send our generating morphism. And this gives a representation precisely if the images of sigma 1 and sigma 2 satisfy the same relation over in the target pattern. And of course, in general, this is going to be a very hard problem. So one approach we can take is to start modifying the choices of Modifying the choices of source and target categories until we arrive at a problem we can actually start to say something about. So, in particular in this talk, I'm going to focus on the target category map of matrices. So, I'm going to define the category map to have objects, the natural numbers, and then a morphism F from a natural number I to a natural number J is just a J by I matrix. I matrix. And this becomes a monoidal category by just taking the Kronecker product of matrices. And of course, Kronecker product is multiplicative on the dimension of the matrices. So this category is going to have object monoid, the natural numbers under times, which of course is different to what we had in the braid category, which was the natural numbers under plus. So it's going to be a useful organizational principle. Organizational principle if we take the subcategory, if we take a subcategory which can actually be the target of one of these functors coming from the braid category. So in particular, I'm going to define this category mat n. So this is going to be a subcategory of mat where we choose some natural number n and we fix this n and then we only consider the object monoid. Consider the object monoid generated by n. So our matrices are going to have size n, m squared, n cubed, etc. And then what we can do is we can relabel our object n by 1, our object n squared by 2, etc. And now we have an object monoid in our category map n that looks like the natural numbers under plus. So this is the category. Category that functors coming from braid are actually going to hit. So we have Matn as a monoidal category with natural numbers, with object monoid natural numbers with plus. And then I'm just going to introduce some notation that will be useful for us later. So if we're looking at matrices in MATN from N to N, so I relabeled this N with just the object one. Object one. So I'm just going to label the rows and columns by the numbers one to n. And then what happens now is if we look at the rows and columns, if we look at the rows and columns of matrices from inmats from the tensor product, n tensor n, or equivalently n squared, which we've now relabeled as 2. The columns are now just going to be labeled by pairs ij, where both. pairs ij where both i and j come from the set 1 to n. And then if we look at mat n33, these are just going to be labeled by tuples of length 3 where each of the ijk come from the set 1 to n. And then I'm going to say a brave representation is natural if it sends f of 1 to 1. And so now these natural representations of b These natural representations of B are fully specified just by giving some matrix, which is the image of sigma under this functor, such that we satisfy this relation over in our matrix category, where now our tensor product is still the chronicle product. And so, what we've got now is that these representations are precisely solutions to the Ambassador equation. So, by restricting to these strict monoidal functors coming To these strict monoidal functors coming from Braid, we get solutions to the Angbex question. And then we could further take subsets of MATN. So of course finding all solutions to the Ang-Batcher equation is still a very hard problem. We could restrict to the subcategory which just contains permutation matrices. So matrices with just one, a single one in each. One, a single one in each row of a column. And then we can look again at braid representations which are permutations, so which hit permanent. And then these precisely correspond to set-theoretic solutions to the F-exter equation. And as we started to hear this morning from Alaria, we now have a lot of tools we can use to start saying things about the collection of representations we have. But in this Have. But in this talk, I'm going to focus on taking the target to be what I call match n categories. So it's going to be useful to just fix some language here because there's going to be a lot of different N's flying about. So this capital N, which is a global property of the whole category, I'm going to refer to that as the rank. And then we have this little n, which corresponds to the This little n, which corresponds to the object we're looking at inside the category, and I'm going to refer that to that as the width. So then we have rank n matrices from n to n that have dimensions capital N to the power a little. So for example, a matrix in map 5 from 4 to 4 has rows and columns which are labeled by a tuple of length 4. Length 4 where the entries come from the set 1 to 5. And then I'm going to call a matrix M charge conserving if the, so I'm using this kind of slightly physicsy notation. So what this notation means is the entry of M, which is in column W prime and row W prime. W prime and rho w. And I'm going to say that this matrix entry is only allowed to be non-zero if w is a permutation of w prime. So let's look at an example. If we're in map from 2 to 2, then our rows and columns are labeled by these length 2 tuples with entries in 1 and 2. And if we look at the column 1, 1, then the only permutation of 1, 1 is 1, 1 itself. Of 1,1 is 1,1 itself, so the only row that's allowed to be non-zero is this first row. Then, if we look at 2,1, well, both 2,1 and 1,2 are permutations of 2,1. So we're allowed to have non-zero entries in this 2,1 column and in this 1,2 column. So, this is the restriction we're making on the types of matrices that we're allowed, and these form a monoidal subcategory. form a monoidal subcategory of MATN, which we're going to denote match M. So then we're going to say a braid representation is charge conserving if it's a strict monoidal functor from the braid category which hits matching. And in the braid case, there's a complete classification of this which is due to Paul Martin and Eric Brow. So then the theorem I want to talk about today. The theorem I want to talk about today is this theorem which says that the set of all varieties of charge-conserving loop-brave representations from the loop brave category into match N can be indexed by the set of signed multi-sets of compositions of total degree n, where each composition has at most two parts. So I'm going to go over all of the things. So this is the rest of the talk is going to be me introducing all of the elements of this thing. Introducing all of the elements of this theorem so that hopefully by the end we can understand the content of this theorem. But I'm just going to go over briefly what I mean by these signed multi-sets that are these combinatorial objects that are indexing our representations. So we have sets of compositions. So these are partitions of integers into two parts where we keep track of the ordering. So we have these three partitions. So we have these three partitions of one in this example, then a partition of three into two plus one, a partition of three into one plus two, and then we have multi-sets of compositions. So we have a set here of several different compositions, multi-set because we're allowed repetitions. So later in the talk, I might say, so here we have this same composition of one repeated three times. I might write this as just a box with a superscript. Just a box with a superscript three. And what I mean by signed is that we have some of these compositions before this comma, which I think of these compositions as having the sign plus, and the compositions after the comma as having the sign minus, and the total degree in this example is 26. So all of the sum of all of these compositions is 26. And this is the same end, so this composition. And so, this composition will correspond to a representation which hits match 26. Okay, so the plan for the rest of the talk, to go over what we mean by the loop braid category, to discuss some properties of match n categories that make this classification possible, then to talk about what solutions we get when n is equal to 2, what solutions we get when n equals 3, and then from there we should be. And then from there, we should be able to do the complete classification. Okay, so first, the loop braid category. So I'm going to introduce this as a motion groupoid. So we heard about motion groups this morning, so we're now going to work in a slightly different setting where everything is a group void. Also, unhelpfully, my notation is quite the same as the notation Celestia used this morning. Notation Celeste used this morning, but hopefully it's going to be straightforward enough to kind of move between the two settings. And then I'm going to do exactly the same thing I did with the braid case, where I'm going to observe it's an isomorphism to a combinatorial category. And then from there, we won't use the topology anymore. So I'm going to be quite brief on the details of the topological setting. And if it doesn't make sense or you don't like topology, after these few slides, you won't need this again. Need this again. Okay, so I define motions in two steps usually, starting from what I call a flow. So the input is going to be some fixed manifold N. So this is the ambient manifold. So when Cheleste talked about her motion groups, we had like points living in a disk. So this M would correspond to the disk here. And then a flow in M is a path F in the space top A. F in the space top HMM. So this space is the same space that Chalese called homeo M. So I use this language because I think of it as like a subset of the category of topological spaces, sort of continuous maps. So we've got this subset of continuous maps from M to M, where we only consider maps which are a homeomorphism. And then I topologize this space using the compact open topology. So then our flows and paths in this space. So then our flows are paths in this space which start at the identity homomorphism. And I'm going to use flow m to denote the set of all flows. So just to consider a few examples, we could have the identity flow where at all t, the path just hits the identity homeomorphism on m. And I'm going to use this capital N to denote that flow. Another example we could have m is the unit circle, and then we can parameterize. And then we can parameterize our unit circle by some theta, and we can construct a flow which gradually rotates S1 by pi, for example. And then we have a way of composing our flows. So if we take two flows, F and G, we can construct this flow G star F. And this composition looks a lot like the usual path composition. We do F twice as fast, and then we do G twice as fast, but we As fast, but we have this composition with F1 because we insisted that all of our paths started at the identity, so we just have to do this to make sure these paths really glue together nicely and give us a continuous map. And then from a flow, we can obtain a motion by dropping in a choice of subset. So a motion is a triple consisting of this flow F, a subset N, Subset N and then the end point at the image of N at the end point of the flow F. So now this starts to look a bit like a morphism in a category where we have the label of our morphism, the source of our morphism, and the target of our morphism. And then together with Chois Farret-Martins and Paul Martins, we proved that this really does give us a groupoid. So for any A groupoid, so for any input manifold M, we get a motion groupoid where the objects are the power set of M. So this is really any subset of M that we can think of. So we can have loops, points, we can have more complicated things. Our morphisms are our motions up to some equivalence relation, which I haven't spoken about, but Chalesta explained to us earlier what this equivalence relation looks like. We have our star composition, our identity motion. Star composition, our identity motion, and then we have an inverse that looks like going backwards along the motion. And so then now I want to consider a specific subcategory of the motion group void where the ambient manifold M is just a unit box. So I'm going to take a very specific choice of objects. So I'm going to consider one object. So, I'm going to consider one object corresponding to each natural number, where the object n is given by a choice of n evenly spaced circles living in a plane in our box. So, for example, if n equals 4, we have a picture like this. And then I'm going to consider two very specific generating motions. So, the first motion I'm going to consider is this motion rho. Is this motion row where this second circle first moves down to the left, and then this first circle moves to the right, and then the second circle just moves back up into the position that was originally occupied by one. So these two circles are just swapping positions. And the second motion I'm going to consider is the class of this motion which starts in the same way. Which starts in the same way, the second motion moves down, but now instead of the first loop just moving right, the second loop moves up through this first loop, and then the loops return, so they've swapped positions. And then we also said what the category composition is. This corresponds to performing one motion followed by the next. In this particular In this particular motion groupoid, we can also put a monoidal structure on this in a very similar way to the way we did with braid. So, if we have four evenly spaced loops and another four evenly spaced loops, we can form a tensor product where we come up with some topological construction that glues these two copies of the unit blocks together and puts these loops back to where they need to be to correspond to the object. They need to be to correspond to the object which we labelled 8. And this we can generalize to a monoidal structure which takes the object n and the object m and sends it to the object n plus m. And we can generalize this to a monoidal composition auto-morphisms, which looks the same, bringing these two different motions together, placing them next to each other. And then in exactly the same way we did with And then, in exactly the same way we did with the braid category, we have a combinatorial category that we can find an isomorphism to from this loop subcategory. So L prime is the stryptonoidal groupoid, again with object monoid natural numbers, but now we take two generated morphisms, which are called sigma and s. S behaves like an element of the symmetric groups, which squares to the identity and it satisfies a brain. Entity and it satisfies a braid relation. Sigma behaves like a generator of the brave group, so it just satisfies a braid relation. And then we have these mixed relations that involve both S and sigma. And then there really is an isomorphism between the combinatorial category and this topologically defined motion subgroup weight. And this is realized by sending. And this is realized by sending this generator morphism S to the equivalence class of the motion where these loops just swapped without passing through each other, and sending sigma to the motion where the loops swapped whilst passing through each other. And so this is maybe quite confusing that I now don't have this generated tau that Celeste had in her talks. That Chaleste had in her talk. So she mentioned that she was talking about what's sometimes called the extended loop brain group and has this extra generator. So I chose when I considered this topological category only to look at things generated by these two very specific motions. Okay, so now I can consider these charge-conserving loop-braid representations, which are these strict monoidal functors from this loop-braid category. From this loop brave category to match n, which send 1 to 1. And again, since we have this isomorphism into L prime, this combinatorial category, we can think of giving these functors just by giving images of the generators L prime. And so in particular, the data of a functor is just given by the image of S and the image of sigma, which means giving two matrices in match n, s and s. In match N, S and R, such that all of the relations we had in L prime are satisfied over in the match N category. Why might we want to do this? So, there's a couple of different ways we could motivate this. So, one thing you could say is that every loop brave representation gives a brave representation, but A brave representation, but this doesn't work the other way. Not every brave representation gives a loop brave representation. So you could see this as somehow reducing the size of the class of functors you're looking at from GRAID. So if you want to consider functors from GRAID, but this problem seems too difficult, you could see this as adding extra conditions on the types of functors you're allowed, which might Functions you're allowed, which might potentially give you a classification problem that you can tackle. But also, these loop break groups have gained stress recently because they potentially model particle statistics in topological phases. And so, understanding these representations can be seen as understanding which particle statistics can occur in topological phases of matter. And these, in turn, have gained interest recently because of potential. Have gained interest recently because of potential applications to something called topological quantum computation. Okay, so now let's look at this match n category and try and understand which properties make it possible for us to write down the complete classification of functors in this case. So, first, let Z be a general matrix in map. A general matrix in match n to 2. So, for example, if we're considering n equals 2, then we have a matrix that looks like this, which we saw before. So, the first property to notice of this matrix is if we look at how this matrix acts on the vector corresponding to 2,1, so the vector with just a 1 in the position 2, 1, that's precisely because this matrix is charge conserving. Conserving. The image of the vector 21 under the action of this matrix is going to be just a sum of vectors which are permutations of the vector we started with, multiplied by scales. And we can completely generalize this to any rank. So if we look at how the matrix acts, how the matrix Z acts on some vector ij, then we can say ij, then we can say that if j is less than i, we'll get this Aijij plus Cijji. If I is less than j, we get dijij plus bijji. And if i is equal to j, we just get a ii ii. So in particular, if we fix our choice of ij, the image under z doesn't depend on the rank of the match category that we're working on. And so to apply this, let me consider three generic matrices in map N22. So I'm going to call these Z, capital Z, and Zeta. And they're going to have entries, corresponding entries, which are lowercase Roman, uppercase Roman, and lowercase Greek. So for example, in the rank 2 case, we have Z as it was before, capital Z, just with these capital entries, and then Zeta with these Greek entries. And then Zeta with these Greek entries. Now we want to look at a relation of form of this Z1, capital Z2, Zeta1, Zeta2, capital Z1, Z2. So all of the relations that we needed our matrices to satisfy, to be representations, were of this form, for some letting some pair of these matrices be equal or all three of them equal. So we want to choose. Um, so we want to check that identifi identities like this are satisfied by our interests. And in particular, this identity is satisfied if and only if it's satisfied when we look at the action on every vector ijk. But we said that when we evaluate each side of this, we're only going to get vectors which correspond to permutations by jk. By jk. And again, for each vector, the evaluation doesn't depend on the rank n that we're working in. So, what we find is that if we suppose that our matrices, our three generic matrices, satisfy this identity, and we delete all the rows and columns which have a label containing capital N, then we immediately get that the identity is satisfied for our new matrix, which now is labeled by all. Which now is labeled by all tuples from 1 to n minus 1. And so, what this tells us is that every loop rate representation in rank n restricts to a representation in lower rank n prime by just taking the indices 1 to n prime and deleting all rows and columns that were labeled by tuples with numbers above n prime. But we can strengthen this using a But we can strengthen this using another property of our match n categories. Any omega in the symmetric group, of course, gives an injective function from the set 1 to n to itself. And this extends to a monoidal functor from match n to itself, which is just given by acting on the tuples labeling the rows and columns with the permutation omega. So, for example, So, for example, and this always gives us a group action of the symmetric group on match M. So, for example, if we're in match 2, then we have one non-trivial bijection which goes from the set 1, 2 to itself that just swaps 1 and 2. And so we can look at how this acts on our generic charge-conserving matrix. Where if we look at the entry in column 1, 1 and row 1, 1, well, what does the permutation Well, what does the permutation do to one one? It sends it to two two. So this entry under this functor will move this A1 down to the bottom right corner, will move the A2 up to the top left corner, will swap this A and D and swap the C and B. And then using this, we can strengthen the lemma we had that now we can say each loop brave representation in rank N. Representation in rank n restricts to a representation in lower rank by taking any subset of the indices 1 to n by just applying this action of the symmetric group to move the indices to the start of the set and then applying the same proposition we used before. So, in particular, each representation when n is above 2 restricts to a Restricts to a collection of n equals 2 representations. But notice this doesn't work the other way. So if we have some matrix and on every subset of two numbers, it restricts to a representation. That doesn't necessarily imply big represent the big matrix is a representation. But if we look at rank three solutions, we really do get an if and only if statement. Do you get an if and only if statement here? So we can see this by looking back at the type of relations that we wanted to check are satisfied. So all of our relations were of this form, and so we say these have width 3 because they're morphisms from 3, from the object 3 to the object 3. And all of our relations that we need to check are satisfied are of this type. They're morphisms from 3 to 3. And so what this means. And so, what this means is that when we want, if we have some map from L to match N, and we want to check if it's a representation, we look at the action of our matrices, we look at the image of these identities acting on some ijk, but the only numbers that can appear on either side of these identities are the ijk you started with, and so if they're satisfied on every subset ijk, On every subset i, j, k, then they must be satisfied as representations into match n. Again, using this symmetric group action to relabel. So our plan for finding all of the rank n solutions is to first look for all the solutions in rank 2, then check which of these we can glue together to get. Of these, we can glue together to get solutions in rank three. Then, once we have the rank three solutions, we know that any possible way we can glue these together gives higher rank solutions. So, then we have the solutions in higher rank. Okay, so let's start by looking at the rank two solutions. So, we said that we have these formulae for how These formulae for how each of our matrices acts on a generic vector. So then we look at the identities we want to check are satisfied. We choose some generic vector. So here, for example, I'm looking at 112. And we just look at the action of each side of the identity on our vector 112. And then we get a family of equations. Equations corresponding to insisting that each side of this identity is the same. And so we get a list of three equations that look like this, the last of which is trivial and is always satisfied. And so we calculated these for the vector 112. Using the action of the symmetric group, again, these equations will look Equations will look the same for 2, 2, 1 as they do for 1, 1, 2. So for any IIJ, they'll be of the same form, but we also need to calculate the equations that correspond to Iji, Ijj, and III. But we get a family of equations that we can solve for the rank two case. And the complete set of solutions we get look like this. We get look like this. So we have one family of solutions which we call the zero-type solutions. So these correspond to this S matrix, this involutive matrix just being sent to plus or minus one, and this R matrix being sent to some alpha times the identity. We get another family of solutions which we call slash type solutions. type solutions where the S solution has just one and minus one and then just this off diagonal in the middle. Oh sorry, but just this off diagonal in the middle and then the R matrix sent to this. The R matrix is this solution again where we just have A1 and A2 on the diagonal and then just off diagonal in the middle with these parameters and all of these And all of these variables have to be non-zero. And then we get two other types of solutions where our S matrix, our involutive matrix, is again of this slash type where we just have the off-diagonal in the middle. But now our R matrix has this extra entry in the top left of this middle 2x2 matrix. And then we also have this other type where we have an entry in the Type where we have an entry in the bottom right corner of this 2x2 matrix. Okay, so we have all of our solutions in rank 2. So now we want to check which of these we can lift to rank 3 solutions. So let's start by looking at what a generic charge-conserving matrix looks like in rank 3. So, if we look at any subset of two indices, we get back to a rank two solution. So, for example, if we look at one and two, we get this rank two solution coming from this A11, this A12, B12, C12, D12, and this A22. Then, if we try and look at, for example, 1 and 3, we get another rank 2 solution coming from again this. Rank 2 solution coming from again this A11, this A13, B13, C13, D13, and this A33. So our rank 2 solutions glue together to give these rank 3 solutions by overlapping on these diagonal elements. So then we can look at all the ways we can do this gluing together of our rank two solutions. Two solutions. So, to give these, it's going to be useful to think of this formalism where we give solutions as these complete graphs. So, this graph just corresponds to exactly the matrix I had on the previous slide. So, these vertices, A11, A22, and A33, are these shared diagonal elements between the range two solutions. And then these vertices, the edges, are labeled by these. The edges are labelled by these two by two matrices, which corresponded to the one, two solution, the one, three solution, and the two three solution. Excuse me, always contain a red, or are they always formed using plan or not always? So they're always formed by just rank two solutions. So there's nothing extra, there's just you have. Extra. There's just, you have to check that everything glues together nicely and agrees on these shared diagonal components. But really, the rank three solutions are just made up of families of rank two solutions. And so let's just recall the type of solutions we could have in rank two. We could have this zero type, the slash type, and then this slash a and slash a bar. So then the classification switch. Then the classification. So I said the classification of brain solutions was done by Raul Martin. So these are all of the rank 3 solutions for which every rank 2 solution lifts to a loop braid solution. So not every braid solution gives a loop braid solution and there are other rank three braid solutions that I haven't given here but when you look at Them here, but when you look at the rank two solutions of those solutions, they don't correspond to any of the loop rate solutions. So, ones that restrict in every rank two pair to a loop rate solution are given by just these five types. So, for example, we can have three slash solutions, we could have two slash solutions, but then we find that the parameters corresponding to these slash solutions lock together. Lock together with one A solution. We can have two slash type solutions and a zero solution. We can have two A type solutions and a zero solution. Or we can have this identity type solution where we have three zero solutions. And so it turns out to be true in the loop braid case that if we look at a mapping of sigma and s to some matrices in match N22, then these become a functor. Then these become a functor, so they become a loop rate representation, if and only if they restrict to a functor on every rank 2, on every pair of indices they restrict to a rank 2 solution, and the restriction to b is a functor. So we don't have to do any extra checking that in rank 3 they really are loop rate solutions. It turns out to be enough just to tell. Turns out to be enough just to check that they give braid solutions and that they restrict to a collection of rank two loop braid solutions. And so then what we find is we have these eight types of loop braid solutions. Here on the vertices I've just given these plus and minus just correspond to the diagonal entries in the S matrices, but there's also a few more parameters here that I just haven't added to make it a bit cleaner. Just have added to make it a bit cleaner, but we get these eight types of rank three solutions. Okay, so now we're ready to give the complete combinatorial classification of solutions in rank N. So I said that these were going to be indexed by these multi-sets of compositions. So if we first consider this set. First, consider this set, which is the product of the natural numbers together with natural numbers of zero. So, this is just the set of all compositions. So, this first element is just the only composition of one. Then we have the composition of two, which corresponds to two plus zero. Then we have another composition of two, which corresponds to one plus one. Composition of three, three plus. Composition of 3, 3 plus 0, 2 plus 1, 1 plus 2, and so on. And it's going to be important for us later our choice of ordering here. So we order our compositions by increasing total n that the composition corresponds to, but by decreasing number in the first part of the composition. Okay, and then I'm going to define this set Jn plus minus, which is the set of all signed multi-sets of compositions of total rank N. So for example, J2 plus minus, we have these seven signed multisets of composition of total rank N. So here I mentioned this earlier that when I write this box 2, I just mean two copies of the composition. Two copies of the composition of one that is represented by a single box, and they're both before the commas, they both have the sign plus, and they sum to two. And then we have the composition of two, which is just two plus zero, composition of two, which is one plus one, and so on. And this is all the signed multi-sets of compositions of total rank two we could have. As n increases, these sets rate. As n increases, these sets very quickly become too large to write the whole set. But for example, we can have the same thing we had earlier: this lambda, which is an example of a signed multi-set which lives in J26 plus minus. And again, we have the same ordering. So within all of the compositions which live before the comma, we have them ordered in increasing size of the composition, but in decreasing size of the top row if they have the same. Of the top row, if they have the same size, and then the same after the column. Okay, so then to go from these signed multi-sets to a solution, a loop-wave representation, we're going to assign a set of parameters to each of our multi-sets. So any choice of parameters will give a different Parameters will give a different representation. So from each signed multi-set, we get a whole family of representations corresponding to this choice of parameters. So I'm going to use this bold face jn plus minus to denote the collection of pairs where lambda is a signed multi-set and this x-bar is a choice of parameters. And the particular choice of parameters we make is for each composition in our sign quantity. composition in our signed multiset, we choose a complex number, alpha s. So s is the number of the composition in the signed multiset. We choose a complex number. If our composition has a second row, then we choose another complex number, bet to s, such that their sum is not zero. And then for each pair of compositions, so in our multi-set, if we have a composition s and a composition t, we choose two parameters, mu st and. Î¼ST and CST. And this is going to be all the data we need to give a representation corresponding to lambda and x. So we're going to give a map R, which takes the pair of a multi-set lambda and a parameter space X and gives a matrix S and a matrix R. And then at the end, the theorem will be that these S and R really are. These S and R really are loop-braided representations. So we're going to do that by giving a list. So we're going to give R by first giving a list of scalars. So these are the scalars that lived on the main diagonal, these 1111 entry, the 2222 entry, and so on. And then a list of 2x2 matrices that corresponded to these 2x2 matrices. Corresponded to these two by two matrices, we got by choosing any pair of indices. And then the same for the S matrix. So we give a list of scalars, A1 to N, B1 to N, and then these matrices, Aij and Bij for every I less than J. Okay, so what's the recipe for taking a pair of a multi-set and a set of parameters and getting Set of parameters and getting a representation. So if we take a multi-set, for example, this lambda here, the first thing we're going to do is label each of the boxes by a number in the most obvious way from left to right. And now I'm going to explain first how to get these scalars. So we consider each number i, and then we're going to look at the composition. And then we're going to look at the composition NS that I lives in. So, for example, if I looked at I, if I took I to be 5, then 5 is in the third composition. So, we're going to look at N3. And so we assigned this alpha S to each composition. So if I is in the top row of the composition it lives in, then Ai is just going to be exactly this alpha. It's just going to be exactly this alpha. If it's in the bottom row, it's going to be the beta. And then there's some technicalities here about choosing the sign, but I think I'm essentially going to skip over this. And then we also need to define the scalars that live in the S matrix. So if I is in the top row and the sign of the composition it lives in is plus, so it's before the comma. Plus, so it's before the comma, then we're just going to make the scalar be one. And if it's in the bottom row, then it's going to be minus one. And then this is inverted if it's in a composition that's minus, so after the comma. Okay, so we have a simple recipe for obtaining all of the scalars from our multi-sets. And then now we need to give this family of 2x2 matrices. So if we look So if we look at a pair i and j, which are in compositions s and t, if s is not equal to t, so for example we looked at 2 and 3, which are in different compositions here, then our 2 by 2 matrix would be one of these slash type solutions filled in with these parameters that we assigned to our multi-sets. And then in the S matrix, we just have S matrix, we just have one, one entries on this off-diagonal. Now, another situation we could have is I and J are in the same composition but in different rows. So for example, five and six. Then we get that the R matrix has one of these two, these A-type solutions where we also have this entry in the top left. We have some minus ones and plus ones corresponding to these signs that. ones corresponding to these signs that I skipped over. And then in the S solution we just get again a slash type solution and then we can also get this a bar solution if the i and j swap over. And then the last type of thing we could have is we could have i and j are both in the same row of the same composition, so for example three and four and then our two by two matrix is just one of these identity type solutions where we just Identity type solutions where we just have these scalars given by the parameters we chose, and the S-type solution is just of the identity type. Okay, so then let's look at how this works in some specific examples. So if we had the multi-set where our n was 3, just consisting of this composition of 3 into 2 plus 1 before the comma and nothing after the comma. Before the comma and nothing after the comma. Then our R matrix is just given by alpha 1, alpha 1, so this corresponds to 1 and 2, beta 1, because 3 is in the second row of the composition. Then if we look at 1 and 2, we get a slash type, an identity type solution, sorry, because 1 and 2 are both in the same row of this composition. Then if we look at 1 and 3, we get one of these A-type solutions because A-type solutions because one's in the top row and three's in the bottom row of the same composition. Similarly, if we look at two and three, and then if we look at the S matrix, we just get a one and a one corresponding to one and two in the top row, this minus one corresponding to three in the bottom row, identity type solution between one and two again, and then these off-diagonal solutions between one, three, and two, three. And then just one more example where we get the slash type solutions. So if we have, again in rank three, we have one composition with a plus sign and one composition with a minus sign. Now we get three distinct scalars: alpha one corresponding to the one, beta one corresponding to the two, alpha two corresponding to the three. And then now between one and three, of one and two, we get this slash time. One and two, we get these slash-type solutions because they're in different compositions. Okay, and so then the theorem is that this construction really does assign to any pair of a sine multi-set and these parameters a strict natural monoidal functor from L to match n. And every such functor is in the orbit of some. Orbit of some image under this map R. So I haven't said much about what I mean by the orbit here. So I'm considering things up to this symmetry under the symmetric group, which I talked about before, and then X symmetries, which I haven't talked about, but this is essentially we consider solutions to be equivalent if we can conjugate them, if we can conjugate by a diagonal matrix to move between them. Okay, so then this is the main theorem that I wanted to get to, and I'm going to stop here. The reason to consider the Uh the reason to consider the the loop setting not the extended one with the with the extra uh basic motion. Is it physics motivated or is there something else? I think no. I think only really because um well I want to say it's like an easier first step but then it depends which framework you're working in. But certainly an interesting question to ask would be when do these representations When do these representations lift to? So, I mean, you're adding many more conditions to check, which might make in some settings might make things easier because you've got more relations your solutions have to satisfy, but you've got more things to check. But definitely, I think it would be an interesting question to think about that. Maybe some very, very basic questions. So, why church conservative? So, first, where does the name come from? Conserving. So, first, where does the name come from? And why that specific definition? Yeah, okay, good question. So, there might be other people in this room that are better at answering this question than me. Firstly, the name. So, I think the name just comes from the fact that we have these tuples labeling our rows and columns. And if we somehow thought of these tuples as labelling, if we thought of our one to n as labelling like a charge. 1 to n as labeling like a charge, then by considering only permutations, we're preserving the sum of the label. And then why are these considered? So I think this really comes from things Chileste and Eric were thinking about, looking at which representations we already knew about of grade categories and which of these representations lifted to loop representations. Representations and observing that some of the ones that did seem to lift were of this form, and then noticing that it was possible to say something about the complete classification by looking at this type. I don't know if anyone wants to add. Yeah, maybe I'll add that. So, if you look at the R matrix you get from UQSLN, corresponding to the standard vector representation, they're all charge consumers. So they're everywhere. So they're everywhere. I mean, it's like the most common. So there, in that sense, this Carge corresponds to what's to do with the central element in the quantum process. Yeah, maybe, maybe so. I think it's mainly just that the like the indices, like you have one, two and two, one, that space is preserved, so you think of that as being weakly charged. Oh, just the pair one, two, unordered. Pair of one, two, unordered pairs. So we're looking at one, it's basically then you take the tensor part, you add up the weights, and then sort of like you search the weight spaces, and it's very best for case. When you say it's spin, you can actually look at the spin. Yeah. That's not what we definitely don't want to say that around you again. Is it base dependent this notion of um yes yeah I guess I guess for example you can have the isomorphism between passes computed by changing faces yeah I'm not important anything. That's an important thing. Well, so you see, there's two kinds of symmetry that you used here. Permutation. So local permutation, of course, is okay. Conjugating by a diagonal, that's okay, that's presumably. But we don't really think too much about, like, if you had two charge-conserving solutions, from one to the other by Q tensor Q. It's arbitrary. You didn't mean that's kind of equivalence that you It's a dialogue thing. Yeah, and I mean, I guess, yeah, I mean, in complete generality, this is going to be a very difficult question. Perhaps we can say, I mean, from a category theoretic perspective, perhaps it makes sense that you should only consider equivalents where you're allowed to. You're allowed to conjugate by matrices that live in the target category. So then you only consider charge-conserving, and then maybe it's then I think you probably don't get equivalences between a thing. But yeah, I'd have to think a bit more about that. But probably we do get some equivalences if we allow ourselves to use all matrices. Good question. Come back to what you had said. So your comment is more about charge preserving a representation of the grade group. So would be the grade group more like than the UQ of the L SF2, so like SF2? I think this is much trickier. I don't think we can make sense of the mode of the model. It's not the same to the loop algebra on the previous. Yeah, it's quite a loop. Yeah, it's the R and have two different R matrices sort of acting on the same centralized algebra. 