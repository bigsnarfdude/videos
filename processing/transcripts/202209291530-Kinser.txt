Opportunity to be here in person with the organizers. And I'm indeed, this is a slight title change. I'm speaking of modulized spaces of representations of tame finite dimensional algebras. I added the word representations for clarity, as opposed to representations of algebras themselves. Our basic setup is that k is going to always be algebraically closed of characteristic zero. So certainly you can do the representation theory part in more generality than this, but since I'm going to talk a lot about geometry, Talk a lot about geometry and particularly moduli spaces involving variant theory. Algebraically closed and characteristic zeros make everything simpler, and I have not really investigated positive characteristic too much. In general, A is going to be a finite-dimensional associative algebra, but for me, since we're interested in representations, up to Merida equivalence, we can just assume it's isomorphic to a quotient of a path algebra of a quiver, where you have a quiver and an admissible ideal I. An admissible ideal I. So I will often say, I might say, you know, modules or representations or something of an algebra, but I'm secretly thinking there's always a quiver, and I'm putting very concrete situational vector spaces and linear maps in front of me. So let me get right to the definition. It's a little technical. I'm going to show you an example in the next slide. And I claim the definition is actually not that technical when you kind of digest it. So an algebra is tame if when you go to examine the modules or representations. To examine the modules or representations of a specific dimension D, there's a finite number of AX by modules. So you've got A modules on the left as you wanted to start with, but you also add some additional right structure of being a KX by module. And you want them to be not complicated write KX modules. You want them to be free of rank D, so that rank D is the same as the dimensions. You're sort of enhancing it to be modules over a polynomial ring on the right side. And you want this to have the property that when you go to start to look for your indicator. When you go to start to look for your indicomposable A modules of that dimension, every one of them is isomorphic to some specialization of this pi module. So we have this whole tensor wave writing it, but you should just think of it as plugging in lambda for x. So every one of your A modules that's indecomposable is obtained by taking one of these finitely many MIs and some value in your base field and plugging it in from lambda. And that's what it's obtained. So you sort of have these finitely many body modules. Finitely many body modules that control the ND composables in every dimension. Or even more informally, if I think of, I can think of them as each MI determines like a one-parameter family because it's a priori just this left A module, but with this right additional X structure, and I can plug in anything from my underlying field for X, I can think of this single bimodule as actually a one-parameter family of left A modules. And let me say, you might see I have, I only have not that many slides. I only have not that many slides, and it's a 50-minute talk. I'm planning to be very casual. I wanted to give this sort of sweeping overview, but I decided it was just a bit much to try to tell you all the details. So I want to give sort of a more loose conversational overview where I tell you the main ideas of the story. And if you're interested, then we have dinner and stuff like that to talk about it more rather than just trying to bombard you with every detail of this story. And so that being said, I won't be in a hurry. You're welcome to interrupt with as many questions as you want all along the way. Many questions as you want all along the way. Alright, so here's a picture of how this would look in a really specific example. Sort of the quintessential starting tame algebra comes from this quiver. And so representations of this quiver are assignments of a vector space to each dot and a linear map to each arrow. And you can do that, of course, in many ways, but the only ones which will be indecomposable, the building blocks for your sort of category of all modules, will be of the following forms. So you can either have Forms. So you can either have an n-dimensional space here, n plus one-dimensional space here, and then this is sort of like the inclusion of your inclusion into the first n coordinates. This is the inclusion of the last n coordinates. Similar here with projections. And those are kind of discrete series. So in those dimensions, 2n plus 1, you've got these kind of discrete series that you don't need any parameters. But then in even dimensions here, nn, specifically for this dimension vector, nn, you have these one-parameter families. And you have these one-parameter families where I can take the identity over the top. Again, this is all up to isomorphism. You can write it down many other ways with matrices, but up to isomorphism, you can put the identity at the top. And then this is a Jordan block of size n with eigenvalue lambda. And this will cover almost all of your indecomposables this dimension, but you kind of need this, you can think of it as a point of infinity where instead of that being invertible, the identity, you put the nilpot and Jordan block there, and you flip the identity to the bottom. And so that's all of, and that's really your starting point for 10 quick representations. Really, your starting point for 10 quiver representations. I want to draw to see explicitly how do you think of this in the KX bimodule picture. So, if you sort of unroll the equivalence between modules over an algebra and quiver representations, actually very concrete, this Ax bimodule thing is really just you're taking sort of a representation of your quiver, where instead of putting vector spaces here, you're putting free kx modules at the vertices. And then this tensoring with x minus lambda, as I said, is just. Lambda, as I said, is just substituting x for lambda. So you can see if I took this sort of representation over kx with three kx modules, I can specialize this, and I take sort of a Jordan block with an unknown eigenvalue x here. I can specialize this by plugging in any x equals lambda and get this whole family. And you might say, well, I missed this one. Well, you can just do like another one, and there's no, you could do another parameter family where you flip the Jordan block to the top. And that shows like a typical feature of these one-parameter families, they might overlap. Parameter families, they might overlap. There's no reason that these one-parameter families, there's no condition in the previous slide where you don't get multiple, you don't get the same isomorphism class multiple times. And so that's really the same thing here, like where's my one parameter family? Well, it's okay if the kx module structure is trivial and every value of x, lambda gives you the same thing. That's totally fine. That's not proven. So people do write it in different ways for almost all, but finally, many, blah, blah, blah. You can make it, but it's really logically the same. And this is sort of a simple story to write. And this is sort of a simple story to write. All right. Questions on the setup? Tame algebras? Let me tell you a little bit about the history of TAME algebras. So, for algebras of global dimension one, there's all this, I really should have actually put a bunch of names here. I'm sorry for all those people that I didn't put those names here. There's mostly in the 70s, there was classification of Tame algebras of global dimension one. So that's the algebra wave, sort of purely, you know. Sort of purely general algebra of putting this, say, their global dimension one. But if in the quiver perspective, that means you don't put any relations on the quiver, it's equivalent to that. You just take your quiver with no relations. And it's exactly the algebras which are path algebras of an affine deconquiver. So sometimes people call these Euclidean quivers or several other names. And so this has like a beautiful, simple classification. And I'm tempted to start rolling off the names of the people, but there were several groups doing it independently in different areas of the world. In different areas of the world. So, in the interest of not leaving certain people out, I'm just going to leave everyone else. Sorry. So, that's beautiful. Tang mounters, we totally understand them for global dimension one and affine and for quivers without relations. For higher global dimension, though, you're not going to get a classification. It's just not something that you can simply write down lists. And that's similar to finite representation type story. If you know Gabriel's theorem for quivers, if the finite representation type quivers. Representation type quivers are these ADE Dinkin diagrams, or if you go to species or more general things, you can get the other non-simply laced Dinkin diagrams. That's all beautiful in global dimension one. But then when you go to quivers with relations or higher global dimension, there's nothing you could write down that would be considered a list or anything of the quivers with relations of finite representation type. Same thing holds or tame algebras. You can, of course, like everything, going back. Of course, like everything, going back to the philosophy of James' first talk of the week, you can always try to specialize down or just pick things and try to do those things. For example, 1974, Riegel figured it out, figured out what the answer is for tame algebras where you have one vertex or algebraically you have one isomorphism of as a simple module. He gave a completely explicit list for this. Basically, it comes down to, well, if you have sort of one loop, if your radical has one generator, then it's finite representation type. If your radical It's finite representation type. If you're radicalized three generators, then it's wild representation types. You just need to consider quivers with one dot and two loops and start playing around with change of basis and you get a very explicit list there. Two vertices and symbols. There is a list in this paper of Hoshino Miyachi in 1988, and it's already, it's not something I could conceptually explain it. It's just a list. And they're pulling out of all these sources of these people figured this out, these people figured this out. We've got this tool that narrows down these, we'll add this to the list. Narrows down these, we'll add this to the list. So it's very, you know, there's no, even for two vertices and symbols, it's not something you can conceptually explain. You just have to kind of look at it, stare at it, and then the proofs are just pulling from everywhere, all sorts of things. So help that gives you an idea that tame algebras are complicated. You can't just sort of, if you want to prove something about tame algebras, you can't say, well, they look like this. The algebra looks like this. Let me start doing something with it. That's not going to be a good starting point. There are a few. There are a few really general, like what I call robust results that are really something really says something about TAME algebras. I mean, two that I would highlight that were kind of important in my work, that I guess I won't say specifically, are by Crawley Bovie. He has some really beautiful results that are about all TAME algebras in these papers in 1988 and 1991. One of them actually says, shows how tameness is controlled, that tameness when algebra is totally determined by some properties of certain infinite dimensional modules. Of certain infinite-dimensional modules, which is kind of interesting because in the setup, you know, we're only looking at finite-dimensional representation theory, and Carley Boovie showed that these certain so-called generic modules that are infinite-dimensional control whether an algebra is tame or not and control these one-parameter families. And then the other one is about Alislander-Wrighten theory of tame algebras, and that in these infinite families, almost all representations in these infinite families are isomorphic to their own. Infinite families are isomorphic to their own outside write and translate. So there's some beautiful results that are useful. You won't explicitly see them in the rest of the talk, but they're very useful in there. So one of the key points I want to put out there, though, that can sometimes be a misunderstanding about TAME algebras is most of the methods, if you go over any stakeholders here, even like two vertices, I'm not sure so much about the local case, but certainly the two vertex case, most of the methods you would use to prove an algebra is tank. You would use to prove an algebra is tame, they don't actually produce it, they don't do it by saying, here's the one-parameter families, and this covers all of them. That's just like an unreasonably specific way to do it. They're often, and I'll show you on the next coming up slides a little bit more about it, they're often that you know you have something tanged like these Euclidean quivers, and they do something like tilting or something like this, or you have a category that's similar to a category of quiver representations. You do some operation, you prove it doesn't change the module category too much. Maybe it only changes the number of any composables by a finite number in every dimension. Indicomposables by a finite number in every dimension. And so you do something extremely non-explicit to show it's tame. Therefore, you're not going to get an explicit description of the indicomposables. And so that's kind of important conceptually below, because sometimes I've, you know, I would talk to someone or ask them some questions about modulated tame algorithms. He's like, oh, well, tame algebra isn't that when you already know all the representations? And that's just not true. You know something about the existence, but you don't know, you in no way would know all the representations of a tame algebra just because you know it's tame. Of a tang out for justification though it's tang. I would say in the vast majority of cases, there's not really a classification of all the representations. All right, any comments or questions on tang algebras? So what am I interested in? I'm interested in geometry, algebraic geometry. And I'm interested in taking these one-parameter families and adding some sort of might call like intrinsic geometry. So in the definition, you just have these. So, in the definition, you just have these one-parameter families, and you can just choose them in so many ways. There's nothing really intrinsic about them to the algebra or the representation theory. You can just start writing them down. There's many ways to do it. You can say, if you take, like even in the Kronecker quaver I gave, if I replace the x with the x squared, you would also, you know, get them bimodule that satisfies those properties, but it would sort of be a double cover of the isomorphism classes. You could do x to the n, and you get many sort of redundant ways. There's not sort of just, even if you Not sort of just, even if you know the algebra and you know all the representations in some way, you don't know, there's not like one nicest way to write them down that's like intrinsic. There's, like I said, here, sort of too much freedom in how you could write down those one-parameter families. So the idea introduced by Alistair King in a 1994 paper was to apply geometric invariant theory. And so this is roughly the idea that if you have a space that parametrizes, I'll make this precise, but kind of too fast in two slides. Too fast in two slides. I'll make it precise. You have a space that parametrizes all your representations, but with redundancy, so, like, for example, matrix representations, you have many different matrix representations in the isomorphism class in different bases, and you have a group acting on it, it's sort of natural if you sort of mod out the group action in some sense, you will get something that's sort of more intrinsic because you've sort of started with all the ways to write it down and then modded out a group action rather than just chosen some representatives at the beginning. Representatives at the beginning. And that's the idea of GIT. But the sort of devilish detail is the group won't act in some natural way. The quotient is actually a variety or even a scheme or anything. The quotient will not, the sort of naive way to take the quotient won't give you something you can use. So geometric invariant theory is a way to produce things that are actual legitimate projective varieties of parametrized representations. Of course, there's going to be a trade-off cost to them. To them. And so, my goal, this talk about moduli spaces of representations, is to specifically understand these moduli spaces of representations for TAM algebras, and particularly the one-parameter families, kind of the building blocks of the families. All right, so here's the tech. So, this is part's not the next one's kind of technical, but this one hopefully is like, I wanted to give like the precise. Go, but this one hopefully is like I wanted to give like the precise definitions of these things, and this part's the kind of very algebraic part of it. So, this is the like algebraic slide, it should be hopefully very digestible. So, if you have a quiver, a weight on it is a tuple of integers indexed by the vertices. So, just like a dimension vector, as you go, you put a dimension of your spaces in each vertex. This, you can put any integer in its vertex, positive or negative. And then a weight, you can think of it as inducing a function on the category of representation. function on the category of representations where when it eats a representation, you just simply dot product it with a dimension vector and spit out an integer to maybe positive or negative. So that's a weight and it gives you a weight of each representation or gives you a number associated to each representation. So the way GIT works is you need to find out what's sort of your semi-stable and stable points and the definition of those, this is kind of secretly two conditions, not secretly, but just kind of small. Kind of smash together two conditions. I say a representation is semi-stable. First of all, when you dot it with your weight, you get zero. Sort of in this kernel of that action. And then furthermore, for every sub-representation, that's always going to be less than or equal to zero mu dotted. So it's sort of giving you some restriction to be semi-stable or some sort of restriction on what kind of sub-representations the sub-module is. That's the way you can think about. And then stable. And then stable is even slightly better. It's the same thing, but none of the sub-representations can give you exactly zero. So you only achieve zero at the very top, you know, v itself. And of course, when you put in the zero sub-representation, and everything else is going to be negative. So that's what stability is. And the cool thing about this, it seems like a fairly arbitrary thing to do, but actually if you look at the full subcategory of state of semi-stable representation, It's theta semi-stable representations. You fixed your theta. It's actually abelian. So you can think of it again like sort of a module category, but it's not really going to be a module category for a finite-dimensional algebra. But it's abelian, so you have lots of nice properties of being able to do homological algebra and such with it. Furthermore, it's even extension closed. And so it's a nice category to work with. And then finally, to kind of motivate this definition of stable, in fact, the simple objects of the category is semi-stable representation. Of the category of semi-stable representations are exactly as stable ones. And so that's the sort of slogan here. This is something that's, I think, it was counterintuitive to me at least, is that you can take this category of representations of your algebra A, you have a finite dimensional algebra. The simples are not that interesting, right? You've got finitely many simples corresponding to the vertices of your quiver. There's not like a deep structure of simples. And if you actually go to the subcategory, which is just really defined by very simple numerical. By very simple numerical criterion, the subcategory can have infinitely many simples all of a sudden. It can have a much, much richer structure of simples. And if you have done anything with GIT or like geometry, that's maybe hopefully sort of intuitive that that's to an algebraist why that would be a good thing because often like the simples are sort of easier to study and some get your hands on because they're just sort of less going on in them. So you kind of create this new category, yeah, which is weirder, it's smaller, but all of a sudden, Smaller, but all of a sudden, these big families of indie composables you want to study, which were not simple and had all these crazy composition series or whatever, they just become simple in this. They become easier to study because they're now simple objects in this smaller category. So kind of weird. Let me pause there. Any comments or questions for this? Yes. Is there any relationship to the semi-simplification of repo-bay? The semi-simplification, I don't think I know. I don't think I know about them. Of the category? Is this a categorical notion of semi-simplification? Yeah, yeah. And oftentimes, a lot of the indicomposables become semi-simple. Yes, that's kind of what's going to happen here. I don't know about an intrinsic version, but what's going to happen is we're going to, like, where we're going is, yeah, we're going to be able to take these semi-simple indecomposables and look at their sort of Jordan holder filtration in this category. But I'm not sure if I'm going to be able to do that. But I'm not sure if I don't know that I think I don't know the definition of semi-simplification of a category. Do any indecomposable representations in there that were indecomposable in the original category become simple? Yes, absolutely. Yes, so that's exactly the point. Many, many of them. And in fact, I'll give you an example. We'll go back to the chronicer query. Yeah, thank you. That's exactly the point. Many of the indecomposables, which are not simple in your original category, they become simple in this category, so you can study. In this category, so you can study these families of any composable. That's exactly right. We'll go back to the Kronecker example in front of the slides. Any other questions or comments? All right, so this is, I guess maybe depending where you're coming from, maybe all my slides are technical, but this one is really technical. But this is for the algebra. I know he has some algebraic geometers. I wanted to give the specific algebraic geometry construction. If you don't like this, you can just take the bottom line for the rest of the talk when I feel here. So, this is kind of what I was hinting at before about your sort of want to try to take a quotient, but the quotient doesn't exist, you have to do something fancier. This is what I'm going to explain in detail, or in at least detail, but completely in some overview. So if you're given your algebra, and it's presented as a quiver with portion of my admissible I, and you give a dimension vector, you get this affine variety of representations of your algebra of that fixed dimension vector. And it's, again, I just sort of, I made the executive. I made the executive decision not to try to introduce all the notation for this, which explains it, but it's very intuitive. It's just you go to your quiver, you fix the vector spaces at every vertex, then you have choices of how to fill in the matrices. Matrix spaces are just the simplest affine varieties. But we want to take the ones that satisfy some ideal. If you think about it, that's saying certain sums and products of matrices are zero. Those put conditions on your matrices that are closed, because you're saying things are equal to zero. You take the closed sub-variety determined by this. Variety determined by this. And so you get these affine varieties parametrizing your representations. But since you've used matrices, they're in a fixed basis, so there's some redundancy. You're not doing isomorphism classes. You're like doing a repetitive way of writing down the same isomorphism classes, potentially. And these varieties, there's no structure. You can't hope for any kind of structure on them. You can essentially get any affine variety to appear like that by some choice of A and D. So you don't have any starting point. They can have many irreducible components. Many irreducible components. If you want to think in a schemy way, instead of affine, instead of, if you place a variety of scheme, you can get any finite type scheme over Z, probably, maybe up to some smooth factors or something. But yeah, you get non-reduciveness. You can get all sorts of bad things happen. So you can't really hope for too much for these. All right, so you've got these kind of product of matrix spaces, and you've taken some sub-variety where some conditions are fulfilled. When are two representations isomorphic is when you can. Two representations isomorphic is when you can change basis to make take one to another. Geometrically, that's saying you have this base change group of change of basis at all those vector spaces acting, and it's sort of by conjugation in some sense. And so that acts on your variety. And then with that in mind, this is the definition of the so-called moduli space. And instead of just, and we're going to do something slightly more general, instead of just the moduli space associated with this, we're going to do it associated to any closed irreducible invariant sub. Any closed irreducible invariant sub-variety. So this is just, for example, maybe also it's intuitive from the geometric background. If I have some variety, which can be essentially anything, maybe I want to study the irreducible components first instead of just trying to understand the whole variety. So in general, you have any irreducible, GLD invariant, closed sub-variety of this representation space. It might be very difficult to say explicitly what that is for a given A or D, but just as a setup, these are the so-called semi-invariant functions on that sub-variety. You take all the On that sub-variety, you take all the elements of the coordinate ring, such when the group now transforms that function. This is the action. So you have G acting on Z. This is GLD invariant. The dot means you take the, I think there's a name for it, contra-gradient index or something, the way you act on functions. If you act on a space, it acts on functions. You take that action on the space of functions, and you want that to be sort of, you want the functions which are eigenvalues for that action. So with this theta g is a scalar, I didn't define this, but. Theta G is a scalar. I didn't define this, but theta was an integer associated to each vertex. And so, how can an integer associated to each vertex eat an element of g? Well, you can go to each vertex and you take the determinant of that matrix and then take that integer power of the determinant. So these are all, these are basically, as theta varies over all the possible weights, you will vary, this is where characteristic zero comes in. As theta varies over all the possible weights, you'll exactly vary over the possible characters of GLD. And so, yeah, so you take the semi- And so, yeah, so you take the semi-invariant functions, which are basically eigenvalues, eigenfunctions, but such that the eigenvalue varies according to a specified character of your group. All right, so you've got all these semi-ivariant spaces. The moduli space then is you take one, you take all its integer, sorry, natural positive multiples, and then at this you can check that's a graded ring, where degree n is given by my index n. Got a graded ring, I can take its proj, it spits out a projective variety. It spits out a projective variety. And that's called the moduli space of theta semi-stable representations, which are in this subarray system. The takeaway, though, so if that's not something you want to think about, and like what you actually do, and the way I actually use it, is I think about it the following way. If I go and I look at this modulite space, it's points. These are now, this is sort of the best way to sort of get rid of the redundancy of the group action. The points are now in bijection with isomorphism classes. With isomorphism classes of direct sums of theta-stable representations, which according to the previous slide, that means the isomorphism classes are in bijection with semi-simple objects of this semi-stable subcategory with that specific dimension vector. Pause again. Any questions on this or should I go away as fast as possible? What kind of projective price can you get? Can you get it? You can get anything. Yes, exactly. So, you can literally, you can just cook up, yeah, you can, there's several ways to do. Yeah, you can, and there's several ways to do it. Yeah, you can just cook up anything. And it's like, for example, it's not hard. And you could, I think there's both like tautological constructions where you can just sort of given your polynomial ring, how many variables, and your homogeneous ideal, you can just sort of make some sort of tautological quiver and weight such. I don't remember how to do it off the top of my head. You can do that. I think this is called. I'm not going to guess the name. But there's, yeah, there's a specific structure. I think it's old too. Like, people in algebraic geometry figure this out a long time. Too like people in algebraic geometry figured this out a long time ago because you know tilting tilting bundles and stuff started there before quiver people were looking at that, I believe. And there's some topological constructions there before Quiver people were thinking about moduli spaces, like long before this. You can also do things like if you're familiar like configuration spaces of points or lines and like P2 or like this kind of incidence geometry stuff, you can cook, you kind of know those can realize any kind of projective variety. You can cook those up in this way too. So there's lots of like kind of tautological. There's lots of tautological things you do. Yeah, good question, huh? Do you variety see taints and software? Well, that's where we're going to get it. Yeah, because that's exactly where my talks are. Thank you for asking. That's exactly what you want. Any other comments or questions? All right. So here's, let me show you what the moduli space is looking back to the concept. So forgetting that, and I'm not going to go through that construction, although, like, the original. I'm not going to go through that construction, although, like, the original proofs of this. So, I will say this: these results you can get from some of the newer papers, just like really super easy. But they're actually in the original papers where I think maybe Dirksen and Weyman and maybe some people before that, they're actually like computing all this stuff, you know, and just using Al Slander-Wrighten theory. And you can actually compute these semi-invariant spaces using all sorts of combinatorics and Al Slander-Wrighten theory, and then you can actually compute that stuff. But I'm just going to give you the answer. So, for example, But I'm just going to give you the answer. So, for example, if you take this Kronecker quiver again, and you look at dimension vector d1, d2, the sort of right weight to look at, and if you sort of, you know, you want to look at the dot product of the representations need to be zero, so that's sort of the obvious weight to take to make the dot product zero. And then if you take this dimension vector, or this dimension vector, you'll find that like this thing is stable. Both of those are stable and they're spaces, and so there's nothing else, and these moduli spaces will just be a single point. Moduli spaces just to be a single point, and that sort of reflects the fact that there's just one isomorphism class of indecomposable, but not by just like a choice, but like it's sort of the point is it falls out of a specific geometric construction rather than like, we just happen to know this, let's call it a point. It falls out of a more general geometric construction. These are kind of interesting now. So, for example, let's look at just the case of one, if I took one, one, so this is just one, and that's the scalar lambda, and that's sort of, and you can kind of see that like these things should. And you can kind of see that these things should patch together. I've got a whole set of K here of isomorphism classes. And then this one, if I sort of think of these scalars here as projective coordinates, you should see they should sort of fit together. And this is like the point at infinity. In fact, this construction will pop out that this moduli space is P1. It's a projective line. But it's also sort of more natural that you haven't sort of distinguished a pointed infinity yet. You haven't made a choice and called this the point of infinity. It's like kind of, it naturally falls out of like taking a quotient. A quotient. In general, what might be surprising is you might think you get a P1 for all of them. So this kind of illustrates a subtlety I wanted to mention here. You might think, well, yeah, but then there's just for higher end, there's just this choice of lambda, this one, and infinity. You always get P1. Well, it turns out the problem is these, they will not be, in general, these will not, for higher end, these representations will all be semi-stable, but they will not be stable. They will not have. They will not be stable. They will not have a, they will have, you know, compositions, a non-trivial composition series in the semi-stable category. And the thing that'll end up parametrizing is Pn, which will basically correspond to one way you can think of it as these are the indecomposables, but if I fill this thing in with generic matrices, you'll actually decompose into the identity and then some diagonal thing with distinct things on the diagonal. And so you actually generically won't get an. And so you actually generically won't get indecomposables. And yeah, I don't know if I can make it super intuitive, but the point is, if you actually compute this thing, you'll find out you get Pn, and it's actually not parametrizing these indecomposables. So that's the downside of the moduli space is they don't see these indecomposables that are not simple in the semi-simple category. So they do send, back to your question, Kent, all these things do become, for n equals one, they all become simple in this category, which is good. These things which were not simple, this whole family became simple. But for the higher ends, it doesn't work. They're not simple anymore. It doesn't work. They're not simple anymore. And the moduli space can't see them. It sees this as a space of a bunch of direct sums of these symbols with different possibly distinct eigenvalues. And this is technically actually this nth symmetric power of P1 as a variety, if you know what that means, which happens to be isomorphic to Pn. I'll answer questions on this slide. All right, so there hopefully gives you an idea. And as I said, really, if you go back to the earlier example. If you go back to the earlier examples, people were actually computing that this ring is a polynomial ring and two variables. For the chronic curve, if I take 1, 1, have to compute these spaces of semi-invariance using some hard for me invariant theory. Finding out this is a polynomial ring, two variables, and so Parage is actually P1. And so, yeah. Yeah, and then I think they do that for higher ed as well. Or they might have a similar theorem for the next one, I'm going to say. To the next one, I'm going to say. All right, so that's sort of background on moduli spaces and how I think they're cool. They're sort of an in like the takeaways. These moduli spaces are like a more intrinsic way to parameterize families of representations without like just making matrix choices. All right. So let me give you a history of moduli spaces and tame algebra. I'm just going to throw the conjecture out from the beginning. It's sort of, I don't know that this was conjectured in the beginning, but like all evidence leads to it, so I'll start there. It's if you have any tame algebra and you take any represent any And you take any irreducible component of any moduli space, that it is, in fact, always a product of projective spaces. Of course, that's very specialized, right? So, like, in a priori, if you go to other algebras, you can literally get any projective variety. So, the idea that all these irreducible components be sort of the nicest possible projective varieties is kind of surprising. I mean, I guess it's not, I can't say it's surprising because we don't know if it's true yet, but it would be surprising if it's true and be sort of like the nicest case. It's sort of, you know, if you want to think of tame things. You know, if you want to think of tame things as being nice, it would give like an additional geometric niceness to them. And so that's the conjecture. So, in particular, like if there's just a one-parameter family, that should be a P1. As opposed to if you have a one-parameter family, why isn't it some sort of singular curve or some sort of like elliptic curve or something? Like, why isn't this one-parameter families and other things? In particular, these are smooth. Like, all the irreducible components are smooth, which is not something you would necessarily expect out of a moduli space. Moduli space. So, where has this been proven? It's been proven for algebras of global dimension one. So, you have that back to my earlier slide. Those are just the quivers without relations. The Dinkin quivers, you can just explicitly do this and compute these things. I think Dumbo Gush and Leedson were the first proof. I think it also falls out of work of Dirks and the Wayman. I think Kendris had another proof later. So, there's lots of ways to go at this. There's even a paper of Ringel in the very early 80s on the sort of rational invariants. 80s on those sort of rational invariants. He really was sort of way ahead of his time on looking at invariant rational functions. I don't think it doesn't, I don't think it proves this, but it's sort of hinting towards this. Very cool paper. It's for tilted algebras. I believe maybe I or someone else mentioned this. So tilted algebras are very close to global dimensional one. So it's like you basically take your global dimensional algebra, you find a module with nice properties, no self-extensions, projective dimensional one, distinct sum ends, which are. Distinct sum ands which are equal to their sort of number of symbols. And you take its endomorphism algebra and you get this new algebra, which is no longer global dimension one, but it's super close. And the interesting thing there is, it's very like, this sort of illustrates the difficulty of this conjecture, is when you take a tame algebra and you tilt it, you just know it's going to be tame because there's sort of only finitely many differences, or you could, you could sort of lose everything. But in general, at worst, you're only going to get finitely many differences. You can't take something tame until. So you might say, well, it's just. So you might say, well, it's just if I know this is true and I tilt it, there's only finitely many differences, you know, you just know it's tame. So what's interesting about the conjecture, well, how tilting changes the geometry is not at all obvious. That's a very different thing to say you have sort of like a bijection on in the bijection on sets is very far from an isomorphism of varieties. That's the sort of simple way to say it, right? So you say you might say of a bijection on sets, but that doesn't tell you anything about the actual geometry. Even, you know, you can have even a bijective morphism. You can have even a bijective morphism in algebraic geometry, which is not an isomorphism, right? So you could have, these finitely many changes could have introduced singularities, and you can get however far from phene one you want. Quasi-tilted, Bobinski. So these are similar to tilted, but you take a tilting object of some sort of other, I don't think any technical details are important, but you take a tilting object of a different kind of category of global dimension one, which is not coming from a finite dimensional algebra. It's coming from like, I think the typical examples are like weighted projective lines if you see weighted projective. Like weighted projective lines, if you see weighted projective lines, and you can get these algebras close to that and look at their moduli spaces and Bobinski prove this conjecture for those. And so those are all these are using like heavily representation theoretic techniques to really do stuff with the semi-invariance. And I'm not an expert in all these techniques. And then a kind of jump forward in a different direction was by Carolyn Kendris in 2015. They went to acyclic gingual algebras, and these are pretty, this is sort of a big jump because This is sort of a big jump because all of these, there's like not too many families. There's not too many one-parameter families. Certainly, for these, at least, there's only finitely many sort of one-parameter families that you can kind of build all the rest by extensions. As you go up, you don't really find anything too new in higher dimension. It's probably true for this, but I'm not expert on it. Acyclic Jingle algebras, you can get more and more, like the number of one-parameter families can grow exponentially with the size of your dimension. So you have to sort of. Size of your dimension. So you have to sort of, it's very far from any of the previous ones, and they did it using more geometry. As I said, so most of these represent, these are like representation theoretic techniques. All right, so that's some history. And now I'll just, in the last couple slides, talk about some recent advances. This is sort of the major, I guess, recent advance was a technical tool. I'm going to very briefly explain this tool. It's actually for all arbitrary finite dimensional algebras, or motivation to prove it. Algebras, or our motivation to prove it, and this is in joint work with Colleen Kindris a couple years ago. Our motivation was to prove, work on TAME algebras, but it turned out the tool just works for arbitrary algebras. And we call it the moduli decomposition theorem. And I'm not, you know, it would take like a couple slides to really write it out. So I'm not going to do that. Roughly what it says, it has three parts, and it says if you want to understand a moduli space of semi-stable representations coming from some close sub-variety z. Coming from some close-up right AZ, it says you can go look at what I call the theta Jordan-Holder factor. So this is the Jordan-Holder factors in the category of semi-stable representations, a list of stable ones. And hopefully you can kind of see, like, as your representations vary kind of continuously in Z, the Jordan-Holter factors kind of have to also continuously vary in some sense. And this can be made precise, but hopefully that sort of makes sense. So there's going to be moduli spaces associated. Going to be moduli spaces associated to the Jordan-Holder factors, and those moduli spaces control this moduli space, determine the geometry not entirely, but only up to a finite birational morphism, which is like fairly close. The finite means there's finite fibers, but also that it's flat, so you have sort of a nice, and it's birational. So it's an isomorphism on an open sub-variety. So it's sort of telling you that if you want to understand these general moduli spaces and semi-stable representations, a good place to start would be. A good place to start would be to understand the moduli spaces where you have stable representations, and you're kind of going to close them up with some semi-stable ones, but like most of them are stable. You should understand those first. And then the really cool thing is in the case of Tame algebras, so this is where we're taking, this is where the fact that your sort of stable families can only be dimension one, at most one, it turns out that if you can show this semi-stable locus of one of these Z's is Of this, one of these z's is a normal variety, then this won't just be a finite birational morphism, it'll be an isomorphism, and it'll prove the, it'll basically prove the conjecture. So this is like the specialization where you're taking advantage of the fact that like essentially the normal rational curve is P1, and so it helps there. And so the downside is hard to prove things are normal varieties. Like you can't just take the equations and just put it in the computer and do it or something. And just put it in the computer and do it or something. You can very small examples, especially at matrices, because the size, the number of variables kind of grows to the squares of the dimensions you're thinking about. So unfortunately, you can't just sort of like brute force it, but it's some criteria. If you know these are normal, these semi-stable loci are normal always in the cases that it contributes to your component, then you just pop out the conjecture as true. So that key sort of is, that tool is really helpful to go beyond this sort of like, what can we do? To go beyond this, sort of like, what can we do with just representation theory and semi-invariance, and like how do we use more geometry? That's sort of the key thing this tool contributes. And then I guess I'm going to tell you the last 10, well, I really thought I was going to end like... The last two slides, I'm going to tell you two more cases that are very far from the earlier ones, and then I'll tell you some suggestions for future directions in the last two slides. So, this one, this is from a couple years ago, joint work. This is from a couple years ago, joint work with Carol, Kendris, and Weyman. We just proved this module, this conjecture I had above, that is true for special biserial algebras, so that all the moduli spaces are always products of projective spaces. And again, you can take maybe a whole slide and some pictures to define a special biserial algebra. Let me not do that. You can easily Google it if you're interested in pursuing this further and talk about it more. You can roughly think of it, though, as sort of related to A and A tilde quivers, but where you sort of take those quivers and they're indicated. Where you sort of take those quivers and they're indicomposables and you push them down and like sort of you're able to like wrap them around your quiver and that and that all indicomposables of your KQ mod I are obtained that way. So they're sort of really similar to A and A tilde, but they've sort of been wrapped around on top of each other. Specialized hero algebras come up in a lot of places. A really key advance, like so for example, they come up in Jacobian algebras associated with surfaces and all this cluster story that people are doing. They do also come up in group representations. Come up in group representation theory, but I'd sort of be cheating to connect to that because that came up in modular representation theory groups, and I'm restricting the characteristic zero. But maybe there's some relation there you want to look at. But that's where the special mister algebra is a class. You can axiomatically write it down, but the point is they appear places when you're not just axiomatically trying to write things down. And I notice here we don't have acyclic. So in the earlier one on gentle algebras, the quiver had to sort of all be going in one direction. It can't come back itself. Going in one direction, it can't come back itself. This works for arbitrary special biserial algebra, so particularly the ones that associated the surfaces have lots of triangles going around in them. So let's flip here. Apply there. And then the next theorem is proven by Cody Gilbert. It just appeared on the archive in August 22, and he proved the conjecture for Clannish algebras, which are basically a next step beyond special by serial, where you replace A and A tilde by types D and D tilde, so they get significantly more complicated. And they include this clanish, these are two. This clanish, these are introduced again by like really the original motivation. Carly Brutney introduced them in looking at like these kinds of generalized dihedral and quaternion groups and their representation theory and characteristic two. And Clannish algebras are the things that popped out again. It's not necessarily connected here because I'm doing characteristic zero, but they do include skew-gendal algebras, which are now kind of naturally arising more recently in cluster theory and algebras associated to orbifold surfaces. Associated to orbifold surfaces. And so when you have these kind of Jacobi-type algebras associated with triangulations of orbifold surfaces, you see skewed gentle algebras, and this conjecture holds in that case. And as I said, the sort of difference here, well, our proofs are almost entirely geometric. We don't have to do a bunch of complicated representation theory, which in some ways like makes it more accessible to people outside of representation theory. Unfortunately, in these cases, we are active in it. We're taking advantage of a sort of what you might call We're taking advantage of a sort of what you might call lucky or magical connection of some things that were known about like affine Schubert varieties that are like fairly complex. That part's not self-contained, but you know, if you quote this one sort of powerful black box about these representation varieties associated algebras and connect them out affine super varieties, you get the normality once you sort of decode everything and then you get the conjecture for those. All right, and the last slide I'll tell you two just suggestions for future. Tell you two just suggestions for future directions. So, as I mentioned, all this projection, this conjecture has just been proven just for a bunch of specific classes of algebra. Now, I've given you some, possibly, you might have missed some, but it's proven for a bunch of specific conjectures. I feel like we're really at the point, we got to go beyond, like, take another class of tame algebras and prove it. And we need somewhere to get like a foothold of it just above that. But I do think full generality is probably out of reach. I wouldn't suggest sitting down with a file of scrap paper and trying to prove the conjecture. So, I went out to get some suggestions if you're interested in working. I get some suggestions if you're interested in working on it for like intermediates, like next steps. So, for an arbitrary tame A, you can look at there's sort of some distinguished irreducible components in which a generic representation has projective dimension one. So, you might have higher global dimension in your algebra overall, but some of the irreducible components in these one-parameter families, like generically, the representations will still be projective dimension one. For those, there's a so-called canonical weight. So, that's part of the problem, is when you just have arbitrary weight. So that's part of the problem: when you just have arbitrary weights, like, what do you do with this weight? You know, there's too much sort of freedom. You can instead look at this canonical weight where it's given by sort of dotting with your dimension vector where this is the Euler form, like the alternating sum of the Xs, where you would just take, look, there should be a second dot there, where you would take just two representations of those dimension vectors. And so you could try to prove, just look at this, and for that weight, it will be true that if you have... It will be true that if you have a one-parameter family of representations of trivial endomorphism ring, most of them, almost all of them, will be stable with respect to this weight. So you know you're looking at something where there will be a modulized space that's one-dimensional, and you can try to prove it's P1 there instead of like something singular, instead of like a singular rational curve. That's the idea I think Kendra has, that's his idea, not mine. And then the next one, this is really, I'm just gonna go just, you know. This is really, I'm just going to go, just you know, just go way off. This is very unspecific, but I think it's a promising idea. Is in general, we could try to go out and be a covering theory. So, covering theory of algebra was introduced by Gabriel and independently by Ed Green in the early 80s. And there's also early papers of Gabriel and Bongards. And I think there's sort of a lot to do with covering theory that's not necessarily being utilized. It's a tool that's sort of maybe not being utilized to its fullest in representation theory of algebra. Representations we have algebra now. And so you could so far look at the things, the sort of simplest things that which are called so-called strongly simply connected. Again, really defining this as a whole slide, so I'm not going to do that. If you're interested, we can talk. You can look at the strongly simply connected algebras, and these are sort of a more specific class of Tame algebras that have nicer properties. And for example, one of the main properties which really is geometry is you have this Tietz quadratic form, which looks at, which basically, if you unpack it, it's sort of the basically, if you unpack it, it's sort of the dimension of your dimension of your group acting minus the dimension of the space plus back in the dimensions of the relations, the sort of naive set of relations defining the sub-variety. And that has, usually that's not like that form doesn't tell you much about your algebra, but it's strongly simply connected. It does. Your algebra will be tamed by this paper here. The algebra will be tamed if and only if that's non-negative. And so that would be like a place you have a little more geometric tools to try to. Place, you have a little more geometric tools to try to prove it for some really broad class. And then, if you have it for strongly simply connected algebras, well, you have there's all this theory of like Galois covers and more general covering functors and stuff from finite dimensional algebras. I don't know that moduli spaces, their behavior under covering functors has ever really been studied. I'm not familiar with any, and again, if I'm wrong, please tell me, but I'm not familiar with any detailed study or big results on the behavior of moduli spaces with respect to covering functors. With respect to covering functors. And so that would be just, you know, to throw out a very loose, wide idea is to try to prove it for the things which are strongly simply connected, and then see how close arbitrary or how arbitrary algebra, tame algebra can be related to strongly simply connected. There's also simply connected as an intermediate thing. Who knows where I would see how the behavior of those moduli spaces is with respect to those covering functions and see if one could approach the general case like that. And that's it. I don't have a thank you slide, so I'm going to ask you. Any questions? So is there a notion of these semi-stable moduli spaces when the quiver is infinite? I mean, because these covers are often infinite. Yes, that's a good question. So the covers are often infinite, but usually your dimension vector upstairs would be sort of finitely supported. Finitely supported. So that would be the idea. Like, you'd have an infinite quiver, but then you'd be looking at, like, so that would be, yeah, that's sort of what causes because you wouldn't, upstairs, you would need to consider many different sub-quivers corresponding to all the sort of interesting finite supports up to like sort of the deck transformation. So probably the thing downstairs and its moduli spaces would be controlled by like a bunch of different moduli spaces for different algebras upstairs. So yeah. This might be silly, right? But one thing that stands out is you, in the TAME case for your irreducible proponents of this project of things, you get homogeneous spaces. Is there some philosophical reason why you expect a lot of automorphisms in the TAME case? Have automorphisms? Oh. Of the moduli spaces? Yeah. But I never thought of that, so there may be s something interesting to say there. No, I haven't thought about that. Interesting idea, yeah. Interesting idea. Yeah. That's one could sort of you're sort of thinking of looking. So I would begin to think some sort of, I don't know, if there's some automorphism to the module category or something that would, or auto equivalences that would induce something on the moduli spaces. I'd say that's an interesting path that I've not thought of. Is there a reason to Is there a reason to expect it's even rational? Yeah, so I believe actually, I thought it's a long time ago that I was worried. I think basically you sort of always have a dominant map from these, these one-parameter families always sort of give you dominant maps to the irreducible components from A1s if you sort of unpack that. And so I guess that's just going to make them rational by Leros' theorem. By Leros' theorem or something. Yeah. So I think it's not that hard that they're rational. For transcendence degree one or the transfer? Yeah, sorry, only in the. Okay, that's a good point. So for the indie composables and the one frame of families, that's true. For the higher ones, no, I guess not. Yeah, you're right. I'll know for the higher, if there's even a reason to think they're rational. Except maybe by our covering, I think actually the rationality. No, I'm sorry, that's a corollary in our paper. They're always rational. In our paper. They're always rational. That's accordingly in the decomposition theorem paper of Kendricks now that I think about it. Because basically, the decomposition theorem says there's a finite birational map to a symmetric power from a symmetric, a bunch of symmetric powers of rational curves to it. So the symmetric powers of rational curves are going to be rational, and then so the target's going to be rational. Yeah, good. That was that is in the paper. Now that's in the paper. Right, well let's think random.