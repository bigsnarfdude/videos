That that that is your screen. Uh yes, that that's it. Yeah. It says report in progress. Yes, okay. So let me start by thanking the organizers. So I'm very grateful for this invitation. It's very nice. It's been a very nice workshop. I've been learning a lot. And it's in a beautiful place. So thanks a lot. So I will talk about operator entanglement, which is one which has been. Which is one, which has been one of my favorite topics for a couple of years. So, it's not very recent work, but I hope it can be interesting to some of you. And I had a hard time choosing what I was going to talk about, so I probably have way too many slides. So, well, I will ask you what you're most interested in. What you're most interested in, and we'll skip some parts. Let me start with a motivation. So, you know, the current picture that you see in many, many places, many, many talks is that if you imagine that you take a one-dimensional system, a speed chain, a speed one-half speed chain, and initially prepared in a in a in a simple product state, and then you apply uh a unitary o uh unitary evolution. Unitary evolution, say Hamiltonian evolution, then this will generate entanglement. And this entanglement is the bottleneck in most calculations that you want to do, analytical or numerical simulations that you may want to do on a classical computer. So in the latter case, the the main Case the main techniques are matrix product states or tensor network techniques, and in that case, you're always limited by the fact that the entanglement entropy blows out. This is essentially because morally the exponential of the entanglement entropy is the bond dimension of the tensors that you need to use. And if the entanglement entropy grows linearly, then the bond dimension grows. The bond dimension grows exponentially. Very funny service. Now, on the other hand, we have learned also in the past 20 years or so that if you think not about the full pure state but about the reduced density matrix, it doesn't look that complic that much complicated. Because you expect that at sufficiently long times, this uh reduced density difference should work uh Reduced density matrix should look either a thermal state or a generalized Gibbs ensemble or something that depending on how much. But in any case, it should go to something that has a description in terms of some statistical ensemble, which is simpler than describing the full pure state. And so this suggests that you should be able to find some quantifiers of Find some quantifiers of the complexity of the evolution, and this quantifier would initially grow because the system becomes more and more complex as entanglement builds up, it spins, but then ultimately it should go down because the subsystem becomes simple. Okay? So what do you mean by complexity? Yeah, exactly. So, complexity. So, indeed, so what what is this what figure of merit to be used? What's the quantifier? And so, I'm gonna argue that uh operator entanglement is a good way to do that, and it's a good quantity to look at this. Is that you know what that means, but okay. I know what that means. Well, I'm still in the introductory slides. Uh and so this is you know sometimes called And so this is sometimes called an entanglement barrier and it's the topic of the talk or at least a part of the talk. Okay, so what I would like to explain in this talk is one that you can define this operator entanglement and that's it that this is a good quantifier of this complexity for this kind of purposes in one-dimensional quantum systems. Then I would like to talk a little bit about dissipative evolution, so Lindsay. About the dissipative evolution, so lean blood, and the fact that there is also a generic operator attacking barrier in that case. And that there are some surprises if you consider a lean blood evolution with so-called strong symmetries. But we'll see. If I don't have time, I would prefer to talk about the third thing, which is operator entanglement of local operators in the Heisenberg picture. So you know that there have been many. Picture. So you know that there have been many works in the past 10 years or so characterizing, trying to characterize the dynamics of quantum systems from the point of view of local operators evolving Heisenberg picture, which are related to OTOX, for instance, and out-of-time ordered correlators, these kinds of problems. And I would like to argue that operator entanglement is also very interesting from that perspectives, and in particular, it's And in particular, it seems that there's a sharp distinction of the behavior of that quantity depending on whether the underlying dynamics is integral or non-interpropriable. And this is something that I would very much like to understand, and maybe some people here in this audience could help with that. Okay, so now let me just give the definition. So, as usual, we consider So as usual, we consider say the Hilbert space of a spin chain with a bipartition, AB and then we take some quantum operator acting on the Hitler space. Here this would just be of course a matrix of size dA dB times dA dB where dA dB are the dimensions of the hybrid space A. The dimensions of Hebrew space A and B. And we would like to ask the kind of questions that we want to ask is: how far is the operator that we are looking at, how far is it from a product, a product operator. So a product of something acting on A only and something acting on B only. So it's not always the case that you can do that, of course. No, no, I don't. Indeed, in some cases that we are going to do, it will not be permitted. Yeah, so it's not always the case, of course, that you can write an operator as a product operator. Sometimes you need to use two terms or more terms and so on. So, what we would like to do is to do a Schmidt decomposition of the operator, and we are going to use the Hilbert Schmidt. The Hilbert-Schmidt norm for the operator. So we normalize both left side, left-hand side, and right-hand side, so that the coefficients lambda here sum to parts. And because they sum to one, or more precisely, sum of lambda j squared, sums to one, we can view it as a probability distribution and associate And associate an entropy as we usually do. Now, of course, this is nothing but saying that this dAD times DADG matrix O, this quantum operator, viewed as a matrix, if we rewrite it as a vector of size this number squared, so we just vectorize the matrix, write an n times n matrix as a n squared dimensional vector. Squared dimensional vector. So we vectorize, and then we are just looking at the usual entanglement entropy of that state hole. But there's really nothing new from that perspective. The definition is just really the usual one that we apply to states. The difference is that now we want to study this quantity for operators and quantum operators in quantum manybody physics. Body physics, when we vectorize them, they are very different from the standard states that we're used to looking at. For instance, the ground states of how we do it or whatever. So the states that we get by vectorizing interesting quantum operators are very different from the states that we are used to. And this is why this quantity is interesting. Definition itself of our. And definition itself, of course, is not important. Okay, so a little bit of history of this quantity. So, as far as I know, this was introduced first by Paolo Bernardi and collaborators. And their motivation back then was to ask how much entanglement you could produce by applying a unitary operator to a viperplane system inside. And they wanted to characterize for a given operator U to be able to have a quantity that could tell how much entanglement you could produce. So they defined an entanglement power as the average of the entanglement between A and B for some quantifier of entanglement, usually a Rhini entropy, averaged over all possible initial states with some. Over all possible initial states with some measure. And so, in general, this is a hard quantity to compute, but for the special case of the purity, or the yes, so if as a measure of entanglement you use the purity, then it turns out you can evaluate the expectation, but you can evaluate the mean. You can evaluate the mean value exactly, and you get some simple identity where this entanglement power is given in terms of the operator entanglement. But that's just a special case. And in general, there is no, I mean this is what they were looking for back then for a for a relation between this entire power and operating segment, but there's no general relation between the two only in that special case. Only in that special case. Anyway, but it appeared in that context first, and then I mean, nowadays it's a quantity that people are studying because of its relation to the question of approximability in terms of matrix product operators. So if you have an operator O, quantum operator O acting on a spin chain, and you want to know whether you can write it efficiently or approximate it efficiently by a matrix product operator. Efficiently by a matrix product operator, then you should compute that quantity. And if it's small, that means the matrix product operator that you will have to use will have a reasonably small bond dimension. If it's really large, if it blows up with the time or with the system size, that means you will not be able to find a good matrix product operator representation. So, yeah, so here is the picture. Picture. So we are all used to this thing. So if you take a quantum at pure state for a spin chain with bipartition AB, you know? Yes, just a question. Does this work for a mixed state? So finite temperature say finite temperature spin chain, so A D is mixed. Yeah, so then this quantity is small. Yeah, so then this quantity is small. Yeah. I I will I will say that actually. This upper entanglement, uh is it uh monotone in some sense? No, it's not an entanglement. I will say that also is, I think, next slide. It's not a measure, it's not an entanglement measure. It has nothing to do with entanglement. No, but low CC, does it decrease under a low CC? No, I don't think so. It's not an entanglement, in the end, it does not. In the end, it has nothing to do with entailment. It's not an entire measure. Yeah, no, I know. The terminology is confusing. Maybe we should call it operator entropy or whatever. I know. Some people call it operator space entanglement entropy. Maybe that's better. Anyway, so nowadays, most authors call it operator entanglement, and that's the name that sticks. But it has nothing to do. But it has nothing to do with entanglement. You can take a purely classical state and it's going to have, I mean, it could have a lot of operator entanglement even if there's absolutely nothing quantum. It's just, it's called operator entanglement because it's really the usual entanglement entropy applied to operators, instead viewed as vectors in a larger single space. Yeah, so okay, so the you know, usually you take a spec it, you compute the secret that should be is the Compute this antagonist entropy. If the antagonist entropy is sufficiently small, then you know that you can approximate it as a matrix product states. And here it's the same thing for an operator. And you know, this vectorization thing is like as if you were folding the legs and then your line would be tossing. Okay? Good. So that's the definition. Now two warnings. When we do that. When we when we do that, uh so one has to do with the fact that if we identify uh operators with states in a larger Kilbert space, this means we are intrinsically uh attaching to operators the Gilbert-Schmidt norm and not any other norm. And that might be a problem depending on what you want to do, the thermodynamic limit. But when we look at this quantity, you just ignore that. In particular, In particular, you might criticize the fact that this is not good for density matrices, because for density matrices, you should use the trace norm and not the 2 norm. But anyway, that's what we can do. And another warning is that, as usual in this business, what people compute in practice is the Reyni entropy for in Rainy index alpha integer and larger than two. And larger than two, typically larger than equal to two. And in principle, this is not sufficient to ensure approximability. In principle, you should look at remex continuous and smaller than one. Okay. So there's a replica trick for this quantity that is very analogous to the one that Olaja was presenting in our talk. So this is how it looks like using tensor annotations. So, what you have to do if you want to compute it with the replicator is that you need to replicate the operator O, then make swaps between the different copies in part A, swap backwards, and then apply O dagger also replicated. And they take the trace. So, here this is your relative boundary condition, so there's a trace that is taking it. This, this will give you the ready version. This will give you the ready version of this operating team. Okay, so now we are actually starting the talk. So some basic results that you can get almost for free using the tricks that Olaja was presenting in her talk, namely the fact that in conformal field theory this maps to evaluating partition functions. Evaluating partition functions on Riemann surfaces with multiple sheets that you can also formulate as expectation values of twist fields. So using this trick, there's one result that comes out very easily. And I think this is what William was asking. So if you compute this quantity in a thermal state, so in the density matrix of thermal state. In the density matrix of thermal state, you will find that it has a very low, so it doesn't scale with system size, and it's just given by some constant, but the constant depends on inverse temperature. And as temperature goes to zero, this constant becomes larger and larger, which is consistent with the fact that the density matrix, when the temperature goes to zero, becomes the projector on the state on the ground state. On the ground state, and the ground state has a lot of improvement. But also, when the temperature becomes very large. When the temperature becomes very large, this thing becomes the identity, and then it's a trivial state. It's a trivial operator. The identity is obviously a product operator, so it has an operator technology. So this expression is not valid in that limit? Well, I mean, it's a CFT expression, so there It's a CFT expression, so there should be a cutoff here. But I mean, when beta goes to zero, this. If I put t large in this expression, it does not validate. This thing cannot be negative anyway. Yeah, yeah, that's what I was saying. It's not valid in that limit. Yeah, yeah, it's a CFD expression. So there are some there should be a cutoff here, and beta should not be temperature should not be smaller. Temperature should not be smaller than it could just go. Then it would change, but uh at the moment uh I'm applying this uh thing. Moment, I'm applying this thing to I'm taking for Bo, I'm taking this thermal density matrix. Okay, and so this means that if you want to write your thermal state as a matrix product operator, you may want to think of it in terms of prototype decompositions. And this is actually exactly the same thing as what we call fretted matrix. We put a prototype composition of this Gibb state. This Gibbs state. And what this means is that then you should be able to compress this network in an efficient way. So if you actually cut here, you could keep track of everything here with a matrix product operator of small bond dimension, reasonably small bond dimension, and the bond dimension will scale algebraically with temperature as temperature goes to significantly. This is what this thing tells you. Temperature. C. Central charge. Central charge. Central charge. I understand that the central charge of what? It's a CFD calculation. So that's this corresponding to the H of here. The Hamiltonian. Yes, yes, yes, yes, yes. Yes, here it's the CFT Hamiltonian. It's a CF calculation in a CFT. H is the CFT Hamiltonian. C is the central charge that we have. Yes, uh thank you, yes. Even though you're using double spaces, uh yes, that's right. Okay, so then uh to come back to the motivation where we want to think of a system of a reduced density matrix and see uh how this uh say that the complexity goes down. Complexity goes down at late times. So now let's consider this type of white partition. And the question we want to ask is: once we trace out B, we want to look at reduced density matrix A as a function of T. And we want to ask whether this thing, this reduced density matrix R can be approximated, whether or not it can be approximated by an MP. And so for this, what we should compute is We should compute is so the previous result was for the half-infinite line. Do you have the result for A being a finite interval? Is there a side of that, but temperature or? How does it look like A? No, it's some function, some hyperbolic tangent of something that involves both the length of the interval and beta. But do you know the limit where temperature is becoming large? Temperature is becoming large. How does it scale as T times the length of the interval? I guess that's three-dimensional variable. Yeah, I don't remember. We can look it up, but I have the results on exponential and I don't know, and I I'm going to say something stupid if I if I try to answer now, but it's but physically you can only question uh physically the question for the temperature Immediate question for the temperature. Because many quantities have a sudden depth. Yeah, but there's no such thing. There's nothing non-analytical. I mean, it's just really an analytical function of beta and I don't think there's anything funny to be found there. Yes. Okay, so what we want to do is then ask whether we can take. Then ask whether we can take this reduced density matrix and approximate it by a matrix product operator. And so we would like to have an estimate of the bond dimension that we would need in the middle, where presumably this is the largest bond dimension for this approximate reduced density matrix. And so what we have to do is first construct the reduced density matrix and then compute the operator entanglement for that by partition number, A1 and A2. And okay, so this is also a calculation that can be done easily in CFT with again the same tricks as what Olaja was talking about. That's a calculation with twist fields, which leads to the following results, that it goes up and then down and then it's exactly zero sometimes in the CFT. That's the CFT the zone. And so I did some calculations. Some calculations in three ferment chains where the results are shown for A. So this is the same length as this one. So A1 is of the same length as A2. And this is for some fixed length L that is quite large. And then everything is plotted as a function of time from so the From so the pro process. So the we are starting from a product state, so it's a quench from our product state, we find both and the reduced density matrix initially is just a projector on the pure state. So its complexity, operator entanglement, grows as the entanglement entropy of the pure state. But then at later times it goes down because the reduced density Down because the reduced density matrix simplifies in some way. So, this is what you see: it goes up and down. And yeah, so for infernance, you can compute this easily, not analytically, but express everything in terms of some determinants that you would then evaluate numerically, and that's what you find. So, it's not, you see, I mean, you could criticize the fact that it doesn't match the CFT calculation. Doesn't match the CFT calculation at all, but at least it's quite at least six. Yes, so and maybe this is something very simple. So, why at large time it should go to zero? Like, we know that row A in the 60 volume should try it to some thermal state. Um basically that thing. Um but yeah, I think the previous slide you showed that the the operator entire state is Thermal state. Somebody needed ideas, some expressions or just two things. So, okay, so in the free thermal calculation, I think it's because my initial state was probably the nil state. And the nil state does go to infinite temperature. And in the CFT calculation, I think you're right. What you find is that to go to a finite constant, but this finite constant does. But this finite constant does not it doesn't depend on on L or on T but I would have to look for that. Depends on what. Depends on what. Well, as Giuseppe says, it should depend on the initial state, on the energy that you put in the initial state. I think you see it. I did this almost 10 years ago, so I don't know. But the axis, is it zero or not? I don't see. No, here it's zero, yes. Here it is zero. But in other instances, it will be non-zero. Presumably, yes. I mean, f for sure, in if you do it exactly in this in a in a concrete spin chain, uh uh what you said just said this is completely true. Said this is completely true. If you don't, unless you go to the infinite temperature state where really the operator entanglement is zero, just because trivially it's a product state, a product operator, if you go to a slightly more complicated thing, like just a deep state, then you will find you will go to a non-zero constant. But this constant is still very small, that's the point. It doesn't scale with system size, with time, and so if you And so, if you look at this for a very large, large, large subsystems, you will still have a huge peak and then goes to a small constant. But so, can a separable density matrix have a finite aperture entanglement? Sorry, say it again? Can a separable density matrix still have a non-zero OE? A separable density matrix. A convex combination. Yeah, yeah, absolutely. That's what I was saying before, yes. Yeah, yeah, absolutely. That's what I was saying before. You can have a completely classical state, just a classical mixture, and still it will have non-zero operator entanglement. Because this has nothing to do with entanglement. It has just to do with whether or not you can write it as an MPO. But you mentioned that quantify. That it quantifies also the entangling power of Yeats in the beginning. Well, that was the idea that these people had, yes. But as I said, so it was the first occurrence of this quantity in the literature, and as I said, they found some relation in some special cases, but in general, no. But it's still small, you say. At late times, you still get the small magnitude irrespective. Yeah, sorry I'm getting a bit confusing. Let me move on. How much time do I have left? I'm feeling this is 10 minutes. Yeah, okay, so this is a catastrophe. All right, yeah, let me just give you some. I have some pictures just to give you some intuition of why this happens. So, okay, you know, You know, there's this quasi-particle picture that is supposed to capture the main features of entanglement dynamics in integrable, at least for integrable systems. When the system is not integrable, there's something else that replaces it, which is the membrane feature. But if we're thinking about quasi-particle dynamics, then the simplest model we can think of is a prequel of SWAT gates. So we can imagine that we start from So we can imagine that we start on a chain of spins or qubits, all initialized in just a product of pairs like this, product of their pairs, and then the time evolution that we apply would be a brick wall of swap gates like this. This could generate some sort of extremely simple yet extremely simple. Extremely simple dynamics, yet non-trivial in the sense that you do propagate quasi-particles to the left or to the right, or information to the left or to the right. And now in this trivial model, very simple model, you can think of this entanglement barrier as follows. So if you look at the state at time t, this is the same picture as here, if you look at the state at time t. If you look at the state at time t, of course, what is happening is that you have just bell pairs separated by an interval that is exactly t times t that are entangled. And so the state at time t looks like this, just bell pairs like this. And then if you ask what is the attainment entropy of that pure state, and then you go by partition, and you just need to count the number of bell pairs that cross the. Of bell pairs that cross this line at time t, and that, of course, just grows as t times log2. But now, if you are interested in the quantity that I'm interested in, this operator entanglement, then what you want to do is first of all look at the full density matrix. So you have to double the picture. Now, with the bra and the ket, the ket on the bra. And the cat, the cat on top, on the bottom. And then, of course, if you ask what is the entanglement entropy, you just get twice the result because you get twice the number of pairs that are crossing. But then, when you do this, when you go to the reduced density matrix of some interval AB here, tracing out part C, then what you see is that all the pairs that have one side in C, they In C, they disappear, they are taken out. And then what you are left with is asking the question of how many pairs are shared between A and B, disregarding the ones that are connected to C. And then when you do that, you obviously find that as time increases, initially you have pairs that are shared between A and B, so this quantity grows, but then ultimately the shares. But then ultimately, the shares, there are no pairs shared between A and B left because they are just too long. And so this is the mechanism between this thing that tells you that the entropy, the operator entanglement first grows and then decays. Okay, so we had a paper a couple of, like two years ago with Sa and the group of Bono-Bermerch in Clonov, where they did this some trapped ion experiment. Experiment. So that was nice, but I'm not I'm not gonna skip that. I'm gonna skip the dissipative part. Dissipative part is quite interesting. I'm happy to talk about it if someone is interested, but I'm gonna skip it now. And now what I would just like to say is this, because I think maybe some people in the audience could help. So now my operator O that I'm interested in is no longer a density matrix. Density matrix. Now it's an operator, initially a local operator, say an operator located on a single site here, phi. So phi here is not a non-trivial operator, so think of a Pauli matrix or something. And everywhere else, I just do the identity. I evolve this in time with conjugating by the evolution operator. The evolution operator. If I want to draw this in a shorter type of decomposition, this would look like this. Of course, in this diagram, there's a large part that simplifies trivially. So there's like a trivial light bone that is coming just from the fact that you are here multiplying a unitary matrix by its adjoint. So things simplify, except for a pyramid, For a pyramid, top and bottom pyramid, that is centered with the tip of the pyramid, which is at the position of this operator here. Okay, and now the question we would like to ask is what is the operator entanglement of this thing for a bipartition? Yeah, so we want to take a bipartition like this and ask what is the operator thing. And because again, And because again, if by chance we find that this operator entanglement is not too big, then that's fantastic news because it means we can actually approximate the operator in Heisenberg picture at time t by a matrix product operator efficiently. And this could perhaps be a way to do nice simulations of time dynamics in spin chains. Okay, so this quantity, so I computed it. So, I computed it for free fermions. Prozen also looked at this 10 years before. And if you do it for free fermions, what you find is that it goes as log t. So, I'm not going to be very interested in the dependence on the position of the cut. So, here the plots I'm showing are depend both on position x and on time t, so on the depth of this surface. On the depth of this circuit here. But for simplicity, let's just take the cut at the same position of the initial operator. So just in the middle. So the cut we put in the middle and we focus on the time dependence. So on these two plots here, this corresponds to looking at things only at x equals 0. So we focus on this quantity at x equals 0 here, and in the free-Verman case, you can just show analytically that it goes. You can just show analytically that it goes as uh uh log t times a pre-factor. Uh that uh also has some meaning, but that I will not explain. On the other hand, in non-integrable models, such as random unit-free circuits, you can show that it grows, this quantity grows linearly and. And numerical simulations confirm that this is the case. And so the point here is that it looks like there's a sharp, very sharp distinction. The behavior of this quantity is completely different depending on whether the underlying dynamics is integrable. Here it's actually free. But or non-integrable. So okay, so th just so then with together with Vincenzo Alba and Marco Widenier, Alma and Marco Midenyak. We did more simulations in spin chains, in integer spin chains. So we did XXZ, we did higher spins, factor Yan for convolution, and we did a bunch of others. And the point is that we were always finding results that were compatible with logarithmic rules. And so then Marco came up with some other. Marco came up with a model where we could actually produce this. Yes. I mean, Joe, maybe I can just point out. I mean, there was also in 2010 where we shared Flash House. Yes, that's where the paper looked at that. There is this difference. Yes, indeed, but not the difference. That's right. Also looking at the C change. Yeah, yeah, I know this paper. We cited in sorry, I don't refer to this on the slide. Indeed, there were attempts at doing Heisenberg the MRG in Heisenberg picture. The MRG in Heisenberg picture earlier. Also, not only Fleischauer, but also Andreas Lochli. I mean, David also had some strict bonds essentially, right? They had a strict bond, that's right, for systems with a conserved charge, and the bond was for observables that were the densities of the charges. That's right, yes. So indeed, so so some of this was uh had been done. Had been done. So, the point is that in the literature you find many results, not so many, but all the results are consistent with this claim that there's a difference between integrable and non-integrable. So, we just said, okay, maybe it's always the case. Let's just conjecture that there is a sharp distinction when you look at this quantity between integrable and non-integrable dynamics. Turns out this had also. Turns out this had also been pointed out in not exactly the same form, but in a similar form again by Tumasz Prosen and Markuz Nitovich. But anyway, so the point is, I think it would be really nice to be able to prove this, to come up with an analytical argument for why this is the case, and which we don't have at the moment. So the best thing we were able to do was to come up with a toy model where come up with a a toy model where we could actually show that indeed in this toy model it's logarithmic. And this toy model is this uh is one of this regular automata that uh Federica showed yesterday in the very last uh slide in her very last slide. So I okay I'm not sure I should I have much time to introduce it, but the point it's it's a very nice model of a circuit which happens to be Which happens to be, in fact, completely classical in the sense that it doesn't generate quantum superposition. But the point is that, so this circuit is defined, sorry, this circuit is defined in the same in this way, so you can think of some sort of RSOS model if you like stat make models defined on around the face like this. Defined around the face like this. But here it's a model of, we want to think of it as a model of qubits that evolve in time. So each vertex here can be in a state that is 0 or 1. And what we are doing is that we are piling up the squares as in a pre-qual circuit. So what we do is that we take from you can think of this as a You can think of this as a unitary gate acting on three spins, but diagonally on the two qubits on the side and non-diagonally on the one in the middle. And the rule is defined in this way. So here you see all the eight possible configurations of the three down spin: 000, 001, 001, 0120, 0011. So in base 2, this is 0, 1, 2, 3, 4, 5, 6. three four five six seven and obviously you can just explore all the possible all the possibilities for the outcome and here the possibility that we choose is the one where these three zeros gives a zero these three this zero zero one gives a one zero one zero gives a one and so on and then when you look at these outcomes zero one one zero one one zero zero in base two this is fifty four. This is 54. And so this is why it's called Rule 54 in the nomenclature of cellular automata. Federica, yesterday you were talking about rule 201. Yes. That's a different one, but anyway, okay, and so then this model has very interesting dynamics because if you just look at a few examples, what happens is that if you color in red, What happens is that if you color in red the trajectories of the bonds, you see this type of solitomic dynamics that shows up. And so it's a very nice model because it's a model with quasi-particles, but it's not as trivial as the circuit swap gates that I showed before, because now it has time delays. So every time two solitons scatter, you get a time delay. They are delayed by a time step one. A time step one, because they travel together for a time step one. And okay, so this was actually known by these people in Germany in the 90s. They were the first ones to work on this, and Crozen sort of revived this topic 10 years ago now. And it's a very nice model where you can do many exact calculations and around. Around 2018, and so it was many people looked at it because it was a good model to study operator spreading. And so, this is what we did also back then for this quantity, for the operator entanglement. And the point is that you can show, you can actually, what you can find is that there is a certain algorithm that tells you, when you look at these pictures of pyramids of operators of time t, you can actually, just by looking You can actually, just by looking, staring at the configurations of solitons that are coming out of the system at time t, you can tell where exactly they were coming from at time zero. And therefore, you can say easily if a given configuration here contributes to the expansion of your operator at time t. There's a certain algorithm that allows you to do that. This is the cartoon of the algorithm. I can I'm not I don't have I don't have time to explain, but it's basically you see the idea is that you read the configuration at the top from left to right, as in some sort of Turing machine, if you want. So you just read the configurations from left to right. And every time you find a left or right-moving soliton, you displace a point here in the triangle. But since you end up and this position, And the position of this point in the triangle is like the internal states that you have to use in your Turing machine. And because this point is stuck inside the triangle, the number of internal states that this thing uses cannot be larger than t squared, than the area of the triangle. And the number of internal states that you are using here happens to be exactly the bond dimension that you need to write this as a. Need to write this as a matrix product operator, and therefore the bond dimension cannot be larger than t squared, and this implies that the operator entanglement is logarithmic. So there are a couple of other exactly solvable models where this thing has been computed, and they all confirm that if it's integrable, it seems that this goes logarithmically, and if it's not integrable, it's And if it's not intecurable, it's linear. But as far as I know, there are just a few examples where you can just do it exactly, but it's still in general an open problem. And having a good having a more general understanding, perhaps perhaps something can be done with I don't know, with quantum to transform matrix because Quantum to the transform matrix because you can think of it as a. I mean, this quantity I think you can reformulate in terms of the quantum transfer matrix, and then what you would have to look at would be the tangent entropy of the state that is the largest the state with the largest eigenvalue of the of the quantum Schoker transfer matrix, which is also related to something that people go To something that people call temporal entanglement. So maybe there's something to do there. This is why I wanted to talk about this and let me stop. Sorry for going over time. Uh yeah, another thing I just wanted to to mention this uh To mention this an operator entanglement for the thermal density matrix is in some sense, exactly what one looks at also in transfer matrix the imagery, right? Software history. So basically you have the quantum transfer matrix and then you cut it in the middle sort of basic. But that's the other way around, no? Isn't that the as far as I understood when you have the I mean invite the light left and right eigenstates, that's exactly like this right and then curve. It's exactly like this way, that they can cut it in this way. So my understanding is I mean and and then if you calculate calculate it by C of T, you get this C over three or C over six times that's not meter. Which I happen some paper 15 years ago or already for that. Okay, so you should and then you can also calculate the entanglement spectrum if you like. So for example apologize that matrix maps. Okay, I'm not sure which transfer matrix you are referring to now, but you should explain it. But you should explain. Yeah, I mean, the quantum transfer matrix, right? Yes. But then, how do you relate the quantum transfer matrix to this thing? Because you would use an MPO in the opposite direction, in the spatial. So you would use an MPO that is extended in time direction or imaginary time direction, and then you would evolve in position. Right. And then how do you relate this to the I mean then but if you then cut it this I mean then but if you then cut it this way then and and you calculate it at low temperatures then the entanglement entropy of this reduced plot goes exactly like like C over three times log beta. The entanglement entropy of the largest eigenstate of this transfer matrix that it were. Well basically I mean you take a quantum transfer matrix and you cut it sort of in half and you calculate the entanglement entropy basically of half of the quantum transfer matrix. I mean the length of the quantum The quantum transfer matrix. I mean, the length of the quantum transfer matrix is proportional to beta. And then the entanglement entropy you get of that is sort of depending on the boundary conditions used, but it's u three block beta. Yes, okay, so then it's probably either exactly the same thing or what I feel that it's basically that it is the same thing. Any other quick questions? For the entanglement entropy for your CFT result, there was gave you the log theta. Similar are with theta equal to infinity when the expansion? So you have to start at infinity and then you decrease. So if you're doing thermal double field, you can do it. I'm not sure what you want to do. So beta is infinity. This, I mean, the density rate. Temperature expansion of this quantity. Of what? So the state, of course, at beta goes to infinity, the state, the rho, the density matrix is the projector on the prime state. Okay? So this has. A large temperature. A large temperature and onto the ground state in auxiliary state, and then the entanglement entropy is just zero. Of course. No, it's the large T expansion about that point. No, but are we talking about small t or large t? Large T. Large temperature. So a large T, yes, the density matrix is just the identity, so that's trivial. Expansion. And then you want to expand. But then I suppose it's this, that's what also probably was yes, we're saying, right? It's this picture here. I asked the question earlier, you didn't have the answer. It's an expansion that depends on temperature. You can look at it for the quantum transfer matrix in an auxiliary space, and at infinite temperature it's just a projector onto one state. And then you can do an expansion. Well, I mean, let me finish, then maybe I think the answer. You let me finish, then maybe I can answer your question. If you stop me every second, then it's so hard to say anything. So, I mean, so at infinite temperature, then the quantum transfer matrix has only one eigenvalue, which is non-zero, and one eigenstate, which belongs to it. And then you can do an expansion around that point. So then the next one comes up sort of if you go to finite temperature. And that basically gives you the corrections then for this entropy. No corrections. And I would say. And I I would say it's this picture, right? And it's just that at large t at very large t there is only a few rows here, right? And as we but I'm not sure what we do. I think this would be a great conversation. We can keep it in the middle of the middle. So we'll we'll reconvene it at a quarter two for the week's time. I mean it's uh what size is So if you really want to match it with some problems, it's so nice to see a lot of work with good drugs and that's what you Um there are instance uh let's say the spectrum of the high properties what you have high star technique for a specific connection to the original model and that's the fact that the other two uh  And then if you don't find the argument spreads, and these arguments, if you want to see bugs for it, then that's not clear. So search for the connection. For a connection with a RSOS or something, you can power it. So they were not around to fit sitting up, which is very, very small. But otherwise, the connection is more or less just dynamically. No, no, I think CFT and CFT you get that's it. That's in in Russian CF. Temperature. Every spin is conformable to the spin. No, it's not user results. No, I think there is no five issues from that. I mean in chat so far. Well, I hope we've got these right now. I was thinking about getting the paper. But in practice, yeah, but that's what you change for. But for uh should be like for JSON Yeah, so I did the idea to a full button function. Because it's very fast and then Uh and not sure if you have the work or not. So that's because you told me that already.