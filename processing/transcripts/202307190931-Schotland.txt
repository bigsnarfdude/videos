Thank you everyone for coming this morning and of course for the invitation to be here. It's wonderful to be back at Van. So I almost somewhat irreverent I don't know we are going to hike yet. Well no no if you're going somewhere else you know backcountry not very popular. Yeah don't worry I think your mic is on if you can hear us. Go ahead, John. Okay. Thank you. So I had plans somewhat irreverently to title this talk Inverse Born Again. So you see the inverse born. So, you see, the inverse Born series is an old interest of mine. And about two years ago, I thought that I had written the last paper I would ever on the subject. But sometimes old things, just like old people, have surprises in store for us. And so that's what this talk is about. So the inverse-Born series, it's a direct reconstruction method. Reconstruction method. By direct, I mean that you have formulas to solve inverse problems. You don't need to do any optimization, you don't need a forward PDE solver. Someone gives you the data, you apply the inverse Born series, and away you go. Now, it sounds too good to be true, and it is. The main point being that it's not a global method. You need some smallest data, that's other some smallest conditions on the data in order to apply this method. Data in order to apply this method. In practice, these smallest conditions are hardly ever important, which is to say you can break it, but you typically don't break it. And what's nice about it is that it has analyzable convergence stability and error. So you can really understand what's going on with the method. Now, until very recently, we had only applied it to inverse problems for linear PDEs. So I'm going to show you. So I'm going to show you something about what happens in the nonlinear case and also for the non-linear case. Okay, so I'll begin with the nonlinear case. The physical application that I have in mind here is to nonlinear optics, and I will choose a particular kind of optical nonlinearity called the Kerr nonlinearity. This is a sort of NLS-type thing. Sort of NLS type thing, and the important, physically important aspect of this is you don't change frequencies. You send in a time harmonic wave at frequency omega, and the light that comes out is still the frequency omega. So this is joint work with Shari Mosco, who I have over the years written a number of papers about this topic with, and a graduate student at Courant Nick D. Filipus. The second topic is what happens for non-local PDEs. What happens for non-local PDs? And here the applications are in quantum optics. And this is joint work with my former student, Jeremy Hoskins, and former postdoc, Howard Levinson. Okay, so let's begin with the case of linear PDE. So this is a setting in which we first started to think about the inverse Born series a very long time ago. So we're in dimensions. We're in dimensions n bigger than 2 in a bounded domain. We have the Helmholtz equation for a scalar wave, u. And we have some coefficient eta of x that describes the scattering of the wave in the medium. And we also, let us suppose we have some boundary conditions on the boundary, some moment condition. Okay, so in the usual way, we can convert the PDE into an integral equation. Into an integral equation, sometimes called the Lippmann-Schwinger equation. And if we do this, then what you see is that the field U is the incident field, which is the field in the absence of any scattering. So that would be something like a plane wave if this were in free space. Plus a term which describes the scattering. And here we have the Green's function for the equation. This is the Green's function for the free. For the equation. This is the Green's function for the free equation without eta. u, of course, is the field when eta is this so-called scattering potential. And well, you see, of course, that this integral equation determines the field u self-consistently. U appears on the left-hand side of the equation and the right-hand side of the equation. So this suggests that one should make an iteration. And this iteration is, in physics, is called the Born series. And I guess mathematicians tend to call it mathematics called the Neumann series. In any event, whatever it's called, this is what you get. So the field is the incident field plus a term which is linear in eta, plus a term which is bilinear in eta, and so on. So this term, physically speaking, represents somehow one scattering interaction with the potential of eta, and two scattering events, and so on. Now I want to write the series in a in a somewhat more compact way. So let's, and this is especially useful for inverse problems. So let's pick a point on the boundary where we might make measurements and call phi the scattering data, so we'll just scatter field. And then so the Born series is just some sum and these operators, Km, are multilinear. Kn are multilinear. So these consist of products of Green's functions and the incident field, and then as many products of eta as you might need. Okay. Now, it's often the case that in suitable function spaces we can estimate the norm of this operator, and it will generically sort of have the form of some constant mu to the power n minus 1 times some other. To the power n minus 1 times some other constant, Î¼. In the particular case that I'm talking about, it's possible to work out what these constants are explicitly, but this really isn't the point. Now, the Born series, as you can imagine, doesn't always converge. In order for it to converge, there have to be some smallest conditions on eta. And those smallest conditions can be expressed in terms of these Morning constants. Okay. So. So let's reformulate this again in a slightly more abstract setting. Not a big believer in abstraction, but this will help us a little bit, I promise. So let us suppose we affix some Bonach spaces X and Y and consider this multilinear operator to be a map from tensor products of the Bonach space X into Y. X into Y. And then we will consider what I call the forward operator from X to Y, which is simply this sum of multilinear things evaluated at its diagonal. So that's just the Born series. And the forward problem then is to evaluate this map. So you pick a scattering potential and you find some phi for each scattering potential that you're interested in. Now, in some sense, the inverse problem is to determine. The inverse problem is to determine the scattering potential, assuming you know the data phi, which is to say you want to construct some kind of a map which goes backwards, and which is in a suitable sense the inverse of the forward map F. And to do this, we make an ensemble. Namely, we say that we can expand i, and again, some kind of multilinear series, in some operators, which I'm going to call. Which I'm going to call script Km, which are now functions of the data. Now I don't know what these script KMs are, but I can determine what they are from the knowledge of the operators Kn, which appear in the forward series. Now, if you remember, or at least if I remember back to when I was a small child, maybe in kindergarten and learning about calculus, there was an exercise called. There was an exercise called inversion of power series. Someone gives you a power series, and you would like to find the inverse of the function which is defined by that series. So, this is kind of an extension of that idea. And we'll see how that works. Okay, so to find these operators, we substitute the series for eta, which is to say the inverse series, into the series for phi, the forward series, and equate terms of the same order. equate terms of the same order. And then we find that these script k's are homogeneous of degree m and they obey a series of relations. So let's look at the first one. So what this says is that in some sense, script k1 is an inverse of k1. Let's not take that statement too seriously for the moment. This is often a compact operator and so one has to be a little careful about what this means. But we'll fix that as we go. But we'll fix that as we go along. The more interesting thing to say is that I can compute now script k2 in terms of the forward operator k2. And there is only one use of that guy. So everything you compute at the end of the day involves only forward operators up to whatever order you need. And then the whole thing runs, is passed through script K1. So what this says is that. So, what this says is that if you can solve the linear inverse problem in some way, then to solve the non-linear inverse problem, you simply have to know what these forward operators are and compute this sum. Now, there are a lot of terms in this sum. And so the issue will be, of course, how many of them you need in order to achieve a certain accuracy. It's your question. I'm sorry. How are you getting these equations? What are you composing with what? You put one series into the You put one series into the other, and that will lead to a series of conditions which you can match order by order in powers of five or eight. It depends on how you get it. You had a series with k and a series with script k. Yeah. So which one did you... Ah, it actually matters very much. So you should substitute the series for eta into the series for phi. You can do it the other way around. It's an excellent question. You can do it the other way around. It's an excellent question. And in fact, of course, the results have to be the same, but what you compute is quite different. I'll come back to this. Okay, so anyway, so this is the recipe then for computing these script operators. And then you sum them all up for a given piece of data phi, and that's what we call the inverse point series. So that's putatively a solution to the inverse problem. You can compute all of this. Problem, you can compute all of this. So, rather than giving some examples, which I will do for these nonlinear and non-local things, I'll just tell you what we know about this series. So, this is joint work with Jeremy. And so, this is a sufficient condition for convergence of the inverse-borne series. And so, as long as these operators obey this sort of norming conditions, then you can show that the inverse-borne series converges. Then you can show that the inverse-Born series converges as long as the solution to the linearized inverse problem is sufficiently small. That's the smallest condition on the data. And then there's a radius of convergence, which one can compute in terms of things that you know. That's nice to know this. But the more interesting question has to do with what is the error that you commit, right? Because it might not be. Commit, right? Because it might not be the case that the inverse Born series, the sum of the inverse Born series coincides with the coefficients that you actually care about. So here is an error estimate. So what this is is the difference between the true coefficient theta and n terms of the inverse Born series can be bounded above by two things. So one thing is a term which goes to zero algebraically fast as the number of terms in the series increases. As the number of terms in the series increases. And a second term which represents the absolute error of the series. So you remember, I told you these readers should be careful about writing that k1, k1 is the identity. It shouldn't be. And if it is, of course, there's no error. And if it isn't, if it's suitably regularized in some sense, and it's often the case that one has to cut off high-frequency contributions in order to make the problem stable, then this is the error that you achieve. Of course, if you compute all this stuff and then compare it to numerical reconstructions, this is pessimistic. The method works much better than we understand it to work. I won't say anything about the proofs of these theorems, except that there's a paper inverse problems to read about it, and it is an application of some ideas about geometry. Application of some ideas about geometric function theory in biohones basis. So, estimations of sort of a block radii of these series are what is behind all of this. Okay, so let's now talk about nonlinear things. So, again, we have some beta domain, and we have a PDE which has a cubic nonlinearity, two coefficients, alpha and beta, in front of the linear order term. And beta in front of the linear term and the nonlinear term. And some boundary conditions. Okay, so I'm going to present, of course, that the inverse problem is to make some measurements on the boundary in the usual way, and to recover these coefficients alpha and beta. And as I mentioned, this describes the so-called Kerr effect on nonlinear optics. And these coefficients alpha and beta are sometimes called linear and non-linear susceptibilities in that subject. So, to make life a little bit easy for the moment, let's take everything. A little bit easy for the moment. Let's take everything to be real: the coefficients and the boundary source and so forth, so that the solution will also be real. So I'll get rid of any absolute values. This is really not essential once we do this, for instance, in RN and keep complex value solutions. Okay, so we're going to follow the same recipe. We're going to turn this PDE into an integral equation. So there is an incident. Um so there is an incident field, which is of course just the field which is satisfied uh which satisfies the equation of alpha and beta uh zero, plus the scattered field. But now the scattered field includes the contributions of a nonlinear term. So far so good. So, once again, u appears on the left-hand side and the right-hand side of this equation. One should make some kind of Born series out of it. Kind of Born series algorithm. The trouble, of course, is that keeping track of all of the terms in the series because of the nonlinearity is a little bit complicated. But there's some kind of work to do. Okay, so we write the Born series in terms of some operators that are relatively easily worked out. But as I say, it's a kind of a long time to short story to figure out exactly what. Short of a story to figure out exactly what these integrates look like. So I won't tell you too much about it, but I will tell you how to bound them. That's the important thing. Details are again in the paper. Okay, so what we find is that you can estimate kn, this forward operator of order n, but now it's in terms of a coefficient nu sub n. Remember, there was no n dependence in the linear case. There was no n dependence in the linear case, and a power of mu. So, mu is what this guy turns out to be. And sub n plus 1 obeys a recurrence relation, a nonlinear recurrence relation at this point. So you add everything up to n, and you take advantage of these things having started from nu 0, which you can compute. So, how do you deal with this? You make a generating function out of the nuance, and one can then show that That one can convert this estimate for kn into an estimate of the previous type, except we simply have to renormalize mu and we pick up a new constant k. This constant k can be computed explicitly once you know the generating function that I mentioned earlier. Okay, so we're back in the framework that we like, which means that the Born series will converge in, let's say, L infinity with a In, let's say, L infinity with a radius of convergence and error that you can obtain from the series. All right, oops. So let's take a look at some numerical illustrations of this. So this is work that was actually done by Nick. So I hope to be able to explain it. So we take omega to be disk of radius one, the wave number to be one. The wave number to be one. And the measurements are taken from a 32 by 32 array of source detector pairs which are on the boundary of the domain. So these are like tiny little Gaussian blobs all the way around. And you measure pair by pair. So you turn on one source, you measure all the detectors, and do this again and again. Okay, so this is a reconstruction with beta equal to zero, which is to say a linear reconstruction. Okay? And this is four terms of the inverse Bohn series. This is a 2D reconstruction, I should say. That's what you're supposed to get, and this is what you get. And now, let's suppose we get rid of alpha, which is the linear term, and reconstruct only beta. So as you can see, the series converges pretty fast for whatever set of contrasts we chose, but Contrast we just chose, but it's a belt you get. There are other examples, as I'd say, in the paper. But this sort of isn't too bad. Now, let's find out whether nonlinearity helps. So now we have both alpha and beta, which are non-zero, and we compute four terms of the inverse Bohn series. Series. And here we have, we set the source on the boundary to be of order one. And you can see that we recover alpha pretty well, but beta doesn't recover itself very well. But if we double the strength of the source, which is where the nonlinearity matters here, this of course wouldn't make any difference even when we were only solving the linear problem, then in fact things get much better. Then, in fact, things get much better. Not perfect, but much better. Okay, so non-linearity helps. Yes. Again, look in the paper. But absolutely. But so here it's non-linearity, you have big data. I'm sorry. Insert big data non-linearity. I mean, what happened was it's. I mean, that's right. So the nonlinear helps if the boundary data is bigger. Yeah. Okay. The term big data is in my head in a different way right now. I like this version bigger. Very good. Let's change gears. Let's talk about non-local stuff. So here's a scattering problem. So this is a non-local equation, but let's say in R3, but with some radiation condition imposed, instead of a non-local boundary condition. So we have our friend this word of the Laplacian. Eta is some potential that we'll. Eta is some potential that we would like to know, and k is some fixed positive number. In quantum optics, u here represents the so-called probability amplitude for measuring a photon at a point in space. And eta is proportional to the number density of atoms in some system. So the physical system here consists of a whole collection of atoms, which are themselves little quantum mechanical objects that can be in one of two states. And eta is their number density. And eta is their number density. Okay, I can explain if we have a little bit of time where these equations come from. But this is the problem. And so, of course, the problem is to recover from some scattering amplitude now, which depends on, let's say, two different directions, the quantity eta. So, again, I will use my friendly inverse-born series. And I'll write an integral equation. I'll write an integral equation and iterate it and so forth. We now have to know a little bit about the Green's function, so this is the Green's function looks like. I need to introduce a small piece over here in order to keep everything happy. And so I have some Fourier integral representation for G. And then I'll just say a few things about this. And then I'll just say a few things about this Green's function. And so, what you can see is that you can obtain the Green's function from the following identity. So it's 1 over x, whatever r, if you will, times the derivative with respect to r of some other function, little g of x. The little g of x you can work out in closed form. So it involves the so-called exponential integral. But you're going to expand. And the result of all of this is that. Result of all of this is that this Green's function g decays nearby the origin as 1 over x squared. You can see this from the lowest order terminus, which has a log in it. But far away, it decays as 1 over x. So this is something which, of course, is very different than you obtain for scalar waves. There is no, all scalar waves radiate, there's no near field. Scalar waves radiate. There's no near field the way there is in Maxwell. But here we have a near field with this kind of decay. And this one of our x decay is why we have a radiation condition from the problem. Okay. So if you work out the asymptotics now, what you find is that the Green's function looks like an outgoing spherical wave times corrections. And then you can compute the scattered field. And then you can compute the scattered field directly. So the scatter field is now, up to this geometrical factor, just the Fourier transform in some outgoing direction of the potential eta times the field u. So use the Born series, iterate this beast, and pull off the geometrical factor. So what you get is a scattering amplitude phi, which looks like this. And now you make the iteration, and you can write phi. And you can write phi as a Bohr series in powers of A. So let's take the incident field to be a plane wave, let's say, in some direction, I don't know x prime, and measure the scattering data falling in some direction x. So what you see is that these forward operators depend on the ingo. Forward operators depend on the ingoing and outgoing directions. And they are, again, not surprisingly, products of Brieves functions that we know and this density or potential that we would like to find. Now, let's take a look at K1, which is the only thing we have to actually invert. Yep, I'm good. Thanks. So that's just a band-limited Fourier transform whose highest frequency, whose band limit is 2k. So you can invert this band-limited Fourier transform and recover. band limited where we transform and recover eta inside of a ball of radius 2k in frequencies of x. So let's now see how this all works in numerical experiments. So we do this first in 2D with 100 sources and 100 detectors. I should have told you, by the way, that these inversions are very, very fast because you can calculate everything in terms of M of T's. And then I'll show you results in 3D with 1,000 sources and 1,000 detector. With a thousand sources and a thousand detectors. So that's 10 to the 6 measurements. Now, all of these computations take place on a small machine in very little time. Time is I don't have off the top of my head. Okay, so this is two dimensions. So we have six Gaussian blobs. So this is what the first term of the inverse Bohr series gets for you. 2, 3, 4, 5, 6. And these are the corresponding errors, which you can see decrease. Now let's do 3D. So we have 100 slices. There are again some blobs. Let's take a look at slice 50. So here it is. And here is a projection along the line which passes through these two blobs. As you can see, And as you can see, well, it works pretty well if you compute five times of the inverse one series. Okay, I think that's about it. Thank you very much. Any questions? Yeah. Okay, so uh you have tried this with explicit non-denario. Try this with explicit non-linear term, namely u to the power 2 and beta of x. So somehow you deal with the coefficient of a non-linear term. Can you deal with the same when the non-linear term is unknown? So for instance, you have beta of x, f of u, f is also unknown. No, I don't see any way to do that. But but on the other hand, if I know f of u, for instance, something which would correspond to, let's say, On to, let's say, a second harmonic generation or a third harmonic generation. So there are many other nonlinearities of polynomial type where this kind of construction works just fine. If I don't know f, well, I'm in the same, if I'm all in the same boat, I think, unless we do something with machine learning. One other question? Yes. So this approach seems to be also the rather suitable for equipment. It is. Has everyone done this? It is. Has everyone done this? We have done it. We have done this kind of stuff over many years for many different kinds of equations. We have done it for EIT, for optical tomography, for radio dimension transport, for Maxwell. I mean, most have written 15 papers about this. In the linear setting, as I say, I thought I had written I had the l wrote the last thing I was ever going to say about this two years ago. But quantum optics and non-linearity, you know, they sort of Nonlinearity, I know these are hasten all your back. So, is there a reason for the one-half power coming from the application? Or are there sort of settings where there fractional powers? Excellent. Yes. I even have slides about that, but I don't want to take up the coffee break. Yes, the power one-half is there for a very particular reason. In quantum field theory, there are reasons that this comes up. If you try, when you quantize, When you quantize the, let's say, the electromagnetic field, the dispersion relation is, well, it's proportional to the modulus of the wave vector k. And the modulus of the wave vector k is, of course, the Fourier multiplier for this period of Plausion. And once you recognize this and you look at the Hamiltonian in the right light, you see that this is what it has to be. I don't know of any other physical application in my world where you have. World where you have fractional powers other than one-half. Thank you. I'm going to say something obnoxious. This particular fractional power, unlike many others that I have seen, which arise from averaging at some point, comes from God. What do we address question? Yes. That seems to put you out of the scope where a theorem is coming design. It doesn't. So all of these things are within the applicability of the theorem. You see, there's an interplay between the size of the support of the thing you want to reconstruct and the size of the data on the boundary. Now, it's certainly true that one can break the theorem. One can break the theorem, and then it, for reasons that we don't understand, the method still works. Now, that's not so surprising, right? Because to get estimates, you have to give things up. You know, just one or two bad uses of coaching sports for the triangle inequality, and you're, you know, you are where you are. Maybe we have some company. Nice. Yeah, exactly back in the center of the one of the computers, another series, but uh another operator. Interested in teaching the wildflowers, I'll find me in the book afterwards in like five minutes or so. Okay, maybe I'll eat up some of your coffee time then and say that this is doable with some adjustments. So, everybody, if we're eight loop that I gave you, within our time constraints, if we catch the 140 bus, this is not doable. It's just an This is not doable, it's just going to take us too long, especially if you want to take pictures of all the nice wildflowers. But there is the possibility of all the wildflowers. I've owned a bunch of people in the government and the government of Parks Alberta and like a few transfers later, all of the wildflowers are concentrated around the loop. So people go up, do half of the loop, do the whole wildflower one, but then we have to come back, or we, as in those who want to take the rest of us, back to town and eat dinner. Us bus back to town and eat dinner at every single hour. Or you can, so that means you'll miss the view into the valley, into the BC. But if you want, then some of us can continue there, but then you have to find your own transportation back and such kind of. So what I would recommend is if you are interested in doing this, please let's meet at St. Louis Hall at like 1 p.m. sharp. We'll all walk down to the bus. Who is interested? We'll catch the 140 bus. It's going to cost around 65 Canadian to take the bottom. Sixty-five Canadian to take the viola up. Then we'll miss a little bit of height also. We'll have to take a look here instead of hiking up to see a little bit of time. Then we'll be at the doorhead and we'll get to take the hole through the alpine lakes, through all of the wildflowers which I've been sharing already to move right to the house. 1 p.m. where? Let's say just outside one phone call. So everyone has their stuff right in the lobby, 1 p.m. sharp. We will leave out because I sort of know where this is. because I sort of know where this bus stop is predominantly, so there's like a matter for me to wander around and find the right spot, but believe it right and so I can look at this. Yeah, okay. How many calories does one have to expend to go in this activity? As many as you want. Eat heartily at lunch. But not too heartily so that you can make it up to you. Bit of elevation, is that typical is that we because that table is actually a really good mood. The scale is just like an edge tape to it. Alright, thank you so much for your time. Enjoy your coffee. I hope to see you on the last thing. I mean two things are both the other one with the colours. One eye could both be colourful. If I walk around, there's a bus for the teacher. And then here. And the computers that you provide stage is not just because it's the station that's fairly discrete. And you understand the light on this page. And everyone wants to leave the bus file because they want to leave. Oh, right. Yes, just here's one of the teams. I think so, yeah. You could get like one yesterday, right? You follow the limits of time, and if there is a one-so there's a limit away. No, no, no. This one is pretty straightforward. So that was my bad. Like this one's the A data stand. I'm going to turn the other one to stay off. We are going the other way, then you do sign that. I haven't decided that. Oh, I don't mind going to share that.  Yeah, just sitting there. So it's just a little bit of a test. I'm always taking perception that basically my child are this, this, this especially of the morning, but that's what it's frequently by this. Yeah, they're they like to like to walk in the morning. And in general, as I thumbed up, there comes like time to waste the language. So, you know, you go up here, it's got to be safe. They say, oh, I mean, especially there are any bushes or they might be too fairies, you know, that's kind of like, but I just both know this, you know. So, yeah, since you climb mountains, you can keep this. Their main goal is to get around it's been a little bit