I'm a PhD student at the University of Toronto, and I'm here to talk about fast radio bursts, and in particular, deriving the probability of event transcoincidence for inhomogeneous noisy spatial processes. And I'm doing this with Der Bingham, Gwen, Needy, Paul Schultz, and David Senning in the entire time of Reginald collaboration. So fast radio bursts were first discovered in 2007. They're these bright, approximately millisecond duration radio transients, and we don't know what they are. We don't know what they are. When I first started in the FRB field, I don't remember who gave this talk, but these two equations have always stuck with me. In 2018, not only did we have more theories for the progenitors of FRBs than we had detected FRBs, but the rate at which the number of theories was growing was greater than the number of FRBs we were detecting. In comes CHIME FRB. So CHIME stands for the Canadian Hydrogen Intensity Mapping Experiment. The FRB purchase has the FRB experiment back end. The FRB experiment backend. It's located in DRAO, which is just outside of Printed PC. Operates between 400-800 megahertz. It just stares at the sky above it as it passes over, and as such, it's able to survey two-thirds of the sky every day. Pauline had talked about the data rate of time, and it's crazy. I've heard that it's roughly the same as the telecommunications for all of North America. But we've been able to revolutionize the FRB fields due. Revolutionized the FRB fields due to the wide field of view, powerful correlator, and efficient de-dispersion algorithms, which were all problems why we weren't detecting FRBs before. So as proof, this is the number of detections of FRBs as a function of time. And then right here is where TimeFRB comes online. You have this crazy jump, and then this plateau again, and that plateau is just because we haven't gotten around to publishing the next X thousand verse, which we are working on. Thousand bursts, which we are working on, but that's just the first year of our operations. So, observationally, there are kind of three classes of FRBs: two or three, it's not super clear. There are one-off or apparent non-repeating FRBs. These are FRBs where we have one burst from a position in the universe we've seen at one time. There are thousands of these. Then we have about 50 or 60 repeating FRBs. So, this is when we see multiple bursts from the same position on the sky. They have random arrival times, but there's evidence. They have random arrival times, but there's evidence of clustering, so they're better described by a Weibull distribution than a Poisson distribution. There's some morphological evidence that they're distinct from one off, so they tend to be broader and narrower in frequency. And yeah, like I said, they're about 50 to 60 at least. There are also two really special repeaters, so if you want to call this its own subclass, it's not clear yet. But these are repeaters with periodic active windows. So the FRB, the repeater bursts still come stochastically, but they only come within. But they only come within, in the first case, four-day windows every 16 days. So the first one is the third repeater I've discovered. The second one is the first repeater I've discovered, which potentially also has a few hundred day period. What's interesting is these are both some of the most prolific repeaters. So then the question becomes, are these the only periodic repeating FRBs, or are these just the ones we've found in the periods before? But we're going to talk about repeaters today, mostly. Sorry. Sorry. So I've said all these great things about QIIME FRBs, but it does, QIIMI FRB, but it lacks in one major area, and that's the angular resolution. So there's pretty significant measurement error, which means that even if you're observing a repeater, you're going to detect a distance between the bursts on the sky, because they just are quite substantial error. Similarly, the probability that you detect two unrelated bursts that happen to be coincidental. Bursts that happen to be coincident with each other are greater than zero. And so, as time detects more and more bursts, the probability increases that we're observing two events that are coincidence and very close together by chance. So, this is kind of just like a GIF to describe what I'm talking about, a very simple Chrome process. You can see that even though they all have distinct true positions, which are the white dots, their error region will overlap and it gets worse and worse as you detect more and more at frame or close in this case. So, the question that we'd like to answer is: how close. So the question that we'd like to answer is how close together do you need to get for n-verse for it to be sufficiently unlikely that they are physically unrelated or men? If it were just the problem in the GIF that I had shown, it'd be quite easy. But there's a few complicating factors that are just physically because of the way that QIIME FRB observes. So the first one is that the exposure of QIIME FRB is uneven and hence we have a non-homogeneous Poisson process. This is what the histogram of FRB detections looks like from the first FRB. Of FRB detections looks like from the first FRB catalog, where this is one of the sky dimensions and this is a proxy for distance. There's noise, and not only is that noise, the error region is large, but it's maximotal. I'll show an example of that later. We have to estimate the intensity from the data of the non-homogeneous response process, but we don't have a null data set. That is, there's no way to unambiguously remove all of the repeat bursts because we don't know for just two bursts that are close together. Don't know for just two bursts that are close together if they're repeaters or not, especially before we do this analysis. So the data set is necessarily going to be contaminated by repeaters. So another more pictorial way of kind of what we want to do is to show what we want to do is considering, so this is just random draws of the position from the FRB localization regions. And so we want to say somehow that this bursts where it's three that are close together regarding Verse, where it's three that are close together, regardless of how you're drawing the position errors, and they tend to be quite close together through every iteration are somehow more significant than these ones over here, which is only two and it jumps in and out of frame. Then, of course, we know as a function of sky, there are some FRBs that are, there are some regions where you're more likely to detect multiple FRBs than others. So, what we're going to, what we've decided to do is we want to model the process that generates the FRBs in Sky, and then we want to modulate it by the error term. And so, this is what the And so this is what the this is some intensity function that we're I'll describe later for the intensity of FRB detections on the sky and then this is what our localization region errors look like so they're these three distinct kind of modes or islands as the China FRB people always say where you can see that they're kind of definitely not smooth and then once we have a model of the process that's generating the FRBs in the sky we'd like to do a predictive inference so if we could just estimate how significant If we could just estimate how significant the repeaters are by saying, kind of describing the cumulative distribution function of the contact distance of k bursts that are close together. So how far away do we expect the next k burst to be, and are we significantly closer than that? There's been some work done here, particularly in estimating the intensity function from data of non-homogeneous song processes observed with noise. So Kukla in 2018, they present an edge-correlated deconvolutated kernel. Deconcluded kernel estimator of the non-community of solid process intensity. And they get a bandwidth selection procedure for the noise scenario. Chakabardi and Gelphan in 2010 also estimated the intensity for the noisy non-homogeneous sound process and derive a likelihood function that we actually use. It's useful. They have this extra complicating factor that they're considering events that are jumping in and out of the domain because of the error that we're observing, where that's not really as much of an issue in our view. That's not really so much of an issue in our view as yet, but it's interesting. But neither of these authors then take the intensity that they've observed and use it to make some kind of predictive inference. Barhan et al. in 2013 do estimate second-order characteristics from the intensity function, in particular the nearest neighbor function of non-homogeneous Poisson process from several order noise, which would be really useful, except for they're interested in the predictive inference for the underlying Poisson process. For the underlying Woissan process instead of the noisy process. So we want to quantify the likelihood of the observations themselves, not of the underlying process, which we know is wrong because it assumes no repeaters. So what we're basically doing is an abasion model that's hierarchical in that we sample not only intensity hyperparameters from some power distribution, but we're also sampling true FRB positions from the local. True FRB positions from the localizations as we're going to account for the uncertainty in the positions. This is what the model looks like. There's four stages. The first one describes how the true positions are converted to observed positions with noise. The second one talks about how many FRBs we expect given the intensity function. The third one talks about where we expect those FRBs to be given the intensity function. And then the fourth one is just the intensity function as described by its intensity parameters. And so now let's really dig into the physical. And so now let's really dig into the physics here. This is what the intensity function looks like. Just kidding, I will not tell you exactly how I derived that. I do not have time for it, but let me say that while it's complicated, it does need to be estimated numerically. The shape of it is well described by physics of the instrument that we know and just spherical geometry. And so let me just kind of jump right to the results. These are the hyperparameters governing the intensity functions, at least the first step. Step. There doesn't seem to be too much degeneracy in the parameters, except for in these parameters here, but we kind of expect that just due to the physical nature of them. The R hat statistic is good in each case. We check for convergence and kind of like a unique solution by starting at different values for each of the hyperparameters, where we pick those starting values based on Latin hypercube sampling from their prior distributions. So, we have basically what I want to say is we have a really good intensity function out. We have a great description of the data of how FRBs are processed on the sky. And the next step is this predictive inference of how exactly do we, how exactly, how close do we need to be for these bursts to be significant and they're definitely repeaters. So what we do is we have now this posterior that is basically just millions of time FRB experiments. We can simulate FRBs from the calculate the kth nearest neighbor distance at a given time. Calculate the kth nearest neighbor distance at a given point on the sky, repeat it, repeat it, repeat it, and compare the observed distance to the simulated separations. And then hence we refer how significant the repeater candidate is. I don't have that for you yet. But there's kind of two really cool things that we're gonna do with it. The simulations are just running, unfortunately, but there's cool two cool thi uh applications that I kinda wanna talk about once we do have this um uh step done. Step done. So the first one is kind of like just looking at where the correction for the noise has the most significant implications. So I kind of have two different intensity regimes and two different error regimes here. So basically, as we're doing the simulations, we have this wonderful consequence that we also know the true positions because we have the true positions before we modulate them with an error. So what we can do is we can look at the cumulative distribution of the distance of the true position compared to the ones with noise. And so kind of what we're The ones with noise. And so, kind of what we're seeing from the first simulations is that when you're in this high-intensity region where the intensity changes a lot as a function of declination and DM, and there's lots of FREs, it seems to matter a lot more that you take into account the errors, because the errors will make the distance that you need have a significant repeater change substantially. Whereas when you're in a lower intensity region on the sky, there doesn't seem to be a big difference between the true underlying just Between the true underlying process and that observed with error. So you can basically just say it's a homogeneous Poisson process in the lower density regions where there's not a lot of variation, and that makes sense. The other thing we'd like to do is look at this claim of an association between a binary neutron star merger from LIGO and an FRB with QIMFRB. So QIIME FRB is not the only one, a poor angular resolution is good. This is an example of an angular, sorry, the Sorry, the positional uncertainty of an event from LIGO, particularly 2019-0425A. There's no A on LIGO. And here on the blue dot is the QIIME FRB. So if these two are associated, it has huge implications for FRB progenitors. We know that binary neutron storm vergers can make FRBs. Localization is consistent between the two. As you can see, it's at a pretty high density region of the localization. A density region of the localization of the gravitational wave, but they're temporally separated by a few hours. This is allowed theoretically. We don't know the exact temporal separation between a binary neutron star merger and an FRB. But there's disagreement in the community about the significance of this because there's lots of places where you could have a high. I don't know, you have as much time, there's no real boundary on the time, and there's lots of positions that are, what's the word? What's the word? Coincident on the sky. So there's definitely a question about whether or not this is significant. And our method is totally applicable because we can just draw positions for the gravitational wave event and compare them to the position of the FRB like we were doing. So instead of FRB and FRB, we do FRB and gravitational wave and hopefully come up with a transquincence probability. So the remaining work is just to let the simulation The remaining work is just to let the simulations run. Some of the repeaters are really significant. They're like one in billions. So we need a lot of trials to quantify the exact significance of the repeaters. Stay tuned for a paper, hopefully on archive in the start of 2024. My summary is that we've derived a method for estimating the case-nearest neighbor distance for non-homogeneous person processes of observed noise. This was motivated by a specific application to quantify repeater significance of time with RB. And since we do a lot of And since we do a lot of comparisons between one-off FRB populations and repeater populations, it has a really big implication about what exactly a repeater is. So it's really important for FRB scientists. Questions for Vita?