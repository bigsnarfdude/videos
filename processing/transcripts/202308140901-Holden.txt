Her PhD in 2018, I think, in MIT, supervised by Scott Shepfield. And then she did a post-doc in Switzerland, in Zurich, under Venerie Werner's supervision. And after that, she took a position in Kohan, where she is also right now. And maybe integrate also has been working outside academia before her academic career. Just an example. An example. I should mention Mina also received the RAM research public for history 2021 for her very influential work on random geometry. So she's working on code area of random geometry relating to probability theory and mathematical physics, for instance centered around random and quantum invariant planar objects. Janet is going to talk about random curves and surfaces. Go ahead, Evelina. Yeah, so first, thank you very much to Evelina for the introduction. And also, thanks to the organizers of this workshop for inviting me to give a presentation. So let me just start by sharing the screen. Yeah, so. Yeah, so before I start the talk, I also want to wish everyone a very inspiring and productive week at Advanf. So I've had a look at the program and it looks like you have a very interesting program this week. So let me go on full screen. So I will be talking about random curves and surfaces. And I should start by emphasizing that my talk is primarily a talk in probability theory, although many of the objects Although many of the objects I'm studying, they are very much inspired by mathematical physics and theoretical physics. So, my talk will have two parts. In the first part of the talk, we will be looking at various random objects, which in some sense can be viewed as uniformly sampled random objects from some class. For example, we will be looking at random curves, random functions, and random surfaces. Then, the second part of the talk. Then, in the second part of the talk, we will be looking at a very powerful technique to study the random surfaces that were introduced in the first part of the talk. And this tool is known as conformal welding. So, we start on the first part and we start with a motivating question, which is how can you sample a curve uniformly at random? To answer this question, we first need to say what we mean by a curve. What we mean by a curve. So, we can, for example, go to Wikipedia and we see on Wikipedia a curve is the image of an interval to a topological space by a continuous function. So to make this a bit more concrete, then we can first fix this topological space and we can, for example, fix this topological space to be one of the most commonly considered topological spaces, namely the set R of real numbers. Then we can also fix the Then we can also fix the interval to be, for example, the unit interval. So, with these choices, our set of curves is the set of continuous functions from the unit interval to R. So then we want to sample an element from the set uniform LADRAN. So uniform LADRAN means that in some sense all possible outcomes should have the same probability. And it's not obvious how to do that in the setting because omega is infinite. Omega is infinite. It's even infinite-dimensional. So, one possible approach to the problem is to discretize it. So, we consider the unit interval, and then we're dividing the unit interval into n shorter intervals of each of length 1 over n. And then we require that our function is linear on each of these shorter intervals. And then we also require the slope. And then we also require the slope to be plus minus root n. I will come back to this choice a bit later. And then we also require that the function is equal to zero when the input argument is equal to zero. So make this choice in order to get some finite set. So the set omega n of the functions as just described, so this is a finite set. So therefore, it's straightforward. Pick some element uniform at random from the set. And we do this, and then we set send n to infinity. So, when we send n to infinity, then it is a classical result in probability theory that the random function we get in this way, it converges to some continuum, a random function. And this is the continuum random function known as a Brownian motion. And coming back to this choice of root n, so we have to make the slope of order root n in order to get some non-trivial limit. Order to get some non-trivial limit. So if the slope had been much smaller, then we would just have gotten a straight line asymptotically, whereas if we had chosen a larger slope, then the function would have gone off to plus minus infinity. So here you can see three independent samples of this Brownian motion. As the Brownian motion, it is a random curve which is arising in a huge number of different settings and applications. For example, For example, it's used to model phenomena in both the natural and social sciences. So, one typical application is that it's used to model the random movement of various particles. For example, we can consider some bucket of water, and then we assume that we have some pollen grains in this bucket of water. And then it's possible to argue that the pollen particles will move around. Particles, they will move around randomly in the water, such that each coordinate is approximately given by an independent Brownian motion. And the reason this happens is because the pollen molecules, they are bombarded by water particles, which is giving the pollen particles some random pushes. And one can argue that the random movement gets should approximately be given by this Brownian motion. So this phenomenon was. So this phenomenon was actually the beginning of brand and motion and it was first described by Robert Brown. So another application is in finance. So here you can see the historical evolution of the US dollar Euro exchange rate over a two-year period and exchange rates and several other financial products. They're often modeled using Brown and Motion and other closely related Other and other closely related processes. So, one reason that Brownian motion is appearing in so many different settings is universality. So, this means that the Brownian motion, it describes the asymptotic behavior of a large class of discrete models, typically such that the asymptotic behavior of the model is not too sensitive to the details of the discrete dynamics. So, then we ask a second motivating question. Motivating question. So, how to sample a self-avoiding curve in the unit disk uniformly at random? So, now we want our curves to be in the unit disk, as it means that our function, our continuous function, is taking values in the closure of the unit disk. And we require that our curve is self-avoiding, which just means that this function is injective. So, here you can see an example of such a self-avoiding curve in the unit disk. Self-wording curve in the unit disk. So, again, we want to sample such a curve uniformly at random. And again, it's not obvious how to do it because there are infinitely many such functions. And just as before, our approach to this problem is to discretize it. So we consider some rescaled version of Z2 restricted to the unit disk. And then we consider functions that are on this graph. And then we require that the speed of the function is n to the power third. So, this is the speed that we need to choose in order to get the asymptotic behavior that we want. And then I'm also requiring that the function or the curve is connecting the points plus minus i. This requirement is actually not so important, but it fits better with what I will be saying next. So, the set omega m. So this set of functions is finite, and we can sample a curve uniform at random from this finite set. And so here I did it for one value 1 over n of one lattice size, 1 over n, and here for some finer lattice size. And then it is believed that when the lattice size 1 over n is going to zero, then we get a random fraction. We get a random fractal curve, which is known as the Schramm-Doebner revolution. The Schram-Derbner revolution is a random fractal curve introduced by Odo Schramm almost 25 years ago. And he introduced this as a candidate for the scaling limit of curves in various statistical physics models. And after Schrum's original introduction of SLE, then it was proven that the SLE does describe. Proven that the SLE does describe the asymptotic behavior of a number of discrete models. So the convergence results stated on the slide is only conjectural, but it has been proven to describe the asymptotic, to describe the scaling limit of, for example, the easing model, percolation, the uniform spanning tree, and so on. So the SLE is uniquely characterized by two natural properties, which are known as Natural properties, which are known as conformal invariants, and the domain mark of property. Ode-Schram proved that there is a unique one-parameter family of curves which is satisfying these three properties, and he denoted this parameter by kappa. So the kappa is denoting how windy or fractal the curve is. So in the figure, you can see sketches of SLE for kappa equals 2 and SLE for kappa equals 4. And each discrete model is believed to correspond to some value of Model is believed to correspond to some value of kappa. For example, this self-avoiding curve should correspond to kappa equals 8 over 3. Daising model corresponds to kappa equals 3 and so on. Stromanum natural variance of the SLE. On this slide, I consider what I call a chordal SLE, which is a curve defined in some simply connected domains, and the domain which is connecting to fixed boundary points. Fixed boundary points. One can also consider other variants of SLE, for example, what is called the SLE loop. So in this figure, you can see a sketch of the SLE loop on the sphere S2. So then we ask, how can you sample a function uniformly at random which is real valued and defined on the unit square? So just as before, our approach to So, just as before, our approach to this problem is to discretize it. So, we consider a Briescale version of Z2 restricted to the unit square, and then we consider integer-valued functions on this graph. So, we are hoping to take some kind of limit when the inverse lattice n is going to infinity. And therefore, it's natural to require that adjacent function values are not too different. So, we require that if we look at So we require that if we look at the function at two at two adjacent points, then the function value is differing by at most one when comparing these two points. So this requirement is written under the figure. And then in order to get the finite collection of functions, we're also requiring that the boundary data are equal to zero. So there are finite So there are finitely many functions which are satisfying the constraints just mentioned and we're picking one such function uniformly at random. And then we're interested in what happens when the lattice size 1 over n is going to zero. So one thing which can be argued, at least for the model on the triangular lattice, is that if we fix some point in the bulk of the domain, and then we look at the value of the function at this point. At the value of the function at this point, then it will be of order log n, where you remember that one over n is the lattice size. So this was proven on the triangular lattice. Then it is believed that when n is going to infinity, then a function sampled in this way, it converges to some continuum random function known as the Gaussian free field. Okay, so I will introduce the Gaussian field. So I will introduce the gasmetry field more precisely on the next slide. But first, I can just remark that in the figure you can see simulations showing approximately what one is getting for n equals 20 and n equals 100, where one has done some interpolation of the function between these lattice sites. Okay, so what is this Gaussian free field? So the Gaussian free field, it is a particular random Is a particular random distribution or a random generalized function. So this means that if Z is on fixed point, then the Gaussian free field is actually not defined at this point. So H of Z is not well defined for any fixed Z in the unit square. So going back to the discrete model, we see why this has to be the case. So by this result of Glasman and Manuelescu, we see that if you consider some fixed point and the function If you consider some fixed point and the function and the discrete function value at this point, then it's actually diverging like the square root of log n when n is going to infinity. So therefore, we see that the limit of the function at this point, it cannot be well defined because the discrete function is converging to plus or minus infinity. However, what one can argue is that the limiting object just makes sense as a distribution or generalized function. So this means. Distribution or generalized function. So this means that if f is some smooth test function, then the integral of f against h is well defined. And this integral will be some random real number. And the particular law will depend on the choice of test function f. More precisely, it's possible to argue that age is an element in the Sobola space, age minus epsilon, for any strictly positive epsilon. So you see that if you set So you see that if you set epsilon equal to zero, then this is actually just an L2 space. So this GFF, it almost has the regularity of a function, but not quite. The precise definition of the Gaussian free field can be given by considering the law of the integral of h against f for any choice of test function f. So the law of these random variables is given, is characterized by this indented equation. So the covariance of So, the covariance between two such integrals is given by this integral, where g is the Green's function associated with the Laplace operator in NS. So the convergence result on this slide is only conjectural, but the Gaussian free field has been proven rigorously to describe the asymptotic behavior of a number of functions in statistical physics models. For example, it describes For example, it describes fluctuations of the height function of abdominal tilings, and it also describes the fluctuation or the characteristic polynomial of various models for random matrices. Another reason this object is of interest is because it defines a generalization of Brownian motion to the case of higher dimensional time. So you remember from earlier that the Brownian motion, it is a function which is defined on some one-dimensional On some one-dimensional set, and which take values in some one-dimensional set. If one takes the same definition and one makes the domain two-dimensional, then one gets the Gaussian free field as defined on this slide. And one can also generalize the definition further to even higher dimensions, which gives some higher dimensional GFF. Finally, another reason it's of interest is because Is because it appears in various constructions in conformal field theory. So then we ask: how can you sample a surface uniformly at random? So again, our approach to this problem is to discretize it. And we consider a random planar map. So planar map is a natural model for a discrete random surface. So to be a bit more precise, So, to be a bit more precise, a planar map is a graph which has been drawn on the sphere, which is viewed modular continuous deformations. In the figure, you can see three different, you can see three planar maps. And here, this planar map and this planar map, they are considered to be the same. And they're considered to be the same because one can get from one to the other by doing some continuous deformation of the sphere. On the other hand, this planar map and this planemap, they are not considered to be the same. So, viewed as graphs, they are. So, viewed as graphs, they are the same, but viewed as maps, they are different because the planar embedding is different. So, in order to get this map from this map, then this edge has to be moved here. And remember that we are viewing the planar map as drawn on the sphere, which means that the complement of this map is also a phase of the map. So, if we pick some natural number n, Natural number n, then there are finitely many maps which have exactly n edges. And we get some natural model for a uniformly sampled surface by picking such a planar map uniformly at random. And if we do this for some large value of n, then we get approximately what you see in this figure. So as mentioned on this slide, circling map is only defined module of continuous deformations. So therefore, there is not a unique way to draw it. A unique way to draw it. If one has some large random planar map, then it's typically not possible to embed it isometrically into R3, which means that it's typically not possible to draw it in R3, such that all the edges have exactly the same length. But it is possible to embed it in such, or one can try to make an embedding into R3, which is as close to isometric as possible. So one does some optimization such that the various edges have a length which is as close. Have a length which is as close to one as possible. And this has been done when making this figure. So this should be viewed as close to asymmetric embedding as possible. To planet maths, they are studied in many different branches of both math and physics. In math, the study of planet maps go at least back to the combinatorics literature in the 60s. So there, Tutmullen and others. So there, Tutmullen and others were proving enumeration or counting formulas for plenar maps. Later, they have been studied in, for example, geometry and in random matrix theory. One application, which is very relevant for this talk, is in random geometry, where probabilists are interested in understanding the geometry of large random planet maps. Another very relevant application is in more formal field theory and string theory, where planar maps are viewed as models for random surfaces. Surfaces. So we consider our large uniformly sampled planar map, and then a natural question is whether this planar map is converging in some sense when n is sent to infinity. And there are actually several ways to formulate such convergence results. And now we'll focus on a particular notion of convergence, which is known as convergence under conformal embedding. So, in order to explain what this means, I first consider the I first consider the uniformization theorem. So, the uniformization theorem is a generalization of the Riemann mapping theorem. So, this theorem is saying that if one has some simply connected Riemann surface, then there exists some conformal map from M to either the unit disk, the complex plane, or the sphere. So, then the next thing one can do is to observe that a planar map is defining. Defining uh, it's defining a Riemannian manifold and, in particular, a Riemann surface. Um, so we will consider the special case when the planar map is a triangulation. Uh, so this means that all the faces of the planar map has as three edges. Um, so as we can give each face the metric of the standard equilateral triangle, and then we're gluing these triangles together according to the combinatorial structure of the plenar map. And then, when we do this, And then, when we do this, then we're getting some Riemannian manifold. So, this Riemannian manifold will be smooth away from the vertices. And then at the vertices, it will have a conical singularity. At least if the number of triangles that come together is different from six. So we see that our triangulation, our random triangulation, it defines some random. Our random triangulation defines some random Riemannian manifold. So, by applying this uniformization theorem, we see that the planar map can be embedded into one of these three domains. And since we work with planar maps that have spherical topology, we know that it can be embedded into the sphere. Okay, so this is an illustration of what I explained on the previous slide. So, here we have our planar map, and here this planar map has. Planar map, and here the this planar map has been conformally embedded into the sphere S2. And this is a figure made by Nicola Gurian. So when we embed our planet map in the sphere, then we get an error measure on the sphere, and we also get the distance function or metric on the sphere. So our error measure, it is defined such that each face has area. phase has area 1 over n. So we know that our Riemannian manifold, it has some area measure and it has some area measure which is defined on these faces. And we choose to rescale this area measure such that each phase has area 1 over n. And it's natural to do this for scaling because we know that the number of faces is of order n. So when we give each face area 1 over n, then the total area of the sphere will remain of order 1. Total area of the sphere will remain of order one when n is n to infinity. Then we know that our Riemannian manifold is also coming with a natural metric or distance function, which can be used to measure the distance between any pair of points. And again, we choose to rescale these distances. And we choose to rescale the distances such that adjacent vertices have distance n to the power minus quadrant. So this turns out to be the scaling one wants to use in order for the total diameter of the sphere. In order for the total diameter of the sphere to be of order one when n is sent to infinity. So this exponent one over four is actually far from obvious. So if we are in the standard Euclidean geometry, then this exponent one over four should actually have been replaced by one over two. And the fact that we're seeing this exponent one over four is illustrating that we have this very big difference between our random geometry as defined by this triangulation and the standard Euclidean geometry. Euclidean geometry. So, okay, so we have this error measure mu sub n, and we have this metric or distance function d sub n, and it's possible or it is conjectured that for a large class of planet mach models, then these two observables converge to some random area measure mu and some random distance function or metric d. function of our metric d in when we send n to infinity so this is um so this is conjecture to hold in very large generality and it has been proven in in one special case so it has been proven in special case when the embedding uh is done is given by what we call the cardi Smirnov embedding so this means that the embedding is actually used by some other method than what I described on on this slide but which can also be viewed as as a discrete approximation to a conformal map and has been And has been proven in special case when the planar map is a triangulation. Okay, and I refer to the site work site at the bottom of the slide for more details. So this limiting object, it is what we call a Leewel quantum gravity surface. So what is this object? So it can be heuristically defined to be the 2D Riemannian manifold where the metric is given by the standard Euclidean. Where the metric is given by the standard Euclidean metric locally rescaled by e to the power gamma h. So here, gamma is some parameter between zero and two, and h is some variant of the Gaussian free field that I was introducing earlier. And these surfaces, they were first introduced by Pol Ekhov in the early 80s in the context of string theory. So, how can we define these surfaces more precisely? So, to do that, I still let gamma be. I still let gamma be between 0 and 2, and I let h be some Gaussian free field in a concrete domain, for example, the unit square. So then the Liouville quantum gravity surface is the surface with a metric given by this formula. So what does this mean? So it means that we are considering a surface which have an error measure, which should be given by the standard Lebesgue error measure, locally rescaled by e to the power gamma h. So e to the power gamma h should be the So, e to the power gamma h should be the density of the random measure relative to Lebesgue error measure. So, our surface should also have a boundary measure along the boundary of the unit square. So, this should be given by the standard Euclidean length measure and then locally we scale by e to the power gamma h over 2. It should also have a distance function, which is given by standard Euclidean distances locally rescaled by e to the power gamma h divided by d sub gamma. H divided by d sub gamma. Here, d sub gamma is the dimension of the surface. So the numerical value of this dimension is actually not known in generality for all values of gamma, but it's known that it is some strictly increasing function in gamma, which is strictly larger than 2. So in a special case, when gamma is equal to the square root of 8 thirds, it's known to be equal to 4, which is related to this rescaling I was doing here of, or this exponent to 1 over 4. Of or this exponent one over four that we saw here. Um, so this definition of an alcoholic surface doesn't make literal sense, um, and this is because um uh h is a distribution and not a function. And if we have a distribution, it's not obvious what each to the power of some constant times this distribution means. But it is possible to argue that this these two measures, u and nu, and this distance function or metric d, that these observables can be defined rigorously. And they can be defined rigorously via regularization of the Gaussian free field. So the idea is that we consider some smooth function, h sub epsilon, which can be viewed as some smooth approximation to h. And then we're using h of epsilon to define, for example, an error measure. And this is illustrated here. And then it's possible to argue that upon some appropriate renormalization. Upon some appropriate renormalization, this area measure is converging to some limiting area measure mu. And this is our rigorous definition of the area measure mu. And the Vandermeasure mu and the metric or distance function D can be defined by a similar regularization. So the construction of measures of this type is classical and it goes back to the 70s and 80s. The construction of metrics or distance function of this type is much, that's a much more difficult. Is much that's a much more difficult problem, and it was also resolved much more recently. So, it was the existence of the metric was proven in the works cited here at the bottom of the slide. And so, constructing the metric is much harder because, in order to find the distance between two pairs of points, one needs to optimize over all possible paths between these pair of points. So, here you can see an illustration of this random error measure associated with the Error measure associated with the L Co G surface. So, this, as mentioned on the previous slide, so this is the error measure, which should have density e to the power gamma h relative to Lebesgue error measure. So, the different colours is representing the density of this random error measure relative to Lebesgue error measure. So, these red regions correspond to high density regions where the Leewel measure is particularly. The Liouville measure is particularly large, whereas, or where the Gaussian-free field is also particularly large, whereas these dark blue regions correspond to the low-density regions where the Gaussian free field is particularly small. So, although I'm using the word density here, this is not entirely correct because the Leewel error measure is actually singular with respect to the Levague area measure. So the tuple, Myukma Nuukma D. This chapel describes the geometry of what we call a gamma LQG surface. So when we work with gamma LQG surfaces, then we want to view them as abstract surfaces that can be embedded into the complex plane in various different ways. For example, in this figure, you can see one LQG surface which has been embedded into the complex plane in two different ways. So here it has been embedded into the unit disk. Here it has been embedded into the unit disk, and here it has been embedded into this other domain U. So, we view these two surfaces as the same, because the measures and the metric in the right part of the figure is just the push forward of the measures and the metric in the left part of the figure under some conformal map file. So, as mentioned previously, these LQG surfaces describe the asymptotic behavior of random planets. Symptotic behavior of random plano maps. And we can get many different LQG surfaces by considering different planomap models. So earlier we were considering random plano maps with spherical topology and in scaling limit they converge to LQG surfaces with a spherical topology and these are defined by considering some variant of the gaps in V field on the sphere. It's also possible to consider random planar maps with the topology of a disk. Of a disk. So here you can see a random plan map with the topology of a disk where this red curve is representing the boundary of the disk. And in the scaling limit, this is converging to an L Cogee surface known as the L Cogee disk. And this is defined by considering some variant of the gas energy field in the unit disk. As we have seen, these three. Three these three random objects: the Gaussian free field, Liu quantum gravity surfaces, and the Schramm Lohm revolution. So these three random objects, they have a number of properties in common. So they're all random objects, which in some sense can be viewed as planar or two-dimensional. So in some sense, all these three objects can be defined in the plane, as living in the plane. As living in the plane. And these three objects also have a number of other properties in common. So, all three objects have intriguing conformal symmetries. And they're also having in common that they describe the asymptotic behavior of a number of discrete models. So since these three objects have so many properties in common, it's maybe not surprising that there are a number of interesting relationships and interplays between these objects. And we will be looking at some of these relationships in this. Relationships in this talk. So, I will now start the second part of the talk where we will be studying performal welding of the random surfaces introduced in the first part. So, I will start by explaining what conformal welding is. So, to do this, I let D1 and D2 be two copies of the unit disk. And I suppose that phi is a homeomorphism between the boundary of D1 and the boundary of D2. Then a corruption well. Then a conformal welding is a conformal structure of the sphere that we get when we identify the band drop D1 and the band drop D2 according to phi. So it's clear that if we glue together the boundary of D1 and the boundary of D2 according to phi, then it's clear that topologically speaking, we get sphere. And it's also clear that if we look at this sphere and we are away from this curve eta, Away from this curve eta that describes the interface between the two original disks, then we are getting. Then this sphere, if we're away from this curve, then the sphere has unique conformal structure. What is not clear is that this unique conformal structure, it also extends uniquely across this curve eta. And we can ask both about existence and uniqueness of this conformal welding. So, this conformal welding problem, it is a hard It is a hard and classical problem in analysis. And in general, both existence and uniqueness may fail. But if we have sufficient regularity of either this homeomorphism phi or of the curve eta, then this can guarantee the existence of some unique solution. So we are interested in doing performance welding in the setting of these LQG surfaces. LQG surfaces. So we want to take two LQG surfaces and we want to conformally weld them together. So I'm starting with two copies of the LQG surface known as the LQG disk, and I'm assuming we have two independent copies, except that I'm conditioning on the event that they have the same boundary length. So remember that if we have some LQG surface, then they come along with some natural boundary measure, and I'm requiring that. Measure and I'm requiring that the bander measure of these two disks is identical. And then we want to go formally weld the two disks together. And we want to do this according to this bander measure. So this means that if we have some small boundary segment of this blue disk, we want to identify it to some small boundary segment of the green disk of the same LQG length. So in the work with Ang and Sun, we argue that this We argue that this conformal welding is well defined, and we're also giving a precise description of the object that we get when doing this conformal welding. So we are arguing that when we glue together the two disks, then the surface we get is exactly the surface known as the gamma-LQG sphere. And we are arguing that the interface between the two original disks is given by an independent SOE. Independent SLE loop. So in this statement contains a number of non-trivial claims. So first of all, it's far from obvious that the sphere and the loop have exactly these laws. But the thing which is maybe the most surprising is this fact that these two objects, the sphere and the loop, are entirely independent of each other. Okay, so then the result on this described here, it builds Uh, this described here, it builds on the result described here. Uh, so here we also want to weld together two disks, but here we only want to weld together this purple curve to this purple curve. And again, we argue that this operation is well defined, and we prove that the resulting object is given by the LPG surface, known again as an LPG disk. And we argue that this disk is without the interface between the Is where the interface between the original surfaces is given by an independent SLE curve. And just as before, we have independence of the SLE and the LQG surface in the background. So this is again proven with Ang and Sun, but building on previous works. So the Croformal welding result described on the previous slide, it has an exact discrete counterpart in the setting of platinum apps. So this figure. Maps. So this figure is illustrating that we have a projection between the objects on the left and right sides of the equality. On the left side, we can have a pair of planar maps with a topology of a disk. And each planar map has two boundary points shown in red. And we are requiring that this blue curve, which is joining these two, which is the boundary curve joining the two marked points, it has the same length as this blue. As this blue boundary curve. And then on the right side of the figure, we have again a planar map with the topology of a disk with two marked boundary points. But this planar map is now decorated by some self-avoiding curve. And the projection simply works by taking these two objects and then identifying the true blue curves or gluing the two planar maps together so the two blue curves are identified. So this projection, it is an exact discrete counterpart of the Discrete counterpart of the welding result described here in the sense that the objects that you see in this direction converge to the objects that you see on this slide when the size of the planet map is going to infinity. And when proving the result on the previous slide, then we were very much inspired by this projection and also several other closely related projections. But I still want to emphasize that the proof of That the proof of this welding result was done purely in the continuum without any concrete inputs from the setting of Linux maps. So the two conformal welding results I presented so far, they are just two among a number of conformal loading results that have been proven in recent works. So, for example, the figure that you see in the top that or the top right figure that you see here, so this is illustrating the result that if one has a particular Is illustrating the result that if one has a particular surface with half-plane or topology, then one can glue together the left and right boundary arcs, and then one gets a particular whole plane, LQG surface, decorated by an independent variant of SLE, which is known as a whole plane SLE. So this is a variant of SLE connecting zero and infinity. And these other figures are illustrating some other conformal logic results, also proven in recent. Proven in recent works. So, all the conformal welding results that I presented so far, they have certain general properties in common. So, in the general setting, we are considering some LQG surface, then we are cutting it into smaller LQG surfaces by drawing one or more SLE-type curves on top of it. And then, if one has chosen these SLE-type curves appropriately, chosen these SLE type curves appropriately, then these smaller LQG surfaces will be independent of each other, conditioned on the event that their boundary lengths match up. Also, if one is given these smaller LQG surfaces and information about how they are glued together, then one can recover the original surface and the SOE curves on top of it. And it's very often the case that one has discrete counterparts in the setting of planar maps, although the proof is completely, I triggered on completely in the continuum. In the continuum. So, so far we have been considering conformal welding of surfaces, and one can also weld or make together continuum or random trees. So, the trees we will be considering are the trees known as continuum random trees. So, they can be defined by considering some Brownian excursion. And then one can, as we consider some Brownian excursions, so a Brownian motion condition to start. So, a Brownian motion condition to start and end at zero and otherwise staying positive. And then we identify two points on this Brownian excursion if they lie on the same horizontal line under the curve. So we're taking this Brownian excursion and we're squeezing it together. And one can argue that if one does this, one gets a tree. And this tree is known as a continuum, a random tree. And then in this work of Plantier, Miller, and Sheffield, they were instead of welding together. They were instead of welding together surfaces, they were welding or welding together two pairs of such continuum random trees. So they were arguing that this operation is well defined and also that what one gets when doing this is that one gets the L Cogee surface known as the L Cogee sphere. And this is decorated by a variant of SLE known as a space filling SLE. So it's a variant of SLE which is hitting every single point of the sphere. Point of the sphere. So, at first sight, this result seems very surprising. So, the first time one sees this, it seems very surprising that one can glue together these two trees and one can get something with the topology of a sphere. But it turns out that one can make rigorous sense of this operation, and this is what is done in this work along with a number of other constructions. So, this result is particularly powerful. So, the reason it's particularly powerful is because it reason it's particularly powerful is because it uh it allows or so it relates uh LQG and SLE to Brownian motion because these continuum random trees they were constructed using Brownian motion so by using this result one can formulate questions about LQG and SLE in terms of questions about Brownian motion and this this technique has turned out to be very very fruitful um so uh conformal welding uh it has Conformal welding, it has turned out to have a number of different applications to the study of both planar maps, LQG and SLE. For example, it has been used to prove convergence results of random planar maps to LQG. So it's actually the case that all conformable welding results that are currently known for random planar maps to LQG, they build on this result on this slide, which is often called the mating of trees result. What I can also use before. One can also use conformal welding to study properties of statistical physics models on planar maps. One can also use ideas from conformal welding. So it was also used to construct a metric or distance function on the LQG surface in a special case when gamma was equal to the square root of eight-thirds. It has also been used to study or to prove various integrability formulas for SLE, LPG, and Liabel CFT. By integrability results, I mean exact formulas. So the idea is that So, the idea is that in the study of SLE, in the study of LQG, and in the study of level CFT, one has a number of different tools for obtaining exact formulas. And by using performance welding and the interplay between LQG and SLE that one sees in performal welding, one can, for example, use exact formulas from level CFD to get new formulas for SLE and vice versa. And conformability has also had a number of other applications for SLE and also other. For SLE and also other objects. So, why is the chromologic so powerful? So, at a very high level, we can say that we are so powerful because we can exploit this interplay between LQG and SLE, and because one can study very complicated surfaces by decomposing them into smaller, independent, and sometimes easier to study pieces. So, in the remaining time, we will be considering two examples. Two examples. So, first, we will be considering an example of the self-avoiding loop on random planet maps, and also the example of random permutations. So, we studied earlier, I presented a conjecture which was saying that a uniformly sampled self-avoiding path, it should converge to the SLE with parameter 8 over 3 in the scaling limit. So, earlier we considered a version of this problem where the length of the A version of this problem where the length of the path is fixed. One can also formulate some random length version of this problem. So, this is what I've done here. So, if we have some self-avoiding path connecting plus minus i, then we give it a weight, which is equal to mu to the power minus the length of the path. And or by length, I mean the number of steps if you view it as a path on the lattice. And here And here, Î¼ is a constant known as the connective constant of the lattice. So, the numerical value of this constant is actually not known, but it's a constant such that mu to the power m is an approximation for the number of length m paths on this lattice. Okay, so we consider with sample a self-voiling walk according to these weights. So, the probability of packing a particular self-voiling path is proportional to this weight assigned by this formula. Then it is believed that if we Then it is believed that if we sample a self-avoiding curve as described here according to these weights, then it converges in the scaling limit to the SLE with kappa equal to 8 over 3. So we can also formulate the loop version of this conjecture. So here we have a self-worlding loop, we give it weight equal to mu to the power minus the length of the loop, and it is believed that this And it is believed that this converges to the SLE, to the SLE loop, as I presented earlier, with kappa equals 8 over 3. So the two conjectures on the previous slide, they are hard open problems, but they can be established in the setting of planar maps. So suppose that you have some planar map with a topology. Planar map with a topology of the sphere, and you have some self-avoiding loop on this planar map. So, again, then I give it a weight equal to 12 to the power minus the number of faces of the map times 54 to the power minus the length of the loop. So, this number 54 here is playing a similar role as this mu on this slide. So, then we're sampling such a loop-decorated planar map or According to these weights. And then we argue that it converges to the LQG sphere with the SLE loop in the scalar map. So in particular, we're getting that this self-avoiding loop, it converges to the SLE 8 thirds loop. So it can be viewed as a planar map version of the conjecture described on this slide. So here I described the group version of this result, but I should remark that. Result, but I should remark that earlier cordal results were established by Gwyn and Miller and also later work together with my collaborators. So the proof is building on the conformal loading result, disk plus disk equals sphere plus a silly loop, a discrete counterpart in the setting of planar maps, and also some important technical inputs from Brown and from this earlier work of Gwynne and Miller. Of Gwynne and Anne Miller. So that was an application to the self-avoiding work on Polanomax. So I will now be presenting an application of performance welding to the study of random permutations. So to describe what we prove, I first need to define what a permutal is. So permutal, it is a probability measure in the unit square with uniform marginals. Marginals. And permutons, they are of interest because they can be used to describe the scaling limit of permutations. If you have some permutation, then it defines a permutant. So this is illustrated in the figure. So here we are considering the permutation given by 23871456. So and in the figure, we're seeing an illustration of this permutation. So the different boxes. Boxes. So each element of the permutation corresponds to each of these orange boxes. For example, we have an orange box here at height 2 because the first element of the permutation is 2. Then we have a box at height 3 because the second element of the permutation is 3 and so on. So then we have the permuton associated with this permutation, it is the measure in the unit square, which has density 8. Which has density 8 inside these orange squares, and otherwise it has density 0. And we see that, so this choice of 8 is made because it guarantees that the marginals of the measure are uniform. So if we have some sequence of permutations, then we say that they converge to some limiting permuton if the associated permutons converge weakly. So we consider we will consider So, we will be considering a particular variant of permutations known as Baxter permutations. So, Baxter permutation is a Baxter permutation if one cannot find i, j, and k such that one of these chains of inequalities is satisfied. For example, this permutation is not a Baxter permutation because these four red boxes are violating this first chain of inequalities. Inequalities. So these Baxter permutations were introduced by Baxter about 60 years ago, and they have later been studied in numerous different works, both in combinatorics and in probability. So Tori said that these Baxter permutations, they have interesting relationships with a number of other combinatorial objects, such as tiling models and planar maps. And it was proven in the work of Borga and Mazzoon that uniformly sampled backstory. Uniformly sampled Baxter permutations, they converge to some limiting random permuton, which they call the Baxter permuton. So here you can see simulations of the Baxter permuton due to Jacobo Borga. Okay, sorry. So in a work with Borga and you, we are establishing your preview formula for the density or the expected density. For the density or the expected density of the Baxter-Permuton. So, the Baxter-Permuton is some random error measure in a unit square. We can consider the expectation of this random error measure, and we can consider the density of this expectation. And we argue that it's given via this formula. So, here, a row is given via this formula, and you can see a plot of the density here. So, our proof is building on ideas from conformal welding of LQG surfaces. So, the first question you might have is why are these random permutations related at all to these LQG surfaces? And the reason is that there is a particular stochastic differential equation which one uses to define the Baxter permuton, which is also arising in the study of LQG surfaces. So, to remove. So, to be more precise, if one considers a solution of this particular stochastic differential equation, then it defines an instance of the Baxter Permuton, and it also defines a particular LQG sphere decorated by four SLV-type curves. And this object can be expressed as the conformal welding of four LQG disks. So, then it turns out that this density that we're interested in. It turns out that this density that we're interested in computing corresponds to some geometric observable on the LQG side, which is which is possible to access via LQG techniques. To be more precise, the identity in the identity equation is holding. So on the left-hand side here, if we vary these intervals I1 and I2, then this is characterizing this density that we want to find. Whereas on the right-hand side, we have some probability which involves the LPD surfaces. So A1, A2, A3, and A4. So, A1, A2, A3, and A4, they are representing the LQG areas of these four disks. And then it turns out that each of these four LQG disks, they can be encoded via Brownian motion by using this mating of trees construction of LQG. And then by using various computations for Brownian motion, one is able to access this probability. This probability involving the alcohol areas of these alcohol disks. So we are computing this right-hand side by using certain estimates on random motion and it turns out that we also are using some exact formulas from Leo Bolsietti, which are also used to describe this. Which I also use to describe this surface. So, yeah, thanks for the attention. Thank you very much, Nina. Yeah, thanks. Do we have any questions from the market? You mentioned in passing a conformal pseudo-phrase. form or switched phrase.