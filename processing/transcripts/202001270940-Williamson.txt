Can you see it now? Great, yeah. So thanks for inviting me. It's good to have a chance to see some snow before like winter is over. I guess I'm the first person to talk about fractons, so that's a bit of an honor at this conference. I don't know if I'm the correct person. But I'm going to give sort of a very biased history, an overview, biased towards my own work. And maybe I should just call it a summary of my own work and some history of some things leading up to it. Some things leading up to it, and then at the end, give you some suggestion of things that we're trying to finish at the moment, which follow on from this. And unfortunately, I think I won't have time to talk about some other important topics in fractons, which is basically like the sort of tensor gauge theory side of things. But I think Mike will cover a bit of this later. So, yeah, in this talk, I'll just talk about having fun with lattice models basically. And then maybe Mike will talk a bit more about gauge theory and sort of reality. A bit more about gauge theory and sort of reality, and hopefully, there's a bit of fun in his talk, but there won't be much reality in my talk. Okay, great. So, also, it's good to go after Zhang Wong's. I think he gave a nice, crisp definition of what a phase of matter and the symmetry-projected phase of matter is, so I'm just going to rely on that. And let's talk about like something that motivates a lot of us who think about lattice models, which is basically to try and classify all gapped phases of matter that are topologically stable, which basically means that there is no There is no operator that could split any degeneracy that would have on any closed manifold, basically. That's local. So if it's like local in space, it can't be degeneracy. Okay, and then we can ask about classifying such phases. And in 1D, it turns out, yes, some smart people worked out. There's basically nothing. Okay, so that's boring. In 2D, there's a nice rich story, but I think at a physics level, it's kind of worked out. Although there's probably some mathematical questions still open there to rigorously prove things. But basically, we expect Prove things, but basically, we expect that these phases are one-to-one with some kind of theory of anions, and then the mathematical theory of anions, it's like a modular tensor category, and then up to some kind of gapless edge stuff coming from invertible topological phases. This is basically what we believe is everything. Okay, so that's nice, but what is there to do there? So then let's go to 3D. And this is where it starts to get a bit less nice. So immediately you recognize that a stack of 2D things counts as a topological order. Things count as a topological order in a 3D. So this is bad. This means that our 3D classification contains all this boring stuff, it's just a stack of 2D things. So people realized this a while ago and wanted to get rid of it. And so they came up with this clever idea to put another condition on the topological order and classify these things. So they wanted to call these guys gapped quantum liquids. And liquid is kind of because you can take this, the definition is you can take this topological order and some basically some region. Basically, some region, you can tensor on some trivial stuff, it's like sort of empty, and then you can do some local unitary equivalence and just grow the topological order. So something satisfies this definition, it's kind of TQFT-like in a sense, it's sort of deformable, you imagine. And then this immediately cancels out this stack of 2D topological order, silly example that you could have in 3D. So then you think, all right, cool. Now I can try and classify these things, these topological quantum liquids. These topological quantum liquids. And I think there's some nice progress on that. So basically, because in 3D, if you have these kinds of things, you expect all the particles to be mobile, you only have point particles and some loop excitations. The points have to be bosons or fermions because they're fully mobile. You can then basically condense all of the point particles and just classify the sort of, if you imagine you can condense all of them with just some anomaly vanishing condition. You can then just classify what kind of gap boundaries of vacuum you get by doing that. And it sort of turns out to be possible to do this, and they end up being some. out to be possible to do this and they end up being some kind of generalized fermionic gauge theories with some copyclists. So that's sort of a nice argument and it seems like at least a sketch level this has done to 3D classification. Okay so should we go home? Like why are we having this conference? And the reason is because that's not everything. Okay. This guy came along actually out of historical order but kind of crushed this picture before it was even done and said alright is this Before it was even done, and said, All right, there's this thing that is not just this stack of 2D topological orders, which is quite interesting. And it sort of has this weird glossy behavior. So just one property is that the ground space degeneracy is somehow like the greatest common denominator of the various lengths of the cube. So it can have some crazy fluctuations. You can look at the excitations in this model, and basically the elementary excitation is a cluster of four. You can see that by doing this a bit, you can. You can see that by doing this a bit, you can move a pair of them in like a line. Yeah, and you can sort of continue to spread it out. So a single excitation can be isolated, so it is sort of like legitimate to talk about a single excitation on its own. And it turns out that, yeah, the single excitation can't move, just now what we call a fracton. The pair can move in like a line, which is a line on, and then you can make sort of a higher composite of a couple of them that can move in a plane, but it's hard to draw, so I didn't draw it. And that's a planon. And this is kind of canonical. And this is kind of canonical of what we call like type 1 sort of foliated fracton phases now. So, I think this example is really showing you that something that's not a stack, so it wasn't really fair to say that everything that's not a topological quantum liquid is boring. And it is sort of an interesting question that challenges the classification of phases to also try and classify these things. Okay. Great. Okay, so what came next? What came next? So, the next surprise, I think, to people was due to Joe Wan. And I guess people in quantum information at the time were interested in this kind of question of having a self-correcting quantum memory. But let me just sort of condense that down to saying they kind of wanted to find a model where to cause a logical operator to happen via some local process, you wanted to have a big energy penalty. So it's a bit more subtle than that, but that's all I'm going to go into. So we knew in 4D that 4D Torah code with only loop excitations would be like quite a good Loop excitations would be like quite a good self-correcting quantum memory because you have to pull this loop over the whole system. So you get sort of a sub-linear energy barrier to this process happening, which will really suppress this when you couple it to a thermal environment. And then if you work it out more carefully, it turns out that there's actually, it'll preserve quantum information for a long time in the size of the system. Or in some sense, it has a stable topological phase of finite temperature. And so then you could ask the And so then you could ask the question: okay, if we believe there's things beyond normal topological orders in 3D, which will always have these string operators that kind of kill you in this game because they have no energy penalty, because you just create a single excitation or pair, and now there's no extra energy penalty to just pull this around the system. So when you sort of couple this to a thermal environment, this process can happen very quickly and it sort of kills your quantum information at like a finite time. So it's a very bad self-correcting quantum memory. But because we had this sort of open question, or this, you know. Sort of open question, or this suggestion there could be things beyond TQFDs and 3D, it was sort of reasonable to ask: can we find a model? It's kind of crazy and glassy, but has no string operators. So we saw in Shimon's model there were still string operators. So it's not very useful as a self-correcting quantum memory. And then via sort of, well, I think a brute force search over some reasonable models, Jung-wong was able to find a whole bunch of models, and then a few of them, I think four or so, ended up having no string operator, which is quite surprising. Which is quite surprising. I think nothing like this existed before in topological order. And the way the local excitations work is that there's some kind of like fractal operator that sort of grows them. So you create them in a small cluster, but then the cluster doesn't move in a linear fashion. You can only sort of separate it out with a small sort of tetrahedra. And then if you want to grow it to the next sort of lattice size, you need a stacked four of these tetrahedra and so on. You can kind of separate them out as far as you want. So a single excitation is legitimate to talk about on its own. To talk about on its own. But to actually move these things around, you need these fractal operators. And then it turns out John actually showed that there was sort of a logarithmic energy penalty if you wanted to move this over the whole system with local moves. Okay. You're doing a historical review. Yeah, a little bit. Many of these ideas existed before in classical models. Indeed, that's right. That's right. And much of the things that you're seeing. And much of the things that you're saying are essentially classical arguments. I agree. Creating these excitations, the logarithmic barriers, and so on. I agree. I think it wasn't, that's all true and motivated these works, but it wasn't clear if you could have a topological order with these properties that were coming from like a very non-topological classical thing. And maybe it's surprising that exists. But I did completely skip over all the. A lot of the math and the models are based on these classical models, which is true. Okay, great. And then, yeah. Okay, great. And then, yeah, it's somewhat similar to those models, you have sort of a crazy ground space degeneracy, but here it's sort of all stable, which is sort of interesting. And then, unlike usual T curve Ts, you can have these big jumps where you just change the system size by one, and something goes from like an exponential ground space degeneracy, exponential in the linear system extent, down to a constant. So, this is sort of crazy. Oh, yeah, and you had a reference you didn't mention. So, what's the reference Kim as about? Oh, okay. I just put Kim in there because there actually were. Yeah, I just put Kim in there because there actually were, just a bit after John Wong's works, there were some other no-string models which are a bit more complicated, so I haven't talked about them. And it turns out, okay, just as an aside, these things ended up not being quite self-correcting, but this kind of, in some ways, a bit interesting and more subtle partial self-correction, because it turns out the energy barrier, I guess, wasn't quite enough to make them self-correcting. So some competition between energy and entropy, and they sort of are sort of self-correcting up to a big enough system size, and then entropy wins. And if you make it bigger, it stops being. Entropy wins, and if you make it bigger, it stops being sort of self-correcting vaguely. Okay, but we don't want to go too much into that, that's another talk. Great, so maybe the next thing that happened was that Yoshida took sort of the idea of these sort of classical instructions where you could use a cellular automata to make a whole bunch of different models, and then found a way of stitching two of these things together to make a quantum model that would have topological order. And so, this gave you like a real infinite family of models. So, then I think it started to make, started to be like a real. Started to make, started to be like a relevant question about thinking about how you can classify these or organize them into families. And then, yeah, in this family of models, you have these two polynomials over Z2, say for qubits, and then they determine the properties of the model. So one determines how one sort of particle hopping operator goes, and the other one determines the other one in the other life splane. Great. And then, okay, in this kind of historic progression, I think there was one more work that was quite interesting before. One more work that was quite interesting before the kind of modern models where we started calling them fractons, which was this also work by Zhang Wan, where he looked at renormalizing these. So Yashida also looked a bit at this, but maybe in a bit less of a careful way. Zhang Wan looked at this with this intangible renormalization. So if you want to think of some way of classifying phases, you could try and do some renormalization process that guides them to fixed points, and then you could classify the fixed points. And hopefully, in one fixed point per phase, that would be a nice way to classify things. That would be a nice way to classify things. But here, if you and when you do this renormalization, you want to keep yourself in the same phase, such that when you land at this fixed point, you're in the same phase you started with. So that's where this entanglement renormalization comes in, where you only do local unitaries, which are an allowed transformation. You can do some coarse graining, which really is just redefining the lattice. And then you can throw away stuff that's totally disentangled, which is also allowed in phasic at once. Okay. And it turned out if you did this for the And it turned out if you did this for the qubit code, you would get this kind of bifurcating behavior. So, here my diagram means that when you do one step of this renormalization, you follow all the errors. So, from this qubit code, you follow the error to some other model, cubic code B, which is shown here, and you follow the error back to itself. So, basically, it bifurcates into a copy of itself at a different scale, and this cubic code B. And then if you continue to renormalize this cubic code B, it bifurcates into two copies of itself. So, you kind of get this tree of different models at increasing length scale. At increasing length scale. So this makes it kind of confusing, like, you know, how would you classify phases by fixed points? Because they kind of don't have fixed points, they have these weird bifurcating fixed points. Okay. Then I think there was a period of harbor nation over nickel. So I'll have to do some other stuff. Okay. Maybe for a year or two. But then, okay, this is a very good, like, there was some spring came around, like, 2015 or 16, and Ha came out of this cave, and with him was Saga. out of this cave and with him the saga. I didn't want to put the angfus, but there's an LCKC you didn't like it. But you guys are. And okay, in spring, like a new model had blossomed. Although I think actually this model appeared in some appendix buried in one of Shimon's paper in a very hard to understand way, but you know, that wasn't the point. I think these guys really understood this model. And it's like the model that launched like a thousand research projects or whatever, if you like, because it's a great model. And it's called the XQ model. This one, It's called the XQ model. This one, the way I'm drawing it, there's one qubit per face of a cubic lattice. We have this like X stabilizer term, which is a 12 body. So everywhere I've drawn a color, there's like a sigma x tensor 12 around some vertex. And then you have these like sort of sigma z terms around faces of a cube. So all the faces that are not, that are sort of parallel to a certain direction, you have a term. And then, so here's the term in like the x direction, and here's one in like the z direction. Great. Great. And those on every cube and every vertex generates all the terms, the Hamiltonian. And this one had sort of a nicer but still different for TQFT ground space degeneracy that couldn't be a stack of toric codes. So it's interesting. Oh yeah, and I want to say one other thing about this model. The one bit of reality I'll say is that at least for this model, there were some proposals how to make this with a more realistic Hamiltonian than this crazy 12-body thing, which I think is an important direction. Okay, and then most people probably know this model, so I just lightning. People probably know this model, so I'll just lightning review the excitations. So, in one sector, we have these fracton excitations. So, you can separate them at the corners of some square membrane, and then it can't move without creating more excitations if you have a single one. But if you pair them up, they can move in some along a lattice direction, they can move in a plane that's orthogonal to that. If you pair them up not along a lattice direction, it's like a composite of two of these and it can only move in a line. Great, so that's like a fractal sector. And then we have this other sector, which is sort of not dual to the fracton sector, which has these. To the fracton sector, which has these fundamental excitations that can move along lines. So an excitation is going to be some combination of excitation of both of these things. And then I colour them according to which direction I can move in. So basically, they can only move along a line unless they create a further excitation at the corner where they turn. Or you can create, in other words, you can create three of them at a corner, basically. They can move along different directions. Cool. And I think maybe the Maybe the one development I really liked was thinking about these things, to sort of put these in context of things we know, is thinking about these at lattice gauge theories. So from before, they seem maybe just completely different to the other topological orders we knew. But there's this story about one way of thinking about topological order, at least gauge theory, like lattice gauge theory topological order, where you start with some symmetric model, maybe like just a global symmetry, you do spin flip everywhere, and then you do this duality map called gauging the symmetry, where you sort of introduce gauge fit. Gauging the symmetry, where you sort of introduce gauge fields, like discrete gauge fields, and then you couple them to the matter fields you had, and you project onto the gauge invariant subspace. And if you started in like the trivial phase, you'll end up in a topological phase, basically. And it turned out that in these models, you just had to start from a much more complicated symmetric model. But a similar story still held. So in the case of the X cube, you had to start from this model that had planar symmetry. So it was like an Ising model of these Plake terms, which probably appeared previously. Terms, which probably appeared previously. But in this context, you think of the planar symmetries, and then you sort of do this duality to gauge them, and you find this lattice gauge theory where this is now like the gauge transformation, and these are like the gauge flux constraints. And it turned out that picture also worked for these sort of fractal models. So you just had to start from a slightly weirderizing model. It had this kind of fractal symmetries, which are hard to draw really, so does the cartoon. And then if you did this Gaussian transformation, you'd find Haas code, all these other type 2 models. Models. So, one interesting thing this brought up was that in this classification of phases with symmetry, you can have these symmetry-protected phases. So, here, immediately, you can see, well you can imagine like maybe there could be under these strange symmetries which I'll call subsystem symmetries that act on some sub-partisal lattice, you can imagine can there be SPT phases? And it turns out the answer is yes, actually, and there's in some sense too many of them, because you kind of can also have this problem of stacking lower-dimensional stuff. But there's a nice Dimensional stuff. But there's a nice connection to some previous work on measurement-based quantum computation. So, in some sense, previous results showing that the cluster state phase, various cluster state phases intuitively were like universal resources that were robust, had a nice phrasing in terms of these phases. So if you only do perturbations that respect the symmetries of these phases, then your resource state will stay a good resource state for measurement-based quantum computation, which is some scheme for quantum computation if you're not familiar with it. You just sort of pair a state. If you're not familiar with it, you just sort of pair a state, and then you measure everything, and that will do the quantum computation you want. And you sort of end up with one row that has the result of it that you like, desire. Okay, great. So you can actually kind of classify these phases after quotienting out by lower dimensional phases. And the way to do that is you just introduce, or one way to do that, which I like, is you introduce this new equivalence relation where instead of having gates that locally commute with the symmetry being your equivalence relation, you will With the symmetry being your equivalence relation, you allow gates that sort of might span the system in one direction. So if you span the system in both directions, you could just trivialize everything. But you allow gates that span the system in one direction and commute with the symmetry as a whole, not locally. But these gates that span the system still have to be a local unitary. The local pieces don't have to commute with the symmetry. And if you do the classification with respect to these things, you get a finite answer, rather than having this whole bunch of choices about how you stack low-dimensional things. And also, it's important. Dimensional things. And also, it's in terms of cohomology, which is familiar from sort of two, from 1D SPTs in this case. Right. No, too far. And I think another nice, well, also maybe not nice surprise from these phases that I really didn't expect was that they can give some contribution to the topological entanglement entropy, even when you calculate it with the Katai-Prescal 11-Wen scheme. So if you're a If your regions that you use to calculate the topological entanglement entropy, which is like this linear, I mean, sorry, this constant correction to the linear scaling of topological entanglement entropy of 2D. There was a sort of clever schemes to distill this without having possible corner corrections and other things that might come from the lattice. And the idea was this should always give you the right answer, basically. And sort of, there were some previous works finding that on cylinders and so on, you might get the wrong answer, but you could sort of attribute. The wrong answer, but you could sort of attribute that to being that you didn't do the calculation carefully enough because you're sort of using some scaling with the L to abstract the constant term. But here, this thing was really meant to, as long as these regions were big enough, give you the correct answer. But it turns out that if these regions basically are aligned along the directions of these subsystem symmetries, you can really get the wrong answer for arbitrarily big regions. And this will persist throughout the world. This will persist throughout these subsystem symmetry protected phases. You can also have these phases for this kind of more crazy fractal symmetries. And then, just briefly, these also could be measurement-based quantum computing universals throughout the phase. And there is a classification by Trithop where you introduce like a distance cutoff, and then you have a finite number of phases in this distance cutoff. Okay, great. Okay, so back to the fracton phases. To the fracton phases, though. I think I want to talk a little bit about characterizing them or how you would actually detect these things, or if you have some model given to you, say even in the computer, how you see what phase it's in, and then also classifying the phases. But first, let me say about characterizing them. So I think some of the first work done on this was looking at some kind of topological entanglement entropy correction. So in the usual TQFT in 3D, you expect still like a constant correction, I think, to the area loss scaling of entanglement entropy. Scaling of entanglement entropy. But for these fractile models, you would get some kind of a linear correction. And I think it appeared a little bit differently for the type 1 and type 2 models. Okay. But I think one problem, so all of these things I'm going to mention have some problem. One problem with this is that from SPTs, subsystem SPTs in 3D, you can actually also get very similar corrections. So if you had some case where someone tried to fool you and handed you a subsystem SPT, if you only did this, you might Subsystem SPT. If you only did this, you might be fooled and think it's a fractal model. So another thing you can do, which can definitely show you something sort of that something crazy is going on, is look at the ground space degeneracy. But sort of the problem with this is that you have to pick some extra information that's really beyond just the bulk of the phase, like some boundary conditions. And then depending on them, you could get very different answers. And so you really need to collect all possible ground space degeneracies to be able to tell something, I think. So that's sort of a hard thing to deal with. One slightly easier. To deal with. One slightly easier thing is looking at the compactification. So this only picks like one direction, and then you make that one periodic. So you don't have to fully close the boundary conditions. But this works especially nice about type 2 models. Because type 2 models have no string operators, when you do this compactification, they become a topological order in 2D. So I now treat this circle I've compactified upon as like being sort of small, and I allow operators that wind around it and treat it as a 2D model. And then for the And for the sort of simple Pali stabilizer models, there's even like a rigorous theorem showing that these translation invariant models are local unitary, or locality-preserving unitarily related to some number of stacks of toric code, basically, in 2D. So all you need to do is count the number of toric codes you have there, and this will give you like a coarser invariant than this ground space degeneracy. But this still has the problem that you did have to pick this one lattice direction, though not three, n length, not three. Okay, so what we want is. Okay, so what we want is something really truly in the bulk, like the topological tangential entropy, but that doesn't get fooled by these SPTs. And really, ideally, it would actually give us some number that we could then use to say which phase our thing came from. We're definitely not at that point, but looking at some generalization of like the S matrix in 2D. So in 2D, you have this S matrix invariant, which is like you look at the braiding of two string operators, and that thing can tell you a lot. So for this sort of simple Paris stabilizer models, it actually. Sort of simple PALI stabilizer models, it actually tells you everything. It'll tell you how many toro codes you have, which is the invariant, the complete invariant. So we've looked at generalizing this to 3D. So the sort of TQFT way is by having some sort of string operator with excitation at the endpoint, sparading with some membrane operator with a loop-like excitation around it. But we could also look at some other kind of 2D-inspired thing where we have these sort of square regions that have one closed base. Square regions that have one closed boundary where no excitation is, and then another open boundary where there aren't excitations allowed. And look at the braiding of these sort of square operators with excitations along only two of their sides. And this is well defined, because along these sides, there are no excitations. And so where they cross, there's not going to be any excitations near the crossing. Okay, so maybe I should tell the results, well, first at a high level. So this one basically tells you if you have some choice about how many directions the string operator goes in, but if you pick all three different directions. Goes in, but if you pick all three different directions, it tells you how many like 3D particles you have. So if it was like purely a TQFT, we think that basically tells you how many torrent codes you have. Although there's a subtlety of you can have a torrent code with fermionic particle or bosonic particle in 3D. It doesn't tell you that, but you can introduce a further quantity from some paper of Levin and Wen that will tell you that. Then the second quantity basically should always be zero for a TQFT, like a topological quantum liquid phase. So if you get a non-zero result of this, it already tells you. So, if you get a non-zero result of this, it already tells you you have at least some fractal stuff going on. And then, by looking at the scaling of this term, so unfortunately, this one is not really like an invariant, because it depends on the exact size and everything and orientation. Whereas the first one is an invariant, because it's sort of topological, makes sense. But by looking at the scaling of this thing, you don't get fooled by these sort of entanglement entropy corrections from SSPTs. And the different, by using the scale. The scalings of these two quantities together with the information about which pair creation operators are deformable, which you can kind of work out based on the Hamiltonian you're given, we could sort at least coarsely some stabilizer models given to us, some simple class of fractal models, into being some various types. So this type 1 means that there basically is a string operator, but it's not a TQFT type. This TQFT type, okay, that's going to be like a topological quantum liquid. And then we divided type 1 into this. And then we divided type 1 into this foliated type 1, which means everything is kind of organized into planes. And if you pair stuff up, you can kind of move along lines and planes. And this fractal type, so there can be things that have string operators, but also this kind of fractal motion, where some hopping operators are of this fractal shape. Then you can have this fully type 2, which means that there's no string operators, and I think everything has to be sort of fractally for that to make sense. Right. And so by using these quantities together, you can at least sort things at this cost level. You can at least sort things at this cost level, but okay, that's still a long way to go to actually being able to have some invariant that's going to tell you which phase your model comes from. And this so far pretty much just talking about like these very simple powerly stabilizer commuting projector models. So I think there's still maybe, maybe it's just impossible, but if you wanted to really have a characterization of these with invariance, there's a lot of work to do still. Okay. Let's move on to thinking about some more high-level classification. So I'll come back to this. So I'll come back to this tagment normalization. So to get some idea of how we should define these phases or think about how to organize the phases, let's look at, we looked basically at the integral and normalization of all of Haas qubit codes and also these like fractal spin liquids in this more careful way, of any. And we found basically that everything of these simple models had this pattern in common. In common. Also, it has this in common with XQ from some earlier work of Will Bershaire and Evan. So basically, if you do this integral normalization after some pre-core screening on any of these models, the simple examples, it flows back to itself and then to some number of these B models. And these B models then self-bifurcate, basically going back to themselves some number of times. So you get this kind of tree where one branch is kind of, there's possibly one branch that's not going back to it, that's only going back to itself once, and then producing the Only going back to itself once, and then producing these other branches that all just kind of reproduce themselves a number of times. So, this kind of inspires you to say, all right, maybe there's some generalized notion of fixed point. Well, we did propose this, that you just want to throw away all this stuff that's like self-reproducing. Because basically, if you just kind of coarse create a whole lot, you're going to have like an infinite number of copies of this stuff. So, if those things are not, I mean, they are non-trivial as topological phases, but if we call them non-trivial, then it's gonna just be basically impossible. It's gonna just be basically impossible to classify stuff by fixed points, because you're always gonna have just more and more of these things popping up. Okay. So, yes. The first work in this direction, I think, was by Cher, Wilbur, and Kevin, which was looking at this for like the X cube and X cube type phases. And I think they had a lot of success with this. So, in that case, it's kind of more clear that this is a good idea, I think. So, there, you have a more, we want to have like a bit more of a subtler version of this. We want to have a bit more of a subtler version of this topological quantum liquid thing to rule out basically the stack as being a non-trivial phase. So we want to introduce a definition where the stack is trivial. And it's motivated by the RG of the x-cube. So if you do this RG of the x-cube, the B model is just a stack of this Tori code layers. And then a stack of these layers just self-reproduces because when you change the scale, you'll have two layers per unit cell. So you just split one, you know, half off into one system, half into the other system, and you have two copies of the original system. Have two copies of the original system at a coarser grained scale in a sort of trivial way. So, yeah, they introduced this definition that instead of just local unit equivalence, let's do a coarser equivalence on these topological phases, where we also allow stacking of Tori codes. And they call this foliated phase equivalence, which also has important connections to thinking about putting these models on different lattices. So I think there's some connection between the IG flow and what structure on a lattice beyond. Beyond, say, lattice structure, you need to define these models. Because everything I've talked about so far was basically defined on just a cubic lattice. Okay. So with this definition, they found x cubed is basically a fixed point, and that a whole bunch of other models ended up being equivalent to x cubed with this sentence. So to generalize this, we basically said, okay, let's do something more crazy and just say instead of just this layers of Torah code, any cell This layers of toric code, any self-bifurcating model. Let's say, like, maybe the classification of self-bifurcating fixed points is like the initial problem. And then we want to quotient out by all those and think about these quotient fixed points which are left over after you get rid of all of those. And with this, okay, the examples we looked at, basically only a few models end up being sort of fixed points that most models actually seem to be self-bifaking of what we looked at. So the Qubicode 1 was not self-bifaking as. One was not self-plicating as found by Ha. And then out of all the other qubit codes, only this sort of 11 to 17, not including 14, were not self-plifating. And this idea also gives you like a nice invariant for these quotient phases. So this is like coarser than a normal topological invariant. And what you do basically is say any excitation, so the super selection sectors is some invariant of topological phase. They give you some algebra. Phase, they give you some algebra. And in this equivalence, you want to say that basically you take the super selection sectors, okay, but now the problem is there's an infinite number of those in these fractal models, because when you move a charge, it's in a different super selection sector. And then you quotient out by anything that flows into these self-bifurcating models that we're throwing away. And that gives you actually a finite algebra at the end. And so, yes, previously it was worked out for x cube. And then it turns out in these models, the cubic codes, it ends up being quite simple. It's just like the z2, and then by some to value, it's z2 in the other sector as well. In the other sector as well. So, in some sense, we have this very coarse equivalence relation and some invariance there. But is this actually a reasonable way to classify phases? I mean, maybe to first approximation, but yeah, you are throwing away like a lot when you throw away these self-bifecating models because they're almost as complicated as the non-self-bifecading ones, really. What is QSS? Quotient super selection sector. Sorry. Yeah, if I have five minutes, what do I want to do? Yeah, if I have five minutes, what do I want to talk about? So, let me briefly say: okay, going beyond these simple models, there were some early ideas about how you would get x cubed by coupling layers. So, basically, you condense these kind of composite particles over many layers, and this is some way of getting x cubed. I don't want to go into much detail, but this gave you a nice route towards actually having some more complicated non-abelian fractals. So, instead of x cube layers, you could generalize this to having say like double eyesing layers. This is to have let's say like doubleizing layers. And in this way, you could get like these sort of wave functions that have non-abelian lineons, and through a different generalization, also non-abelian fractons. Okay, there has also been some other idea about how to get non-abelian fractons by taking this sort of bilayer with swap symmetry and then projecting onto the symmetric subspace, like gauging this symmetry. This basically takes any particle that gets permuted between the two, sorry, any pair of particles. Sorry, any pair of particles that's symmetric under. Sorry, no, yes. You want particles that get permuted by this symmetry. And then when you gauge this, it kind of coalesces into a single non-abelian particle. So this is some route to give you, so we can really turn like even a type 2 particle into a fracton. The price you have to pay, though, is that if you started with this type 2 model with no strings, when you gauge this global symmetry, you introduce a gauge charge, which is going to be a 3D particle. So you don't actually get a type 2 model anymore. Although you can turn something that was a type 2 excitation into a fracton. Type 2 excitation into a fracton, a non-abelian fracton. Sorry. So this, I think, points to one question that's sort of interested in, which is still open, which is like making really a non-abelian type 2 model with no sort of string excitations. And now, let me just skip to, right, there are some, in ongoing work, there are some further, more crazy coupled layer constructions inspired by some interesting work of Albin. Okay, great. Okay, great. And then we actually have some extension of an idea of saga, which basically lets you, the upshot is you can make anything that could be a symmetry defect in 2D basically, of an abelian symmetry, can become a fracton. So at this point, we can really just make like whatever crazy like type 1 fracton you want. We can make all these crazy models from gauging global symmetry that could have more fractally non-abelian particles. And there's even this sort of super general string membrane. There's even this sort of super general string membrane picture where we couple some graded 3D model to some graded 2D layers, which contains all the previous things I said. So at this point, when we go beyond these stabilizer models, which there already was some difficulty in classifying things, it seems like basically anything can happen. So that's bad for classification. But this is the idea I just wanted to get to, to finish on, which I think if you want to have details of this, go to Kevin's talk and Danny's talk later in the week. You'll talk today, right, Kevin? The week. You'll talk today, right, Kevin? So, Kevin will explain this in more detail this afternoon. But basically, there's some idea for hopefully classification, but at least iterating hopefully all possible fracton models, which is that you actually start within a TQFT, and then following some work of like this crystalline sort of defect crystal SPTs and SETs, we make a network of defects that are actually non-invertible. And then by doing this, And by doing this, you have some limited list of choices of things we actually know, which is like there's going to be some TQFTs in this 3D bit, it's going to be some topological defects on this 2D bit, there's going to be some topological junctions on the 1D bit, and then some topological point excitation on the 0D bit. You can really enumerate everything, even though it's sort of a lot of data. And then hopefully, this will give it a route actually towards classifying fracton phases. And to show the promise of this construction, I think Kevin will cover how you can make X cube and sort of a non-abelian D4 generalization. And sort of a non-abelian D4 generalization of X cube from this. And Danny will actually cover how you can make a type 2 model out of this. Great. So hopefully, if that's interesting to people, you can go to their talks. Am I into question time now? Okay, great. Let me say one last thing, which is basically, I'll just skip over this, but in terms of actually this being useful to classify stuff, I think in 2D basically, if you believe that this gives you all fracton models, this gives you a reason why there's no gap to 2D fracton models. No gapped 2D fracton models. Or at least there's none of these non-trivial topological defect missiles in 2D. And it's a pretty simple reason is because if you want your 2D model to be topological, then you need that these domain walls are fully gapped to vacuum, otherwise some particle can pass through them basically. So you have this picture, and now you're just choosing these points, these point defects. But if you have some excitation that doesn't condense on either of these walls, That doesn't condense on either of these walls near this point, and you want to sort of pick which patterns of these condense to make your model, basically, there should be some modularity if this thing doesn't condense, such that you should be able to measure this with some operator that goes from one boundary to the other. And near the corner, this operator is local. And then, so basically, whatever pattern you pick, when you start building up these large operators that hop your fractons around, it's going to be some local operator that anti-commutes with them, which violates the topological order condition. So, basically, this is like saying all fractony things in 2D of symmetry. Saying all fractony things in 2D are symmetry breaking, spontaneous symmetry breaking. Great. So I think this sort of shows some promise of this defect approach for classifying phases. I'll leave it there, thanks. We've got a couple minutes for some quick questions. So Dom, I thought you cannot construct the hard code to use the FSD. If I ask you or true? So far I haven't been on fine. So far, I haven't been able to find that construction. Maybe Danny can talk a bit more about what the difficulties to that are. I think it's just somehow it's because in this defect construction, like the points are sort of useless, so everything has to be near edges. But in Rasco, if you look at the excitation pattern, it's not nicely organized around two edges, basically. That's kind of the reason. But I think it's a bit superficial, this reason. So I hope we can do it. I hope we can do it, but so far no. Okay, well, no question. I guess we can continue the discussion over complete brain with yourself. So we'll get a ticket.