One private information revisit. Great, so thanks everyone for coming. It's been a fun week so far. It's been great to be a visitor in this wonderful community. So this is joint work with R. V. J. Krishna, who's an economist at Florida State, and with Brunel, who's in the audience. So as usual, please direct your difficult questions to him. Okay, so added Okay, so at its core, this paper is basically a very long and involved comments on a previous Econometrica paper by Williams, which I'll henceforth call PPI. It's an abbreviation for its title, Persisting Private Information. And what that paper does is it studies continuous time contract problems where the agent has private information that's persistent over time. And so what we do in this paper is basically three things. First, Three things. First, we identify three independent issues in PPI's analysis and model formulation. The first two concern the formulation and analysis of incentive compatibility. And the third concerns the fact that the contract derived in the main application is actually not up. For the bulk of the paper and the talk, we then address these issues in the context of PPI's main application, including introducing some new ideas. Including introducing some new ideas for analyzing incentive compatibility in continuous time screening models. And especially important for today, our analysis leaves open several important questions, including a full characterization of the fully optimal contract in PPI's model. And so just as a disclaimer, I don't want this talk to come across as too negative. What we really want to do is clarify the issues that existed in Williams' paper. That existed in William's paper, given that it's been influential in this area, and then even more importantly, inspire additional work into space. Okay, so let me start with some broad economic motivations. So here's a very classic economic problem that's been studied for 30 or 40 years. Imagine there's a risk-neutral principal who can provide insurance to a risk-averse agent who has a privately observed income or endowment stream over time. Now, both parties can commit to an infinite horizon. Both parties can commit to an infinite horizon contract at the initial date, and no one can remit later on. And the goal here is to basically trace out the Pareto frontier. We want to find the contract that minimizes the principal's lifetime expected cost of insuring the agent, subject to a promise-keeping constraint that says the agent gets at least some amount of lifetime utility, and of course, subject to incentive compatibility. The agent should be incentivized to truthfully report his endowment shocks. Or is endowment shocks? And the sort of hallmark results that come out of these models, at least when the agent's type is IID over time, and these models were cast at discrete time as well, the main finding is that the optimal contract induces what's called a miseration, which means that almost surely, under the optimal contract, the agent's consumption and utility converge to their lower bounds, which might be minus 50. And if you reinterpret this model as one And if you reinterpret this model as one with a social planner and a large population of agents, this miseration result basically translates to the statement that cross-sectional consumption and wealth inequality explodes without bound at the optimum. This result holds under weak preferences in both partial and general equilibrium settings. And so if the basic takeaway of this result is that infinite inequality and impoverishing people is the optimal thing to do, the socially optimal thing to do for insurance purposes, well, this is a pretty striking. Insurance purposes, well, this is a pretty striking and extreme result. And there's been a significant literature in economics over the last 30 years basically aimed at identifying slightly different models in which this amiseration result can be overturned. Nonetheless, it's typically, this is a quote from a monograph, one of the main monographs on dynamic taxation. Nonetheless, this emiseration result is typically regarded as being the hallmark result of this literature on dynamic social. Results of this literature on dynamic social contract and with private information, which includes the large and policy-relevant literature today on optimal dynamic taxation. And so you might want to understand its driving forces within the class of models of which it was originally. Okay, so everything I've said so far holds in models where the agent's private information is IID over time. That's a useful simplification, but it's also quite unrealistic. In reality, agent's private information In reality, agents' private information is typically highly persistent since labor income has high degrees of positive serial correlation. On the other hand, persistent private information is theoretically challenging to handle because it gives the agent a new source of information rents. Namely, the agent not only has private information about his preferences over the allocation today, but also private information about his preferences over continuation contracts. And it turns out that this new source of It turns out that this new source of information rents means that global incentive constraints are likely to bind at the optimum, which makes these problems a lot harder to analyze. So they've only started receiving attention relatively more recently. So a first natural question is, does this classic emiseration result hold under these more general type processes, more realistic type processes? And the literature has been mixed on this. A 2009 JET paper. A 2009 JET paper found that the answer was yes when the agent's income follows a two-state Markov jump process with symmetric transition probabilities and when the agent has very specific functions. The Williams paper, PPI, found that the answer was no in a continuous time model where the agent's income follows a diffusion process, and in fact reached the opposite conclusion that the optimal contract leads to long-run lists, where with probability one, the agent's consumption goes to its upper bound. The agent's consumption goes to its upper bound. And PPI also made various claims that these differing results were due to fundamental differences in IC constraints that arise in continuous time models. More recently, in a paper with our third co-author, Vijay, and another co-author who's not on this project, we revisit this question in a fairly general discrete time model where the agent's income can follow basically any final. Agent's income can follow basically any finite state ergodic Markov chain. The agent can have general utility functions. And we find that the amiseration result is very general. And notably, this class of models allows for certain discrete time, discrete type approximations of the PPI model. So it's a little unclear where the differences in results are coming from. So a natural next question is what's going on in PPI to drive these different results? It turns out that the That the contract derived in that paper from which these conclusions were drawn was not actually optimal. So, what we do in this paper, and for today I'm going to focus exclusively on PPI's main application. There's more detail in the paper. But there's three independent issues in the PPI paper. The first two concern problematic formulations and analysis of incentive compatibility. The first issue is that. The first issue is that the analysis is based on the strong and unconventional assumption that the agent can't make up for past misreports. In other words, the agent can't engage in one-shot deviations. I'll make this more precise later. And this constraint is too strong to be economically reasonable. The second issue is that the agent's strategy space is in some sense too large, and so the agent is able to run Ponzi schemes where he's under-reporting at an exponentially exploding rate. Reporting at an exponentially exploding rate. And this is too weak. In fact, the contracts derived in PPI are not incentive compatible with those data sets. And so, what we do is we address both issues and provide a full analysis of incentive compatibility. The third issue, which is again the most substantive one, is that the contract derived in PPI is actually not optimal. And we observe this by noting that under this contract, the agents can. That under this contract, the agent's consumption satisfies a standard consumption Euler equation of the sort that arises in self-insurance problems. And it's sort of folk wisdom that fully optimal contracts basically never have that problem. And based on this intuition, we can show that the contract in PPI is strictly sub-optimal, even within a restricted class of contracts that we call self-insurance contracts, which are basically implemented as self-insurance problems or consumption savings problems. Problems or consumption savings problems for the agent. And then we do identify some conditions under which PPI's contract would be optimal. The first being in an alternative model, in which the agent can covertly save and borrow outside of the contract. And the second being the special non-generic case of PPI's original model in which the agent's type has exactly zero. And then in the paper, and a little bit of the talk, we then talk about some broader implications. Some broader implications of this analysis. For the literature on social insurance, our analysis doesn't support the notion that there's a general failure of the classic immigration results. The case of permanent shocks, zero-mean aversion is special. For the literature on continuous time contracting, which is most relevant for this audience, we introduced some new ideas for analyzing incentive compatibility in continuous time models that draw sort of very close parallels to Parallels to discrete time reporting problems. And then, as sort of part of a more standalone contribution, we also characterize the optimal self-insurance contract in this particular class and draw some connections to a class of renegotiation group contracts introduced in a so that's sort of the outline. I do want to give one key disclaimer, which is that the PPI paper makes three The PPI paper makes three main contributions. The first is to introduce techniques to derive necessary first-order conditions that have to be satisfied under any incentive-compatible contract. This methodological contribution is not implicated by anything I'm saying here and has been important and influential with this literature. Our analysis concerns only the other two parts of PBI, namely the verification of incentive compatibility and the economic. Incentive compatibility and the economic response. So, enough blabbering, let me jump into the model. Okay, so I'm just going to describe PPI's model. So, time is continuous and runs over an infinite horizon. There's an asterisk here because in PPI there's both a finite horizon setting and an infinite horizon setting. We find it more convenient to work directly with the infinite horizon setting. The agent's income or endowment, B, follows an OU process. An OU process. And the key parameter here is going to be this rate of mean reversion, lambda. When lambda is bigger than zero, we say that shocks are transient because they eventually decay over time. When lambda is equal to zero, this is just a Brownian motion, so any shock today has a permanent added effect on all future times. Now, only the agent observes his true income, and the agent has to submit reports about his income to the principal. So the agent's reported income. So the agent's reported income is denoted by yt, and it's convenient to denote the agent's report, yt, as his true income plus mt, his misreport at time t. So when m is negative, the agent is under-reporting. When m is positive, the agent is over-reporting. And an assumption made in PPI's model formulation is that the misreports must have absolutely continuous sample paths, namely, the agent can only alter the drift. Can only alter the drift of the endowment process. And delta denotes the derivative process. And so when the agent sets delta negative, this means that the agent is under-reporting the current increment of his income. Okay, and then script M denotes the set of all income-adapted misreporting strategies that have absolutely continuous sample paths. Okay, the principal then commits to a contract, which as a function of the agent's history of reports gives the agent transfers of the consumption good. And so it's going to be convenient, just notationally, to reparameterize this contract in terms of the agent's recommended consumption, CT, which is just the transfer plus the agent's current report. And this is the amount that the agent would consume if his current report were truthful. Truthful. Of course, if the agent is not being truthful, then his actual consumption is different from the recommended consumption. And so we denote his actual consumption by C super M. And this is, you can write this as recommended consumption minus his current miss report. So you can think of the misreport as being the amount of consumption that the agent is diverting for private consumption relative to what's recommended by the contract. The principle is. The principal is risk-neutral. The agent is risk-averse and has care utility. Both parties discount at the same rate, rho. And a standard interpretation of this discounting, which will be important later, is that rho is the market rate at which the principal can borrow and save to finance the contract. Okay, and then formally, the principal's problem is to solve a constrained Pareto optimality problem. The principal is The principle is optimizing over contracts to minimize the total lifetime resource cost, subject to a promise-keeping constraint that says that the agent gets at least Q0 units of lifetime expected utility, and subject to incentive compatibility, which requires that truthful reporting is optimal for the agent among his feasible set of misreports, which I'll denote by F. So I want to highlight this. So, I want to highlight this because we don't necessarily want to assume that the agent has access to all misreporting strategies. To clarify when various contracts are or are not IC, it's going to be useful to pivot across different feasible sets for the agent, imposing various sign restrictions or tail restrictions. And therefore, it's useful to formulate incentive compatibility with respect to different physical states. This is not in PPI. This is something that we're doing to clarify what's needed. Within whatever feasible set he has in order to maximize his lifetime expected utility. Of consumption. Yeah, of consumption, CF, the actual consumption. So does that utility or depend on some initial condition? Considering the utility. Will it depend on some initial condition? Oh, good. So I didn't say this. The initial condition for the endowment process B0 is fixed in common meaning. I'm just thinking because you say the lifetime constraint is greater than equal to Q0. When time moves, is it the same Q0? Oh, so this is a constraint on the agent's lifetime utility from the time zero perspective. It's commit it's c it's full commitment at time zero. Only at time zero. So when time evolves, the agent's continuation utility is gonna gonna move around. Okay. Gonna move around. And can go up or down as much as much as possible. That is not necessary to be satisfied with. No, no, no, no, absolutely not. No, no. Here, we're thinking of a time zero Pareto frontier and picking a point. Okay. So, now that we have the model, let me describe the three issues, and then this will motivate our main analysis. Okay. So, the first issue is that PPI imposes rather strong sign restrictions on the agent's feasible misreport. On the agent's feasible misreports. In particular, it initially introduces the model with the relatively standard and well-justified assumption that the agent is constrained to only under-reporting his endowments. And the basic idea here is that endowments or income are partially verifiable. If the agent claims to have $10 today or 10 apples today, the principal can say, okay, show them to me. Say, okay, show them to me. If the agent only has nine and the agent can't borrow or produce outside of the contract, then the agent won't be able to produce the $10. But if the agent actually has $11, the agent can just hide the $11th and eat it today. So this is a relatively standard agent. In the agent program, why does he want to hide his control? Why does he want his control M to be? Oh, so by. Yeah, yeah, so the basic idea is that if the agent under-reports his income today, then the principal who's providing insurance is going to think that the agent had a low income realization today and is going to give a larger transfer to the agent. There's no insurance yet. There is no insurance yet, right? Insurance is not in the model yet. I don't I didn't see it. Well, the agent is risk averse and the principal is risk neutral. So it's going to be efficient for the principal to absorb much of the risk and to help stabilize the agent's consumption. Insurance is just the contract, the payment. Yeah, so the basic idea is low income today means a higher transfer from the Income today means a higher transfer from the principal. So the agent will have an incentive to under-report today in order to get a higher transfer. And of course, at the optimum, this kind of behavior will be deterred because a lower report today, which comes with a higher transfer, will be coupled with lower continuation. Just for curiosity, how do you see that directly in this model? That low report implies higher continuation. Oh, so it might not be completely obvious. It might not be completely obvious from the way that it's written here. But if you look at this problem and drop the incentive compatibility constraints, it's just the first best problem, then clearly the agent's utility is concave, the principles risk neutral. So the first best optional thing to do is to perfectly stabilize the agent's consumption, which entails larger transfers with a true reason. And the second best is sort of look at a PPI. Okay. So PPI and So, PPI introduces the model of the assumption that the agent can only under-report income, but then bases the actual analysis on the much stronger assumption that the agent can only under-report increments of his income. Obviously, this second assumption does not follow from the first, and moreover, the second assumption rules out the kinds of one-shot deviations that basically all analyses. That basically all analyses of dynamic instead of compatibility are based on, where the agent would misreport for a small amount of time and then revert to truth telling. We don't know of any analogs in the literature, and this assumption is also used heavily in most of PPI's analysis instead of competitive. The second issue is that PPI omits necessary tail restrictions on the agent's misreports. Namely, as we'll see, the agent can run what are effectively policy schemes. What are effectively Ponzi schemes where the missed report diverges to minus infinity very, very fast? And it turns out that the contract derived in PPI isn't actually incentive compatible under PPI's assumptions for this reason. Finally, the most substantive issue is that even once you address the first two issues, the contract derives in PPI is strictly suboptimal whenever there's non-zero meter version of the agents income. This is actually due to a specific This is actually due to a specific part of the derivation of PPI, namely an incorrect choice from the initial condition of the contract. We describe this in the paper, I won't go through it here. But the main point is that the economic conclusions derived from this contract aren't working. Okay, so what I want to do now is tell you about the contract derived in PPI and then walk you through the latter two observations. Okay, so So as usual, given reports why from the agent, the principal can sort of back out what the Brownian shocks must have been had the agent actually been telling the truth. And we denote this by this inferred Brownian process by W super Y. So this is the usual thing that shows up when you do the Martingale representation of the agent's continuation utility. And this process is going to coincide with the standard Brownian motion that's driving the agent's income only when the agent is truthfully reporting. So we can describe the contract in terms of this inferred shock process. So there's this parameter F that depends on the discount rate and the rate of mean reversion, which basically represents the agent's risk exposure, how volatile consumption is, or how sensitive consumption is with respect to the Browning shocks. To the Brownian shocks. And so, with this notation, this contract specifies, I'll call this contract PPI, specifies that the agent's recommended consumption is just an arithmetic Brownian motion with positive drift. As the risk exposure goes down, so that's better insurance, the volatility of consumption goes down, and the drift of consumption also goes down. Of course, is it just the recommended consumption? Of course, this is just the recommended consumption by the contract. The agent's actual consumption is going to be different. And with a little bit of algebra, you can show that the agent's actual consumption when he's following a misreporting strategy M is equal to the consumption that he would have gotten had he been following the truthful strategy, plus this additional term that's proportional basically to the cumulative misreports up to time t and And minus the current missed report at time t. This shouldn't be completely obvious, but it follows directly from these two bits. Okay, so when is this contract actually incentive compatible? Well, our best reading of PPI's intended assumptions, there's a little bit of ambiguity here, but this is our best reading, is that the agent's, is that he intends for the agent's feasible set to consist of all misreporting strategies. Of all misreporting strategies, where the agent can only under-report increments of his endowment. And the measure over paths of the report process is locally absolutely continuous with respect to the measure over paths that would be induced by truth telling. This is the basic condition that you need in order to apply Kierstan. So, observation two, part one. When there's not When there's a non-zero meaner version of the agent's endowment, contract PPI is not incentive compatible given this feasible set. In fact, the agent can achieve effectively infinite consumption at all times through a sequence of strategies. So here's the basic argument. For any positive kappa, we can consider the sort of Ponzi scheme strategy where the agent under-reports at an exponentially Growing rates with rate kappa. Such strategies are in this feasible set. Here I've simplified something so the agent is actually misreporting at time zero. So it's actually not in this feasible set as I've written, but you can smooth this out easily. And under this strategy, the agent's actual consumption, or rather, the gain that the agent gets from following this strategy over truthful reporting is going to Truthful reporting is going to be proportional to this expression over here. And it's clear from this expression that as you send kappa to infinity, the agent's consumption is going to explode to plus infinity at basically all times. This means that the agent can actually achieve a lifetime value of zero, which is the upper value. Okay, so the lesson from this is that in order for this contract to This is that in order for this contract to be incentive compatible, we need to constrain the rate at which the agent can underperform. The approach that we take is to basically impose a no-Palmsy condition, the sort that's familiar from consumption savings problems. So formally, for a positive rate R, we denote the set M super R as the set of misreporting strategies satisfying this condition. And really the way that I want you to think about this is that this is a standard no-point. This is that this is a standard no-Ponzi constraint in a sort of fictitious consumption savings problem where the interest rate is R and the agent's asset process is given by this cumulative misreportance in time table. Now, this is going to help us, but you have to be a little careful about how you implement it. Because when, again, under the same assumptions, when there's non-zero meaner version, contract PPI. Contract PPI is still not going to be incentive compatible when you further constrain PPI's feasible set with this no-ponty constraint whenever the rate R at which the agent can misreport under this no-pony constraint is bigger than the discount rate. And this follows just from the same calculations as before when the agent follows this APONSI scheme strategy with a rate that is A rate that is larger than the discount rate, but smaller relative to the rate in her no-pony constraint. This strategy is going to be feasible and is also going to yield strictly higher consumption than truth-telling at all times. Uh it depends on what does it mean. Uh zero, yes. Mm-hmm. Does M even negative? No, no, no, we're not assuming now that M has to be negative. The important thing is just going to be to ensure that it's positive. In principle, yeah. So why then? Well, if you use these kinds of strategies where the agent is under-reporting, so that m is negative and divergent to minus infinity. divergent to minus infinity. That would be excluded by the question. So the R is constraining the rate at which this integral can blow up to either plus or minus infinity. It's saying the cumulative misreports have to go to zero. Also, it can be minus infinity on really hard. Yeah. Okay, do you have to have a limit or just lay here for the input? I think limit is. I think limit is probably fine. We we've written it with limits to make certain clear. So assume that the limit exists. Yeah. Let's build that into the definition of the strategy scope. Okay. Okay. But if you're a little bit more careful about how you apply this no-Ponzi constraint, then it turns out that, again, under the same assumption of non-zero immune reversion, contract PPI is incentive compatible for any feasible. Compatible for any feasible set that satisfies the no-Ponty constraint at rate rho. So, in particular, all that we need to do is ensure that this condition holds when r equals rho, but we don't need to impose any sign constraints, for instance, on the agent's works. But the contract, while I see, is not optimal among contracts that are. Among contracts that are IC, when the agent's feasible set satisfies the no-Ponzi constraint at any strictly smaller rate. So, the basic idea here is that when you impose sufficiently tight tail restrictions on the agent strategy space, the contract from PPI is going to be IC, but it's not optimal. Grayed out down here is the the fact that when you have exactly zero meter version, the contract from PPI is actually optimal and is going to be incentive compatible under basically any strategy it's possible. Under basically any strategy space. So, the rest of the talk, which I think is actually not that long, I want to sketch the two-step argument for this observation, which is also going to lead us to our approach to analyzing sim compatibility. The first step here is to note that contract PPIs include in, but not optimal within, a class of indirect mechanisms that we call self-insurance contracts. And then the second step is to show that these self-insurance. And then the second step is to show that these self-insurance contracts are incentive compatible when reformulated as direct things. And just as an aside, our perspective on these no-Ponzi constraints that we're using is that they're needed to generate an economically sensible model. Without them, weird things happen. So for instance, without these no-ponty constraints on this report, it turns out that contract PPI can be indirectly implemented in an alternative model where the agent can covertly save. Model where the agent can covertly save and borrow outside of the contract, but can't be directly implemented in the original model. And this is not reasonable because when the agent can covertly save and borrow, there's effectively more incentive constraints, and so the principle should be more constrained. Yaksha and Beatrice and their co-authors have then gone further and looked at a class of what they call linear contracts that's larger than the class of self-insurance contracts that we study and showed that when you direct And showed that when you drop all sorts, when you don't constrain the asymptotic growth rate of the agent's misreports, the optimal contract in that class involves zero risk share, which suggests to us that PPI's model basically becomes degenerate. So let me describe the indirect mechanisms. So here's just a restatement of what contract PPI is. Under truth-telling, recommended consumption follows an Recommended consumption follows an arithmetic Brownian motion that has positive drift. Of course, this means by the law of large numbers that consumption converges to plus infinity, i.e. the contract leads to long-when bliss. When you plug the consumption process into the agent's utility function, you can see after a short calculation that the agent's marginal utility follows in Martingale, New York's contract. Another way to state that is that the agent's Euler equation is satisfied. Equation is satisfied in a sort of fictitious world where the market rate is equal to the discount rate. So, whenever you see Euler equations, you think consumption savings problems. So, motivated by this, let's think about an alternative setting where the agent, where there's no principal and the agent is just self-insuring in a risk-free bond with rate of return bar. So, in particular, So, in particular, the agent has some initial assets A0, has their own endowment stream, and then can save at this risk-free rate R, which might be different from both. And so then the agent's self-insurance problem is to maximize the lifetime utility from consumption, subject to the usual flow budget constraint and the usual no-ponzi constraint on assets. And we can solve this problem in closed form. This is related to discrete time characterizations and some prior work. And basically, the solution looks very similar to the consumption process under contract PPI, except the interest rate R enters the risk exposure and enters the drift. So for rates R that are lower, then the Than the discount rate rho, the risk exposure is going to go down, and there's going to be a lower drift. And of course, the agent's Euler equation holds at this rate. So an immediate corollary of this is that you can implement contract PPI by just letting the agent self-insure at the ambient market rate of R equals rho. And you can see that just by comparing. And you can see that just by comparing the solutions to the self-insurance problem to contract PPI. And so, an implication of this is that the properties of contract PPI, namely the long-run bliss property and various comparative statics with respect to the mean reversion parameter, can be understood in terms of known results on consumption savings problems and precautionary sequence. Moreover, this suggests a class of indirect implementations that we might consider. That we might consider. We call these self-insurance or SI contracts. And so this is going to be a class of indirect implementations where the principal basically acts as a bank for the agent. So the principal starts at time zero by giving the agent some initial asset holdings, zero, allows the agent to borrow and lend from the principal at some rate R, which the principal is choosing. You can think of this as being like a tax or subsidy imposed on the agent's savings. On the agent's savings. The agent then just self-insures as they want at these terms. The principal monitors the agent's asset holdings at each time, but there's no communication about the actual endowment. And the principal collects some flow tax revenue at each instance. Okay, so Ethereum, the specific self-insurance contract in which Specific self-insurance contract in which there's no taxes on the agent's savings implements contract PPI. If lambda is positive, if there's non-zero member version, then the optimal self-insurance contract induces a rate R that's strictly less than a rho and strictly dominates contract PPI. If lambda is equal to zero, then the optimal SI contract is actually contract PPI. So let me quickly explain the intuition for this. So to find the optimal self-insurance contract, The optimal self-insurance contract, all that the principal is doing is picking some time-invariant interest rate and some initial asset holdings for the agent in order to minimize the total resource cost of the contract. And so let's focus on the second point. When there's non-zero mean aversion, the optional FSI contract is different than contract DP. So the basic idea in any insured setting like this is that the principal wants to stabilize the agent's. Principal wants to stabilize the agent's continuation explosive. And there's going to be a key trade-off between distorting the drift of the agent's continuation utility and reducing the agent's risk exposure. Now, under, so it turns out that, as usual, continuation utility follows some confusion. Under contract PPI, continuation utility has exactly zero drift. And has strictly positive risk exposure. Now, if the principal were to set a higher interest rate than Rho, this would be harmful in both dimensions. It would induce a positive drift distortion, which is worse than the zero drift distortion under contract PPI, and would also expose the agent to more risk. So the principal is never going to want to do this. On the other hand, by setting an interest rate R that's lower than rho, Rate R that's lower than rho, the principle induces negative drift, which is worse than under contract PPI, but at the same time reduces the agent's risk exposure. And intuitively, at the optimum, just equating the marginal cost of this drift distortion with the marginal benefit of the risk reduction gives you the optimal contract. What's going to be optimal is that R is true just. Let me see. Okay, in the last, I think, three minutes. In the last, I think, three minutes, let me tell you about how to analyze these as direct mechanisms and our approach to insectic compatibility. So, once you have this class of indirect implementations, you can then easily reformulate them as direct mechanisms, in which the main state variable is the agent, what we call virtual assets. So there's expressions up here. The basic idea is that the agent sends reports into the principal, and then the principal allocates Allocates assets and consumption to the agent exactly as if it were the agent solving their own self-insurance problem if the true endowment were equal to the reports sent by the agent. So basically the principle is just replicating whatever the agent would have done in his self-insurance problem. And so you can track virtual assets like this. This is just a state variable like promise utility, and then you can write recommended consumption. And then you can write recommended consumption in terms of the concurrent value of the virtual assets and the concurrent type of value. And so, what we want to show is that these direct revelation self-insurance contracts are incentive compatible with the appropriate no-pointing constraint. And so, a first pass to the proof is just that you can observe that when the agent tells the truth in this direct revelation contract, it induces the consumption process. It induces the consumption process that would have been optimal for the agent in his self-insurance problem. And so we just need to show that every consumption process that could have been induced by the agent could induce in this reporting problem is also feasible in the self-insurance problem. And then optimality in the self-insurance problem will tell us the truth problem. Is that a one-minute warning or is that a time to warning? And then you can just show by construction of the contract and by the feasible set that in fact this is true. Feasible set that in fact this is true. So truth-telling is optimal. Okay, so let me just quickly note. What you'd like to do then is to actually verify and send a compatibility without reference to the indirect implementation. One challenge under PPI's original formulation that reports have, or misreports have absolutely continuous sample paths, is that it's well known that in discrete time reporting problems Incentive compatibility implies that the agent actually wants to report truthfully at all histories, even those where he's misreported in the past. And so, what that means in the present setting is that if the agent is at an off-path history where he's currently misreporting, he'd want to set the drift of his misreports to plus or minus infinity. This has some adverse technical implications. For instance, the agent doesn't have a relatively best reply, and his value function only satisfies his HB. only satisfies his HAB equation as a super solution. And so what we show how to do in the paper is basically to extend the agent's reporting problem to a larger strategy space that allows the agent to submit discontinuous reports. This allows the agent to jump back to truth-telling instantaneously. And this then allows for a very easy formulation of the agent's stochastic control problem where we view the missed reports as a control rather than a state and highlights that the State and highlights that the agent's reporting incentives are basically the same as they would have been in a discrete time model. And so, the last thing I want to highlight is that this approach of extending the agent strategy space, because of its technical simplicity and parallels to discrete time, seems in some sense like the right one for analyzing incentive compatibility and continuous time models. And so, a question is: is this more broadly useful than others? So, concluding remarks, we do some other stuff in the paper analyzing optimal self-insurance contracts. Optimal self-insurance contracts, relating them to renegotiation-proof contracts, in other paper Brunos. And most importantly, we know that under regularity conditions, the optimal self-insurance contract isn't the fully optimal contract as part of. And so an important open question is, what is a full characterization of the fully optimal contract? Hopefully, this is a question that's interesting to people asking. So, with this, I'll skip the summary and just say, The summary and just say thank you and apologies for running three minutes earlier.