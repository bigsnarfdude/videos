And interesting as well. So, yeah, I'm going to talk about MIPIT games in computer spaces. This is a joint work with my PhD student, Concha Vio, and we have recently started to work in this area to this area and we are still learning and exploring. So, your comments are very welcome. So, here is an overview of the work. So, in a classical Olympic games, usually state control and noise. State control and noise processes take values in Euclidean spaces, like RD. In this work, we want to extend the mucidine theory to the case where these processes take values in Hilbert spaces. And to do so, we need to first establish the well possessed of coupled stochastic evolution equations in inverted spaces. And to our knowledge, this problem has not been investigated in the literature. So we established the well-posedness of coffee-testoplastic. Possibly solve computer stochastic evolution equations in a fairly general setup, in a semi-linear setup, and then we use that as the foundation to address the MIFID games in liberated spaces in an LQG setting. So, why are we interested in such a framework? Here is a motivation. So, indeed, such a framework becomes very useful in dealing with systems that involve delays. So, here we have an idea. Involve delays. So, here we have an example. So, this is the interbank model with a repayment scheme that was proposed by John Pierfuk and his collaborator. So, in this market, we have like N banks, and X oil represents the monetary reserve of bank oil, which is impacted by the rate of borrowing at the ending of the bank, and also by rate of repayment. So, if the bank is borrowing at time T after a fixed amount of time, it needs to make a payment. It needs to make a payment, and if it is lending after a fixed amount of time, it receives a payment. So that's why we see that we have what control action and the delayed control action. And then the objective of each bank is to keep their load monetary reserves close to the average load monetary reserve of the market. So, in general, for this system and systems that involve time delays, so these systems So, these systems have a past-dependent behavior. So, their situation at the current time is not only a function of their state at the current time, but also a historical state. So, we can describe these systems using stochastic delay differential equations as in here. And as you can see here, this is a non-Markovian system. Now, one way to deal with such stochastic delay differential equations is to represent them or To represent them or link them to the infinite-dimensional spaces. So we form this extended state, which includes the state of the system at time t and part of the history of the state that is relevant. And this lives on a Hilbert space, and we can show that it satisfies this stochastic evolution equation where A, F and B are appropriate operators between associated Operators between associated spaces. So now this system is more and we can solve it. So if I go back to the example that we had, so since we have a delayed system, we can extend the state of each bank and we represent this system by a stochastic evolution equation in vertex space. And then we have a midfield game or an end-player game where the An end-player game where the state of each agent and also its control input take values in inverted spaces. Now, we want to address this problem. So, about the literature, so as I mentioned, we specialize to linear quadratic immune system a little bit later. And these problems in finite-dimensional spaces have been extensively studied. Also, a linear quadratic optimal control problem. Linear quadratic optimal control problems in a single agent setting have been studied in the literature, so infinite-dimensional version as well. However, when it comes to stochastic games and amphibi games, inverted spaces, the literature is very limited. So there are a few published works that investigate the interbank model that I just presented. And in these works, most of the analysis rely on heuristics. Rely on heuristics. So, in this work, we want to establish a mathematically rigorous framework in a fairly general setup to address such problems. So, here is the outline of the rest of my talk. So, I will start with some preliminaries of infinite dimensional analysis. Probably you are familiar with that, but I think it's useful for the rest of the talk. I will lay down the notation and also the main elements of the model. Also, the main elements of the modeling. And then I will investigate cockhead stochastic evolution equations in Hilbert spaces. I established the belt-wonteness and in a semi-linear form. And then I specialize to MIFIT games. So I use this as the mathematical foundation to investigate linear quadratic MIFIT games in vertex spaces. So we use a three-set of the So we use a three-sectable inverted spaces H, U, and V, and the orthonormal basis of B we denoted by the sequence of EIs. And we work with three classes of operators. I want to focus on two operators in particular, trace class operators. So these are bounded linear operators that satisfy this function. So if this operator is defined on the hem data space, Defined on the data space V, then this term, this absolute value of the initial product, can represent the impact or the influence of the operator in the direction EI of the orthonormal basis. And this summation together can be understood as the total influence of the operator in all directions defined by this autonomous basis of the space. So if this quantity is finite, then we should. So if this quantity is final, then we can define the trace of the operator in this form. And this trace is the total impact of the operator across all directions, but in this case, we are also talking about the impact. Another operator class that we use are positive operators, so these are bounded linear operators if the operator is defined on the Hilbert space edge. So it is self-constrained, and then for any element in the Hilbert space, For any element in the Hilbert space, it satisfies this condition. So the inner product of each element in the Hilbert space and its image under this operator is non-negative. So this operator doesn't change the direction of x in a way that it creates a negative projection on to x itself. Okay, now I define juvenile processes. So for a positive and trespass operator, base path operator we can define a cubinal process that takes values in the inverted space spin and this winner process shares the same properties as finite dimensional winner processes except for this one so it takes values behavior aspects of course and for this function we can see that the increment of the cubiny process over a time interval is normally distributed between zero and a covariance which is zero and a covariance which is equal to the length of the interval times the trace class operator which defines the cubinar process. And we can construct a cubinar process in this form. So this is an infinite sum over a sequence of mutually independent one-dimensional linear processes and EOI and land oil here, the sequences of EOI and LANDOI together. Together, the yogonal lights, the trace class, or herital. So we can construct a tubinal process in this way. So we work with two classes of processes. M2 processes, so these are X values, so depending on the bonus space that we are using, and these are progressively measurable processes that satisfy this condition. So they're square integer. Condition. So they're square integrable and we define H2 processes that satisfy this condition. So this condition obviously is stronger than this one. So H2 processes are a subset of the space of N2 processes. Okay, so next here we have a stochastic evolution equation. So in this equation, x In this equation, x and u take values in a um take values in a Hilbert space and as you can see here, W here is a cubinar process, take values in the Hilbert space B. And this operator A, this is an unbounded linear operator and also the infinitesimal generator of a C0 semigroup, which is. Semi-group, which is a bounded linear operator, and satisfies this condition. So its norm is uniformly bounded. All the other operators are bounded linear operators in this equation. Now we define the notion of Moi's solution for this stochastic evolution equation. So a Moide solution is an H2 process that satisfies this integral equation almost surely and Almost surely. And this integral equation involves the C0 semigroup associated with the unbounded linear operator that defines the stochastic evolution equation. And in the literature, it is shown that this linear stochastic evolution equation admits a unique move solution. Okay, now I present our work. Uh so as I uh mentioned uh we will first establish the Velprozministo uh coupled stochastic evolution equations. So we assume that we have n stochastic uh evolution equations which are coupled and these equations are driven by independent cubinear processes. We want to use this to address later on linear quadratic mid pie games. So the first step for us is to show that indeed there exists To show that indeed there exists a sequence of independent huminar processes on a Hilbert space. So, to us, this was not clear, we couldn't find this in any phrase. So, we showed it in our paper that indeed we can construct a sequence of independent cubiny processes on a Hilbert space. And then we use this sequence of cubinar processes. Quinn processes to define a set of n-cocker stochastic evolution equations as you can see here. So XI represents the state of stochastic evolution equation I. So as you can see, A is the same operator as before. So this is an unbounded linear operator. And then we have these linear mappings, Fi and Bi, that also appear here. So this is the semi-linear. Here, so this is the semi-linear stochastic evolution equation, and the coupling comes through this term. So, this bold phase X is the state of all n stochastic evolution equations. So, obviously, bold phase X is an HN value process. And WAs are a sequence of independent cubiny processes. Okay, now we define the notion of multiple. Defined the notion of mild solution for this set of equations, which is similar to what we define for single stochastic evolution equations. So here, a moil solution is an edge process, obviously here, Hn value, that satisfies this integral equation almost surely. And again, this equation is involved with the C0 sample associated with this unbounded. Unbounded linear operator. Okay, so now we make some assumptions. So, for example, we assume that the initial conditions of stochastic evolution equations have a final second moment, the control action belongs to the entire space. We impose some measurability conditions, and also, just let me go back to the system here. We assume that these non-linear operators, Fi and Bi, are. Fi and Bi are inches continuous and they are of linear growth, so they don't go too fast. Now, under these conditions, we can show that there exists a unique mind solution to this set of n-propitive stochastic evolution equations. So it's unbounded A, it's an unbounded linear operator, and it's That linear operator, and it's the infinitesimal generator of a C0 semi-group. So I just defined it here. So this is the infinitesimal generator of a C-zero-sen group. So this C-Zero Sen group is a bounded linear operator and is uniformly bounded as well. Okay, now um I don't know if that was all is it mapping uh H to H? Which mapping? AB, A, yeah, it's H to H, H lives on H. Yeah, yeah, now I use this framework to address linear quadratic unique things in Hilbert spaces. In Hilbert spaces. Okay, so here I have n agents. The state of agent satisfies this stochastic evolution equation, which is linear in this case. So the operators are defined as before. A is an unbounded linear operator, and the rest of operators are bounded linear operators. Moreover, we see that the state of agent I is involved by the average state of all agents and moreover. And moreover, here we have a stochastic volatility. So the diffusion coefficient is involved with the state control processes and also the state average process. So given the framework that I established, this is a well-posed system, and then each agent needs to minimize a cost functional as in here. In our paper, we have a general, a more general cost functional. And more general cos functional, and also we have some coefficients in front of xn which is removed here. So now we want to solve this problem. So we want to find the set of control inputs that yields an equilibrium for the system. Uh we don't solve the end player game directly, so we move to the limiting case where the number of agents goes to infinity uh to solve the limiting game. To solve the limiting game, so using the microgain methodology, find an equilibrium for the limiting game, and then we use that equilibrium and show that it yields an approximate equilibrium for the enterlayer game as well. So, here is the representation of the system in the limiting case where the number of agents goes to infinity. So, as we can see here, each agent in this case is interacting with the mean field. Instead of the average, Instead of the average state of agents, same in the cost function, also we have the input instead of the average state of the agents, and this simplifies the problem. So there is a decoupling property here that simplifies the problem. A few minutes later, I will show that this X property indeed is a deterministic process, and each agent can compute. Now, we aim to find an equilibrium for this system. For this system, so NH equilibrium. So, more precisely, NH equilibrium consists of these response strategies of agents to this mean field, explore, and then when agents use these equilibrium strategies in the limit, they should generate the same mean field that was used to obtain the best response strategies. This forms a fixed-point problem that can be Be presented in two steps. So, to address this problem, first we fix the mean field. So, we replace it by G, we assume that the mean field is known, is even. We replace the mean field by this mapping. And then once we do that, this is a single agent optimal control problem in infinite dimensional spaces. We can use the techniques for these systems to address this problem. Address this problem, and then the imposed consistency condition, indicating that the optimal state of agents together should generate in the limit the same influ that was used to obtain the optimal strategies or best response strategies. Now, before I address the problem, I'm going to introduce some mappings. Uh so it's just the a Nash equilibrium for the limiting A but uh so the just condition so so I'll just don't understand why you take the limit here not putting that by some part here oh yeah it's here because I haven't yet Here, because I haven't yet introduced the optimality because of mutation, yet kind of abuse of mutation. It's abuse of mutation. It should be optimal. So here, as I mentioned earlier, we have a stochastic volatility, we have the sleep process and also the control process that appears in the diffusion coefficient. Due to the presence of these processes, To the presence of these processes in the volatility, and also from ETO's lemma applied to stochastic processes in Ebert spaces, in the solution we obtain for linear and linear functionals, as in here in terms of traces of some operators. We can use the Ream's representation theorem to represent these mappings, these functionals, in a nicer form in terms of inner products, which involve mapping. Which involve mappings delta 1 to delta 2 and language gamma 1 to gamma 2. We can show that all these mappings are backward. Okay, now I go back to the solution of the problem. So the first step, we fix the mean field, we replace it by G, and then we want to solve this optimal control problem. So we want to find the control input. Find the control input that minimizes this cost functional where x satisfies this equation. And here I drop index i because all agents are symmetric. The optimal control input in this case can be given by this equation. So as you can see, the optimal strategy is in a linear state feedback form. So it's a linear function of the state. Moreover, it is involved with the question. It is involved with the coefficients that are themselves involved with the mappings that resulted from the risk representation and theory. So that's the difference with the finite dimensional. The form remains similar. And this solution, this optimal control strategy is also involved with pi, operator pi, that satisfies this operator differential recurring equation, process Q, that satisfies. Process Q that satisfies this linear evolution equation. Now, the second step, I impose the consistency condition. So, given a fixed mean field, I was able to obtain the best response strategy. Now, I can calculate the expected optimal state, and as you can see, this is also a function of G. Now, if you look at this MOOC consistent. Look at this MOOFI consistency condition here. Both sides are functions of G. So we define the mapping from G to the expected value of the optimal estate by epsilon. And now we want to investigate if this mapping admits a unique fixed point. If so, this unique fixed point characterizes the mean field. And we use Bonanchi fixed point theorem to Bonach fixed point theorem to show that. So to use the Bonach fixed point theorem, make sure that all the operators and processes that are involved in this mapping are bounded. So we start with COI that you can see here. So we show that POI is bounded, and as a result, we can show that other mappings that involve POI are also bounded. Another process that appears here is Q. Process that occurs here is Q. So for Q, here is the equation that we obtain. So it's a function of the fixed mean field. So we show that if we vary this fixed mean field, which is like an input in this equation, then the variations of Q are bounded with respect to the variation of G. So we have this property here, and then we can use these properties to These properties to find a contraction condition. So, if this condition is satisfied, then the mapping associated with the Ni-Fif consistency equation admits a unique fixed point. And this condition is a function of the time horizon, the norm of the CISERA standing group, and also the norm of some other operators that appear in the model. Next, we investigate the Next, we investigate the feasibility of this contraction condition. So we show that there exists a time coincidence, capital T, such that this contraction condition is satisfied. So if T is a small enough, then this contraction condition is satisfied, and the mapping associated with the mean field consistency equation admits that we need fixed points. Also, we can fix T, and then if other operators And then, if other operators that appear in the model are sufficiently small, still this contraction condition can be satisfied. So, this unit fixed point, so under this condition, the unique fixed point and the mapping characterizes the mean field. And then we can show that the set of strategies as described here form a Nash equilibrium for the limiting gain. Nash equilibrium for the limiting gain. So this strategy is linear in the state of agent Pi and it involves export the mean field, operator pi, and the process Q. So the mean field, operator pi, and Q are characterized by the fixed point solution to this set of consistency equations. So as you can see, X4 satisfies a deterministic equation, which can be calculated by the agent. CoI satisfies Coil satisfies an operator recurrent differential equation and Q satisfies this linear evolution equation which is involved with the main field. Okay, so so far I talked about the limiting game. So we found a Nash equilibrium for the asymptotic game where the number of agents goes to infinity. Now I want to make the connection with the finite player game. So in particular I want to show So in particular, I want to show that the set of strategies that we obtain in the limiting case yield an epsilon Nash equilibrium for the finite player game where there are n agents. So here, since all agents are symmetric, I just assume that all agents except agent 1 are following the natural equilibrium strategies that we obtain in the limiting case. And one agent, agent 1, deviates from this set of strategies. And then I want to. This set of strategies, and then I want to show that this equation holds. So, meaning that if agent 1 unilaterally deviates from the set of obtained strategies, it can benefit at most by epsilon n. And should that epsilon n be small if the number of agents in the n is sufficiently large? For establishing the epsilon property, epsilon Nash property, we We calculate the difference, the magnitude of the difference between the limiting and finite player processes. So here we calculate the H2 normal, the difference between the mean field and the average state, and we show that it's of order 1 over square root n. Also, for the state of agent 1, this is the deviating agent, we show that the H2 norm of the difference between the state Of the difference between the state of the agent in the limiting case and in the final player game is of order 1 over square root n, and same for the cost functional. So, this is the magnitude of the cost functional of the agent in the limiting game, and this is the cost functional of the same agent in the finite player game. So, this also is of order 1 over the square root n. So, using these properties, we can show the We can show the epsilon Nash property for the set of strategies that we obtain in the limiting case. We can show that this set of strategies form an epsilon Nash equilibrium for the finite layer n. So if agent 1 unilaterally deglites from this set of strategies can at most benefit by epsilon n, and epsilon n is of order 1 over a square root 10. So the larger the number of agents, the better is this underestimation. So let's stop here. Thank you very much. An equation. I think there are two approaches. In one of the approaches developed by Peter Kennedy and Mini Month, it's one over a square root n. A square root n, there is probabilistic approach developed by Rena Carmona and his collaborators. So, in that case, this depends on the dimension of the state. Which could be very difficult to establish for this case because it is infinite dimensional state. So, that's one of the challenges if we want to use probabilistic average for establishing the epsilon match property for the general. Does the unbound has a operator give it? No, because we use the C0 semi-group theory, and with that, because this is bounded, and in the solution, we use a moist solution. So, for this system, a strong solution doesn't exist. And the moist solution is involved in the C-zero semiconductor, which is a linear and bounded operator. 