Thanks, Bjorn, and thanks to the organizers for inviting me. So what I want to talk to you about today is work I've been doing with my PhD supervisor Bjorn Sansteda, who unfortunately couldn't be here for the conference this week. And I should probably give you a bit of a warning. The work that we're doing doesn't explicitly have multiple time scales in it. You're not going to see an epsilon in this talk. C and Epsilon in this talk, but when I talked to Bjorn, he said it would be of interest to people, and please take your complaints to them. So what I'm going to talk to you about first is just some motivation for what we've been doing, have a look at some of the numerical results that was our jumping off point, return to some simple work that Bjorn's done previously, and then see how we extend that to the problem we're looking at. Okay. Okay. Okay, so in Bjorn's group, we're mostly interested in spatial patterns. So these are patterns that you see in space that change over time. So I've just brought up a few results from the literature here to sort of as examples. So here we have spiral waves on the surface of the heart, the electrical chemical potentials of the heart. We also have spiral waves and target patterns. Spiral waves and target patterns in the oxidation layers on platinum alloys, and then we have similar patterns. You see, like spiral waves here and target patterns here, where the targets sort of radiate outwards in these populations of slime molds. And so our overarching goals are sort of to investigate the existence and stability of these waves and how these two separate different types of patterns, spirals and targets, interact with each other. Interact with each other in where they appear at the same time. So, what more clearly what exactly is a target wave? Sure, so here you can sort of see that you have these like sort of target patterns, these concentric circles. And over time, what happens is these circles sort of radiate outwards. So they're like traveling waves with radial symmetry. Right. And so what I want to do is. Right. And so, what I want to talk to you today are some related or slightly simpler patterns like this. So, in all the pictures I'm going to show you from now on in the talk, I'm going to give you plots in space and time. So, along the horizontal, we have space, and then along the vertical, we have time, where time goes from the bottom to the top. And what I'm showing you here in this first panel is an experimental result by Perrud et al. in 1993. By Perrot et al. in 1993 of the Seema reaction. So, this is a reaction where they took two tanks of chemicals separated by a thin gel layer, which allowed the chemicals in the tanks to diffuse slowly into the gel. And what you find over time are these spatial temporal patterns that you can see here. So, you have some core region that spits out wave trains into the far field. Bar field. And at the same time, they did some experimental simulations of the system by way of the Brusselator, which shows very similar looking patterns. So you have this core region which spits out wavetrains into the far field. And in particular, what they saw is that they could produce these what we're going to call defect solutions with Going to call defect solutions with arbitrarily large striped regions in the center, even down to just a single line that goes up. And also you could find, and this is a little hard to see, but in this example here you see that the background states are synchronous. The wavetrains move outwards in synchrony, while as in this example they actually spit out like alternating asynchrony. I make sure I understand that the gel is the center line? It's the center line of the two tanks. The tanks like a rectangle is the gel where you assign the whole thing as well. So the whole thing here is the gel, this is time. So what we're seeing are like spatial temporal values. Okay. And so more recently, so. Recently, okay. And now at this point, I should also thank Guillermo for introducing the Brusselator earlier, so I don't have to. We're going to be considering this system, the Brosolator with diffusion, this reaction diffusion system, which was developed in the 60s after Turing did his work on the Turing bifurcation earlier. And at the time, or at least in the mid-70s, Okmudi. Or, at least in the mid-70s, Okmoudi and Nicholas described this PDE as a prototype of any system leading to dissipative structures, analogous to the harmonic oscillator as a prototype in classical or quantum mechanics, which seems like a pretty big claim. But at least for us, this is going, this is somewhat important because there is an interaction in the brosillator between two different types of oscillations. So, what you have is What you have is if you were to set your solutions to be time-independent, then you can find Turing patterns, and then if you set them to be spatially independent, you can find Hopf oscillations. And it's an interaction between these two very distinct types of oscillations that can lead to these non-trivial patterns. So, slightly more recently, Justin Zone and others did some numerical Did some numerical studies of the Brusselator, which I've reproduced here, and they found that not only can you find these what we're going to call contact defect solutions, you can find them with any number of stripes in the middle. And not only that, as you continue the system in the bifurcation parameter, which in this case is the diffusion ratio, these solutions connect to each other non trivial, in this way they snake backwards and forwards. Way they snake backwards and forwards between saddle node applications. This is very reminiscent of some behavior found in things like the Swift-Hohenberg equation, which I'll talk about in a moment, where you can find something called a snakes and ladders bifurcation. And it was Bjorn's idea that we try and look at this and prove not only that we can find these patterns, but that they should align in this way. But that they should align in this way to form this snake. So before I go on to exactly how we set up the problem, I think it's probably easier to understand the basic geometry in the finite-dimensional case. And so where all this started was, or at least where a lot of the proofs were done. It was a paper by Bjorn and also Margaret Beck from Boston University on the Swift-Hohenberg equation. So, this is the Swift-Hohenberg equation here. It is a fourth-order PDE in space, and in this context, we're going to look for stationary solutions in time. So, we can imagine that this time derivative is zero, and then we're looking for solutions that exist in like the four-dimensional phase space. In this case, what we're looking for are these kind of solutions. So, in the system, we have an equilibrium, happens to be at the origin. happens to be at the origin, which is going to be our background, and then there is a periodic orbit in the center. And what we're looking for are solutions which start off at that equilibrium, move into a neighborhood of the periodic orbit, orbit some number of times, and then return. So they're heteroclinic connections. And the key way we're going to sort of think about these is we're going to have to assume, there's no current way known to how to. No current way known to how to prove these except computer assisted proof. Assume that we have some heteroclinic connections between the equilibrium and the periodic orbit. Then you can imagine how you would obtain this purple solution would be to cut this heteroclinic and cut the it's reversed, lasymmetrically reversed, and glue those two things together to find this finite core region. And in fact, that's more or less how this. And in fact, that's more or less how this goes. So we have our equilibrium at zero, we have our periodic orbit, these both have their stable and unstable manifolds. And we assume that we have these heteroclinic connections. We then look for this purple solution, which is going to shadow the green solution until it gets into the vicinity of the periodic orbit. The vicinity of the periodic orbit, where it then transitions to moving around and shadowing the orange and follows it. And I can't go into all of the details about how you set up this proof, but what I can at least do is demonstrate why we should expect this to happen. And so if you look at the spectrum of these invariant objects, so the equilibrium has two stable eigenvalues, two unstable eigenvalues. Unstable eigenvalues. And so the unstable manifold here is two-dimensional, the stable manifold here is two-dimensional, and we're looking for a one-dimensional intersection of these invariant manifolds. Of course, we're sitting in R4, so this isn't actually generic at this point, but it turns out that there's some extra structure in the Swift-Tohemberg equation, namely that it's conservative, we have a Hamiltonian. Conservative, we have a Hamiltonian. And if we restrict to the zero-level energy set, we're now in R3, and the intersection of these manifolds is generic. Yes. Why don't you think that you have a cell that has a complex conjugate that can value equal? If you know what I mean by that, right? That's the origin in the complex player. The sum is going to be zero, so it's going to be settled for conservative settlement R4. I would need to check. I might have just drawn the wrong picture. Because it looks like it spirals away, it spirals in a way. It could be like that. Well, I mean, these oscillations here are the periodic... I know, but they still have. Oh, yes, that's a good point. I'm not sure. I would have to check. You could be right. As far as we're concerned here, though, the splitting 2 of 2 is like the structure that we need. That we need. Right. And so if we look, so one other thing. So far, I've described to you the construction of symmetric solutions here. So once you assume that you have this front solution in green, you also have its commensurate back solution in orange because of the reversibility of the Swift Harmonic equation. And so long as you want to ask for cement. So long as you want to ask for symmetric solutions, so ones that respect this symmetry, it's sufficient to look in the zero energy level set. But you could also ask whether you could find solutions which do not respect this symmetry. And in that case, you can find them, but at the expense of leaving this zero energy level set. This is still okay because effectively the energy level at which you make the Energy level at which you make the connection becomes an internal parameter of the system, and so the intersection is still true. And so, what Margaret and Bjorn found is that what you find are these two branches of symmetric solutions here in blue, which snake backward and forward and are connected by these horizontal lines of asymmetric solutions. Of asymmetric solutions, and hence the name snakes and ladders. What's sort of important is as you move up this structure, the symmetric solutions sort of increase their core regions. So as you move up, you're orbiting around the periodic orbit more times. You add stripes into the inner region. So what we want to do is essentially try and use the Essentially, try and use the same construction in the Brusselator, assuming we have these front and back solutions, show that we can do this process that gives us these symmetric solutions that snipe backward and forward, and see if there are any asymmetric solutions joining them. So Justin's numerics in their paper they essentially said that they couldn't find any asymmetric solutions. Find any asymmetric solutions. I believe that there are some good reasons that their numerical scheme didn't find any, which I'll try and explain later. But we do believe we should be able to find them, although it is hard. So let me explain how we set up the problem. So the Brusselator here is essentially a reaction diffusion system, two components. So I'm just going to write little U to be the combination of capital U and capital V that I've shown you already. Shown you already. And then what we're going to do is use a spatial dynamics framework. So we're going to rewrite this system as a first-order system in space. So you do the normal thing. You let little v be equal to the x derivative of little u, and then this equation here becomes little x times d inverse ut minus f of u. Of course, now in our Brussels later system, we have solutions that we want to find, which are We have solutions that we want to find, which are definitely not time stationary. We have these oscillating tails in time, so we cannot get rid of this time derivative. So what we have is legitimately infinite dimensional. So we can't remove this time derivative, and that essentially means our phase space becomes the space of, let's say, periodic functions on some fixed period. Period. It turns out that this is fine. We can still use all of the geometry we want to use up to some technical assumptions which Bjorn and And and others have sort of established previously. So when Bjorn first gave me this project, he sort of assumed that the difficulty in this problem would just be like upgrading from finite dimensions to infinite dimensions. Somehow the geometry would be the same, and we would only just have to care about these additional technicalities. It turns out Technicalities. It turns out while these technicalities exist and you have to pull a crank together to work, it's actually much harder for a different reason. Hopefully, I can illustrate that now. Okay, so again, we can think about the system in terms of the phase space. And obviously, the space space is infinite-dimensional, but I'll do my best to sort of capture the essential elements here. So, the Turing pattern in the center here, remember, we're thinking about this as. We're thinking about this as dynamic in the space variable. So the Turing pattern is essentially a periodic orbit in our phase space. So this picture in the core region is essentially the same. However, in the far field, we now have these homogeneous oscillations. These homogeneous oscillations are homogeneous in space and they're fixed points. But there's a complication. But there's a complication because of time shift symmetry. So, this is the picture I've been showing you the entire time so far. And what I've done to get this picture is just take this picture and shift it some amount in time. But now you can see in the far field here, this homogeneous oscillation is a different point in our phase space to this one, because they're represented by distinct periodic functions. Periodic functions. And so, what you have in your phase space now is not just a single fixed point, but a circle of fixed points representing each one of the S1 symmetry applied to the Hopf oscillation. And this is what really complicates everything. This is a symmetry you can't factor out, and you have to include in basically everything that you do. But essentially, the game remains. But essentially, the game remains the same. So, we're going to assume that we have these front and back solutions, this green and orange, except now once we know that we have this one front here, for example, our shift symmetry then guarantees that we have a front for every single fixed point in this circle. Basically, our phase space is going to be S1 equivariant, and we have to carry that through. So, but again, essentially we have reversibility. So, once we have the front, we have the back, and the game is the same in the sense that we're looking for a solution which starts at some fixed point in the background, moves around, orbits some number of times, and then returns. Interesting questions now arise, though, because is it possible that you connect to different fixed points in the background? And it turns out if you're looking for symmetric solutions, And it turns out if you're looking for symmetric solutions you cannot. You cannot. But if you look for asymmetric solutions you can. But one more point is we should be able to count dimensions to see if we should even expect this to occur. So okay, so we can do the same thing. What I'm going to show you here. What I'm going to show you here is sort of like a fourth-dimensional model of what's actually going on. So, here in the background, each of our fixed points have two eigenvalues at the origin. One corresponds to translations in space, the other corresponds to this S1 symmetry that we have. And then we have one additional stable and unstable. So, when we go to make these connections, what we're trying to look for is a connection between. Trying to look for is a connection between the three-dimensional center unstable manifold and the three-dimensional stable center manifold of this ring. And thinking about this just in R4, we now see that we have somehow more dimensions than we had before. So we have three and three intersecting in R4 will d uh intersect in a two-dimensional two-dimensional manifold generically. Manifold generically. But it turns out this is actually what you want because these solutions, once we find them, need to be invariant to both spatial translation and temporal translation. And so this works out, and it turns out you get the symmetric structure that you want. But if we go to look at the asymmetric solution, something very strange happens. So now, just like in the case of the Swift-Cohen. Case of the Swift-Hohenberg, you can't restrict yourself to the geometry as it stands. But unfortunately, unlike Swift-Hohenberg, there is no conservative structure anymore. But what you do have is the detail I've somewhat hidden at the moment, is that there's this second zero eigenvalue of this periodic orbit, essentially corresponding to the fact that the Turing pattern in a reversible system generically comes. In a reversible system, generically come in one-parameter families. So, not only do we have this single periodic orbit, we actually have a cylinder of periodic orbits, each one with a different wave number. And to look for connections now between asymmetric states, you actually have to use different wave numbers in the core region. Unfortunately, this is a complication because now you have to somehow make Now, you have to somehow make the dynamics around this work, around this cylinder work. The way you do that is by moving into a co-moving frame, which adds a parameter. So now, what we have is this three-dimensional manifold trying to intersect with a three-dimensional manifold and a free parameter. So, we actually get three-dimensional intersections. And it turns out what this is, we think, is that once you have your asymmetric solutions, you can not only You can not only shift them in time, but you can also shift the phase of the background oscillation to get any phase difference that you want. Unfortunately, I can't show you any pictures of this because every attempt we've made to simulate this numerically has failed in a quite dismal way. So, I would like to show you, but all we can really say at the moment is this is a prediction. So, asymmetric solutions should exist in two parameters. Solutions should exist in two parameter families, which you can explore via this phase difference. And in order to get these solutions, you have to look at them in a co-moving frame. Otherwise, the symmetric solutions really follow the same sort of setup as before, assuming you can factor in this symmetry in the background. Okay, so just wrapping up, so some future directions. We want to fix the numerics. We would like to actually show that these exist somehow. That these exist somehow. We would also like to know how exactly these asymmetric solutions connect. So, you know, in the picture with Margaret, you know, you have these two symmetric branches that snake and then are connected by these lines, but we have no idea what this is actually going to look like. We know some things are in between, but not what it looks like. So we want to have a look at that. Also, from the beginning, if you remember, the motivating example was not necessarily. Motivating example was not necessarily exactly the case I've described, where we have this homogeneous background, but here it looks more like you have these wave trains radiating outwards. And that was also what was found by Perudinol, albeit in a different region of parameter space for the Brussels leader. We think our setup will also prove that these source defects exist, although there is an additional complication which I can Complication which I can sort of go into later if you're interested. And finally, we would also like to look at the spectrum and stability of these layers. But I think I'll end things there. Thanks for listening. Thank you very natural presentation. Questions? Yeah. Did you find the second snake? Or did anybody find the second snake? So the second snake exists. Exists, this is more a failure of my numerics. So, to construct this diagram, we set things up in order. So, we were looking for periodic solutions of discretized space. But it turns out to resolve these small oscillations in here on a large enough domain takes a lot of Fourier modes when we were using Fourier discretization. So, I set up auto on a supercomputer at Brown and let it run for a product. And let it run for approximately like 14 hours to make this picture. I could do the same thing again and get the other one. I didn't bother. Especially since as soon as you try and look for asymmetric solutions with the same code, it doesn't work. So we're moving on to. It might give you more indication where you might connect or whether that connects or is local. I mean uh it would probably be still worth just cranking another $50 on your supercomputer. Yeah, in principle, yes. Uh I mean I could probably do that. Uh I mean I could probably do that. Uh if I if I have a few minutes to like start the code running like I might do that later. But you would expect that it's it's sort of the form where there's like faults that you get to connect to them together. I mean that's what you have together example. Yes, but now we have sort of like this additional degree of freedom. I'm not quite sure if you really get like a one-dimensional line here or not. Somehow we need so what we what we did try to do to find What we did tried to do to find this branch was to so in the actual theory, these saddle nodes are not what produce the asymmetric states. Instead, it's like a very nearby pitchfork bifurcation. So what you can do is naively just break that symmetry, continue around, restore the symmetry, and then you'll be on the asymmetric branch. But this doesn't work, we think, because of this one-parameter family of solutions there. Auto has no way of telling the difference. Auto has no way of telling the difference between this family without some additional condition, which we don't really know. Yeah, well, how you know? I don't know. Yeah. So instead, what we're sort of trying to do is pivot to a core far-field decomposition, which And and Ryan Gogh and others have sort of implemented before, where you really bake in the asymptotic boundary conditions into the problem at the beginning. And that way we should be able to specify what the phase difference. To specify what the phase difference should be and then continue from there. I get confused on the basic thing. Like, why do you call the far field a fixed point? Because somehow when I look at that, I thought it's like oscillating. It's oscillating in time, but it's constant in space. So we set up the problem as a spatial dynamical system. Whereas the far field means a range of X's. Yeah, it means like in the far X. Yeah, it means like in the far x field. And so because these are like constant periodic functions in x. And so we know some are stable because you see them in them. Yes, so I think, well, I don't exactly know, but what should happen is that these should be stable and then it'll be unstable and stable, sort of alternating as you move up to the level. But we haven't really investigated the We haven't really investigated the stability of these defects yet. Just so I understand this correctly because I wrote this paper on contact defects with Buran that he's well aware of. So he's thinking and you are thinking that this picture, just because you get close to these periodic patterns, it changes the generic multiplicity of contact defects that we predict. Well, I'd say they come in one parameter family's parameter us by the way, by the frequency and the far from the middle. We get very confused. Yeah, I mean, I don't really know what to say, except like phrasing it this way. Yeah, yeah. We don't really know exactly why. It just seems to that somehow the fact that you have this additional. The fact that you have this additional center direction in the background means that you have enough things to match and you have one parameter left over at the end, which can be anything. That was exactly Bion's reaction when I showed it. So I'm just curious. Did you try to to compute Hamakinix to Sabu? To serve separately, and then hemoclinics to the servo road record separately, just to see how they embed it in the picture. I'm just curious. I'm not exactly sure what you mean. I mean, if you have a heteroclinic connection, if you miss a data, you're going to come back to the saddle. If you're on a periodic or you miss the saddle, you're going to come back to the periodic orbit, which means you have. You would recognize it. Yeah. Which means you have hemoglinics to limb state, hematlinics to self-eurobit. My question was that. Right, if you can find the opposite. Maybe it's just a stupid idea at all, right? If you can find the opposite connection. So I don't know about this problem. This is something that Bjorn and I did have a look at in the Swift-Hohenberg case. And in fact, so that was like this geometry, I guess. And in this case, you actually can find that reversed connection. Connection, which I think we call the plateaus. But whereas you find these connections sort of for each value of your bifurcation parameter in a discrete family, you actually find one parameter family for each bifurcation parameter of these plateaus. I think. I mean, we didn't write this down properly, but. I'll show you the latest thing. Right. So. Okay, so. Okay, so let's thank Timothy again. Yeah, what I understood is there is a small grade. Yeah, maybe. Are you getting a confidence? Yeah, maybe if we do reconvene a water bath, I also need to go to the bathroom. Okay, so we have a quarter break. So we have a quarter break and then we come back for the round table discussion. Yeah, to have like around an hour of a little bit of a discussion, collecting some themes and so please come back in a quarter. Let's take a public quarter quite a bit. Yeah, also. I don't know, and then there was a question for us to speak.