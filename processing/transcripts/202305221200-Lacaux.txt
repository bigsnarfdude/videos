About Gaussian and stable skills on file paths. So, sorry for the delay. There was some trouble with my slide. I didn't sound the good person or you didn't sound like, I don't know. So, first, first time here, it's really nice. So, really, really thank you for the invitation. And I want to present a work with. I want to present a work with Fabrice, which is about fractional Gaussian fields on fractal. So, in fact, I would like to talk about the stable case, but it's still a work in progress. So, I will focus on Gaussian part. And if I have time, the two last slides are about the stable case. Okay, so to begin, I will give you some recall on fractional bonus. Some recall on fractional Bonnet motion really quickly, and the link that we can do with Laplace operator because our field are introduced using Laplace operator. Then, in fact, everything holds on general fractals, but we will focus on the talk on Sierra Pickin' gas cat to have a special example. But everything can be generalized using the same demonstration. Using the same demonstration of a proof. And I will introduce the fractional Laplace operator in the sample phonemen. And finally, I will give you what we have done, how we define fractional Gaussian fields on simple Skinget scat and what we have obtained. And so if I have time, what we have on fractional unstable case, which we should finish soon to write the paper. To write the paper, okay. So, to begin, what is fractional Bohnian motion on Rm? So, that is simply a central Gaussian film. So, you can characterize it giving its covariance function, and so the covariance function is there. And h should be between zero and one, I did and one, sorry, I didn't write this uh on uh the slide, and the more h the greater h is, the smoother the trajectories are. Are the trajectories are so you see that's from this example, okay? Very irregular and very smooth. So this field has a stationary increment, and you can compute very simply the variance of an increments. And the variance on the furniture is given by the distance between x and y to the power to h. So using now class. So using now classical entropy, what you can find you see that H will control the sample smoothness because you can prove by entropy method that there is a modification of fractional Bohr motion which satisfies this. So that gives you an upper bound of the modulus of continuity of the fractional Bohnian motion and it is really optimal. And you see that as a consequence, the sample path are in fact located The sample paths are in fact locally Elderian of index not h but gamma as soon as gamma is less is strictly less than h and as i say it is optimal that means that you cannot have trajectory with such that we are locally half a if gamma is strictly bigger than h okay so that is uh the kind of thing we would like to prove except that you you will see that i cannot conclude that See, that's what I cannot conclude that it's optimal in our case, but we would like to find for our fields some modules of continuity and try to understand to conclude about the sample path regularity. Okay, that's why I give you these records. Next, I'm going now to do the link with the Laplace fractional because I won't introduce fractional Bohnian motion using a covariance. So I will introduce it using Laplace operator. It's using Laplace operator. So there is a survey by Lodia, Sheffield, Sand, and Watson, a quite recent survey. And so they link fractional Bohrian motion to this random measure. So what is this random measure? W there is a Gaussian random measure, a white noise. So the Lebesgue measure is intensity. Delta is the lapel on Rm. On Rm, and so here you got a fractional Laplacian with the power s where s is positive. So you have to understand this measure as in the distribution sense. And so that means that if you apply this measure to a function f which is in the Schwartz space, you will say that it is the integral of the Laplace operator applied to f under w. Under double. Okay for you? So this implies that this random variable is Gaussian and this variance is the norm in L2 of the Laplace paratoly to F. Okay. And so reading the survey of Laudiar, what you can see is that there is a link with fractional Albonian motion, and it is the following one. Following one if s because this is done in Lodia and Al for any S, and I say that in for fractional Boolean motion there is a parameter that which is between zero and one. Okay, so for well-chosen S, S between n over over four, n over four plus one ohms, you can see that in fact this random variable is the integral of f times the fractional bony motion. bony motion dx and h is linked to s with the following relation so you can check that means that h is between zero and one and describes exactly zero one okay so uh in fact the h is simply the random measure x applied in some uh to the um direct distribution okay so that will be the point of view we So, that will be the point of view we choose. So, that means that in all the talk, what I will do, I will consider a fractal set, so it will be the Sierpinski gasket. I equip this set of a distance D and of a measure with a measure mu. And the fractional Gaussian fields on K will be introduced as the random measure, which will be the fractional. Measure, which will be the fraction, the Laplacian on the fractal k, the fractional La Pressian applied to W. And W will be a Gaussian random measure with intensity mu. So on the toll and also in the paper, we focus on K, which is the Sierpinski gas cut, for the distance which is the octadine one, but in fact, there are. One, but in fact, they are all equivalents, that doesn't matter. And the measure Î¼ is the Hausdorff measure on the Sierpinski gasket, but we normalize it so it is a probability. So the framework is good for you. Yeah? Well, on the subplicity acid, what is the Laplacian? Sorry. What is the Laplacian on the subplicity acid? Okay, so that will be the second part to define the Laplacian. To define the representation, right? Why do you choose this set, this fractal set? Just as an example. But my question is why it should be fractal. No, in fact, we can generalize several things to any metric spaces. But in fact all, there is some kind of fractal dimension of the set will play a little bit. Of the set will play a link, a role in the sample path regularity. You find something interesting. Yeah, it will really depends on the fractal dimension of cap result. Okay, so now the Schepinski gasket quickly. Maybe everyone knows, but that will make a nice picture. And the fractional Laplacian, which is the Neumann one, because you know that there is several Laplace operators. With several Laplace operators. So the Sierpinski gas cat, you can identify it in R2 first. You begin with a triangle, with vertices Q1, Q2, and Q3, which are given there, and you apply contraction function, which makes that if you apply the first one, zero would be sound to zero. This one will be sent to itself, and this one. Be sent to itself, and this one will be sent to itself with the other function. So, if you apply one time, you will send this triangle to this true one. And you repeat, repeat, you repeat, you repeat. And if you repeat it,     Okay, so one nice property of this measure is that it is Alforce regular. What means Alforce regular? It means that the volume of a ball is around air. It's like, okay, because you have an upper bone and a lower bone. Hormone and a lower bone, its behavior is like R22 to DH. And so dh is the Hausdorff dimension of my set. So here dh is ln of 3 divided by ln of 2. Okay? Right? So you won't see this anymore, except that I need it to explain why it is interesting for us. So now to define the Laplace. So now to define the Laplace operator, the first step is to define a quadr um a symmetric form. Okay, so we choose uh v0 the vertices and for any function f we define e n by this. So that's quite awful, but that means that here this point is in fact in a small triangle of order n. This point is in the same triangle of order n. So here you control So here you control the difference, the distance between two points which are in the same triangle to the power two. Okay, so you have the quadratic distance between two points which are in a small triangle. And you do this for all the triangles of order n, and you obtain which is the turn there. Okay, then to define the form, you are with a simplest proof that so far. A simplest proof that somehow we don't prove it's already done, in fact, that this defines an increasing function, and so there is a limit, and you denote by EFF this limits. So that this exists should consider f such that limits is finite. Great for you? And then what is classical? It's not our job, it's done by Kigrami. He will be a local direct reform. E will be a local Diracle form, which is a strongly local Diracle form on L2, where k is still B by mu. And when you've got a local Diracle form, you've got semi-Markov group and a generator of its Markov group. And so the generator will be denoted by delta, and it is the Laplacian on K. And since I have in. And since I have imposed nothing on the quadratic form on the boch, on the boundary, sorry. It will be the main Laplacian. Okay. And Fabrice and Lee has done the same work, but imposing that on the boundary the functions are equal to zero and they work with a direct application. With a Jiricle application. Okay, for you? So, one thing is important then, simply to introduce the last constant that will be of interest in the results is that so I say that you have a semi-group. So, you've got also a kernel for this semi-group, which is called the heat kernel. And Barlow Pankins has proved that this kernel is behavior is like this. What I mean by like this was to use. I mean by like this was to use in the slide that I can have an upper bound and bound PT by this up to a multiplicative constant and I have the same lower bound of course with another constant. Okay for you? And so d dw is called the work dimension of the Sierpinski gasket and is equal to logarism of five divided by ln of two. And since it is bigger than And since it is bigger than two, this call this kind of control sub-Gaussian estimates. So then we work on L2, but we impose that the integral of f is equal to zero. So we now consider minus La Persian, and we already know that it has again values that we can ordinate or donate. So I'll let. tonight so lambda one etc and we choose a non-tonormal basis uh phi j e j is associated to the eigenvalue minus namda j and you have this so this answer i think your question no two chain question i think what is how do you define laplacian so la placian is defined by ke game because Is defined by Kigami because we got the Dirich reform and then the location, the fractional Laplace. The fractional Laplace is defined using unorthonormal basis, and you decompose this F in is orthonormal basis, and you add a weight, which is one over lambda j to S. Okay, that's quite classical. I don't know with the density of the of the scale. Uh yes, uh uh up to uh we need to subtract. Yeah. We need to subtract one kernel. When we will define the risk kernel there will be a one and so in order to uh to um to ensure the integrability uh of uh the heat kernel. And so this explains why you need that the integral is equal to zero there. The integral is equal to zero there. Okay. Okay, so you can check that this will be a convergent function, and it is quite classical because you want that La Passion minus s applied to phij is equal to phij, since it is an eigen function, one over lambda j x. So you define Laplacian, I guess. It doesn't depend on the autonomal basis that you use. Whatever one you will have with. You will see the same result. Okay, so now I have this, and this will be again a function which is square integrable and with integral equal to zero. No other question? Okay, so now I have everything to define fractional Gaussian fins on Sierpinski-Gascat, but I have already given the definition. In fact, in the previous slide, I have said that. In the previous slide, I have said that we understand it as a Gaussian random module obtained via the Laplace operator. So what we prove once we have this is that for S well chosen, in fact, there is a density. I denote the density by x to delta. So I just see that I didn't write what I mean by density. What I mean is that now when you look at X applied to F, you can prove that it is the same as F. Okay, like it was written for fractional Bonion motion. Okay. So then we prove that this density has Alder sample path up to a modification and we control the Alder sample path by this quantity that we denote by H. Okay. So the question is, is it optimal? I come back to this after. Yeah. The measure on the density gasket. Yeah. What is the measure? The measure mu s, what is it? Yeah. So the measure mu s was defined there like this. There is an only solution that satisfies this. So that means that if you take a small, small triangle, which is obtained by as the transformation of the first the hugest triangle, apply n times, okay? Apply n times, okay, its volume is three to minus n, and there is only one measure that satisfies this, and this is called the Osdorf measure. It's uniform. It's uniform, right? Yeah. Okay. So H will not describe norm zero one, it will describe zero two and the And the upper bound is the dimension marsh minus the Osdorf dimension of your front. You can ask, okay, why S is between these two? In fact, first, Fabric and Lee has proved that everything also works if you replace Newman Laplace by directly one. And if you look at their work, you can also generalize this result and prove that there is a dimension. And prove that there is a dimension, there is a density for s bigger than one minus dh divided by two dw, but you won't have h equal to this, h with s equal one. Okay, so you won't be greater than this quantity. Okay, we didn't write it, but you can find it's exactly the same thing, and if s is less. And if s is less than dh divided by 2 dw, there is no density. Okay. So in fact, how we can do this, I will just define you x tilde. What is x tilde, in fact? And x tilde is linked to a risk kernel. So we define the risk kernel as this. And we need here P T won't be integrable on all R. On all r for the Neumann Laplacian. So we need to consider pt minus one. And one is the volume of the Osdorf measure applied to k. If the volume is not one, you should make a difference with the global volume of your space. And so this function, we can prove that it is square integrable and we can link it to the Laplacian. We can prove that in fact We can prove that, in fact, if you integrate this function times another function f with respect to mu, you obtain the Laplacian, the fractional Laplacian, of course. And so this allows us to prove that, in fact, the density of our fields is nothing else than the stochastic integral where you integrate now the Wyze kernel. So you can prove that I have exactly the same distribution. Exactly the same distribution and that they are equal. Okay. And then to obtain the sample path regularity, now you have an integral representation of your density. So you can use entropy method compute the variogram. Don't speak about variogram because we don't know if it is stationary, but you can compute the variance of an increment and try to control it using the distance and if we have a well control. We have a well control, it works. So, my time is finished, I think. But you will tell me. So, in fact, using classical entropy method, you can generalize the result I present at the beginning for fractional Boozy motion. You do not only have the trajectories, you can have an upper bound of the modulus of continuity, which is exactly the analog of the one I prove ion. I proved, no, I didn't prove. I proved, no, I didn't prove for fractional Bonal motion, the one I stated for fractional Bonyan motion. Okay, and from this, it follows that the sample path of this modification is Palderian. Okay. So the same has been done by Fabrice and Lee for directly elaboration. They also obtain on a problem of the modulus of continuity. So the question is: is it optimal? Is it optimal? We did not succeed to have an lower bound for the variance of the increment and how we obtain the optimality usually is using the lower bound that we have for fractional Bohr motion, but we don't have here. So it seems to be optimal because for fractional Boonian motion it is, but I cannot answer to this question. Cannot answer to this question at this time. So, there is a session of open problem. Okay, uh, no, because I have finished, it is time. So, you tell me. Yeah, I still have time. Okay, so one, due to, so now this slide is specific for CPRPinski gasket. Other things can work on general factors, okay, and even on some metric spaces. Some metric spaces, but in the Sierpinski gasket, there is several properties of symmetries. So, for example, you are symmetric with respect to this line, to this line also, and to this one. And this will have consequence on your field. And your field will satisfy exactly the same symmetry. So, that means that if you choose one of these free symmetries, you applied. Symmetry, you applied it and then you apply X. In fact, it is extended. There is a typo on the slide. It will have exactly the same distribution as your initial extender. Okay. Another symmetry, some kind of symmetry property, is that there is some self-similarity in the factors. So here you have self-similarity for. Self-similarity for the Sierpinski gas cat, and all we translate on our fields not simply. We cannot prove it, it is not true, I think it's not true, in fact, that our field is self-similar, but it satisfies a kind of self-similarity property. So, what you do, so f y, you just you apply n times one of the contraction function. Okay, you will then send k is. Will then send k easy image will be k index y i sorry then you can define the fractional Gaussian field on k1. You follow all the steps except that you will have a a measure which won't be uh of m of uh volume one, so you have to um to do P T minus the volume of K one. The volume of Ky. So you will define this new field, and then if you apply it to x, to f y, apply to x where x describes k, you can prove that it is exactly your fractional Gaussian fixed on k, but up to this normalization. So there is a kind of self-similarity, but usually self-similarity is this, but they are exactly the same kind. Yeah, sound true. And that's why we call this field fractional Gaussian fields of index H because H is linked to the self-similarity properties as for fractional Bohrian model. Okay, so quickly, quickly, what we are with saying that you're missing something because you only have the empty identity. Sorry. Yeah, you're saying that you cannot get the full scaling. Full scaling will be like this. For fractional Boonian motion, you have BH, the same BH. So you delete your space by epsilon. So you have the smaller space. Okay. This is in French. So, in the two parts of the equality, you have exactly the same field. Okay, there you don't have, and the reason is that there is some condition on the integral equal to zero, and so you don't have if you cannot preserve this condition when you contract. Condition when you contract. Okay. Else there is here, there is no condition, so you preserve the Laplace operator in this case. Okay? So I say I deserve the field in some aspect. You can use discrete random discrete Laplace and prove that it is an approximate approximation of this. Approximation of this one. You mean that this field is discrete? You mean that this? I wonder what is this? Xi is exactly the same field as X, but you build it on the smaller triangle. Okay, so for example, if I apply only one time one function f okay, my triangle will be Okay, my triangle will be one of these three ones. Okay, and I build the fractional Gaussian fractional Gaussian field, sorry, on this one, for example. Okay, and so XY is not the restriction of the fractional Gaussian field on the initial one. That's what is said. If it was a restriction, we will have exactly the same results as fractional Bohr merging. So quickly. Emerging. So, quickly, the idea: if you want a stable process, it's just do not consider a Gaussian measure, consider a stable measure. Okay, so what we have done more or less finished last week to write the paper. So, now we have to read and read and check that everything is okay, make the introduction, the conclusion. Okay, so we have replaced W by a symmetric alpha-stable random measure, and we can we uh And we also define our field x as a distribution. So that means that xs applied to f will be this integral and w alpha will have a control measure which is mu, the husdorf measure. Okay, so what you can prove is that s is large enough, so alpha is between zero and two, since you want stable process, if L is H. Process if LaRD is age enough, everything works. So that means that you will have a density, and the density will be given by the integral of the risk function, of the with kernel. Integral. This time I have written what is on the blackboard. In fact, we also prove that if S is less than this, there is no density. Okay, so this is optimal. So, this is optimal, and then we can study sample path moose, try to find if we have also an upper bound for the modulus of continuity, but we do not anymore use entropy method and we use some Lepage, some series representation of our fields and the gas here. I forgot the last. I forgot the last name, Rodmiss. Inequality. Okay, I forgot. So, what we proved, just to conclude that my last line, in fact, if S is small enough, there is the density is not anymore continuous. It is even unbounded almost only on your compact set K. Okay. And if S is large enough, there is a modification that. Is a modification that is continuous, and you can have an upper bound of the modulus of continuity. What here you found exactly the same kind of things that you have for Gaussian fields, except that you have not the same exponents. Okay. And the logarithm term, I don't explain you what is beta, but is not for Gaussian case, it was one half, so sometimes it is one. Half so sometimes it is one half, sometimes it is three halves, but it's classical that uh it changes for stable fields. So, at the beginning of first me, I was surprised to find that there were unbounded trajectories for S small enough, but if we look more clearly what we obtained during this for occluding calc, we can easily check that in fact the field which is obtained, okay, it is a fractional Bohnian motion, but it corresponds to what. Bonyan motion, but it corresponds to what we call the moving average representation of the fractional Boon motion. And so in stable case, that means that we will have what has been already a lot studied, which is called moving average fractional stable motion. And what we know for this moving average fractional stable motion is that in dimension n equal to one, this h is. Equal to one, if h is less than one half, there is no trajectory which is continuous. The field is unbounded almost only. So it is consistent. Okay. When h is bigger than two, in fact, since h is always less than one half than n divided by one half, the field will be on board also almost. This is also a motion. So we don't have this case for fractional Bonian motion when n is bigger than two. So now, just since you will have the slide, all the paper that I have cited, but it's just a non-exhaustive bibliography, and thank you for your attention. Thank you very much, Selima. My questions. You said you were applying a Gaussia type layman for your it works on a factor first get this Gaussia type yeah but it has already improved been proved by I think Barlow and Perkins that it works on Barlow spaces and so Sierpinski gasket well when I say that it works on fractals I mean the fractal of Barlow and so Fractal of Barlow, and so each works the Gaussian Lorenz inequality has been proved. But did you do it on fractals or general metrics basically? If we want to extend the work on general metric spaces, we need Garcia-Ramson general metric spaces. But we can do also like we in the Klining case, we have worked a lot with Hermin Biame on such stable fields, and we do. Stable fields, and we do not use Gersh-Aramson inequality. So there is several, but if we don't use Gercia-Rams inequality, we have to find the other way to do this kind of things is to define a sequence which is dense on your metric space and that you control the distance between each term of the seconds and you control the number of points that you have. Number of points that you have in any ball. Okay, so you can have also other kinds of methods. But since Garcia Ramsey works, it's simpler, I think. So is the basic philosophy of this regularity theorem? Is it along the lines of Kolmogorov's regularity? For the Gaussian case, yes, I can say yes, it's listening to Kolmogorov in terms of lemma. Yeah. For the stable case, in fact, we use a series of presentation which allows to say that conditionally to several things, I can consider that I have a Gaussian field. And so we apply some kind of results that we know on Gaussian fields, like for example, what you say, and we prove that it still works when we come back to the stable fields. I think we have a question from Daval. I see why the reason that I'm here. Dabal? Yes, so if I may, just as a quick check if I understood what happened. So if you look at your fractional Brownian motion on the Sierpinski gasket, when h is one-half, is that the same as the barlow? The same as the Barlow Perkins Brownian motion on Sir Pitsky asked it? I think so. No, because that's not the same because for Barlow Perkins, he indexed the Finn the Field index bar R with value in the Sierpinski gasket. Sierpinski gasket. No, that's this. Here, my fins are indexed by the Sierpinski gasket and take values in R. Thank you. Sorry. But the kernel is the same, the it kernel is the same. Thank you so much. 