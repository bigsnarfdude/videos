The highly complex critical behavior from the intrinsic randomness of quantum mechanical measurements on critical gravity. Yes, hello. Can you hear me? Yeah. Okay. Well, thanks for the organizers to give me the opportunity to give this talk. Unfortunately, I originally wanted to come in person, but there was a change. In person, but there was a change in schedule that in the end prevented me from doing that in the last minute. So I'm giving this talk virtually. I hope you can still understand what I'm doing. So I'm talking about, I'll be talking about the effects of measurements, quantum mechanical measurements, on critical measurements. Measurements on critical ground states. And the basic idea is that, as I'll explain in more detail in the next slides, that the criticality of the critical ground states, like an icing model or something like that, is dramatically changed by the presence of measurements in a rather radical way. And so there is a new scaling behavior. is a new scaling behavior emerging, and that scaling behavior is much, much richer than the scaling behavior in the critical ground state. And so I'll present a controlled RG analysis, an epsilon type of expansion, to access the scaling behavior. So that's work I've done with my student, Rusika Spatil, at UC Santa Barbara. UC Santa Barbara. So can you see the cursor? Yeah, I think so. So the effects of measurements, especially in the context of the measurement-induced phase transitions in deep quantum circuits, which I'm not talking about, but is sort of background. And I don't expect the audience to be familiar with that. So the effects of measurements in these circuits. The effects of measurements in these circuits have attracted significant attention in the last years. However, so these are new phase transitions out of equilibrium. However, there isn't really any good analytically based tool for understanding these transitions in some analytically controlled way. So there is a variant. There is a variant of this which looks very, very different, which is more tractable. And so another set or class of interesting quantum systems subject to measurements was introduced in 2023 by Garrett, Weinstein, and Altman. And there have been a bunch of papers, several papers, on this topic. This topic considering the effects of measurements on quantum critical ground state. So, as I'll explain, what I'll be doing is somewhat different, but in the same spirit from most of those papers. So, let me go to that. So, the aim of this talk is really to that we show that performing measurements in this case. Performing measurements, in this case, will be weak measurements. I'll be briefly reviewing what that means without post-selecting the measurement outcomes on quantum critical ground states of 1D Hamiltonians, critical Hamiltonians, that could give rise to very rich and actually highly complex, completely novel scaling behavior. And that is due, that novel scaling behavior due to Behavior due to the intrinsically interministic, that is, random nature of the quantum measurements, of quantum mechanical measurements. So if we know, if we do a measurement, you have a state on which you do the measurement, and you measure an operator, but it's intermittent deterministic. You don't know which measurement outcome, which eigenvalue of the operator you get. There's just a probability description. And so what this talk: Description. And so, what this talk is about is precisely that probability. So, in a way, this can be viewed as part of a general theme of preparation of novel quantum states using measurements. That has been an interesting theme in recent years. And so, here the state we will prepare, we will get is a rather complex state, but in addition to the In addition to the idea of the concept of state preparation, the state that is being prepared here, the novel state, has rich universal critical scaling behavior. It's sitting at an RG fixed point and has universality and that of a kind that is qualitatively new and not seen in measure unmeasured quantum states. Measured quantum states. So, in a way, the key point of the talk is, which is that we illustrate this general notion, this general idea, with explicit and detailed RG calculations that we can control analytically in the two examples. So, well, well, I present two examples in the two examples we present. And so And so again, such new critical behavior arises from technically, as we'll see, a so-called measurement-dominated RG fixed point, where the strength of the measurements is finite. It occurs at a finite measurement strength. And we will show how to analyze explicitly in the examples that we give. That we give using these controlled RG analysis and epsilon expansion. And so to come back to the earlier motivation of measurement-induced phase transitions and circuits, so this is easier in the problems I will study here in these problems of measurements on critical quantum states than in the general. Than in the general system in the other systems, which are the measurement-induced phase transitions and quantum circuits. But the scaling behavior is similarly rich and in a way qualitatively similar. Are there any questions about this? Okay. So that's the purpose of a talk. So that's where I want to get. So that's what I want to get at. So specifically, I will illustrate the effects of weak measurements on in certain examples and the effects of weak measurements on quantum critical grounds in examples of A, the tricritical, the one-dimensional tricritical, and B, the critical quantumizing model. And so in cases A and B, we will. We will do measurements in A on the local energy operator and in B just on the local spin operator in a quantumizing model in a lattice formulation. And so by applying a controlled RG analysis, I'll present, we find that both problems exhibit a qualitative new rich scaling behavior governed by a measurement-dominated or We're governed by a measurement-dominated RG-fixed point, which we analyze with an epsilon expansion, which I'll define. And so, conceptually, since I have a finite strength of measurements, there's no post-selection. The measurements are intrinsically indeterministic and are random. So, this is a problem, in a way, if you think about it technically, of a random conformal field through. Of random conformal filters, random CFTs, CFTs with randomness. Okay. So the results that I'll highlight that highlight the complex rich scaling behavior are the following. So we can, in the measured states, In the measured states, we can measure correlation functions of local energy operators or local spends. But these will depend on the measure and the outcomes of the measurements I've done. And so now there's an infinite hierarchy of independent critical exponents which correspond to energy correlations or spin correlations, and this is called a multifractal. This is called a multifractal. I'll explain what it means. So, I can calculate the energy-energy correlation, the two-point correlation function of an energy operator in a fixed set of measurement outcomes, raised it to some power, and an average of all the measurement outcomes. So, depending on the power, this correlation function decays with an exponent, and that exponent The exponent, and that exponent will depend on the power I've chosen. They're completely independent exponents. It's an infinite hierarchy because I can choose any power. And so, another way of thinking about this, there's actually a continuum of critical exponents, which I will probably come back to. Another feature is so these are fixed points and involve CFT, and in these systems, due to the system, In these systems, due to the indeterministic nature of quantum measurements of randomness, there are in certain correlation functions that we can describe, there are logarithmic factors multiplying power laws. So typically, at a critical point, two-point correlation functions just decay at a fixed point, at a critical point, with some power law. With some power law. But in these kind of systems, the power law is multiplied by the log of the distance of the two points. And that's a hallmark of what is called logarithmic CFT. So this is an example of a logarithmic CFT. Now, then we can ask questions about entanglement measures and the usual simplest inflation. Usual simplest entanglement measures are the nth Reni entropies. So the Nth Reni entropy, so this is a critical system. It behaves like the logarithm of the size, in this case an interval of the length of the interval I'm looking at. And so there's And so there's a universal number in front, which is sometimes called the effective central charge. And so it turns out, so we calculate those, and as opposed to ordinary CFTs, which are just ordinary unitary CFTs, that is, for example, the unmeasured CFT in the critical ground state. State. There's an independence of this effective central charge. This is not the usual one. So all these Rainy entropies come with independent coefficients in front of the log of a subsystem size. And so we can calculate them in an epsilon expansion, these universal numbers. And finally, I'll talk about a connection with boundary CFT. With boundary CFT. So I will explain that this is a problem of a boundary CFT. And so at each boundary CFT, there's a universal number which we described in an old paper in Affleg and I, which is a universal number called the effective boundary entropy, the boundary entropy. And so in these problems, there's also such There is also such a universal number which I call the effective boundary entropy, which I'll describe. And however, interestingly, this boundary entropy can be related to the Shannon entropy of the measurement record. So what that means is that if I do measurements, I get some measurement outcomes. I'll be more explicit. And so there is a probability distribution, which is a Bohn rule probability distribution. The Born rule probability distribution to get those measurement outcomes. So, this is a critical system. So, I can calculate the, I can consider the Shannon entropy of this probability distribution. And it turns out that this Shannon entropy is related to this boundary entropy that is available and was discussed in the paper many years ago on the boundary entropy. So, a subset of So a subset of these results, so so far I've talked about the tricholizing state, the measurements on the ground state of the trichirlizing model. So I will spend most of my time here. And so there are equivalent results when I do measurements with the spin operator, sigma z, of the transverse field quantumizing model. All right, are there any comments, questions? All right. So let me go to the details. So I will discuss the tricritical quantumizing model. It's conceptually the simplest place to discuss. So it is convenient to use a particular lattice regularization of the tricholizing model, which was is due to O'Brien Findlay. Due to O'Brien Findlay, which has just a spin one-half a qubit Hilbit space at each lattice side. So there are two degrees of freedom. And so the idea is very simple. So even though it's not obvious, so the transfer field quantumizing model has this Hamiltonian 1D lattice, and we add some term which involves three spins. Spins and this is the H3 term. Oops. And so obviously the Ising term is invariant under Cramus-Vanier duality, but it turns out that H3 is also. So I add H3 with a coupling lambda 3 and I get a one-dimensional phase diagram, if you want. So when lambda 3 is zero, I get the triangle icing, I get the icing model. Triangle icing, I get the icing model, the critical icing model. And if I crank up this lambda recoupling, at some point I get the tricritical icing point. And if I go beyond, I get the gapped phase in the tricurtical icing system. So we use this. It's convenient. It has a spin one-half qubit Hilbert space. So at the tricurtal point, these operators. The these operators, sigma z, sigma z, and sigma x, can be described in a continuum language by identity operator, where the coefficient of identity operator is non-universal, it's an expectation value. But then it has the energy operator. You get the energy operator trigger Ising model, which has a known scaling dimension. You get the sub-leading energy operator. You get the subleading energy operator, and you get the next subleading energy operator. And what is important to notice is that there are two different, the sign change between this and this. And so we define this operator, which is sigma z, sigma z at nearest neighbor lattice sides minus sigma x. And so this is an operator. So this is an operator involving two sites, neighboring sites. And if you it turns out it changes sign under Cramas-Vanier duality. So here is Cramas-Vanierni duality. If you take this operator, it changes sign. Moreover, this operator is simple in that you can square it. And if you simple algebra, if you work it out, the square is always the identity. The square is always the identity. So this operator has only eigenvalues plus or minus one. And so in the triggerizing model, we make the measurement protocol that we measure this operator on all the even links. So it's an operator involving links, JJ plus 1. And so on even links, all these operators commute. And we can just do measurements of this operator on all the even links. So when we do that, Even links. So when we do that, we get a set of measurement outcomes plus or minus one, one for each even link. Wow. Comments, questions? All right. So the next thing I want to just probably review, I want to review the idea of weak measurements and cross operators. So this is technology we This is the technology we use. So we have these measurement operators, and so just for notation, we don't denote them by lattice side plus one half in the middle of two lattice sides, but just on J, which is the left lattice side of the two. And so there's this measurement operator, and there are objects that are called Kraus operators, and so they have. And so they have the measurement outcomes m, which are plus or minus one. And so these cross operators, they can be rewritten as exponentials of measurement operators because the operators e squared of one. And so these cause operators satisfy the so called POVM condition, which is crucial for anything we're talking we're doing here. thing we're talking we are doing here is called the it is a positive operator valued measure we don't need that it's just this property at every lattice side these operators satisfy this property so these are weak measurements in the sense that there's a parameter lambda in there and if the parameter lambda goes to one here then I get projective measurements strong Projective measurements, strong measurements. And so these class operators just project onto the eigenstates of the measurement operator. So what we have now, we have the unmeasured state is the quantum critical state of the tractalizing model. It's a complicated state. It has scaling. And so there's a Bohr rule that says that the probability to get a set of measurement outcomes M. A set of measurement outcomes m on all the lattice sites is just given by k dagger k expectation value in the ground state, where k is now a product of all these k i's over all the even sites and is their mission operator. And this also satisfies this POVM condition. And the POVM condition allows us, says that I have Says that I have a normalized probability, born probability. Are there comments or questions about that? All right. So continuation of weak measurement discussion is that, well, after obtaining a set of measurement outcomes plus or minus one on all the even lattice sides on the unmeasured state, the unmeasured state becomes the post-measurement. State becomes the post-measurement state, and it's the state. It's the cross-operator applied on that state divided by the norm of the cross operator. So that's the state that I get after doing measurement, after doing measurement with these measurement outcomes. And the Born World probability I've written again here. Are there any comments, questions? No. Now so what we want is we want to measure observables in the presence of measurements. So this is a very general discussion. So OI is a local operator or a product of local operators. So a convenient operator is, for example, the product of two operators at different sites, which I calculate the average. If I calculate the average, I get a two-point function. Two-point function. So OI could be a product of two spins at separated by some distance or many other things. And so for technical reasons, to make the discussion simpler, we first assume that the operators we discuss, whose expectation values we want to calculate, are commute with these cross operators, which have to do with measurements. And so Do with measurements. And so now the following calculation brings in the number replicas, the number of replicas to do these calculations and of averaging over measurement outcomes. So the averaging of measurement outcomes is the over bar. Oops. Is the over bar here. So let me explain. So we introduce our replicas. So let me. R replicas. So let me, where does this come from? So we want to calculate the expectation values of, let's say, of these operators, O1 until ON, each one in the post-measurement state, characterized by measurement outcomes, vector m. And then we want to average over all the measurement outcomes. So in the next line, this is written out explained. This is written out explicitly. So there is the born probability P0 for obtaining a measurement outcome. And then next to it is these expectation values of these operators. And so we just use this formula here from the previous slide. And so this can be written as, well, we can just collect all. Well, we can just collect all the powers of this P0, P0 was this, and we can write it in an unnecessarily complicated way, where we, so there is, of course, n minus 1 powers, but we can write it as limit r go to 1 and take the power r minus n. So this will be relevant for the discussion, this limit. And so. And so this so it's just rewritten. And now we can work in a tensor product Hilbert space, which is the tensored Hilbert space of the ground state projectors and all these operators k. And so the operators that we actually want to measure, the O1 to O n, form the first n factors of this tensor problem. Of this tensor product Hilbert space, and there is a remaining R minus n factors where there's no operator. So this trace is a big trace. So we calculate that big trace for arbitrary number of replicas bigger than n, and then take the replica limit r to 1. So that idea goes back to the papers that were done in the quantum circuit language. But so here it's very simple to explain. That's all we do here. Explain, that's all we do here. Are there questions about this? Okay, one comment is that if I have just a single expectation value of an expectation value of a single operator, nothing happens because then I just get this condition. And since the sum over the M measurement outcomes over K dagger K is one, I K is 1, this is unaffected by measurements. So this POVM condition implies that if I just measure a first moment of an operator or a product of operators, this is unaffected by measurements. So the next step we do is we generalize or soften the measurement outcomes. So the measurement outcomes M of I. The measurement outcomes m of i, i is an even lattice side, had previously only values, could only take on values plus or minus 1. And in these exponentials that we wrote, rewriting the measurement operators, there was a variable lambda tilde m. So lambda tilde was a strength of the measurement that we do. And so now we generalize this to We generalize this to a real number. So the cross operators are now looking like that, where Ti at the even lattice side is a real number with some distribution. And that is a generalization of the previous case, because in the previous case, that Ti, so the probabilities was just a sum of delta functions, where Ti is either plus or minus. Ti is either plus or minus lambda tilde corresponding to two values of mi. So this is a more general way of describing the measurements. And it turns out that will not affect the universal physics. It turns out the universal physics will only depend on the cumulants of, actually, on the second cumulance of this distribution and will be unaffected by any further details. That comes from. The details. That comes from the fact that we consider universal, we're interested in universal properties. And so, given that, we will just replace this sum which appeared this term here. We will replace it. Instead of the sum over the measurement outcomes, we have the integral over the continuous measurement outcomes weighted. Continuous measurement outcomes weighted by the probability weight. And this k dagger k raised to the tensor R is just taking that form where the index A goes over all the replicas. So there is a tensor product of the Hilbert space raised to the power tensor R. And so E hat A acts only on the H H H H H H H H H Acts only on the eighth factor and acts identity on all the others. And so the t's come from this distribution, and distribution implies, so we choose a mean zero, because that's what the mean was for the m's. There were just plus or minus one at every lattice side, i, even lattice side, and it has some kind of variance. And uh, so uh So, the variance is a measure of the strength of the measurements. And so, now we are supposed, we need, in order to evaluate these expectation values, we need to do the sum. The sum has turned into this integral, and so we have to figure it can contemplate this integral. And so, this integral And so this integral can be viewed as, it can be handled with a cumulative expansion. So it's an average of an exponential of something involving a random variable. And that has a cumulative expansion. It's an exponential of the cumulants. Here's a second cumulant. Of the square of what is multiplying the random variable. And there's higher cumulants. I've not written the higher cumulants. As it turns out, they are randomization group invariants. Riemannization group invariant, as I'm not explaining, but we can show in the paper. So after all the dust settles, we have to contemplate this exponential, and the exponential involves a sum, the square of this sum. And so now I can, there are terms where the EIA is squared, but this gives one. But this gives one, and so this gives a trivial factor. And there are terms where the EIs are in different factors, different replicas, different factors of the replicated Hilbert space. And they have to be the only terms that remain are where A and B are not equal. So in the end, the observables that we calculate, we need to calculate, or want to calculate, are given here, where we operate, we have a We operate, we have a trace over the replicated Hilbert space, and we have the operators that act on the first n factors and the remaining r minus n factors. And we have an exponential of this term, which involves the operators that we measure, but in unequal replicas. So that's the basic thing that comes out of measurements. And so now. And so now we will treat that in a field three formulation. So, what comes on the next slide is just translating this in a field three. So, the idea is that if we project on the critical ground state, we can think of this as the zero temperature limit. The zero temperature limit of the Boltzmann factor. And this can be written in terms of a path integral. Maybe I don't have to explain this. It's probably known. So I work in a space-time space-time. And so there's imaginary time going from 0 to beta over 2, or from 0 plus or 0 minus to beta minus. Plus or 0 minus to beta, minus beta over 2, their periodic boundary conditions. And so if I let beta to infinity, I project onto the ground state at the time slice tau equals zero plus or minus. And that is this here. And I have to use the weight. So here we have theories, we have conformal three ground states. I think. States, Ising models. We here we discussed the trichlising model. So I should use the Boltzmann weight, the action of the trichlizing model. I write it in the Lander-Ginsburg formulation and using, so because that's intuitive, I could write it. We later use conformal filter ideas. But so Uh so uh uh so we have to use the action, so we have to do a path integral uh over the space-time. And uh now in the the only effective measurements is on the on the time slice at tau equals zero. And there we have the action, the conformal field reaction in space-time, but at a zero time slice, we have this operator that is. Have this operator that is just coming from translating the operators EI, EIA, EIEJB in different replicas into field-through language where they become operators. So I'm talking about the trichalizing model. So tricholizing model, the energy operator is phi squared in Lambda Ginsburg, or phi one two in Kupp's language. In cuts language and cuts table language. And so the scale dimension of the operator E is one-fifth. And so this is on the boundary, on this space. And so I have two-fifths as a scaling dimension of the product of the two epsilons. And that's a relevant perturbation on the time slice, which is a one-day thing. And so we do a controlled RG in the Controlled RG in the sense that so this is of course relevant, and so delta is a coupling constant of this disorder, which is just up to a trivial constant, the strength of the measurement. So if I turn on measurement, I get a relevant operator, and it flows away to large values. And so we sort of it flows to large values. It flows to large values, and so we control this user expansion. So we realize that we want the tricholizing model. The tricholizing model is a member of a sequence of models which is the conformal minimal models with index M even and Even. And so, but that one we can also think as the Q-state trichralopots model with a value of Q which satisfies this relation. So we're going through all the minimal models of the CFT with even M having those central charges. And in those, when we think about them as a POTS model, the energy The energy these are tricruital Q-step POTS models and M is even. And the energy operator is the energy operator of that trichriggle Q-state POTS model. And if we look at the dimension, so dimension of the energy operator when M goes large, goes to one-half. So we have two energy operators here. So that goes to one. To 1, so the dimension of the coupling constant, which is that of the perturbation we add, is 1 minus this dimension, twice the dimension of the energy operator. It is small and goes to zero. So as we approach the four-state POTS model, this becomes marginal, but if we lower four dimensions, this is slightly relevant. So we can do an epsilon expansion, and that's what we do. An epsilon expansion, and that's what we do. So, this is analogous to the epsilon expansion in Wilson-Fisher, except that in this case, the dimension of the space-time always remains 2. But instead of varying the dimension of space-time or space in Wilson-Fisher, in the Wilson-Fisher-Epson expansion, here we vary the central charge of the unmeasured conformal third 3. So, in practice, it's a Q-state POTS model with values of Q. State POTS model with values of Q related to M. And so we can think of this as varying the number of POTS states in the Q-state triangle POTS model away from Q equals 4 downwards. So it's an expansion in this parameter. And so then we can do an epsilon expansion. So let's see. So I should ask: how much time do I have? Am I close already to the limit? Okay. How until what time do I have? Until 10.10. Okay. 10.15. Okay. So we did just do an Epsom expansion. It's a standard idea. So we have a coupling concept, which is the strength of this measurement, and it flows away. And it flows away, but if I control it with epsilon, which epsilon is small when M is large, M refers to picking a POTS model that is close to the four-state POTS model, then I can control the beta function. So, you know, the beta function to one loop order, simplest case, it's controlled by it's given by looking at the OPE of the perturbing operator with itself. Of the perturbing operator with itself, it gives the perturbing operator back. And there's a number which I can calculate, which turns out to be r minus 2. R is the total number of replicas. And so remember, R should be 1 here, so B is negative. So I get a one-loop RG equation. And so Y is the coupling constant, sorry, is the scaling dimension. Sorry, is the scaling dimension of the perturbation, which is small going to zero. And so I get this beta function, this Rg function for the coupling constant. And so it has a fixed point which is controlled by y, which is proportional to epsilon and with corrections. So it's epsilon over 4. It's epsilon over 4, 2 minus r. And so we have r smaller than 1. So this coupling constant, the fixed point, is non-negative, positive. And that needs to be so because delta should be a second cumulant of a probability. So there is a control fixed point. So there's also a two-loop result, which I'm not talking about how to calculate it. Calculated. And so, what I just like to. So, what do we do with this? So, we have a fixed point, this is controlling the epsilon expansion. And now we can discuss observables. So, one observable is to, for example, calculate the correlation function in the tricolorizing model of the sigma z operator. And it's convenient, so we look at it at odd sites, so only at odds. Sites, so only at odd sites, and then these commute with the measurements which are taken at even sites. We can generalize that, but for simplicity, let's not talk about this. So in a fixed realization, in a fixed measurement outcomes, fixed uh set of measurement outcomes, we can calculate the two point function of the sigma z operator at different odd sites, i and j. Odd sides, i and j. It's a random number depending on the measurement outcomes. I raise it to the nth power, and then I average over measurement outcomes. So how do I represent this in a field three that I described? We just have to calculate the two-point function of an operator, but that operator is just a product of all the spin operators that I want. Operators that I want to measure in different replicas. There's n factors, and so this calculates the nth moment in the replica formulation. And these are all calculated in space at the zero time slice in imaginary time. And so now, how to calculate the scaling dimension of this two-point function? Well, we again use Well, we again use an OPE. The one-loop calculation is simple. So we have to just remember that the spin field in the generalization of the ising trichele point to the tricheleq-state POTS model for these values of Q when M is even, so that scaling dimension in the unmeasured state is known. And so the so then we need to consider the OPE. To consider the OPE of, just as we did before, of the perturbation with this operator. And so this OPE is easily calculable. I don't have to talk about the details, but it's simple. So the perturbation with the operator gives the operator itself, and there is an OPE coefficient that depends on the moment order. And so that, in the end, So that, in the end, tells me what, to one loop order, the scaling dimension is of the decay of the nth moment. And so if I work this out, I think I'm running late on time, it's n times the scaling dimension of the operator in the unmeasured theory times the correction that comes from the measurement. And it involves epsilon and it was the number of replicas. The number of replicas goes to one. And there is an OPE coefficient that is. There is an OPE coefficient that is calculated in the POTS model. And so it turns out, so in that POTS model, I can go to epsilon equals zero. I can evaluate that at m equals infinity, epsilon equals zero, because there will be just a correction, which is order epsilon, which I would have to factor in and contribute look at when I look at the order epsilon square corrections of the scaling dimension. But Of the scaling dimension. But to get the basic physics, it's enough to do the one-loop calculation. So the scaling dimension with which this nth moment decays depends on the moment order n. And so this is calculating epsilon expansion. So epsilon is really 3 over m plus 1. And so m will be equal to 4 in the trichoidal IC model, but they do the epsilon expansion coming. Model by they do the epsilon expansion coming from M large. The same idea as in Wilson Fisher. And so what I see is that there is the moment the exponent that I get for the decay exponent of the moment depends quadratically on n. So that will be becoming more complicated and worse. There will be higher powers of n of the moment order appearing in here. And so all that, what this says is physical. What this says is physically that instead of a spin-spin correlation function with the unmeasured state decaying with one exponent, all the moments decay with different exponents. So that is usually referred to as a multifractal. And it comes, of course, from the fact that there is the disorder, which comes from the randomness of the measurement outcomes, that they are unpredictable. And I have to uh go through this replica calculation uh uh to to To understand that. So there is a second thinking, a second thought that goes with this. So these are really moments of the spin-spin correlation function averaged over all the measurement outcomes. So they all decay with some critical exponent that decays with some exponent depends on the moment order. So since this is really a property of a fixed point, of a Of a fixed point, of scaling, that must mean that underlying this is a probability distribution for the random variable, which is the two-point function, before I do the average. And that must also scale. There must be a scaling form of it. And that scaling form is known. I haven't written it down yet. But once I know the probability division as a scaling form, I can take n away from integer n. Take n away from integer n, I can take n real. And so then the exponents will just turn out to be continuously pending on n, the real moment order. So I get a continuous spectrum of scaling exponent due to the measurements. So I have a lot of more things on the slides, but maybe that's all I can get to. All I can get to organizers. Can you tell me, Sarah? Yes, I think you are. Should I wrap up? Hello? Yeah, hello? Yes, go ahead, wrap up. Wrap up, okay. Right. Okay. So I've gone through this piece, and so maybe before, so that. For so, so that so the key idea that I just want to emphasize is that there's a field three, and the field three is a field three, is a CFT, and the only effects of measurements are in space-time of a CFT, in imaginary time, tau equals zero time slice. And there's a relevant perturbation which comes from the measurements. And I've not post-selected. And I've not post-selected the measurements. I've just asked let the measurements do whatever they want to do. And so that leads to relevant perturbation at that time slice. And we use the Epsilon expansion to arrive. So there's a relevance, so in general it flows away, but through the Epsilon expansion, we can control Control the strength of the measurement strength by a small parameter epsilon, which is the idea of the epsilon expansion. And then I have the standard epsilon expansion tools to calculate observables in this epsilon expansion at this fixed point. The fixed point is interesting because it's a fixed point with finite measurement strength. So all the measurements. Measurement strength. So all the measurements take place randomly, and it's a problem of random Kerkle behavior, really. And so one feature, one consequence of that is this multifractality of the correlation functions of, let's say, spin. There are other correlation functions of energy, and so we have discussed. And so that was the first part of the results section that I. Of the results section that I mentioned at the very beginning. So similarly, one can discuss at this fixed point the presence of a log CFT, and one can calculate entanglement, which I'm not going to get to, and show that the coefficients of the log of subsystem size in all the Rhini entropies are numbers, universal numbers, depending on a fixed point, which can calculate the Epsom expansion. Can calculate the Epsom expansion, and the Epson shows me that for different ends, I get completely unrelated numbers. And finally, I didn't get to the boundary entropy, which is related to the Shannon entropy of the measurement record, which is just at the fixed point, there's a born probability to obtain any set of measurement outcomes. It's some probability depression, which we have control. Probability diversion, which we have control over in the epsilon expansion. And then we can calculate the Shannon entropy, and we see that that Shannon entropy is related to the boundary entropy related to that defect in space-time that is now appearing here. So that's all I have to say for now. Thank you very much for listening. I have one question. Better than if you don't use the energy operator but you use like X or Z I have a hard time hearing you. Would it be possible to maybe talk more loudly in the microphone? Microphone? Yes, so if you don't measure the energy operator, but you measure X or ZZ. Here now. So you're asking, I have discussed the measurement of the energy operating tricolorizing model. Are you asking what happens if I measure some other operator instead? Measure like X or Z J plus 1 that have a non-zero expectation. Have a non-zero expectation value? I have really a hard time hearing you. So you're talking about measurements. So I'm measuring the energy operator, and that's what we are talking about here. Yeah, here, if you measure the operators which are on top of your slide. Yes, yes, yes. A linear combination of those, yeah, the difference, yeah. Yeah, so if you measure. Yeah, so if you measure that, then you have an unsuited expectation value, right? I have an expectation value, but in the difference, the expectation value drops out, right? It's the same. If you measure sigma x, for instance. Right. Yeah, okay. I understand what you're saying. So if I just measure sigma x, I may run out of this fixed point that I discussed with a relevant perturbation. Discussed with a relevant perturbation. So I end up with a system that actually corresponds to just uniform measurements which are post-selected. Because that's great Chromas Vanier duality. So the main difference is that it's still a relevant perturbation, but basically you are not grabbing all the different references, right? Replicas, right? I'm not what? Says again? So the main difference is that you are not capping the difference replicate with the government, even though the perturbation is relevant? Well, if I don't measure this operator, but measure something else, like the sigma x, right, then I don't stay at this fixed point. I go to another fixed point, which is a much simpler fixed point, in which I Much simpler fixed point in which I don't have all these features coming from the randomness of the measurement outcomes. That's what I mean. I cross over to another fixed point, which is simpler. Thanks. Page 13 of 14, please. The definition of a coalition function. Say, I really have a hard time. You say, say this again. Have a hard time. You say, say this again, maybe slowly and loudly. Sorry. Page 13 once again. I cannot hear. What are you referring to? Say this again. Can you show the next pages, please? Oh, the next pages. Okay. Okay, I can do that. You mean you. 13. Thirteen, but page thirteen twelve or thirteen, yeah, thirteen the definition of the correlation function, right? Oh, you want the page with a correlation function? With a definition of the correlation function, yeah, okay. Oh, the definition of a correlation function, okay, good. Function. Okay, good. That was here. So I take each one of the operators to be the same, but it's not just a local operator. It's a product of two local operators. It's a product of two spin operators separated by some distance on a lattice. And all the operators O1 until O are just the same operators, a special case of this formula, right? Okay, thanks for the index. Okay, thanks for it. The index does not refer to signs or anything. No, the index refers to just an operator. Yeah, maybe I could have chosen a better notation, right? So it's a very, very general formula. I can take, you know, it allows for expectation values. That is, the over bar, the expectation value means I sum over, I average all the measurement outcomes. But I can take different operators or two-point function of. or two-point function of, you know, I can take the in O1 could be a two-point function of a spin operator, O2 could be a four-point function of an energy operator, or it's a very general formula. Thank you. So to put this in maybe to use, it's been put to use in that section here. So this is what I didn't get to. But so this is a very unusual CFT. Is a very unusual CFT, right? Because it's a log CFT. So it's not obvious that it is one, but it is one. And the Epsilon expansion can prove that it is one. And this is a slide that proves it. So I haven't explained how to get this formula. But if you calculate this particular observable, so I take two lattice sites, I and J, and so. And measure this correlation function or linear combination of correlation functions of this particular moment. So it's an unusual thing, but it's an example of this previous formula that we just discussed. So O1 is EIEJ, O2 is EI, and O3 is EJ. In the first In the first term. In the second term, you know, I have O1 just EI and O2 is also EI, so again, the second moment, and O3 is EJ, and O4 is EJ. So it turns out, so this is an example of this big formula turned into real life where we actually calculate. Where we actually can calculate something with. And so the peculiar thing is that at this measurement-dominated fixed point, where is no post-selection of measurements, I let the measurements do whatever they want, I sum over all the measurement outcomes, I get a power law whose exponent we can calculate. It's one of the previous slides. It's all in the paper. There's a fairly long paper about this we wrote. It's on the archive. But the power law is multiplied by a Power law is multiplied by a log. So that shouldn't happen in ordinary CFT, but it turns out in log CFT that happens. They cannot be unitary CFTs. And the lack of unitarity in this CFT is coming from the replica limit, that I have to take the limit, the number of replicas going to one. And so that is. And so that is a source of this extra log. So we should be clear that, of course, if you have a critical point, correlations decay with power loss. And if, in addition, I have a marginally irrelevant operator, a correction to scaling, which is marginally irrelevant.