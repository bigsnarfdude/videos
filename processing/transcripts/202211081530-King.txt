Thanks very much. Yeah, so I want to talk about a problem that I bring about basically over the whole pandemic. And I'm hoping that this will stimulate a little bit of discussion because there's quite a wide range of methods that people have been using to approach problems. I want to talk about one subset of those methods, but I'm particularly interested in how these methods, not only how they work and when can you apply them, but when is it optimal to apply? But when is it optimal to apply them, and when is it sort of counterindicated? So, just to get this out of the way, I want to make sure that I acknowledge my two collaborators in this project. Kian Ying Lin was a postdoc at Michigan, and now she's moved on to a position at Los Alamos. And Ed Ionides, my long-term collaborator in statistics at Michigan, but also helpful conversations with a number of people who are members of this workshop, as it turns out. And I don't know if they're currently on board because I can't tell if anybody's paying attention. On board because I can't tell if anybody's paying attention, but they've been really, really helpful. And then there's some funding as well. All right. So, what I want to talk about is the problem of inferring the structure and parameterization of models, right? So, this work is, the goal here is a little bit different than some of the talks we've seen where the attempt is being made to use genomic data to actually infer things like who infected whom, to actually look at what. To actually look at what happened over the course of a specific outbreak. Here, I'm interested in seeing a particular outbreak as an instance of some more general phenomenon of a model and trying to infer the structure and parameterization of that model using some kind of data. So the models that I've got are all going to be Markov processes. And I think it's fair to say that essentially all the models that have been talked about. That have been talked about during this workshop, and almost all of the models that are in the literature are Markov processes. It's a very broad and very useful class of models. And for example, all the compartmental models that we talk about, the phylogeographic models and so on, are all examples of Markov processes. And then the data are genome samples, and specifically, you know, these can be taken from From individuals over the course of an epidemic. They can be taken from within individuals over the course of a chronic infection or a persistent infection. And so there's really quite a lot of latitude here. And typically, I'm going to be, so very often people want to assemble these samples into phylogenetic trees. And so I'm going to be focusing on that. But my goal in all of this work, that's what I kind of want to. And that's what I kind of want to really emphasize here: is really kind of construct, I feel kind of a plumber here. So I'm kind of constructing a pipeline the models and the data. And the goal here is to have it work for the broadest possible, most flexible class of models within this very, very general class of Markov processes and construct a pipeline so that information can flow onto the models from the data with as little leakage as possible. With as little leakage as possible, sort of maximally informative, maximally efficient in. And for that reason, I'm going to focus on exact formulations of the likelihood. So today, I really want to dig into the mathematical underpinnings of this. I hope you'll indulge me in at least considering this for a little bit, even if it's mostly equations. But so the question that I want to focus on is not only how do we compute the likelihood in this situation, but This situation, but uh, but under what circumstances is it a good idea to bother doing that? All right, so I share a little bit about uh existing approaches. Um, and I would say that there are really three broad classes of existing approaches to this problem. Uh, the first is based upon, uh, it's a very broad class, and it's based upon summary statistics of various kinds. We've seen uh a number of talks. A number of talks this workshop that adopted this kind of an approach. And so, here, perhaps one even circumvents the need to construct a phylogenetic tree altogether. Yong Shen's talk, for example, is a great perfect example of this. And of course, these methods are, you know, hopefully make up for in robustness what they lack in statistical efficiency because they throw away potentially, well, they throw away some information. Well, they throw away some information. It's not clear necessarily how much information gets discarded in the passage from data to summary statistics. If we focus ourselves on methods that are based on phylogenetic trees, and there's sort of two classes of these, the sort of broadly speaking approaches based on the coalescent originally proposed by Kingman back in the 80s. And then methods that are based on On linear birth-death processes. And these two methods actually share a lot of similarities, despite the fact that they're seen as competitors. The coalescent-based approaches really rely upon a large population size, small sample fraction assumption. So you have to have a large enough population so that it can be. That it can be well described by a coalescent. And the small sample size approximation is really needed so that the samples that one has and the tree that one estimates is not, is sort of roughly independent of what's going on at the large scale. Similarly, the linear birth-death processes, well, they don't need the large sample size, sorry, large population, small sample size. Sample size assumptions because the linearity of the birth-death processes means that every subclade, every lineage from any point in time is essentially independent of all of the others. But both of these approaches provide the ability, those assumptions provide the ability to perform certain backward in time calculations and And often a lot is lost in that observation, and to the point that many people imagine that one can only work backward in time in these kinds of problems. So compute, to be clear, so computing the likelihood in these methods really relies upon the ability to perform these. The ability to perform these backward in time calculations. And so, of course, when can we get away with doing that? We rarely have linear processes. In fact, almost by definition, if we're interested in infections, we don't have linearity. And for example, at the beginning of an epidemic outbreak, the large population size assumption would seem to be very suspect. Nevertheless, an error is just an approximation looked at. Error is just an approximation looked at in a different way. And so one can ask: under what circumstances are these approximations good, and contrary-wise, under what circumstances might they need to be revisited. So that's what I want to do today. And my goal is to show you how one can compute the exact likelihood of a Markov process model, or at least a fairly general class of them, without the need for any such assumptions. So, in particular, in the case where we have In the case where we have small populations and possibly large sample fractions, so a large number of the individuals in the population being sequenced. I should say, please feel free to interrupt me at any point if something's not absolutely clear. I assume everything is totally clear up to this point. But anyway, so what are the ingredients of the approach or that we need in order to do this? Or that we need in order to do this. The first is, of course, a Markov process model, as I was saying. And so I won't repeat the definition of a Markov process, but we can think about x of t as being some kind of time-dependent variable of interest. For example, if we take the toy example of the SIR process, where we have infections that move individuals from the susceptible class. Individuals from the susceptible class to the infected class and recoveries that move them here. Maybe we even have loss of immunity or something. We have some rates here. Let's just put some rates on here, lambda, sigma, and eta. Then we can think about in this simple case, x of t as being something like s of t, i of t, and r of t. So the numbers of individuals in each of those compartments at time t. So for concreteness, So, for concreteness, I'm going to assume that x is a jump process. That is, it stays constant until at certain points in time it changes its values. But one can generalize that considerably to consider more general models with continuous valued state variables, for example. Importantly, I'm going to allow these rates, lambda, sigma, eta, whatever they are. Perhaps in a more complicated model, there are more rates. I'm going to allow these things to be time-dependent. Dependent to be state dependent. So they depend upon the value of x, which means that the model is nonlinear. And there's a great deal of flexibility in there I want to emphasize. So the second ingredient is data. And here's just a toy phylogenetic tree, just so you remember what they look like. Look like, but we can have a phylogenetic tree or multiple trees, perhaps because we have different strains or different introductions, or perhaps even different trees sampled from the posterior of the tree reconstruction model. But regardless of that, we're going to assume these are what Javier was calling dated trees. Dated trees or time-calibrated trees. And that's a really crucial requirement of what I'm about to tell you because we're essentially going to be assuming that the branch points that occur here correspond to actual transmission events. And that itself is a problematic assumption. I'm in good company making that assumption, but that doesn't make it any less problematic than an assumption. That's one of the things that we can certainly talk about. All right. All right. So, importantly, also, I'm not going to make any assumption. The methods I'm going to talk about are not going to need any assumption that the sampling here is uniform or unbiased, that the sampling effort is constant through time, any such thing. So, really, one of the great strengths we're going to see is the fact that we can accommodate a really wide range of different sampling regimes. In addition to the phylogenetic data, we may have some sort of optionally other data streams. Other data streams. For example, we may have epidemiological incidence data, case counts or something, hospitalizations, other covariates, changes in vaccination, and so on and so forth, NPIs, whatever additional data streams or time dependencies we want to incorporate, those will not be any kind of problem. Those will not be any kind of problem. And I'll just, in passing, notice how we can sort of merge the phylogenetic data with those other data streams. So I'll just use Y to refer to whatever those other data are. All right. So I'm going to have to explain what I mean by a jump process. So let's suppose, again, this is just for concreteness. Let's suppose that this is a jump product. Let's suppose that this is a jump process. And so, what is that? So, x of t is basically, if we look at it through time, it is here, pretending it's one-dimensional, but basically it's constant and then it jumps. It's constant and it jumps. Maybe it jumps at different amounts, at different times, and so on. But it's characterized by the time and the nature of the jumps. So, for example, if we think about a simple So, for example, if we think about a simple two-dimensional model where we just have s to i and back again, an sis model, and for this model, we might have x of t as just s of t and i of t. Then our state space, so x of t takes values in a state space, which is just a two-dimensional integer lattice. So, if we just think about that, it's right, we can only have an integer. It's right, we can only have an integer number of susceptibles and an integer number of infectives. So the state space looks something like this: with this axis being the i and this axis being the s. And if our state is a particular value at some time, then the stochastic process is one of jumping, right? And it can jump from one place to another. So perhaps, let's see. So the infection process results in loss of one susceptible and increase in one infective. The recovery process The recovery process results in the increase in one susceptible and the loss of an infective. And in more general circumstances, you know, we might have jumps that take us to all different kinds of places, right? Because we want a very flexible model. We're not going to presuppose a simple structure like that. We want this to be fully general. So these jumps, I'm going to use the symbol U to refer to jumps. In the SAS model, again, there's just two. There's just two kinds of jumps, but in general, there could be many of those. So, one way to sort of encapsulate everything that you might want to say about a jump process like this is to write down what's called the Kolmogorov forward equation, or the master equation for it. And this just describes how the probability evolves. So, let's let p of t of x be the probability of finding the system. Of finding the system in state X at time t. And we'll suppose that at time zero, we have some given distribution of possible system states. We'll call that P0. Then this satisfies the following differential equation. dp dt is alpha u t x minus u. Tx minus u times p t x minus u minus alpha u t x p of t x, where the sum is taken over all possible values of u. And these alphas, these alphas are just the rates. So if in our simple SIS model, if we had a force of infection lambda and a recovery rate rho, then those rates would be the rates associated with these two. The rates associated with these two pathways there. And then in the simple model, there are no other jumps possible. So all but two of the terms would vanish in this expression, right? There would only be two terms in this expression, one for infection and one for recovery. How am I doing? You guys follow me? Do you want more details? You want to see the equation? Yeah, sure. I've got it right here. So in this. So, in this, let's just look at the specific case. Let's move this out of the way. All right, so in the SIS case, right, there's just two terms in this sum that are not zero. We would have dp dt equals, I've got lambda here, t of x minus minus one, one, because that's this vector here. This is the minus one. That's this vector here. This is the minus 1, 1 vector that we get from an infection times p of t of x minus 11 minus lambda of t x p of t x. That's the terms that correspond to our infection process. And then we'd also have the terms. If I assume rho is constant here, I would just have rho times p of t x minus 1 minus 1. Minus one minus one, because that's the change that I get when I have a recovery, right? Move in this direction minus rho p of tx. So, but the key thing is that, you know, once I've got a model, right, that boils down to a specification of jumps and their associated rates, and there's an associated equation here. So, if you know this equation, well, if you know the model, you know this equation. Well, if you know the model, you know this equation. And if you solve this equation, it tells you everything you could possibly want to know about the process, right? It tells you what the probability is of finding it in any state at any time. So this is called, as I said, the Kolmogorov forward equation and or the master equation in the context of jump processes. Right. And we can And we can, you know, it may not be an easy thing to solve, but it's solving it does give you a lot of information. So, one, you know, one would want to solve that potentially, or at least want to work with it. Okay, so, right. Where am I? Good. All right, so there's some more ingredients that we need. We're adding up ingredients. I keep doing that. Ingredients. I keep doing that. All right. More ingredients that we might need. So we're going to assume that we've got some kind of a map which maps, we'll call that I, that maps our state space, whatever that is, our integer lattice down onto the non-negative integers. And this is just the number of lineages of virus lineages or pathogen lineages in the population. Population right at any given time. Whenever the system is at state X, the number of lineages is I of X. So that's how many distinct, I mean, you can think about it as a number of infections if we're thinking about these lineages as being viral lineages, consensus sequences, for example, inside of infected individuals. Then I of X would be the number of infected people in the population when it's at state X. At state X, if we're talking about within host samples, then I of X would be the number of distinct viral lineages that are present at any given time. Okay, so notice that I'm assuming that I've just got a single integer here, and that's a restriction on what I'm about to show you and how we go to the problem of actually dealing with multiple different kinds. Dealing with multiple different kinds of infections or multiple different kinds of lineages is a very important and ongoing research problem. We're gonna need a set B of jumps that correspond to birth. So this is the subset of jumps. We called those U before, those little vectors, that result in the birth of a new lineage, right? And so for Right, and so for if we're talking about epidemiological dynamics, those are transmission events, those can also be mutation events, those can be if we're talking about things within a host, but in general, anything that results in the branching of lineages. So, this is branch points in a phylogenetic tree. Okay. And you could, you know, I'm going to assume that whenever there's a branch, it's just a A branch, it's just a binary branch, right? We only get one offshoot at a time, so we can only get sort of branch points that look like that. You could generalize to situations where you've got polytomies, you have multiple lineages that spring out of a single lineage at time, but I haven't found any good motivation for considering such things. And we can talk more about that if you like. So, here's one extra ingredient, here's a second extra ingredient. Ingredient. Here's a second extra ingredient. A third extra ingredient is we need a sampling rate. And this I'll call gamma. This is the rate at which we sample genomes. And this is a map from time across our state space into the non-negative reals. So gamma at a given time when the system is at a particular state is a sampling rate. This is the rate at which This is the rate at which genomic samples are taken. And it's not important that this is allowed to be time-dependent. So the sampling effort can change through time. It's allowed to depend on the state. And in fact, it's not even necessary that this be an absolutely continuous function. We could, for example, if we don't think that the timing of samples is particularly informative, then one can just sort of condition on this being, you know. Positive at a particular value, a particular point in time. So, to accommodate finally the optional extra data that, you know, our case counts or whatever, we might need a measurement model as well. But in the interest of time, I think I will put that off unless there's interest in the form of questions. All right, so. So, when you've got all those ingredients in play, and I emphasize that these are not difficult things to come up with, right? If you've got a model, you can write these things down. The only thing that maybe is unfamiliar to you is the notation I'm using, but the concepts I assure you are things you've run across before if you've written down one of these models. So it turns out that if you write down the following. If you write down the following equation, so this is a nonlinear filtering equation, dw by dt. We're going to sum over all possible jumps. I'm going to write down something here that looks exactly like our Kolmogorov forward equation. But then we're going to add some more terms to it. So we're going to add. So, we're going to add a term over all jumps that result in a branching, an expression that looks like this. Ooh. Let me back up. Sorry. Let me back up. How are we doing? Oh, God. Why am I taking up so much time? All right. Right. Yeah, I guess I won't do that. We don't have a lot. I guess I won't do that. We don't have a lot of time. So I'll write down this expression. And I'll finally write down this expression. Okay, so let me talk about this a little bit. So here we have the Kolmogorov forward equation that we saw before, those terms from there. This term describes the branches. The branches that occurred but were never observed. And this describes the samples that could have happened but didn't. All right, then we've got some additional terms that only show up sometimes. Sometimes. And here, somehow, all the time has gone. So what happened last time, too. So yeah, there's no way I can even really write this equation down. Well, yeah. So there's an equation. There's some extra terms here. One can compute the solutions to this equation by By using, for example, Monte Carlo. And what we've done is shown that the likelihood is just if you solve this equation for w and you sum up over all x of w t of x, that gives you the likelihood. So you can compute this likelihood exactly without the need for any of these approximations. And the question is, the foremost question that I'd like to pose for your consideration is when is it worth it? Consideration is when is it worthwhile to do this? The flexibility that's here allows us to consider a wide range of different kinds of situations, but with time dependence, time dependent rates in the model, time-dependent sampling processes, and so on. And it seems to me, at least as a starter, that one runs into situations, for example, at the beginnings of an outbreak. At the beginnings of an outbreak, where the sample sizes are, I mean, sorry, the population sizes are small, and also at the situation where we have beginnings of susceptible depletion, which is where nonlinearity rears its ugly head, susceptible depletion and/or strained competition. Or strain competition, so competition between different strains, where again, those nonlinear effects are pronounced. So, yeah, so apologies for giving you just a tease of that luscious equation that I'm sure you were just desperate to find out more about. But perhaps there's enough there that we can begin to have a conversation. Anyway, I'm ready for any questions. You've got them. You got the tree, I try to understand. You said the tree is given and you have data is that sequence and data observed over time or under many different conditions. You want to write down the likelihood. Yeah, so what I'm interested in, yeah, obviously the construction of the tree is itself a difficult problem. And it interacts. And it interacts over time collected sequences. Yeah, so for example, sequences collected over time. Yeah, if we can construct a dated tree, I'm interested. The question I'm asking is, what's the likelihood of this tree under a given arbitrary Markov process model? Yeah, but is that tree is not constructed based on the Markov process model? This is, this is, as I say, this is not unproblematic. So, really, there's two parts to the problem, right? There's the Problem, right? There's the sequences to tree, and then there's the tree to the model, right? And these interact with one another. If you want a complete solution to the problem with these as the data, the tree is really just an intermediate quantity. So there's an awful lot of work has gone into constructing trees from sequences, but what's been lacking. But what's been lacking, at least in terms of rigorous arguments that are exact likelihoods, is this connection. So, what all I'm doing here is providing this connection. To get the full inference, you'd have to integrate this in, for example, treating this, what I've given you as a prior for the tree in a general Bayesian estimation procedure. Right, but you're absolutely right. Any other questions? I cannot see the Zoom. questions I cannot see the Zoom so should we not sure how we do that I think you should feel free to unmute yourself and speak up if you'd like to wait this is yeah we need to change or what's going on he's changing it over okay okay there we go there's the chat um uh what does Uh, what does anything do that? Yeah, oh, W. That's a really interesting question. So, here in this slide, here this W things, yeah, so it's frustrating to run out of time to talk about this thing in detail, but W here is a kind of a weight. If you integrate this thing, I should say here, integrate it to the very last time point, the last time. The last time point in the tree. So, if our tree, if this is our time t, if we integrate this equation all the way across forward in time, right, then this weight is something that is the likelihood of the tree conditional on the state being x. If you sum that over all x's, you have the full likelihood. At any time prior to that, at any other time, w is this. Any other time, W is this quantity that doesn't really have an interpretation. And there's actually a lot of confusion in the literature that attempting to make sense of quantities like W that are based upon information that sort of combines the causal process that leads, that's expressed in the Markov process with information from the future. And so there's all kinds of strange intellectual backflips that are done to try to explain what W is. What W is, you know, essentially it can't be the probability of anything because it depends upon things that haven't happened yet. And so the proper way to understand W is it's just an instrumental quantity. It's just a partial weight that one has to sort of sum over across time in order for it to be the likelihood. But once you've done that, it gives you the likelihood at the end. So good question, Landon. The end. So, good question, Landon. Thank you for asking that. Is there, oh, here we go. Can we think of it as a dynamic programming type variable? Good question. I hadn't thought about that. Do you have some can you can you elaborate? I think he kind of He can't speak. He can't speak, but he can type, maybe. I don't know. Perhaps that's not so easy. Not so easy for discussion, it's not a dynamic programming variable. Ah, that's interesting. Maybe we can follow up on that afterwards. You probably have some insight that I don't have. I'm not so familiar with dynamic programming. Yeah, I guess right. I think, right, because you have like forward part of the algorithm and then back and then trace that. There's no backward part of the algorithm. In dynamic programming. Right, right, right, right. Dynamic programming, right? Right, right, right. So, interesting. I won't try to, yeah, yeah. But Landed, let's let's talk some more about that. It sounds very interesting. I can go ahead. So I guess this is a more general conceptual question to take you back to the beginning of a lot of biodynamics, biogenetics as currently practiced is let's try to. Practice is like let's try to estimate specific things, you know, the most recent zero, um, or things like that. And you say, you know, we want to learn general things about this process. Well, general things only in the sense that I'm interested in model parameters, right? If those model parameters are T0 and R0, then that's perfectly fine. That's the only thing I mean. I just wanted to make a bridge between the sort of approaches we saw in Dave Rasmussen's talk or in the last talk we saw. Talk or in the last talk we saw, where we're interested in inferring transmission pairs or actually what the structure of transmission chains actually was in a specific incidence, a specific instance, as opposed to determining parameters and possibly model structure, right? Is there significant competition going on? What's the rate of loss of immunity? Is there loss of immunity that's taking place over this period of time? For example, what's the shape of the incidence function and so on? So, those kinds of questions, along with the Those kinds of questions, along with the numerical values of parameters, can be estimated using this approach because it's a maximum likelihood approach, right? Or it's a likelihood. That's, yeah, that's the only, there's no hidden significance there. So if there's no more questions, we can also take some time for the person with the live or I don't know anybody else. We know if anybody else is on the same team. Maybe I'll go on the presentation for two days before we see it.