And so we have the pleasure to have Jervis Anatopoulos with us, and he will talk to us about measurement equal field theory. Right. Yes. First, let me thank you for the invitation to be here in this lovely conference and for presenting this work of ours. Now, we have been working, this is going to be mostly a review talk about the program we have been developing. The program we have been developing in the last 10 years about measurements in QFT. Now, what I'm going to talk is that if you want to define fundamental quantum information concepts in relativistic systems, you need, by definition, a practical and consistent theory of measurements for the fields. Now, we will present one such formulation that we have been developing, which involves a QFT modeling of interaction between the system and Of interaction between the system and the apparatus and the use of temporal observables. So, this is going to be the subject of my talk. A non-technical review is found in this entropy article of what I'm going to talk now. And I will also present some results from here that are forthcoming. Now, the point of view of our program is, sorry for that. So, the point of view of our program is Of view of our program is we know that quantum information and quantum field theory are often supposed to be so it is mutable. I'm going right so. Right. So in quantum gravity, for example, there are common statements about the convergence between QFT and quantum information, especially in relation to holography or black hole information paradox. But in fact, to be proper, to do a proper quantum information theory, we need to start from first principles. So this is our point of view. First principles means how we get extraction of information from a quantum information. Information from a quantum field theoretic system, a relativistic quantum system. And so far, quantum information theory has mostly been developed in the context of non-relativistic quantum mechanics in the sense of not using the main principles of QFT. Now, our thesis here is that we must start, as I said, from first principles. And if we want to do relativity, relativistic quantum information, we need to... We can only do it with quantum field theory. And also, we need to talk about correlations of other types, not only the spatial correlations, like the Bell-type correlation, but also temporal correlations. Ideally, we would like to converge to a theory that treats all types of correlation of quantum theory. But the backbone of any relativistic theory, like the backbone of any quantum information theory, is how you extract information. Is how you extract information from a quantum system. So, this is a theory of quantum measurements. Now, why quantum measurements are challenging in relativistic quantum theories? Let's see a very simple example. Suppose we have two different space-like separated events. Now, in the common, in the standard formulation of quantum theory, you have the reduction, the state reduction rule, which says if Which says if p happens before q, then we need to do this reductions to reduce the state with respect to p. So if you have the sequence, if you are in one reference frame where p is before q, then you have the sequence of states. Now, but if the two measurement events of space like separated, we can also always find a reference frame in which q prime is not the same operator. It's not the same operator, it's Lorentz transform, is earlier than Q prime. So we have this sequence of states. Now, if we see those two regions together, we see that in this rectangle here, we are going to have two different descriptions. In one reference frame, it's going to be pi pi p acting on psi, and the other is going to be q prime acting psi prime, which are not in general related by Lorentz transformations. Related by Lorentz transformations. So, what does this mean? Is that the change of the quantum state over measurement is genuinely different in different Lorentz frames. This is an old result. It does not affect prediction, physical predictions of the theory, because probabilities are the same. If P and Q commute, then the two expressions will give the same probabilities. So, this point is made very forcefully by Wigner, who said that. Who said that not the state, but the probabilities are the fundamental elements in a relativistic quantum series. So the state is just a placeholder for information. And this is the standard resolution of this problem. I agree very much with that, but the problem is, how would you define information theoretic quantities if the notion of the state is not ambiguous? Of course, and Of course, and the challenge, therefore, is the level of information. Of course, the reduction rule is the problem here because it describes a global change of the quantum state. If you see here, we see that it happens on a whole Cauchy surface quasi-instantaneously. And perhaps there's also change in relativity. Or, as Wigner and many other people have suggested, just work with probabilities and try to define information in terms of probabilities. Information in terms of probabilities. This is the attitude we are taking here. Now, what other challenges, except for the usual projection rule, exist when describing a relativistic system? Localization. How can we formalize the notion of particle localization? This is an old problem. It's a problem of QFT, not only of particles, because particle physics, because particles appear in QFT, and we need to talk about the localized system anyway. Localized system anyway. Now, the earliest position operator was developed by Newton Wigner, and which is fixed with respect to particular Lorentz frame with this rule. But this Newton-Wigner operator is not space-time covariant, essentially, because time is not an observable. And if you actually talk about localized wave functions with respect to the unit of ignorant operator, this evolves superluminally. Evolves superluminarily. So the notion of localization is an old problem. And now we have a couple of theorems, now I mean in the last 50 years or so, in the last 30 years or so. One is the theorem by Malament that SARP localization is impossible. We cannot have that disposition operators. And there's another theorem by Hegelfeld in the 90s that even an unsharp localization, if it existed, if you try to implement it naively, You try to implement it naively, leads to superluminal transmission of information. So, what does this mean? If we are going to talk about a localized system, which cannot be completely localized in QFT language, we say that we have to re-normalize the state by including, for example, by dressing the state with photon fields that are non-local. So, this is at least the most common interpretation of these results, this interpretation by Bucholz and Englkafson. But if you do not have localized But if you do not have localization well-defined, protocols like the local operations and classical communication, how are you going to define it in a relativistic theory? And there is also paradox first pointed out by Shorking that if you really assume that you have single-time measurements described by the projection rule, then you are going to get problems with causality. Shorkin's arguments. Arguments suggest that we cannot have ideal measurements in QFT. And if we don't have ideal measurements, then notions like qubits which suggest the use of relativistic ideal measurements, how can we define them? So these are the problems that would appear from the foundations of quantum field theory in relation to information theory. Now, of course, ideal measurement is not. Ideal measurement is not a problem. We can always use POVMs, and essentially, the approach I'm going to describe is going to use POVMs, positive operator-valued measures, in order to describe measurements. Now, the key point, this is the point that we have to emphasize, we do not know of any other way of having a local causal unitary point interaction except for quantum fields. So, I don't think this is a theorem. I don't think this is a theorem, it's just that nobody has been able to construct an alternative description. So, at least, even if we have to include the measurement device in our system and describe the quantum measurement, we must have genuine QFT interaction between system and apparatus. This is essential because many models are easy, but they do not involve QFT interactions, are easy to construct. So, let me give a very selective history of QFT measures. History of QFT measurements. The first treatment by Landau and Pyles treated the discussion of quantum fields measured by a microscopic system. And they obtained some results, but Bohr strongly objected to the results by Landau because he expected when you're talking about the measurement device, you have to talk about something macroscopic, not microscopic, like Landau and Parliament assume. So, for example, in measuring the quantum. So, for example, in measuring the quantum electromagnetic field, the test charge must have a charge that is much larger than the field of electron charge. And its scale must be much larger than the atomic scale. The argument is essentially if you have a probe, you need, yes, it must be a small system, but must be large enough so that there is little radiation reaction. This is the key point. If radiation reaction is small, so it can record fair. So, it can record faithfully the quantum, the value of the field. So, it has in modern language we say that detectors must be sufficiently coarse-grained, and there is a general proof in the development of quantum measurement theory. Now, the most well-known QFT measurement theory is Glauber's. It's Glauber's photo detection theory. It was developed in the 60s. Glauber got Developed in the 60s. Glauber got a Nobel Prize because of the application of this model. It's semi-phenomenological in the sense that fundamental. If you look at Glauber's paper, he does not actually prove this expression. He just suggests that perturbation theory suggests that these are correct formulas for single-time detection probability and two-time detection probability and n-time detection probability. The key point here is that if you have n detection probability Is that if you have n detection events at different space-time points, you need a 2n QFT correlation function. So, n probability with respect to n events, you need 2n correlation function for the field. Now, Glauber split the electric field into a positive and negative frequency component. This split is not local, and one might fear that if we have a system of retarded propagation, A system where retarded propagation effects are important, these photo detection probabilities might not be causal. And we expect to have setups in space where these retarded effects are going to be important in the next decades or so. So we need an improvement over Clauber's theory, which I must say is extremely, extremely successful in quantum optics. You might say it is the standard model of photo detection at the moment. Now, a type of model that has been A type of model that has been widely used are the UNRU DeWitt detectors. These detectors essentially have the detector is an particle system in the sense it moves, it is along a point-like trajectory, a space-time trajectory, and you have an interaction where you have some operator for the detector and you have some general composite operator for the field. Usually, if this is color field, If this is color field, the composite operator is just the field itself. Now, there is dozens of papers on Android-Devid detectors, mainly starting from Andrew in the demonstration of the UNRWA effect. And with the detector, it's a much simpler demonstration, almost a textbook demonstration that you get acceleration temperature without needing to talk about Rindler wedges and this complicated. And this complicated QFT description. But of course, the problem is if it is a point-like, it's not a proper QFT, problems might arise with causality in the 100-day detectors. Another approach is following more axiomatic QFT. This idea originated from Helvig and Krauss. It has recently been strongly developed by the York group, by Chris Huster and collaboration. York group by Chris Huster and collaborators. It is essentially: you have two field systems. One field is the probe, one is the detector. They interact in a finite space-time region through an S-matrix, and you can define probabilities for the probe-Hilbert space. And this is a description of measurements. It's rigorous. It avoids some covalent problems like the problem mentioned that Shorkin. Like the problem mentioned that Shorkin had presented, but it's not yet a practical working tool. So, our approach, we call it QTP quantum temporal probabilities. We have been working on that, me and my collaborator, Dina Savidu, for about 10 years, and we have started expanding it in the last year or so. I'll explain what I mean by expanding. And let me say what are the key ideas. What are the key ideas? First, interaction between a quantum system and the measurement apparatus, of course. Now, the later must be a macroscopic system that behaves effectively classically. It's a quantum system, of course, but it behaves effectively quantum mechanically. How do we do that? We assume that it satisfies specific coherence conditions that guarantee classicality. So, this is the first thing. So this is the first thing. The second assumption is that what are the observables we are interested in? The key point is what are we measuring when we are doing an experiment, a high-energy physics experiment, for example, because this is where QFT is applied. What do we measure? We measure particle detection events. What is a particle detection event? You have a detector at a specific location and this detector clicks ideally at the moment. ideally at the moment of time. So in most cases, the position of the detector is fixed in some reference frame and what changes is the time of detection. So it is essential that we among all variables we have the space-time location of the measurement event. We might have other quantities like spin, like if you want to do quantum information, you'd like some discrete quantities like spin or Or polarization or momentum or energy, but it is essential that we have the space-time location of the event. And I emphasize space-time, not space, separately. So, because time will also be treated as a random variable. So, the observables are intrinsically temporal. They have some temporality. I mean, this is where we started from. We started from trying to define the time of arrival for QFT, and then we saw that this. For QFT, and then we show that this our approach can be generalized to arbitrary observables that involve also time. And essentially, we treat time as a macroscopic time of detection, as a macroscopic quasi-classical observable associated to the detector. The detector is classical. Now, how do we do this? I'm not going to go into technical details. Going to go into detail, technical details. I'm just going to say that we are using the coherent histories framework to formalize classicality conditions. This has been developed in the 80s by Griffith, Soman S, and in the 90s by Gelman and Hartle. Any of these review references is good enough. We are only in, it has been developed as an interpretation of quantum theory. We do not necessarily subscribe to the interpretation, but we follow the framework for the description. The framework for the description of classicality. This is important. So, what is this framework? If you have, in the simplest case, suppose we have a discrete time history, meaning a string of projectors, each projector is a measurement outcome, let's say, for the system. And if you use the standard formula of quantum theory, formulation of quantum theory, in which you have projection unitary projection unitary evolution, you get a probability for this n events. For this, n events written in the form 4, 2. This is the sequence of unitary projectors, and this is Hermitian conjugate. It's a standard formula for sequential measurements. Now, the key point noted by Homness and Gelman and Hartle was that the set of histories has a nice logical structure. We can define OR and NOT here. And these class operators, this that obtains here, can actually be. That obtained here can actually be proven to be additive, so that we can use this property. The problem is that, unlike classical probability, there is no additivity in the probability measure. This probability measure that I wrote here, this probability here, does not satisfy additivity. You have additivity for the amplitudes, which is natural if you think about it. Now, amplitudes are additive, but probabilities are not. So, what Gelman and Hartle suggested. So, what Gelman and Hartle suggested, we introduce a quantity known as the coherence function, a dagger is missing here, where we have this class operators, and we can define probabilities only if the coherence condition is satisfied. This means that the off-diagonal, if we take a set of histories and the off-diagonal elements vanish, then we can define probabilities. This is the transition to the classical description of the system. And this is what we employ in order to say that. We employ in order to say that our detector behaves classically. We don't use anything more than that from the coherent histories approach, but this condition for the coherence. So this means that if pointer variables satisfy, if histories of pointer variables satisfy this condition, they effectively behave classically. So they are appropriate as a quasi-classical objects by which to describe measurement. So, this is one thing, how described classicality condition. Then, the second thing is, how do we formulate the field apparatus coupling? We just have, suppose we have one, only one apparatus, so only one measurement. We take the QFT Hilbert space, a Fox space for free fields, and the Hilbert space for the apparatus. We assume a factorized initial condition. This is standard in quantum measurement theory. In QFT, this should not be. In QFT, this should not be allowed because there are some theories, but if we work at three levels, lowest order and perturbation theory, there is no problem. And we essentially, as I said, we want a practical theory. We work only at three level in this interaction. Three level in this interaction, I emphasize, between the field and the detector. The QFT might be an interacting theory. It's not affected by that. So we have an interaction Hamiltonian, which is of this form. Which is of this form. This is we can take any composite operator that is local coupled to a current operator for the apparatus. And what can be this O composite operator, for example, for a scalar field, it can be the scalar field itself. In this case, it's very similar to the Android-Devitt detectors. It can be the positive frequency part of phi. Frequency part of phi, which is then we recover Glauber's theory. We do that, because remember, Glauber's theory involves splitting into positive and negative frequencies. If we do the splitting by hand, which is a non-local operation, we will just recover Glauber. Or we can take phi square. This has an interpretation. This term has a dagger A. A dagger A is essentially scattering, if you put it in the description. So this involves part. So, this involves particle detection through scattering. Here, this particle detection through absorption that appears here. And you can have more complex particle detection. So, for somebody familiar with QFT, we have a lot of option depending on the actual system we want, the actual physics of the detector. Is it scattering or is it the absorption? We can choose this operator. And now we can derive. And now we can derive the derivation, it can be made very elementary, as I will show you. It's a probability density with respect to space-time event. It's just the two-point function with respect to this composite operator smeared with a field with a quantity here, which we call the detector kernel. The detector kernel is essentially an expectation value of the translation operator between some state that appears. In some state that appears in the Hilbert space of the detector. So, this is lowest order to perturbation theory, right? So, and to lowest order in perturbation theory, it's very simple. Probability just needs the Weitman function for this O. It's very, very elementary derivation, but it's not rigorous. The fully rigorous derivation involves, as I said, the quasi-classical treatment of the detector. Just assume a switching function. Switching function is an artificial. Switching function is an artificial way of describing the coupling. Let me remind you that we do not want a switching function. We want a genuine quantum field theory interaction in general. But if we just play with the switching functions, which we usually take as a Gaussian, we can calculate the transition probability to lowest order in perturbation theory. This is just standard formula of perturbation theory. The two-point function appears here, another point, two-point function appears. Here, another point-to-point function appears here, and take this probability and define with the effective volume associated to the switching function. So, it's essentially the integral of this switching function, and you get the same expression, sorry, you get the same expression that you obtain with a, I'm not, the same expression that you obtain with a more rigorous analysis, you just take with the back of an envelope. Taken with the back of an envelope calculation. Ordinary QFT with the switching function. The role of the switching function is essentially the sampling, plays the same role as the sampling, how well we sample the position and time of the detection event. So if we have n detectors, we can again work at three level. And at three level, we get n events probability. You get the 2n correlation function, which has. Which has n indices are time ordered, like Feynman propagator, and n indices are anti-time ordered, like anti-Feynman propagator, right? Time order, reverse time order. So you have n time ordered, n anti-time order, and the expectation value. And this is the correlation function that appears. Again, we have the same pattern, n measurement events to n correlation function. To n correlation function. Remember, Glauber, Glauber had the same pattern, right? Because again, Glauber was inspired by the lowest order perturbation theory. N detection events to n correlation functions. The only difference here is we go do a more explicit modeling of the apparatus, and the apparatus, the information of the apparatus, appears in these kernels defined as earlier, one kernel for each recording device, let's say. Recording device, let's say. And if you just try to use an index notation so that the positions, the space-time points in the correlation function are treated by some abstract indices. This is a two-n index object. Upper indices are time-ordered, lower indices are anti-time ordered. This is just a shorthand. And we also write the kernel in this way and a very compact formula. A very compact formula with contracted indices then appear. So the key point 2n correlation function. Now, this is, I think, our main result in relation to applications. Why? Quantum measurement theory, quantum information theory is based on notions like projective measurements, CP maps, which are defined in terms of Hilbert spaces. On the other hand, Terms of Hilbert spaces. On the other hand, practical use of QFT has moved away from Hilbert spaces in the last, let's say, 50 years and moved toward correlation functions, generating functionals, path integrals, and so on. And the second language in QFT is convenient for most practitioners because it is fully covariant. It can be made explicitly covariant. So you ignore the, say, let's say, canonical language of the. Let's say canonical language of the Hilbert space and work with correlation functions. This is the standard practice. Some textbooks in QFT even completely forget nowadays the canonical origins of the theory. Now, and the key point here is that this formula relates an object with a probability of measurements derived through, let's say, traditional quantum measurement theory to objects, to an object that is very familiar to QFT, a correlation function. A correlation function. But what type of correlation function? Now, usually we have S matrix formalism. I mean, this is the most practical formula for QFT because it describes all scattering experiments. We do not have scattering experiments here in general. And in S matrix, we have correlation functions which are time-ordered only. S matrix is expressed in terms of time-ordered functions. Here, we have Here we have time-ordered and time-ordered, anti-tight time-ordered indices. Where does this appear? There is another formalist for QFT, less well known, because it does not apply to scattering. Scattering is the most important application of QFT in high-energy physics, but it applies to problems like non-equilibrium QFT in early universe cosmology. This is the closed-time path formalism, which was developed in the 60s by Sphinger and Keldys. And this closed-time path formalism And this closed-time path formalism, this is a review in the 80s, and you can read in the book by Calcetta and Hu about non-equilibrium QFT, how it can be applied. It applies there. It's different from Smatrix. It's more versatile than Smatrix in the sense that it can answer questions. Smatrics is not constructed to deal with. In particular, it applies when we want expectation values or probabilities at finite density. Of probabilities at finite density. And the key point is that these probabilities, these correlation functions that we found also appears in the CTP generating functional. This CTP formulas. This CTP formula can be expressed in terms of path integrals, which makes it simpler to do some functional calculations. And you have, in general, you have correlation functions with n time order and then anti-order. Time order and then anti-time order. Now, what we found is that we need to have correlation functions which have the same number of anti-time ordered and time orders, n equals m. And this is a particular, to this end, we need to construct a rather different generating functional. Interestingly, this generating functional had been constructed using CTP by Kilset and who in the 90s. We just found out this year. This year, and this generating functional was used in order to deal with Boltzmann equation and non-equilibrium problems in QFT. So, essentially, what we found is that the generating functional of our probabilities is almost the same with the generating function that Calzett and who had proposed in the 90s about describing non-equilibrium QFT. So, this is the new upgrade, the results of our work in the sense that we can use the formal evolution. That we can use the formalism of measurement to non-equilibrium problems, which was something unexpected from our starting point. And let's talk about the application of the formalism. So the formalism, there is some background in the calculation, but eventually what the key, the message, let's say, of our result is that the n measurement event is a 2n point correlation function. So we have done time of measurement event event event event event. So, we have done time of measurement, use it for time of arrival probabilities for some correlation measurements. We have also applied it in relation to black hole evaporation issues. And one of the most important thing we are trying to do now is to apply it to possible experiments that can be done in the near future in space. So, where we have large separations between different detectors. Between different detectors, more than one detector, so that retarded propagation effects are important. And also, we want to apply that to non-equilibrium QFT. So let me, how long do I have? 10 minutes. Okay. So let me talk about the arrival time problem. So this is the early application and to see some interesting physics that arises here. That arises here. So, the problem of arrival time is elementary in a sense. You have a source that prepares an initial wave function for a particle around x equals zero, and then we have a detector at a fixed point x. We are looking for the probability density of detection. What time, the probability with respect to the time at which the detector clicks. Now, this problem has no canonical answers like take the Born rule and find the result. Take the Born rule and find the result because there's no time operator in Panel theory. There are analogous problems in discussing tunneling time. How long does a particle take to tunnel through a barrier? Again, a problem with many different proposals, but at least this one is now experimentally testable. Now, if we take our formulation that I mentioned, we just have the two-point function and the kernel associated to the detector. So you just write the two-point function for in one. You just write the two point function for a one particle state. It's elementary calculation to do this. I mean, it's elementary QFT calculation. And modulo summary definitions in order to take into account the absorption probability, we get this probability density. So we reduce this to one dimension for simplicity. So this is just the initial density matrix, P and P prime, energy and energy prime, should be prime here. Prime, should be prime here. Yeah, there is. And this is the velocity, which means p over energy. And the points, the only difference is this type of operator, which we call the localization operator, which depends on the physics of the apparatus. It's just a combination of, this would be K here, of the detector kernel. And we can prove that maximally localized. Prove that maximally localized corresponds if we take a Lorentzian kernel for the detection kernel, in which case this operator becomes unity, and we get some results that have been obtained before. I mean, sorry, the maximum localization P of M is the one obtained by Leon. And if you take to the non-relativistic limit, it's the well-known P of M by Kikovsky for the time of arrival probabilities. So this is what we get, but of course. What we get, but of course, any L any localization operator can apply to specific experiments. This is just the ideal localization curve. Well, distinguishing between time of arrival proposals is difficult. There is a recent proposal that's saying that Bohmian mechanics has a very different behavior in time of arrival. So, some groups have started discussing the possibility of measuring this. Of measuring this difference at the time of arrival. In general, it's very difficult because you have to take an initial state which is in the in which the wavelength of the initial state must be of the orders of the distance which is traveled, which is a very difficult technical problem. So this probability density, again, I'm confusing this, this probability density is not truly covariant because yes, the correlation function is covariant. Yes, the correlation function is covariant, but the kernel is not. Why is it not? Because if you have an apparatus, the apparatus defines a preferred reference frame at which it is at rest. So the apparatus is usually not destroys Lorentz covariance of the probability density. This is not a surprise. And we have been able to prove an interesting uncertainty relation here that the mean deviation of the time of Mean deviation of the time of arrival satisfies this inequality. This is the expected results on the basis of the elementary Robertson inequality. But here, this is an expectation value of a more complex expression. And it holds for all possible detectors, not only the ideal ones. We can prove this. And so this is mean deviation for the time of arrival, unlike other uncertainty relations for time. uncertainty relations for time like the Mandelstan thumb which involve which describe the speed of quantum evolution rather than mean deviation. How can we do mean deviation? Because we are having a genuine probability density through the P of M so this term is new. Sorry, I'm still having still mastered this. This term is new in some non-relativistic limited corresponding to an expression that had been obtained even by Landau and Paul. That had been obtained even by Landau and Piers for uncertainty relation. And why is it interesting? Because even if we have states with momentum with an infinite uncertainty, we get a finite expression for delta t. For example, this is an example of the Levite distribution. Anyway, we proposed that perhaps local particle localization can be defined in terms of this quantity. As I mentioned, particle localization. As I mentioned, particle localization, the notion of localization is difficult to implement quantum mechanically. So we had the proposal that use delta t as a measure of particle localization. It's an operational definition. It does not involve properties at a single moment of time because it involves time. So it goes around the restriction of Malaman's theory and it essentially follows solely from the two-point function of quantum field theory. Now, Theory. Now, this is one-point correlation function. We can work with two-point correlation functions. In quantum optics, this is very common. This in Glauber's theory, you have a two-events probability. This is the joint probability for two detection events. This is widely used in quantum optics, in phenomena like photon bunching and anti-bunching. In the Hanbody-Brown-Twis effect, these are applications of Glausier formula. Of Glauser formula, we get the corresponding expression again, a four-point function here. And well, we have used it in order to discuss a two-point correlation function for bosons and fermions in this setup like this and derive an inequality. How long do I have still? I have like quite one. Okay, so I'm going to rush to the final application where I'm going to a very different topic. This is Hawking and Radio. This is Hawking radiation. As I said, quantum gravity is one of the main motivations and black holes for describing, for trying to define information notions in QFT. Now, the point is in Hawking radiation is what about time correlations in photon radiation? The standard theorem that exists is the so-called Hawking-Walt theorem that says any field measurements. That says any field measurements at scri plus at the future null infinity is equivalent to a measurement of a field at the Gibbsian state with a temperature equal to the black hole temperature. Now, this is an asymptotic statement. Essentially, it involves the S-matrix. So if, and it is a single-time measurement. How about a two-time measurement? Now, before I go to the two-time measurements, I should say that the Hawking-Whalt theorem is the reason people say we have a problem. People say we have a problem in information paradox in black holes, because if the black hole evaporates, then the information that has gone has become thermal according to the Hawkinghold theorem. And somehow the original information is a pure state, it has evolved into a mixed state, which is the thermal. So, is information lost? Do we have a non-unitary evolution? And the key point here is that. point here is that again problem the key point here is that the quantity that is thermal is the reduced density matrix at scri plus according to the Hawkingwall theorem and the reduced density matrix of a composite system does not in general contain the full information if you take into account dynamics it does not contain all the information of multi-time probabilities so this is relatively well known in open quantum systems theory and the thing Theory and the single, so the reduced density matrix lacks the totality of information. And so if we have, so what the Hockey-Wold theorem is using is it is taking this Cauchy surface, in which it is defining the state of the system, and then it reduces to the part that corresponds to infinity. Of course, if you have finite time, it's not like this. Not like this. The Cauchy surfaces are of this form, parts. So if we take a correlation measurement, as I said, a two-event measurement, one event will be here, one event will be here. If we rush and take everything at scry plus, they are going to be on the same surface. So they're going to be equal time measurements. We cannot distinguish, right? The time difference is killed by taking the limits of t goes to infinity. And so the whole. So, the loophole in the Hawking-Walt theorem is that, yes, the system is described by density matrix that is thermal, but this has been updated by taking only single-time measurements at the asymptotic Hilbert space. If you take, first calculate the probabilities here and here, and then take the limit, you don't it doesn't the procedure does not commute because the difference between here and here is irreducible. Between here and here is irreducible. So we did calculate the correlation functions using our expression here. It's in detail analogous expression. It involves four point function of the field. Analogous calculations have been done before in relation to stress energy tensor fluctuations. This is much, much simpler. And we found that some very complex expression like here that the That the correlation function is not, it's definitely not thermal. It's not the same that you would obtain from thermality. What are the implications for this? Is that, well, the Hawking-Wold theorem essentially involves the two-point correlation functions of the field because this is where single-time measurements are two-point correlation functions of the field. If you go deeper and stay at finite time, you get something that. time you get something that is non-classical sorry that is non-thermal and what would this mean about the information paradox i'm of the same opinion that has been expressed by wald and unru there is no paradox so this is a minority opinion let's say in the field that non-unitarity is a prediction of the theory and in any case some information again sorry some information Again, sorry. Some information can be stored in the correlations and perhaps back reaction. If we do a treatment that incorporates the back reaction of the black hole to the field, some information can be from the state before the collapse can be recovered. Perhaps. So the key point is that the Hawking-Wall theorem. The Hawking-Wall theorem does not cover all physical cases. That's the message I want to say. And if we want to discuss whatever the opinion one accepts, that there is a paradox, there is no paradox, the key point is the quantum information balance of black holes is much more complex than it being usually assumed by taking a single time density matrix at null infinity. If you want to have information from multi-time correlations, correlation From multi-time correlations, correlations at different times, then you need to have an upgrading of the quantum information description, not just the entropy, let's say, of the final state. So this is, and this is one of the motivation for our scheme. We want to use our measurement theories in order to define informational quantities. And I'm finishing with just this message. If we want a rigorous extension of quantum A rigorous extension of quantum information theory to QFT for many applications, ranging from black holes to even problems in space experiments. We must have a consistent and practical theory of QFT measurements. We are trying to develop such a theory. This is what we call the QTP. Other groups are also trying to do so. And our method has benefit that it is at the level of being practical. Level of impractical simple formulas that can be calculated for elementary system, and remarkably, it provides a unification, let's say, with a functional formalism that has been very widely used in many problems of QFT, the CTP formalism. Thank you very much. Okay, thank you very much for this great talk. Now we are looking for questions. Okay, Jose Antonio. Okay, hello. I'm sorry for a very elementary question. I like A very elementary question. I like your talk, and the subject is fascinating conclusions, also. But there was a little part where you talk about problems with your probabilities not satisfying elementary rules. And my question is if these quantities that you call probabilities had the interpretation of conditional probabilities in any sense, and whether these two things that you were trying to combine were conditional to different things. The problem is that you need to get an exclusive and exhaustive set of alternatives in order to define probabilities. So if you have one exclusive and exhaustive set of alternatives, Inclusive and exhausted set of alternatives, and then we try to compute the probabilities. In general, this rule of probability assignment does not satisfy the Kolmogorov action for probability. It's not a general probability. If we have histories, that's a problem. So what is the resolution? I mean, the people working on the coherent histories suggested that it only makes sense to talk about probabilities if this condition is satisfied. If this condition is satisfied to kiss me. So, this is the rule. So, you have a candidate probability measure, which becomes an actual probability measure only for sets of histories where this condition is satisfied. So, this is a candidate for probability measure because you cannot use this and have invariance under additivity. So, this is the state of the system. State of the system. Quantum probabilities are very different from classical probabilities in this sense. This is one aspect where they are very different. Okay. Another question? Yeah, I'm sorry. Okay, I hope. Do you have an audience from Zoom? Yes. Okay. So okay, I do. Okay, we need to go to the next one. Yeah, we need okay. Um, another question. Let me also see in the in the okay. Uh, why don't I see it? Okay, Benito go ahead. Go ahead. Hi, can you hear me? Yes. Okay, thank you. Thank you very much for the nice talk. I have plenty of questions, but I'll just ask, perhaps a couple of them. So just on your main message, you said end measurements or two end point functions, kind of, I mean, represented by two end point functions. And I was a bit lost in the. lost in the in this decoherent histories approaches you you kind of sandwich you kind of sandwich in certain projection operators in between kind of the unitary evolutions yes or the let's say exponentiated this matrix or whatever um but in your approach are you sandwiching in these projectors or i didn't get the impression that you were doing that am i correct well i'm i right i did not Well, I'm I right. I did not yes, you can do that with the projection operators defined with respect to the to the to the detector. Not with respect to the field. Yes. Yeah, so you're saying detector click this way or detector click that way. Right, exactly. Yes. Yeah. Oh, okay. I understand. And you also mentioned that you made some analogy with Glauber's approach and saying that this is kind of a lowest order perturbation. Lowest order perturbation theory point of view. But I mean, are you trying to go beyond this lowest order perturbation theory in your definition? Right. These probabilities are easy to write at three level with respect to perturbation theory with respect to the field and the apparatus, right? So like glaubes, let's say. So, like glaubes, let's say we don't try to go beyond that. My opinion is that higher order terms will be manifested as noise. So, the signal, say, is in the lowest order. Okay, I see. I see. And can I just ask a final question or is it just maybe too much? Sure, sure. And yeah, so when you discussed the evaporation problem, you pointed out correctly that, well, maybe what you have. Well, maybe what you have in the end doesn't look like a thermal density operator or something like that, right? Or a thermal state, or let's say a KMS state, to be more general. Yes. However, this is not the cleanest statement of the problem. I mean, what is really problematic is whether the entropy of the state has increased. Whether it looks thermal or not is just a particularity, but the problem. But the problem, the reason, I mean, this is. I mean, I'm not saying you're claiming to have solved the problem. I'm just pointing out that the big issue is to do with entropy, not necessarily with the exact KMS or the exact form of a KMS state as the aspect. Yes, yes. Well, my point of view at the moment is just an end goal rather than something that we have achieved: is that entropy is not necessarily a good measure of information. So, we need to start from first principles, formulate everything in terms of probabilities, and then use these probabilities in order to define information. And probably, well, possibly, this is not going to be the same as the Fonheuman entropy. Okay. Okay. So, there's a lot in between that you have to work out. Yes, yes, certainly. So, at the moment, we're just focusing on the fact that there is additional information that is not. Additional information that is not being carried out by the reduced density matrix. And we want to find a way to quantify this information. Okay, perfect. Thank you very much. All right. Okay. So, unfortunately, we have to move to the next talk. I also have still a ton of questions. Also, I have still a ton of questions, and I have to say, I personally appreciate extremely your talk and think that in particular, the fact that you emphasized the basic problem at the beginning of measurement in quantum field theory, and that that's something that has to be resolved first before you can really apply quantum information techniques. I think that's a very important point that's often overlooked in the Point that's often overlooked in the contemporary literature, and anyway, we hope to continue this discussion in the afternoon discussion session. So, now we'll move to the next talk and yeah, let's thank this.