Sorry, Carmen is going to talk about chain duality for categories over complexes. So there you go. Okay, thank you so much, Andy, and thank you so much for organizing and for having me. I mean, I wish we were all in Oaxaca, but that's why my Oaxaca is in quotes over there in the first slide. So yes, the project I'm going to be talking about is talking about is uh it's based on a recent preprint that i have with jim davis and um well it's it's part of a it's part of a let's say of a bigger scheme of a bigger project that we have in mind uh but this was essentially uh you know we started with a big project and then we realized that we needed some some technical results and they ended up being quite interesting in themselves so this is what i'm going to talk about today okay so Okay, so let me first of all give a little bit of context. The result I'm going to be talking about is, well, we will boil down to details, details, details, but it's a result that's needed for a certain version of the surgery exact sequence. So let me first of all give everybody some context about what surgery theory is about and what are the fundamental questions that you would like to ask. So surgery theory has a Ask. So, solutary theory has a very, very long history. Essentially, things got like you know, started for real with Milner's classification of exotic spheres. And also, people who worked on the first steps in Jerjury theory was Salivan, was one of the most one of the really important people that shaped the beginnings of trajectory theory. So, what a fundamental question. So, what are fundamental questions for Sajiri theory? What does the theory in general want to answer? So, first of all, you would like to answer some existence questions. What's that? So, suppose if you have a space X, then your question would be, when is X homotopy equivalent to a closed manifold? So, you know, existence of manifold structures? And another very important question for For solidary theory is understanding the uniqueness question. And this is where the problem of spheres, exotic spheres, actually came in. The not unique diffomorphism classes of those spheres. So what's the unique question? So if you have a homotopy equivalence between two closed manifolds, say N and M, you could ask, are they isomorphic? Isomorphic. And isomorphic is very vague. If you're talking of manifolds, that doesn't really mean anything. But it's like I'm using that word as a placeholder for, well, you know, what different things could happen if you looked at different categories. So isomorphic here would say, would be either if you're in the topological category, you would be thinking of homeomorphisms. If you're talking about piecewise linear, you could be talking about PL homeomorphisms. And if you're talking about smooth manifest. And if you're talking about smooth manifolds, your word isomorphic would be just diffeomorphic, which was the exotic sphere situation. Anyway, so these are the two main questions. And of course, as I said, Segurity Theory has a very long history. These were the motivating questions. And then the thing is, how do you build up like technology to answer these questions? And yeah, so one of the Yeah, so one of the key tools for answering this question is the sojourner exact sequence. And with such a long history, the sojourn exact sequence has had many different versions of it. So the one that we're going to see in the next slide is already like a very big jump in history from the original geometric surgery exact sequence to a more computational algebraic version. So, what we're seeing here on screen. So, what we're seeing here on screen right now is the algebraic surgery exact sequence. Right, so I wasn't going to go into like a lot of details on the history, but as I said, this is already a rather advanced version of the whole story. So, okay, so for people who are not so familiar with surgery theory, there are several different There are several different groups in this sequence. In this version, there are abelian groups. In previous versions, well, there were difficulties with that. And the key player here, the term that you are most interested in computing is this term here, which is called the structure set. Of course, the structure set. The structure set will actually give you well, all the information that you give, like a representative, an element in there, would be like the representatives of the structure set are given by just homotopy equivalences from a closed M-manifold to X, to this X right there. So it would allow you to classify those homotopy equivalences. And as I said, compare. And as I said, computing the structure set, the structure set is the main goal because that's the key ingredient in computing, well, the manifold model I said, the set of homomorphism types of n manifolds homotopy equivalent to X. So yeah, so the structure set is kind of like the goal. But then of course, there are always obstructions to computing those, you know, to computing together. You know, to computing, to computing, depending on what your X is and what your manifolds are, what your spaces are, they're going to be obstructions. And the key obstructions live in this group right here. This is the quadratic L-CORI group. And also the different ways of understanding that group. But like I said, it's stated right here. I like it stated right here. The most reasonable way to think about it is this: that it is a group of abstractions. And now there are several maps here, but one of the map that's most difficult to compute and also the map that's key into the hill story is this one that's marked here, assembly map. So, yeah, so the assembly map again has. assembly map again has been one of the important pieces in this whole puzzle that has shaped the history of the Sagier exec sequence and you know just not just because of its importance but also because different versions of the Sagier exec sequence were more or less computable or useful for computations depending on how you interpret Depending on how you interpret your assembly map. So, in particular, in the very first version, in the geometric so you exact sequence, well, assembly map was very, you know, it's a very difficult, let's say, it's a very difficult exercise, almost it could get to be impossible. So, of course, there was an interest in understanding this a lot better. And the version that we have here is already a very, very big improvement. So the So, where in the old versions you would have had the normal invariants, now we actually have this nice homology group. And well, the key, now getting a little closer to what I'm going to talk about, is that eventually Ranitski and also together with, in partly also with Michael Weiss, they They gave a very interesting way to interpret the normal invariance as this homology group. But not only that, this was actually understood as also an L-theory group over some K-base categories. Now we're getting a little closer to what I'm going to be talking about. These are the categories that I'm going to be talking about right now. Now. And what was the interpretation of surgery in this case? Well, the interpretation is that now you have two groups that are of the same nature. You have this L-theory group over some K-based categories. Your information there is kind of fractured or indexed by K-K case. I will explain this later in more detail: case as simple cell complex. case as in visual complex in the first application. So yeah, so two groups of the same nature, they're both L-theory groups, but well, one is over this group ring and the other one is over this K-base category. So all the information there is kind of like fractured or let's say controlled by your simplicial complex K. And what is the assembly? How can you understand the assembly math in? How can you understand the assembly map in this case? Well, it is a passage from understanding local concernuality or local information to spaces that you can now see that they have like global concern. So the locality over here is controlled by how you fracture things using the information of your simplicial complex. And the assembly is really like now you have. Is you really like now, you have like pieces of a puzzle and you're going to assemble them. You're going to like really glue things together and assemble all the information. So local punker radiality will become global punker ideality. Okay, so this is kind of like a very slightly high-wavy, very, very general quick introduction to what the setup is. So as I said, this version of assembly is more complex. This version of assembly is more computational, it's in a sense more powerful, and one would like to understand this better. So the theory that Ronitzky and Weiss established, well, they defined these K-base categories, but those K-base categories, in order to define the L-group, they need to have a notion of duality, of chain duality. And the problem was that And the problem was that, well, they did define things. What Dave wrote is all correct, especially this is more anitkid advice because he wrote the work that he did. I should say that he should have done some proofs that we are not there. And then it's kind of like a little unreliable if you're in the very base of your whole building, you have some. Of your whole building, you have something which is not proven. So the missing thing is that if these K-base categories actually have the duality that you need them to have. And that's what I'm going to be talking about. Okay, so what is a change duality? You said you need those k-base categories to have change dualities as kind of key for the curl construction. What is it? So what is a change duality? So let me give you the definition. So a The definition. So, a changeuality. So, we're talking about changeuality on a certain category, additive category. Let's call it A is, well, it's an additive function. So, it's an additive functor from this CHA means, just means the category of finite chain complexes over the category. Okay, so finite chain complexes over the category. And you have this additive functor which gets you to. functor which gets you to the well it's um because you're going to understand this as a contravariant functor or you could just uh say that this is uh the op of of the of the category uh so yeah so we have this t the big t the additive functor uh so in order to define the chain duality we also need the existence of this natural chain map which is uh we denoted with this this tau hat here this this tau hat here and let's let's um pause for a second here to to see what the tau hats that map does just um let's mark this a little bit so um it's going to be homes from tc to d so we have um we have a c and we have a d and some people call this tau head a switch map because the result of applying the map will have switched c and d C and D. So these two things are going to be switched. Okay, so now we're going to have C over here and D over here. So this is clearly a very, very important thing. Okay, so that's what it does. And the important property of this tau head map is when you apply it twice, you're going to get back the identity. And this is a natural chain map. Okay, so this is all the information we need for chain duality. Need for change duality, we need our additive functor, and we need this switching map. For our purposes, we didn't just want to have a change duality, we wanted to have a strong chain duality. And let me say exactly what we mean by that. Well, if I take my Tau Fancto from the previous slide, it's very, very small, but the previous slide is a reminder up here. Remember that for just a change. Remember that for just a chain duality, we had the additive functor t, the big t from chain complexes over a to chain complexes over a, and we had the switch map that done twice is the identity. That's a chain map. So now suppose that I restrict this to just serial cycles, as I'm doing like here on the first slide. So I'm restricting the serial cycles, and now I'm going to have here an isomorphism of abelian groups. Of abelian groups. Okay, right, so I'm going to look at what happens to the identity on TC if I apply the tau, the switch map to the identity on T C. And what I get, well, what I'm going to get essentially, I'm going to do the same as I did with C and D before. I'm not going to say what was my D. So my D was. My D. So my D was calculated in the same way. Yes, D was D was D, and this was our C. And now we switch these two. And what I'm getting is, well, I'm getting T of T C, so I'm getting T squared C. And then I'm also just getting C on the other side. So that's what we did before. So that's what we did before with C and D. Now it's a specific case where your D is T C and C is T C. Okay, so now we have identities here. The identity of T C lives here. We apply the switch map. So we're going to get tau of the identity. And we're going to call that E of C. That map is going to be called E of C. So now that's a very, very important map in what we are trying to prove. To prove. And it's also part of the strong chain duality definition because, well, you can just construct a map from t squared c to c but this notion of strong chain duality, what it's telling you is that that map that you have constructed, the E C map from T squared C to C, that that map is a chain homotopy equivalence. And that is, you know, that is what it should. Um, you know, that is what it should be if you're expecting your category to have um chain duality, so yeah. So, so this chain homotopy equivalence is our kind of like, you could say that that was the goal, and that is essentially what was missing from Ranitsky's, you know, from his from his proofs, was the proof that The proof that, well, we'll get there. We haven't really gotten there just yet. I'm starting to blame him too early. So, this is just a definition. I'll blame him. I'll get to see the problem in a second. Okay, so strong changuality. Now, the A here is just an abstract additive category for the application that we were talking about. Application that we were talking about at the beginning of the solar exact sequence, that A has to be, you know, we're interested in a specific example of additive categories. And the specific example that we're interested in are the so-called K-based categories. Now, K is in this whole story, it's a simplicial complex. Much of the theory also goes through, if you think about posits, Adam's fluoro. Um, Adams Flora and Matco had versions where the K could be a ball complex. For us, especially also for the sake of this talk, K is going to be a simplistic complex. Okay, so what's the definition of a K-based category? Well, it's an additive category. We can define what are the objects, what are the morphisms. So, okay, so the category, the cabinet. category the k-based category we usually call the category of z round bracket k mod so c k mod and the objects the objects are well they are finitely generated free z modules with a decomposition which is controlled by each of the simplices in your in your simplicial complex k so all of these uh sigmas are simplices in k and then we have And then we have well, that also there are like different definitions of this, but for our application, each of these m sigmas is a finitely generated free abelian group. Okay, so that's how you kind of like decompose your module here. Okay, so those are the objects. Now, what are the morphisms? Well, the morphisms are going to go a little crazy because you want to have a morphism from From one of these finally generated free C modules, say M, you're going to heteromorphism from M to N, but now each of these M's and each of these M's are fragmented or decomposed into all of these summons, which are indexed by different simplices. So, it's what looks here like a nice little arrow, is essentially going to be decomposed in many different areas. So, it's a collection. Many different areas. So it's a collection of Z-module morphisms that, well, I'm going to send pieces indexed by sigma to pieces indexed by some sigma prime. And what's the relationship between sigma and sigma prime? Well, the slogan here is going to be, since we are in K-base categories, this is a CK module category. The slogan here is that you're going to be going from bigger simplices to smaller simplices. So from bigger to smaller. So in this particular, this particular, you know, if you're taking this to be k, you will have errors or non-trivial, possibly non-trivial errors when your sigma is greater or equal than sigma prime. equal than sigma prime. Okay, if you had a K-OP category, everything is reversed and then the slogan changes from smaller to bigger. And we will see an example of that in a second. Okay, so this is a key definition. Let us see, let's see before we move on to anything else, let's see an example. So suppose So, suppose that your K is just one simplex, and I'm going to label my simplices in my one simplex here. That's going to be K. I'm going to be labeling them as, well, the zero simplices are going to be sigma naught and sigma one, and the one simplex is labeled by tau. So, what I am going to do now is I'm going to look at if I had the simplicial complex of simplicial complex of k itself well that actually gives me i can understand this as as a chain complex of as a z k module chain complex and in order to do that well you see that in the in dimension one that will be indexed by by tau and that gives you your your c for the uh for the one simplex and what do i have in dimension zero i have the um well the the Well, the thing that's labeled that's indexed by the sigma zero and also by the other vertex by the other one simplex, sorry, zero simplex, sigma one. And this is going to be C plus C. And you see how this slogan here, the login that we had right before, bigger to smaller, actually does hold because, well, tau is the bigger one. So these are the correct directions for those arrows. For those errors. Now, it's also interesting to see what happens if we look at K-Op. So, this is kind of like the dual version. Dual, dual, you're going to note that there's lots of like minus duals right here. That's just to stay within chain complexes instead of like going to co-chain complexes. So, essentially, it is a co-chain complex, but just looking at things in negative degrees. things in negative degrees so that you can keep the uh you know you can still have things as uh as chain complexes so now this is a little different because now i'm looking here at chain complexes of um over the ck op module categories you notice that there's an op right here and what does what that does is that now your arrows are going to have to go the other way around but still everything really does fit because It because I'm having trouble here with them. Okay. Now it's all good. You can still see the slide helpfully, but I can't take notes anymore. So let me just get in and out for a second. No, this is a problem. Okay, technical problem here. What's happened? Well, that, you know, I have this slide, I could continue talking, but I like to have an option of pointing and writing. And somehow that has stopped, and I'm not sure why. So, what's the battery level on your pencil? No, no, it's it's okay, it should be okay. Let's see. Uh, 67. 67 yourself. Oh, yep. So somehow the pens it had forgotten that it had a lot of friends, the iPad. Okay, so as I was saying a moment ago, now we have the KOP. Both categories are important. Both this example with the K is important. For the applications, the OP is even more important. So that's More important, so that's that's why it's just um I'm making the point here of also seeing this um K-OP version, and um, as I said before, for K, the slogan will be bigger to smaller, but as you can see for the for K-OP for K-OP, we do have smaller, this login line is going to be smaller to bigger simplices. So that's how your areas are going to go. Also, going to go. Okay, yeah, so now we've introduced the K-base categories. We've seen an example. Now, this, now we can state the main result here. And the main result is the thing I was complaining about before, the theorem that says that this category of CK-op module chain complexes is an additive category with strong chain duality. So essentially, the same that Saying that, well, the map EC that I had from before, this duality functor, that if you do it twice to C, are you going to get back to C. So essentially, if you forgot about the K-base structure, this would go back to the classical thing of saying, you know, the dual of a dual is just C. So if you take the dual of C twice, you're going to get back C. And the complaint was that, well, this is a theorem and all the definitions are there, but there was no proof that this actually was a homotopy equivalence. So if there's no proof of that, then everything would collapse. So this has worried several people, and therefore there are several different proofs of the Several different proofs of this. So, one proof was given by. Let me actually write it down. So, first proof of this was given by Adams Floro and Tibor Machko. And this is from, it was published in 2018. And very, very recently, Frank. Very recently, Frank Connolly also has given a very nice proof of this result. And the third, or let's say, well, you know, Frank and our team, Davis Robbie, actually published, you know, the preprints out like almost simultaneously for some strange reason. So, Davis Robbie, we also have a third proof of this and proof of this and essentially they're all they're all different so depending on what you want to work on or what your what your goals are what your fellow girls are you might want to look at different ones this this this is slightly difficult to read frank has a very interesting inductive proof and we have a proof which is based on geometry so we we do from the three proofs ours probably the the most geometric one okay One okay, so I want to talk a little bit about the proof now, and as I said, we do make a connection with geometry. So, let me first of all, well, let me start by making that connection. So, okay, so in this slide, we're going to understand what are the K, what is the notion of a K dissection of a space, a K or a K up dissection of a space. So, well, So, well, so what does a what does so we have a space CW complex X? What a dissection allows us to do is to subdivide this CW complex X into subcomplexes. And the union of all of these subcomplexes, which each of them is going to be controlled by one of these simplicies in K, just a little bit like what we had before. A little bit like what we had before with the definition of the k-base category and everything. This is happening in a similar way, but now for spaces. So we do have a CW complex, which we subdivide into subcomplexes. Now, here we have two examples, just to, I don't know, like maybe to make the notion of a k-dissection clearer and then, you know. Clearer, and then, you know, just to have like nicer pictures, I decided to pick different examples. So, these two examples, two different examples on two different spaces. So, if we focus first of all on the one here for the example for the k-dissection, what I have originally is some cobodism, you held X here, is a cobodism from some manifold to another manifold. Manifold and in this example, again, k is just one simplex. So, one way to create this k-dissection is by saying, well, the piece indexed by sigma naught is going to be a boundary. The other piece indexed by the other zero simplex is going to be the other boundary. And your compodism down in the middle is going to be indexed by the top. By the top. Now, so that would be if you were trying to do a k-dissection, if you did a k-op dissection, now let's focus on the other example over here. Well, a k-op dissection for to construct that, you actually need to look at the dual kaons in the simplicial of the of your simplicial complex. So, see back here in the k-dissection, I have a little arrow pointing to the Pointing to the one simplex, but over here it's actually pointing to the dual currents when you take those duals in your one simplex. You're going to have a dual current for your sigma naught, a dual current for your sigma one, and you're going to have this, well, zero-dimensional now, dual current for tau inside of k. And what you're actually doing in order to construct your k-op dissection is you're taking a Dissection is you're taking a reference map to these dual counts and taking like the pre-images into the into your space of all of these all of all of the dual counts that you have here. So for example, the piece that's indexed in the K up dissection that's indexed by sigma naught will be a pre-image of this. You all can. And so on, so on, right? So if you took the pre-image of tau, now you will get this. You will get this KO dimension one manifold, which is the X star now. So, yeah, so K of dissection, we have these pieces and they come from essentially taking pre-images of the dual camps. Okay, so what's the connection between these K-dissections or these K-op dissections? Or these k-op dissections, what is the connection with the chain complexes and the k-base categories that we saw a moment ago? Well, if I write down the chain complex of X and I write it down in terms of the pieces that I just constructed here, well, I'm going to get a direct sum index over sigmas in k. And what I'm getting is the, well, we get it relative, relative. We get it relative, relative chain complexes, so that's that's what you get. And similarly, on the other side, you also get this direct sum of relative chain complexes over here. They look the same on the group level. Since this is a K-dissection, you will get a chain complex in the CK module category, and your morphisms will be. And your morphisms would be, well, what we described before. It could go from bigger simplices to smaller ones. So simplicity indexed by tau could go to things that are indexed by sigma naught or sigma one. And essentially, as I said, this on the level of groups, it looks the same. K of dissection and k dissection looks the same. But if you look at the differentials of the chain complex, you get something a little different. That's where the Different. That's where the subtlety comes in. Yeah, but we now can see the connection between taking a space and chopping it up into pieces, which are indexed by the simplicity in the chain complex. And you now look at the chain complex of your fractured space, and what you get is something over the CK of module category or the CK module category. Category or the CK module category on the other side. And this is essentially the key of what we have to work with. Okay, so let's have a look at a second example. So the previous slide just showed K dissection K was a one simplex. Now I'm going to take a two simplex. K in this slide is a two simplex. Okay, is a two simplex. Say two simplex in this slide. And again, I'm going to have k-dissection and a k-op-dissection of what? So now the space, the space that I'm k-dissecting is the geometric realization of the two-simplex. I'm taking the geometric realization of the two-simplex, and I'm K-dissecting with K-V at two-simplex as well. This is a rather special example. So you see what happens in the K-dissection situation. Happens in the k-dissection situation? Well, what am I getting back? Well, I'm essentially just each of the pieces which is color-coded with different colors is, well, it's just one of those simplices in your simplex. What does the K-op dissection look like? Well, it will be the dual k-ons. They're not all labeled, but because there was too many. But because there were too many labels, but you can get the idea of what these things are. So, for example, this one will be the dual k-on for this simplex right here and so on, so on. And the thing in the middle is the dual kaon for the biggest cell, for the actual simplex right there. Right, so now we have this is a different example of a k-dissection and a k-ob-dissection, both very useful. Section, both very useful, but we actually are interested in a little bit more. So there is a notion of a refinement of a dual cell decomposition. And you see how this new picture that just appeared is a refinement of both this picture and this picture. Now, the difference here, the key difference here is that, well, each That well, each of you know the dual cones are just cones. If you have a manifold, they are going to be cells, but if you don't have a manifold, they're just cones. But what I get from this refinement is pretty interesting because now I have a lot of cells, but they are genuinely, they are cells. So, this is what we call the dual cell decomposition. And, well, what are they? Well, for example, Well, for example, this dual cell is the dual cell of the zero simplex sigma naught in sigma naught. This is our notation here. What is this pink thing? Well, that's the dual cell of sigma naught in tau. So yeah, you can label again. I haven't written all of the labels here, but all of these dots are These dots are zero cells. Then you have all of these are the ones that I'm just pointing at right now. You have a lot of one cells, and then you also have these two cells. And of course, there's nothing specific to a two-simplex. This is a construction that you could generalize to essentially any dimension you wanted or any simplicial complex that you want to think about. What is the dimension of each dual cell? Well, if you think. Well, if you think about, well, first of all, in this notation, for this notation to make sense, tau has to be of greater dimension than sigma. You know, the smallest that you have here is sigma naught, sigma naught. Obviously, tau here is bigger than sigma naught. So what is the dimension? Well, it's the dual cells, the dimension of the dual cell is going to be the k dimension of sigma. Dimension of sigma in tau. So the dimension of tau minus the dimension of sigma. And yeah, each of them is homeomorphic to a disk. And this kind of decomposition is, as we will see, it's going to be useful for us in our definition of duality. Okay, so now I'm going to make a connection with With of connection of this kind of geometric approach, I'm going to go back to K-based categories. Only this time I am going to define something which is not just a K-based category. You know, this dual cell decomposition, you can think of it as a positive as well. I mean, there's a slight abuse of notation here. I don't understand that, but you can think of this. But you can think of this decomposition as, just as you're using K, a little bit like abusing notation for K, you can also abuse notation for the dual cell decomposition. You have this new posit DK, where the objects are, well, as I mentioned before, it doesn't make sense to think about taus that would be like smaller than sigma. You always want your sigmas to be smaller than tau to actually get something in your decomposition. Something in your decomposition, so your objects are these ordered pairs, and the morphisms where the morphisms are orderings between these two pairs. And you do get that this pair sigma tau is less than another pair sigma tau prime if you have this property, this sigma is going to be the smallest. Sigma is going to be the smallest, this tau is going to be the biggest, and the other two, where the other two you see that they land there in the middle. So that's the definition of the DK posit. So since we do have a posit, we actually can give the definition of a K-base category, but now it's going to be not K-base, it's going to be DK-base. not k based it's going to be dk based so we do have this definition of z dk complexes and if you look at if you look at that well you do have um the the chain complex of of of t k of the decomposed thing is is going to be isomorphic to this tensor product of code chains and i mean the code chains of um I mean, the code chains of simplicial simplicial complex of K on this side and simplicial code chain complex of K on the other side. And what does the isomorphism do? Well, it's going to send each generator, which is a dual cell, it's going to send it to this product of, well, generators in the first thing in the tensor product, which I label with a little hat, just to remember that we're talking about the code chain. That we're talking about the co-chains and the taus from the other side. So, dual cell of sigma and tau goes to the product sigma and tau. And that's an important isomorphism that will be useful also later. So, this is one to actually remember. Okay, so moving on a little bit. So, we've investigated and seen a bunch of examples. And seen a bunch of examples of this round bracket category. Now, that's all very nice. It gives a very geometric approach and a very good understanding of how to cut up spaces or control spaces by subdividing into sub-complexes. But for many purposes, we would like to have not just an additive category, but an avidian category. So there's a way to do that by So there's a way to do that by embedding the CK module category, the round bracket category, in another category, which just by keeping the reminiscent notation of Renitskian vice, the square bracket category. So we are now going to be working mostly with this new category, which is abelian. How do we define that? Well, CK mod category is a category where the objects are a functus. Are functors from k, where this implicit complex k, to z modules, and the morphisms are going to be natural transformations. So, you know, we just introduced this category for the purposes of having an avidian category which has better properties. So, some examples of that. Well, we could think of this. This could be an example. So, you could have a functor which takes a simplex and it just sends it to C. And then that functor, well, just takes a morphism and sends it to the identity on C. This is one nice example or one very, very basic example. And of course, if you think of it, there's also an augmentation. of it there's also an augmentation map from well this um this this this uh functor that this is actually a functor um but essentially it could decompose into um you know again again you would have like you would be able to see that um what this augmentation augmentation does is that it's it's it's taking any serial simplex it's taking it to one and any simple One and any simplex that's bigger than that will just go to zero. Again, I could have taken, instead of starting with just k, I could have taken dk as the indexing cat as an indexing category. And if I take dk, well, what was dk? This k was this postet. I had pairs. So the input would be, well, this is the functor. The input would be. The functor, the input would be the pair sigma tau, and that will be sent to just C, and then morphisms will be sent to the identity. And similarly, a little bit like with this simpler case, similarly, I can also define some version of this augmentation map, which, well, we saw before how this is isomorphic to the chain complex of the dual cell decomposition. What does this omit? What does this augmentation map do geometrically? Well, what it does geometrically, let's look for a second here down in the little picture. This is the chain complex of this picture is isomorphic to this tensor product. What this augmentation map is doing, it is taking every, well, it's taking sigma tau, they've send them to zero if sigma is not equal to tau and sigma sigma is going to one. What it does to Sigma is going to one. What it does geometrically is that every zero simplex gets sent to one, and everything that's not a zero simplex, everything that's bigger gets sent to zero. So that's what this augmentation method does geometrically. Okay, so now we're kind of ready to give the definition of the K-base chain duality. What does it mean to do? And what does it mean to do k-based chain duality? So now, this expression is a little bit difficult to parse. So if you take a chain complex and you have your k-based duality functor t here and you apply it to your chain complex, you have this, you get this kind of like difficult expression here. So, in order to at least visualize this a little bit more, I've drawn this picture. I've drawn this picture. Of course, there's a problem that there's a minor star out here, and that makes pictures almost impossible. But I want to motivate, at least, at the very least, I would like to motivate what's inside of the parenthesis a little bit. We try to motivate, oh, that looks bad. We're going to motivate what's inside of the parenthesis. So remember when we did k-dissections of our space. Our space. So we also looked at the chain complex. So if I put little labels on this, this will be so one of these pieces, well, as a space, it's just that piece would be X sigma, but as a chain complex in the category of functors, I can understand it as C sigma naught. These other Ps will be C sigma one. Sigma one and then this codimension one piece will be the square bracket C tup. So those are the chain complexes of those pieces. Okay, what happens if I what the thing inside the parenthesis is telling me this just that, what the picture for that would be is zoom in a little bit. Well, the next to the pointer, yes. So this piece will stay the same because essentially we're taking a tensor product. When you're evaluating on sigma naught, you're taking the tensor product over something which is just a point. So that piece will stay the same. The light pink piece will actually. Piece will actually also stay the same for the same reason, tensor product with something which is just the chain complex of a point. So that's it. But the thing that was just the KO dimension one thing in here, now you see what's happened to it. So this is the chain complex version. This kind of like would be like the space picture of how you could think of geometrically. So what we're seeing here. So, what we're seeing here is that we're tentering by something which is one-dimensional. So, you know, that's why I'm getting this bigger picture right here. Okay, so that's what happens, at least before you take the dual right here, that's what happens to your what's happening inside of the parenthesis. That's what happens when you take the k-base dual of something. Of something. Now, this looks very complicated. The KVSUs look very complicated, but there is an interesting take to this: if you actually forget the K-base structure, you forget, maybe you're like taking K to be a point, or you completely forget the K-base structure, what you're actually recovering is just plain ordinary duality. So TC would just become. So Tc would just become C minus star. And this is what this last line here is telling us. So what this last line here is telling us. Just zoom in a little. Yep. So what this last line is is telling us that if I forget the K-base structure, essentially just like take the KO limits of this T C. Of this T C functor, then what I'm getting is that that's actually equal to the K limit of the C minus dual. So K limit because this was K based and I have to forget the structure. So that's why I'm taking K limits. How do we see that? From the algebraic expression, so we can see that, well, K limit is just Limit is just given by this. This costs a little bit of proving and working with Gianedo Solema to actually see this. But you can see the connection between this expression and this expression. And you can also maybe remember that we talked about the augmentation map that takes this to this. So essentially, what I'm forgetting is all of the path. Is all of the parts that have been like made bigger by the k-bay structure now? They're going to get so this one simplex is going to get like current stone to a point. And that's what this what this map here is doing. And of course, the map goes in the other direction because I have the minus stars and everything. But this was this augmentation map from before. That's the map that gives you the connection between the K limit of T C and the K limit of C. And the K limit of C. So this is the key of the whole idea. Now, of course, there's slight difficulty in the actual proof of what we want to do. We want to do this twice and get this homotopy equivalence. But once you understand this map, well, it just boils down to doing it twice. doing it twice and um in the doing it twice well you get um uh you get this this nice commutative diagram right here um you can write down by you know you can write down and get a horrible expression of what this t squared c is with k base and everything but you can actually show that um there's a slightly nicer version of what you get by doing t squared c by writing Squared C by writing this term up here. And these two things are isomorphic just on the nerves. So the nicest thing about writing it like the square up here is that maybe you recognize what's inside of this square bracket. So the upper row is the C is just stain C, and the pink, that was our dual cell. That was our dual cell decomposition. And we also had an augmentation map that said that all of those dual cells, the zero cells, are going to stay where they are, and the one cells are going to get, you know, they're going to get sent to zero. And so that augmentation map sends this pink thing up here, this pink thing, it will send it to here. And of course, that's your E up here. That's your E up here. That's uh, so you get a weak equivalence on this top row. You have isomorphisms because of your net as lemma, you have isomorphisms on the vertical row. So, what you get on your key, on your key map, which is this one down here, this one, you get a quick equivalence. And that's all that's why our connection with the geometry was so important because we see that this is. the we see that this is a we see that this is a weak equivalence based on the geometry of these uh dual cells here and then well you could complain oh there's square brackets around of these things well if you're weak equivalence in the square bracket category you are a homotopy equivalence in the in the um or initial k-base categories without the square brackets so that is all that is all good and this looks like this is a summary of what how like this is a summary of what how the proof goes and just to just like uh half a minute to just you know this seems like a like a technical result it's like a one extra proof of something that kind of we already believed so why would we bother to do that because well we do have some future goals for this so essentially what we've seen what we've proven is that the categories have the right The categories have the right chain duality so that you can define L-theory of such a category. So now we're confident about this, we're happy with that. This is also isomorphic to this homology with coefficients in an L-theory spectrum. And what Jim and I want to do now is to understand equivariant versions of this by understanding: well, what we want to get is. Well, what we want to get is equivalent homology right there. And we want to do that by understanding what happens if our category here, instead of just being indexed by K, it's indexed by K with an action of G of some group G on the simplicial complex K. And that's where we have quite a bit of work. Well, we have quite a bit of work done in this direction, but it's still not completely finished. So, that will be our first next scale. And then, finally, well, once we get that, there's various different applications that one could think of. One initial motivation of something that we wanted to do with this is to actually give a proof of the well, this kind of like fault-core theorem that says that if you have your G is this semi-direct product. Is this semi-direct product, and the equivalent the cohomology of R is the cohomology of a point, and what you cap is does this S theory group. So essentially, this is essentially a case of Faraday's conjecture. And well, yes, that's where we are at. Thank you so much for your attention. Thank you. Thank you. Okay, does anybody want to ask any questions? Actually, I can't see the CMO people, so maybe like the last time. Does anybody in the CMO auditorium want to ask a question? No? Okay. There seemed to be no question. Okay. There seem to be no questions here. Okay. Yeah, sorry, now I can see you. Right. What about anybody on Zoom? Does anybody want to ask Carmen a question? No? So can you say a bit more about how the last thing would be part of the Ferrell-Jones conjecture? Yes. There's a K-theoretic for a Jones conjecture and an L-theoretic one. And this is, well, you see that here the coefficients are, well, it's an L-theory spectrum in both of them. And essentially, Faradon's conjecture can be understood as an assembly map. So that you go from equivariance homology theory. Equivariance homology theory to well, if it's k-theory, this would be k-theory of a group ring, if it's a theory, it would be a theory of a group ring. This is, you know, this, of course, there's like so much work on Farado's conjecture. There is a very nice paper by Jim Davis and Wolfgang Luke that gives a very adequate approach of the to the, you know, very adequate approach to the. adequate approach to the to the FerroJohn's conjecture to actually approach this problem. But yeah, the Ferrari's conjecture is a huge field of work with work on when does this help, when do you have such an isomorphism based on different versions of OMG? Okay, this also would be a little different. So, I mean, that's, I can, I can tell you in a break if you. I can tell you in a break if you want. It is a rather long story to just summarize in a few words. Just saying that this is a time in the folklore theorem that people know about, that this is true. And you could frame it as a statement that kind of like the whole framework would be Farrell-Jones because you're thinking of this kind of assembly map. But of course, it's not like I'm going to. But of course, it's not like I'm going to prove the whole conjecture or anything. Maybe I can ask: since you have an infinite group acting here, it starts to look like maybe you're interested in infinite k. It wasn't quite clear whether your simplicial complex was finite or not. Okay, so yeah, so my simplicial complexes are finite. Because otherwise, I mean, if they were infinite and you had infinitely many simplices. And you had infinitely many simplicities coming in, then it would be a little bit complicated. They're finite. Yeah, I should have said that. That should be in the picture. Yeah. Thanks. Any other questions? Okay, well, let's thank Carmen once again. Thank you.