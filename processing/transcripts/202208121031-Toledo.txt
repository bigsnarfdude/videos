workshop and also for finding and also the presenters are really learned a lot. So right so let me start also by acknowledging my collaborator Denny from the Institute of Physics in Mexico and also acknowledge a MIT's fellowship. Alright, so I'll start by first talking a little bit about what motivated this project. So many processes in biology, chemistry, Processes and biology, chemistry, and economics for that matter. And probably more. In many cases, there's where normally we're interested in knowing the probability that at a given time, a given event happening for the first time. So usually that t is a random variable, and so we would like to know the distribution, the first passive distribution. So for instance, an example is RNA polymeris. There's this process whereby. There's this process whereby it backtrace and then it takes some time, which is a random variable, to get back to where it was or either through cleavage return to where it was or continue making RNA. So this actually was modeled as stochastic resetting and backwards fact recovery using stochastic resetting. So I'll be talking a lot about that. You also have inside the nucleus of cells different segments in DNA that need to In DNA, that need to meet in a timely fashion for vital processes. And so the time for that is also a random variable. So you can ask the question, what's the first passage time? Right here, it's an example of a drilostophila. You have a source. The source is emits from the odor plump. And so the fly is flying around and making decisions based on the concentration. And through those decisions, eventually lands on the source. So you'd like to know what's the mean first passage time. Know what's the mean first passage time for that. And also, you have a sue of models, especially by Sidney Retner, in which they model one-dimensional lines and lambda, and they ask the question of what's the first passage time for those events, right? So that's kind of the thing I'm interested in here. But the other side of the coin is, well, ultimately, acquiring story processing information and acting upon it will come at a cost. Will come at a cost of energy. So we presume there should be a trade-off between one and the other. So here's a simple example. Imagine you have a naive prey and you have a predator. This is just a Brownian particle, one dimension, and the prey. And the predator stochastically relocates or resets to positions visited by the prey in the past. So the predator does that with a rate Q, that's the resetting rate. And also there's a parameter lambda. And also, there's a parameter lambda, which is like a continuous variable. And you can move that to change the searching strategies. You can go from a passive search, in which the predator is more likely to jump to position closer to the initial position of the prey. And if that's for lambda positive or lambda negative, the predator jumps to positions closer to the current position of the prey. So what one could consider one could consider that the predator's means for displacement is some sort of proxy for the energy cost. So you can see that you have, well, three different regimes, but I'm just going to talk about these two for now. So you have the active search and the passive search. This is like a Browning particle in a harmonic potential, that's just basically flat. Whereas this one, the predator is actually chasing the prey, is diffusing as the prey. Whereas if you look at the log. Whereas, if you look at the logarithm of the mean first passage time versus the logarithm of the reset rate, you can see that both regimes show the same behavior in log log rate. And as you increase the resetting rate, pretty much the mean first passage time is the same or very close one to the other. So you can ask the question: well, what's the best strategy if I want to optimize energy and if I want to optimize time? So that's sort of the global idea of this. The global idea of this, right? So, but I'm going to do that in a different way. So, here's sort of the steps I'm going to follow. So, first, I'm going to talk about first passage time for a Brownian motion with stochastic reaches to random decisions. And I'm going to show a model that we came up with that's quite general. And then, with that, I'm going to introduce the concept of mean for stopacidrophy and talk about Lendauer's principle, just to enunciate it, and show how it works. And show how it works, how we can compute the mean first passage entropy. And then talk about what we call a tropically stable search machine and show the phase diagrams of the dynamics and the entropy for this sort of machine. So let's start from the basics. So I would like to know the first passage time distribution for a Brownian particle starts at x naught, and there's an absorbing boundary condition. Absorbing boundary condition at zero, that's the target. So I asked the question: what's the first passage time distribution? So here's your Langevin equations, but it's better or it's easier if you go this way. You have your Fogger Planck equation, you solve it, and you add the absorbing boundary condition at zero, so you add an image at minus x0. So this is your solution, and then you compute the survival probability. You compute the survival probability by integrating this quantity from zero to infinity. So that's telling you the survival probability of the Bringing particle. So basically, the probability of finding at time t the Browning particle in the positive semi-axis, given it started at x dot. So there's a relationship between, there's an equation that relates the first passage time distribution with the survival probability. It's this one right here. So you compute the derivative and you have the first passage time distribution for this case. The first passage time distribution for this case, right? So it's a Levitic distribution, so that means it has a fat tail. So it's normalized, but the first moment is infinity. So that means that the particle will always reach the target, but on average it'll take an infinite amount of time. So now if we add the stochastic reset, so basically what happens is stochastically you're resetting in this case to a fixed position. So this model is the Evans-Majumda model. And so this is a Poissonic. And so this is a Poissonic process independent of the Brownian motion, and the parameters, the resetting rate, is the parameter in the Poisson distribution. So these are the points where the particle is resetting. So you can write again the Fokker-Planck equation, initial condition, boundary conditions. And you can use the backward Fogger Planck to solve this, to get the mean-first passage time. And in that case, you get this behavior. So you have mean-first passage time. Behavior. So you have mean first passage time versus resetting rate. This is the analytical expression, and you can see that in this case, it's actually within equality. So when you go to Q, when the resetting rate goes to zero, you don't have resetting rate, so the time, the mean first passage time diverges, as in the previous case. When the resetting rate goes to infinity, you're resetting your particle too fast, and you're not giving it enough time to find the target. So that's basically that. So there's a minimum here that you can actually compute. Actually, compute leads to a transcendental equation, but so you can compute it numerically. So, all of these, all of this is done in this paper. So, since then, there is a problem. Other people have worked on similar problems. And the idea is to say, well, I'm going to net into the same position as that and say, what happens if the particle just resets to some just reset to some distribution that I know. In fact, of resetting distributions, it could be an infinite set as long as it is keeping basically a given distribution, probably the second reset, it resets to another decision, sample from a different distribution, and so on. So this is just an example in the case of the Example in the case of the resetting distributions are all Gaussian, the same Gaussian with mean C0 and standard deviation sigma. And this is the mean first passage time. So this is how it looks. And now I just want to mention these two parameters. You're going to see them a lot. So it's W and C. Think of this as a proxy for the resetting rate. And think of this as a proxy for the inverse of the standard deviation. Okay, so how. Okay, so how does that method work? So the first thing you need to realize is that in between the resets, everything you know about grammar motion still holds. So that means that survival probability in between the resets is still the error function, the one that I showed previously. But thing is now the resetting is hindering the first passage process. So that means that this time here is actually a random variable. So you need to average that time over the That time over the resetting rate distribution length. So that's what's happening here. Also, since you're resetting to random positions, so you need to average over the position, over the resetting distribution for that particular resetter. So that's what's happening in this expression. You compute this theta function, which is you can see this expression. You can understand it as the average survival probability in between reset n and n plus 1, given that n. Given that n resets have happened. So, once you understand that, then there's a relationship, there's an equation that relates mean-first passage time with survival probability in Laplace space. So, from that, that explains this product here. So, this product comes from taking a convolution of survival probability, conditionalized to a different number of resets. So, when you do a plot, it becomes a product. It becomes a product. And this sum right here corresponds to marginalizing over the number of X's. So that's how we get to this formula right here. The other interesting thing is that you can also interpret this theta function as the probability of n plus 1 resets given that n resets have happened. Because if you survive up to this reset, then that means that that reset is going to happen. So by that, you can write the problem. So by that you can write the probability of n resets and it's sort of like tossing a coin. So it's just the probability of having n tails and one head as the last event. So that's what's happening in this expression. And with that you can compute the mean first passage number of results. So notice that these two formulas, well this in the case of mean first passage time, it's actually a formula so you don't have to solve any differential equation to obtain To obtain the mean first passage time, right? And this works for the Evans MajumDAN model and also works for some samples I'm going to show here. And so far I haven't found an example where it doesn't work for me. So for instance, here we did some simulations and we compared with our model. You can see the mean first passage time versus W for different values of C. So the lines are simulations. Sorry, the lines are. Sorry, the lines are analytical results. The points are data from simulations. And you can see a very good agreement. Same goes for the mean first passage number of resets. So this is the case in which the resetting distributions are all the same Gaussian. So it's just one Gaussian right now to get this. The other thing that I'll come back to is the fact that you have what's called a metastable minimum right here. So that's, I'll come back to that. I'll come back to that. So, okay, so the method works. I'm not going to spend more time on that. So, I'm going to go now to the entropy part of the talk. So, there's this thing called Landauer's principle. And what it says is that by reducing the randomness of the physical entities, for instance, if you're storing a bit in question, you have a bit and you change the value, you have something stored in there, and then you erase it by storing something else that you. You erase it by storing something else that you know probability one, the value of it, then you're changing the entropy of that system. And by doing that, there should be some manifestation, physical manifestation of that. As in the case by going from entropy different from zero to entropy equal to zero, then you should be dissipating some energy. So that's, and that was principle. Very, very simplified. Simplified so that, well, actually, it's from 1961. This idea was proven on different settings by different groups. This is one of the groups. And you also have this other paper in which they talk about stochastic thermodynamics of resetting. So they do a consider stochastic resetting and mix it with Landau's principle. What I'm going to show is. Principle. What I'm going to show is that with this method, we can actually compute the mean first passage entry. And so the way we do that, it's the same way as in the previous case. We just separate the process as sub-processes. And so we know that the entropy before the resetting is simply given by the Gaussian distribution that solves the Fogger-Prime equation. The Hugger prime equation. So when the reset happens, now you're basically taking, you're erasing the information coming from the Brownian process, and now you're storing a new values that you're getting from this distribution. So there's a change in entropy. But similar as in the previous case, when I was talking about the mean-first passage time, the time here is a random. The time here is the random variable. So, because it's hindered by the resetting, so you need to average over the Poisson distribution. So, that's what's happening here. So, you compute first the entropy change per reset, then the average entropy change per reset, it's just averaging over the Poisson distribution. So, that's the, so that's every time there's a reset, on average, that's the change in entropy, right? So, notice that you have here the resetting rate. The resetting rate, and you have the diffusion concept, and right here you have the information regarding the distribution, the resetting distribution. Basically, it's going to depend strongly on how narrow or broad your distribution is. And then you just average this over the problem using the probability of resets, of number of resets, and that's the mean viscosity change. So you have three reductions. So you have three regimes, three possible regimes: externally driven regime, the zero entropy regime, and the maximal demon regime. And basically, when you're here, it means that you're gaining more entropy, and by Landau's principle, you're gaining energy. Here, it's zero, and then Maxwell Demon, you're dissipating entropy, and by Landau's principle, you're dissipating energy. So, how does that look in some of our simulations? Some of our simulations. So I have a question. So, normally, when you're invoking Lando's principles, it's for systems coupled to a heat bath or multiple heat baths, and hence the KBT log to write the T in there. So, here there's no notion, I mean there's no necessity to coupled to a heat vat. So, are you interpreting this kind of in an abstract sense, or how do you account for that? So, yeah, it's coming from an abstract sense, but in principle, you have the Brammy. But in principle, you mean you have the rambling particle coupled to a heat path. I mean, mainly, I'm first showing the mathematics of it, right? And while we were doing this, we were thinking of just a grammatic particle and heat. So there is a temperature, right? But I don't know. I'm happy to hear people's thought on that. So anyway, so we can compute the mean first passage entropy. Passage entropy, and so we have the three regimes. You have the Maxwell-Demon regime, then in this line, you have the serial entropy regime and the external drip regime. So, similarly, for the mean first passage time, which I showed previously, the dashed line corresponds to the zero entropy region. So, sorry, this is for, in the case of the resetting distributions, are all Gaussian, the same Gaussian. So, now the question is: can I optimize? Can I optimize the mean first passage entropy and the mean first passage time? So, really, the depends how you want to optimize this. I'm just going to show here that you can actually overlap the phase diagrams for the dynamics and for the thermodynamics. And by that, you can actually tune the parameters and see which tune the parameters and optimize it however you want. However, you want that. So, one second. Nice question. Jack. How does your entropy of the mean first passage compare to, say, McFadden's result for the entropy of a Passan? Sorry, for what? McFadden's entropy of the Passan process. Yes. A basic first passage time process with calculates to be entropy. It's a classic paper from 1964. If you don't know it, you might probably look and compare it. You might want to look at compared to a very elegant way of calculating. It's another first passage time or point process kind of problem. Okay. For which you can get an explicit entropy rate. Okay, so it's an entropy rate. Right, so you have the mean first passage entropy. That's the entropy error of that. Okay, okay, yeah. I don't know that paper, but that's that reminds me of the paper I mentioned in. Paper I mentioned initially by Zeifert, stochastic thermodynamics and the I forgot the type. But yeah, there's a paper in which they talk about stochastic thermodynamics and the Landauer's principle is stochastic resetting, right? So and what they compute as entropy rate. So I, yeah, there's probably a connection, right? Yeah, so I'll look into that. Yeah, thank you. Thank you. So, okay. So, now, so what I'm going to, so the interesting thing here is that you can see that the mean first fashion time as you increase W, so it's a proxy now for the resigning rate, the mean first faster time goes down for all values of C. But as C increases, as C goes to infinity, that means that the dispersion of the distribution is going to zero. So you're going back to the delta Dirac distribution, the Yevan L June model. Analogy model, and so this goes up, right? The mean first massive sign here goes up, and so this metastable minimum or local minimum becomes the global minimum, right? So I'm going to, so now what I'm going to show is how this local minimum behaves for different values of C and overlap that with the thermal thermal style. Just real quick, even for low C, does this ultimately go back up somewhere? Sorry, for what? Even if we're at the low C, like C equals 1.2, does it eventually have a minimum? It has to be? No, actually, yeah, that's a good very good question. So actually, here it is. So these are the metastable for each value of C. These are the metastable minimums or the local minimums. And so you can see that for C below 1.8, you don't have that. So the mean first passage time just goes down. It doesn't have that local minimum. Local minimum. And so you can see that as you increase C, it converges to the LNS Legion dark model. And so this line here is the thermodynamical phase diagram. So here you have the externally driven regime. Here you have the maximal diemen, and this point corresponds to the zero entropy regime. So that's pretty much the whole story. Now I'm going to complicate things. I'm going to complicate things a little bit by adding another, by changing the distribution. So now, in this case, what happens is that I'm going to toggle between two distributions, right? So when the particle resets for the first time, it's this distribution, just a Gaussian. And when the toggles, when the resetting event is even, then I use this distribution right here. It's just toggling between these two. So now I have these two, well I have four. I have these two, well, I have four parameters, right? And I have this other parameter, alpha, which is the ratio of the dispersion. So let me... Okay, so first I'll show the results actually, the method works perfectly with simulations. There's complete overlap between the analytical results and the simulations. There's no fitting parameter here. And here I'm showing the mean first passage entropy for different values of alpha. Entropy for different values of alpha, right? So this corresponds to alpha, I believe it's 0.4, and this is for 1, and this is for 4.3. So this is just to show that the model works. But now here's the interesting part of the talk. So thing is that when you're changing the information, when you're resetting, you're changing the information, right? And so if you have a very broad distribution, then that's Broad distribution, then that means that the reset when that resetting happens, you're likely to gain information. If it's very narrow, then it's the other way around. So you see that the standard deviation is really important for that matter. On the other side, the resetting rate, if it's too large, then there's the typical time for reset, which is too small. You're resetting too fast. So that makes the distribution, the Brownian process distribution, be very narrow, right? So that also, Very narrow, right? So that also affects the information that you're losing. If the resetting rate is very small, the typical resetting time is very large, and so your Brownian, your Brownian, your Brownian process will evolve sufficiently to have a very broad distribution. So those are the two effects that have an interplay in terms of the thermodynamics regimes. Yeah. Is the Z0 same for the two or Same for the two or? It could be different, it really doesn't matter. I mean, for the simulations I showed, they're actually, I think one is set to one and the other one is to 0.1. So they're on the same regime or you don't have to be on the same regime of the maximum email versus no? Yeah, exactly. That's the point I'm going to, yeah. So the cool thing is that, so if you only have one Gaussian, is that the whole system will be in either of those regimes, right? But by having two. Right. But by having two distributions, you can actually select one of the distributions to be, you can select the standard deviation in a way such that the average entropy change per reset falls in one regime, the Maxwell-Diemen regime, for instance, right? And you can select the other one to fall in the other regime. But overall, the whole process is the mean first passage entropy is zero. And so by that, you're creating a sort of machine in which Creating a sort of machine in which information goes in, or entropy goes in when the resetting is even, and entropy goes out when the resetting is odd. Just circling that river. So in this case, well, it's actually possible. So these blue curves corresponds to the silhouette, corresponds to the mean first passage time, minimum. Minimum, metastable minimum, right? But now I have a bunch of them because I'm also varying the alpha forever. So alpha grows in this direction. So any point in the blue silhouette is a metastable minimum. Now, if I'm in this yellow line right here, it corresponds to the zero entropy. But any point in this yellow line corresponds to a situation in which I'm in the zero entropy regime. In which I'm in the zero entropy regime, but locally I'm gaining entropy from one reset and I'm losing entropy from the other reset. And so anyway, this is another way to look at it as a function of alpha. So another comment I want to make is that in reality, there's a detail, right? When I compute the entropy, Compute the entropy, the initial entropy during the mean first passage entropy. What I actually need to use is not the Gaussian distribution. What I need to use is the Gaussian distribution with the image ring. And so when I do that, the calculations are no longer, and you cannot get to close expressions. So we did that all numerical. And so this yellow line actually moves to this red line. So you still get the same behavior, although it's slightly different. Same behavior, although it's slightly different. So, as a matter of conclusions, so we've shown a novel method to compute the mean first passage time in a very general way in which the resetting happens to random position sampled from a set of resetting distributions. And with that, we can also compute the mean first passage entropy, or at least that's a proposal for that. And we also show that there's a you can. Also, show that you can play with that, and just the second simplest case in which you have a toggling distribution, you can create a machine that just circles around the image. So, I think this is also useful to convex matter glass formation machine learning in the sense that you ultimately want to optimize not just time, but you also would like to optimize some sort of energy attached to them. So, thank you. So, thank you. Any questions?