Yes, I'm getting nods. Okay. Oh, and Dr. Herzog tuned in, so that's great. Yeah, I'm hoping that the mere exposure hypothesis of psychology is going to work on all of you today. It basically says that the more you're exposed to something, the more you'll like it. And since this is, I guess, the third talk on Longevin dynamics that we've seen in less than seen in less than 24 hours. Hopefully you're starting to like it more and more. So this is this is a I'm going to be elaborating maybe on a particular result that Dr. Hirzog shared yesterday, mainly regarding Langevin dynamics and singular potentials in a weighted topology. I want to take a step back and actually just start with the Hamiltonian system. With the Hamiltonian system, because I think it gives a really good intuition as to what Langevin dynamics is doing. And so, if we look at the Hamiltonian system, right, it's one of the more simple position-momentum-space continuous dynamical systems. And we're just talking about the motion of a particle subject to a potential. And in this case, the Hamiltonian is conserved. But when Langevin dynamics came around, basically the idea was to add a friction. Basically, the idea was to add a friction term and a stochastic forcing term to the momentum. So we have this parameter gamma that shows up in both of these terms. The idea is that you're going to lose some momentum due to friction and also you're going to be basically in a noise bath or a temperature bath of some sort. And we can convert to a generator of a Markov semi-group as well with Launchman Dynamics and almost all And almost all the results today are going to be working in the generator case and the semi-group case rather than the dynamical system case. So I want to cover some history, even though Dr. Huzag covered some as well. So it's the convergence to equilibrium in linguist dynamics has been really more recently an important subject of interest because of molecular dynamic simulation and machine learning as key reference. As she referenced earlier today. And in these settings, the rates of convergence basically provide a rough measure of how long you want to run an algorithm to take some random samples from a Gibbsian posterior. And Dr. Herzog touched on that yesterday, where you're actually taking the log posterior because it's Gibbsian, so it's hype exponential. This has led to a number of works attempting to find explicit bounds on the rate of convergence. Bounds on the rate of convergence under various assumptions, and today's particular assumption is the singular potentials. So, back in 77, Tropper started with talking about dynamics mixing when the Hessian of the potential is bounded. In 2001, Wu established some exponential convergence in R2. And then, kind of the first result in the Lyapunov direction was with Lyapunov direction was with Matting Lee, Stewart, and Higgin, and as well as Talay in 2002. And they were working with polynomial-like potentials in general dimensions. And they utilized the Lyapunov function, basically a perturbed Hamiltonian. So they would start with the Hamiltonian, which is just the kinetic energy plus the potential energy, and they would perturb it by this term q dot p. And it ends up working for polynomial-like potentials basically because. Basically, because when you take a derivative and p, you get q times the gradient of the potential. And then, since it's polynomial-like, the gradient behaves very similar to q, and then you get kind of the rank growth condition or decay conditions. So, these works motivated the development of Volani's hypocorrosivity. And in the case of launchman dynamics, he was able to prove. case of Launchman dynamics he was able to prove convert us to equilibrium in H1. This is kind of the twisted gradient idea. And the potentials he was working with satisfied Poincaré inequalities, but also this estimate on the lower bound or of the global bound of the potential, which was that the Hessian is kind of bounded by the gradient. And you can add a constant to that just to get away with a little bit more. And DeWol, Muhat, and Schmeiser, which I'll refer to as DMS in this paper, they recovered a similar convergence result to Folani, but they instead used a perturbative L2 approach. Basically, by utilizing an operator that you basically add a resolvent to keep it bounded, then you can get a sort of twisted gradient that doesn't have to push you to H1. You can stay in L2. This is kind of the transition between working with these nice potentials and then all of a sudden singular potentials, it was Conrad and Grathaus and later Grathaus and Slugenbauer who established results on singular potentials and this was unique ergodicity and polynomial convergence under a more general condition. And that was this condition which is based That was this condition, which is basically saying that the Hessian, instead of being bounded by the gradient, like in Balani, is actually bounded by the gradient squared. But the special thing here is that we can push an epsilon small. So the gradient squared is going to grow very quickly, of course, near infinity or near singularities. But by pushing epsilon small in in most places, you can get really, really uh small results here, which is good. Uh, small results here, which is good. Uh, we'll see why later. Um, and then this is uh kind of got expanded in the in the late 2010s by Cook, Herzog, Maddingly, McKinley, and Schmidler, and then later Herzog and Mattely because they adopted some Lyapunov approaches to establish convergence, but they weren't able to find explicit rates. And finally, most recently, this is the paper that's been referenced numerous times in the past 24 hours by Balduwan. In the past 24 hours, by Baldoin and Gordina and Herzog, they established explicit rates for convergence in the weighted H1 topology. This is their gamma calculus paper. But the reason why I'm here today is that unfortunately these rates didn't scale super well with the friction parameter gamma. So kind of the results I'm going to be presenting today is explicit rates for convergence, indeed in L2 and weighted L2, that actually scale really well with gamma. Really well with gamma. So, my results, I'm going to introduce the conditions on the potential just so that we know exactly what we're working with before we get into it. And so we just have to satisfy the following properties. Number one is that U is smooth everywhere that it's not singular. So basically, if you consider every place that Q doesn't make U equal to infinity, then it's smooth there. And of course, we don't have to. It's smooth there, and of course, we don't actually need C infinity, but you need sufficient regularity, and we ended up working with C uh the set, which is the you know R minus the singular points, is connected, and actually these level sets, these sublevel sets of the potential have compact closure. The integral e to the negative potential is finite. This makes a lot of sense if we're going to be using the invariant measure. Going to be using the invariant measure. And finally, for any sequence in our space where u is going to infinity as k, actually, we need the gradient to also tend to infinity as k goes to infinity. And then here's our special assumption, which is the same assumption that we saw with Grovehouse and in both of Grovehouse's papers and collaborators. And this is the one that. Collaborators, and this is the one that really gets used extensively along with a Coincrease inequality on Q. But this is, we also have a Coincade inequality on Q due to the first four conditions, I believe. Okay, so this is really the, we like to call it the pre-theorem, but this is the theorem for convergence rates in L2 dμ. And basically what's going on is that we've established that for any positive friction parameter, we can find an explicit constant, really an explicit rate, such that for any function in L2 of mu with mean zero, then we get exponential convergence of the semi-group, Pt being the Markov semigroup induced by the stochastic process. And we want to do You know, we want to get these explicit estimates that I was talking about on Lambda. And so, you know, there's part two of the theorem that says indeed there exists. Now, this constant, lambda bar, is indeed a constant or a bounded constant such that the following lower bounds on the exponential decay rate hold. And that's that, you know, this lambda in part one, the convergence rate, is bounded from below by a constant times the minimum of the friction parameter and its inverse. It's inverse. And so this is basically saying that you can't get worse exponential rates than basically linear as gamma gets small and reciprocal linear as gamma gets very large. So I want to introduce a proof sketch here. And this is really the DMS approach. Double Mahogany Triser. Uh, the double magnetizer approach, and that's that you're you're introducing an equivalent norm of this form, which is the L2 dμ norm, and then you add like this perturbative operator to it. And you make delta a little bit of a coefficient on the operator small enough so that the norm stays equivalent. And that'll be true for a bounded operator A. So the big work is finding A, and this is actually well defined. You know, it's pretty easy. Well, you know, it's pretty easily defined by EMS, but finding A and then proving that A is indeed bounded. So the fact that A is bounded kind of is a result of that resolvent sitting out front in the operator along with the Poincaré inequality. So A is really dependent on a Poincaré inequality in the Q marginal. And that's the point of this operator, pi sitting inside of there as well, because pi is integral. As well, because pi is integrating out the p-marginal so that we're only receiving a concrete inequality in the key margin. Okay, so how does this actually work? Once you introduce the operator, then you calculate the derivative of the norm of the semigroup and you get a lot of stuff. But the important thing is that the operator A is giving us exactly what we want when it sits in. When it sits in front of L, and that's basically the Poincaré inequality in the Q marginal. We always pick up a Poincaré inequality in the P marginal, just by the nature of Langevin dynamics. And then we pick up three extra terms, which here I call T2, three, and four. And those three extra terms we just have to show are bounded and small. And this is where that assumption number five on the potential, which is growth houses. The potential, which is Grothaus's assumption as well, comes into play. Is it there's a basically a constant on these later three terms that depends on that epsilon we choose. And that constant will tend to zero as we push epsilon to zero. So that's really what happens there. And you have to choose delta correctly as well. And then we pick up lambda, the convergence rate, the right way. And everything follows my grunt laws after that point and equivalence of norms. Coins and equivalence of norms. So that's like I said, this is the kind of what I would call the pre-theorem because it's an L2 and we actually want to talk about a weighted norm topology. And to do that, we actually use a Lyapunov function approach. And in the Lyapunov function approach, we want to introduce our Lyapunov function because it ends up being a Lyapunov function of what we call L star, which is the L2 with respect to mu adjoint of L. And it looks very similar to And it looks very similar to the generator, but we have some negative terms just depending on how integration by parts works out. And we call a function w star with the right regularity properties a weak Lyapunov function with respect to L star of constants alpha and beta if it satisfies basically a very standard Lyapunov function inequality, which is that L star w star is less than or equal to minus alpha w star plus minus alpha w star plus beta and this w star is is really the weight that we're going to end up using in our weighted l2 space so this is really our main theorem and that's uh that we uh are considering this lyapunov function with constants alpha and beta and the the lambda here is the same lambda as in theorem one because we actually rely heavily on theorem one for the proof of this theorem we then set m as a constant m as a constant equal to eta epsilon lambda over beta we have choice over epsilon and of course lambda and beta have already been fixed and then we recover uh this this inequality instead this rate instead and you can tell it's relatively similar it just depends on epsilon now and then as well as alpha over two but we're getting convergence in in a new norm that's the important thing there's a second part here and that's There's a second part here, and that's that somewhat explicit Lyapunov function can exist instead of working with some, you know, we wouldn't want to prove this for some arbitrary Lyapunov function, and nobody knows what the Lyapunov function looks like. So we end up finding a Lyapunov function. And this just states that one indeed does exist. It's equal to an exponential of the Hamiltonian plus this small extra term. And we have some bounds on alpha. We have some bounds on alpha and beta dependent on gamma here as well. So, how do we end up proving this? Well, this is where I was saying it heavily dependent on theorem one, is that just by a direct calculation in this new norm, we can use the Lyapunov structure of W star to get a negative alpha. So we have dissipation kind of on one norm, and then from theorem one, we have dissipation in another norm, and it's only this m beta term. norm and it's only this m beta term that that we pick up that's non-dissipative and of course since we had some choice over m we pick m small enough and everything is good to go uh the second the second part of the theorem ends up being somewhat brute force-like so dr herzog and his paper with mattingly kind of introduced a function like this already and so that's where the intuition came from uh is that the you start with this function w star that you start with this function w star that has the form given on the page here and you give yourself a little bit of open open area for these constants kappa and sigma sitting around as well as eta to be determined and then a brute force calculation which basically just consists of young's inequalities and assumption five once again on that potential that's the growth house assumption gives the necessary bounds once you choose the suitable constants So the rates here, it's maybe a little bit obscure that the rate in this second theorem is indeed on the order of gamma and gamma inverse. But of course, the lambda term in theorem one was on that order. And so that you just have to verify that the alpha term when that one is smaller is also of the order. And indeed, it is. So a conclusion is that the rates of convergence for singular potentials in both the L In both the L2 d mu and L2 W star d mu norms are on the order of gamma and gamma inverse. And actually, the second case is especially nice because the growth of W star near infinity kind of cancels the decay of your invariant measure. It's basically e to the Hamiltonian, while the invariant measure is e to the negative Hamiltonian. So you provide a slightly stronger topology there, and that's kind of the benefit in that case. In that case. And then there's a couple extensions that we're thinking about. That's to linear Boltzmann and then also to Noze Hooper, which Dr. Herzak talked about yesterday. And that's all I have. Thank you very much. Okay, thanks, Evan, for a great talk. So I think we're a little bit over time. So maybe we can go over one quick question and then we can discuss more after all the second session. So anyone have a question? Session. So, anyone have a question for Ada?