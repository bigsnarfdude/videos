Thank you very much, Ali, and the organizers for a wonderful workshop, bringing all of us here, and the A4SR for helping with our expenses and making this possible. And also BIRS for hosting the site. It's a great pleasure and a privilege being here with you. So I was asked to give an overview of certain recent developments in. Recent developments in upload transport and short gear bridges. This is, as you probably know, a field that has been developing very rapidly the last 20 years or so and becoming very relevant to a number of control applications as well as physics and other disciplines. So most of what I'll be talking about is joint work with Jung Xin Chen, who is here, Kiel Pavon, and Alan Tannenbaum. And links together other developments as a story. So, the subject, for those of you that are not familiar with this, began several years ago with Gaspard Mons. I'll say a few more things in the next slide. Kantorovich is another giant of the subject, and Schrodinger, the same Schrodinger that originated the Schrodinger question Party. Originated the Schrodinger equation quantum mechanics. So the field relates to optimization, developed optimal transport related to very interesting ideas in optimization and duality, mostly due to Kantorovich. And the Schrodinger bridges brought in ideas that became more familiar to probabilists and statisticians and engineers later, namely Maxim likelihood. Namely, maximum likelihood large deviations. So, the basic theme, the way I see this, is that, and many others, I mean, not just me, see the field, is that we are going from the situation where we are thinking of a dynamic system with the states being on a certain manifold to a collection of particles, a large collection of particles, characterized by their probability distribution. And the probability distribution. Distribution. And the probability distribution itself is a point on an infinite dimensional manifold of distributions. And the geometry of the distribution is what's important. So, and this has applications, statistical physics, biology, computer science, control, multi-agent systems, and so on and so forth. And I'll be talking a little bit about this Riemannian structure of the manifold of probability distributions, which is referred to as P2, and W2 is the corresponding metric, the Wascherstein metric. So, again, some brief historical remarks. This is a picture of Rue Mange in Paris. I took it. It's right next to a very famous Boulangerie. And Gaspar Mange was a father of many things in mathematics and one of the founders of the Colpole Technique. In 1781, he wrote this remarkable treatise and the story behind it. And the story behind it is long: how he came up with these ideas, Memoire sur la theorie de Blais de Ramblais, where he posed the problem of moving mass from one point to another, reallocating resources. Now, many years later, Irving Schrödinger, the father of quantum mechanics, brought in a Dungan experiment where he tried to reconcile marginal. Marginal distributions of stochastic evolutions at two points in time. And in addressing this problem, he came up with basically a maximum likelihood problem and a large deviations problem at a time when Kramer and Sanov were not in the picture yet. So way before everybody else. And he actually solved the problem to some degree. There were a series of Of contributions. I'm not going to go into details on that, starting with Robert Forte on the existence. There was Bernstein, the reciprocal processes, huge literature that started in probability just because of that. Büling and many others, and Robert Simpon is another important name. There is an algorithm which allows solving related problems. Related problems. And then we go to Lenin Kantorovich in the 40s, who basically invented linear programming, duality theory, infinite-dimensional spaces in order to solve exactly this problem. And he received actually a Nobel Prize for contributions in economics because of that, because it relates to transportation of resources. And then we come to a different phase in the 70s and late 80s with. In the 70s and late 80s, with some great mathematicians, Fulmer, Mikami, Leonard, and I left out several others who started understanding Schrodinger bridges and the relationship to optimal mass transport. And then at the same time, in the late 90s, Jan Breignier, Jean-David Menamou, Robert McCann Gambo, Otto Vilani, and several others, Ambrogio, put Put in place a solid mathematical theory for the standard mass transport. And the two subjects started becoming more and more closer together after that, after 2000. So here I'm going to tell you part of that story. So the Mohn's problem is known also as Ertz Mooger's problem of moving mass a distribution from one little books. I don't know how to do it. Wonderful books. I don't know how to do oops. I don't know what happened here. But that's it. Sorry, it is the green button. Uh-huh. The green button on the screen. The green button? Yeah. Upper left corner. Upper left corner. Of the window. Of the window. Oh, here. Oh, okay. Thank you. Maybe I'll use this one where it's much easier for me. Okay. So Okay, so trans. Let me say, hit the laser. Okay, transporting basically a distribution of mass from one location to another, and it is a transportation map. So the formulation of Gas Parmonch required that we find a transportation map which moves mass from one location to another, from x to t of x, that's the y. For most of this talk, the measures are going to be absolutely continuous with respect to the benefit. Absolutely continuous with respect to the back and will always be living inside the Euclidean space, though you can do the same things on manifolds. So, and the densities are going to be called row 1 and row 0 and row 1. One is the initial and then the other is the final distribution. The problem of finding the transportation map T is a very complicated one because it involves the data in a non-linear relationship here. Here. This notation means that the T pushes forward a certain distribution to another. So it took a lot of time before this is understood properly how to address it. And the problem is, for those of you that have not seen this before, is that if you have a Dirac delta and you need to split it, there's no transportation map. And that's part of the problem why, as we'll talk shortly, in looking at In looking at distributions as a manifold, the word almost Riemannian is used because you don't have rich enough tangent directions to go in all possible directions if you have singular distributions. You have a Dirac delta, you don't have a vector field that will take you to two Dirac deltas of half size. So, part of this problem took people like Ape. People like Abel, they wrote huge treatises on how to understand it, and it took 150 years before Kantorovich came to the picture and relaxed this problem. So his idea was instead of looking for a transportation map, look for a joint distribution coupling on a product space where the x's and the y's are thought as coordinates in this product space and goes as. Yes. Well, quick question. In the previous slide, I'm missing something. Before you go to the joint, where is the measure new in the right-hand side of the equation? In the original formulation? Yes, yes. So this is. So you try to minimize the transportation cost. So new is being transported, and the math, the And the condition is that the math T pushes forward μ to μ. That in itself corresponds to the. So that's the constraint. That's the constraint. Right. And this thing here is equivalent to that. Yes, yes. Yes. And it's a highly non-linear constraint. That was the problem. So going forward, Going forward, one and a half centuries, we come to Kantorovich, and he basically relaxed the problem. He said, I don't care about the transport map, I'm going to relate x to y, and this is going to be the cost. So he thought of a multi-value transport map. So you can take a mass and you can split it between different locations. So doing so requires finding a joint distribution on the product space with a co-develop On the product space with the correct margins. So his condition was this: that the joint distribution, if you integrate in one direction, you get mu and in the other direction you get mu. So these are the constraints, and any such joint measure is called a coupling. So you see the coupling. And if things are nice and you don't have the direct delta, so if you have a direct delta in the mu that needs to be split, then That needs to be split, then the joint is going to have to have direct deltas in suitable locations. Otherwise, you may get a joint distribution which has a more complicated support, but when the marginals are absolutely continuous, or one of them is sufficient, then you get the support of the joint measure to lie on a very thin set. And that thin set And that thing set is exactly a transportation map that takes you from X to Y. What's that again? Sorry, please repeat that. Yes, so in general, you may have a coupling which has support in many places. But if the marginals are nice, for example, one of them is absolutely continuous with respect to the take measure, then you actually do get. then you actually do get a solution which the joint probability, the joint measure here, on the joint space, has support on a very thin set. So it's zero on the side and lives just here on this curve. And this curve is the optimal solution to the Monst problem we talked earlier. That gives you the transport map, T going to Y. Is that right? So now, this problem was posed originally by Gaspar Morse more generally, and many things can be said, but I'm going to skip that part. So that the question is: how does the Moles problem differ from the Kantorovis problem? And as long as C is nice and μ is not atomic, so it's Nu is not atomic, so it has absolute continuous. The infinite of the MONS is the same as the meaning of the cantor. So there's a lot that can be said around this. Yes? From the previous slide, that you could construct M T to be monotonic function. Be monotonic, yes, yes, yes. There is, t is not arbiter, it has fraction. It's the gradient of the convex function, exactly what you're saying. So there's a lot more behind it. So, there's a lot more behind this. And I'll mention a little bit of that. So, going forward, for everything we'll be talking about here, the space is an N, and we're talking about the underlying space having a metric, and we're looking at distributions on on this X space. On this x space. And the p2 sub x denotes the probability distributions, the measures on x, which have a finite second-order moment. And W2 is what's called the Wascherstein distance, and this distance is the minimum cost of transporting from one distribution to another. So this is a metric. So, this is a metric of probability measures and second-order moments. This turns out to be a very nice space. It's almost Riemannian, and we'll talk about this next. Almost means that the tangent space may not be rich enough around various points, meaning that in the neighborhood of this point, you cannot go to an open neighborhood. Because if you have a direct delta, you can only move in one direction. So now this optimal mass transport turns out to have a very beautiful dynamic formulation and this was discovered by Benamu and Brenier in their attempt to develop computational tools for solving Ottoman Lausanne's problem. Again on the left hand side I always indicate that this is the Wash-Stein metric between the two distributions, the one that we had before. It turns out that Before. It turns out that this is equal to this expression, and I'm going to explain why this is so, because this is kind of a busy expression. The thing I would like to underscore here that what you see in the right-hand side is the kinetic energy of all the particles. A particle at location x has a velocity v. The v and the density satisfy the continuity equation. And you are solving it over a window of time between 0 and 1, and the distribution shifts over from one location to the next. So, this is basically average kinetic energy over time, so this is action integral exactly in the spirit of physics. And that's exactly why it's so essential also in the things we are going to be talking about in the next hour. Going to be talking in the next album. So, the reason that this is so nice and what is happening can be traced to some very, very simple elementary high school mathematics on drawing curves on a plane. So if we are in Rn and we have two points in Rn and we just draw a path from one to the other, and I ask you what is the shortest length. Of course, the shortest length. Shortest length. Of course, the shortest length is a straight line. And if I want to traverse from beginning to end with some velocity, what is the optimal I can do so that I don't pay too much? Of course, acceleration and deceleration is costly. So if I know where I'm going, I have to decide on the velocity and just go on a constant velocity. So it turns out that, and that's very easy to show, that the Euclidean distance, this is all in Euclidean. This is all in Euclidean. Over paths. So x is a function of t, it's bold here. It doesn't show. So this x here is an element in Rn. The bold is a path. So there's a slight difference that's not so visible here. So the path starts at x and ends at y. And along the path, you integrate the velocity. Ben FEMO is obtained for geodesics of constant velocity. Right? Right? So now you can push this a little bit forwards to dealing with measures and you can say, well, now if I'm looking at probability laws on paths, so in other words, curves from beginning to end and I put some measure on it. And the same value is the infinite over probability measures on paths. On paths. These are continuous, that are such that we have a direct delta at the beginning, direct delta at the end. This is basically a rephrasing of our problem in the setting where we think of all possible trajectories and we put some weight on them and we see which one is best. And all the weight will be exactly on that optimal trajectory. Optimal trajectory. Then, oops, sorry, I'm questioning the wrong thing. Then you can extend it to thinking about general marginals. So if I have the starting point is distributed according to row 0 and the ending point according to row 1, you write exactly the same thing as before. This x squared is this expected value, and this p now. And this p now is constrained to be equal to the two modules of the two eights. So, going down here, you see that the expression we get is actually optimal over paths that since you have a continuous velocity, the mass will be distributed according to this continuity equation from the beginning to the end. To the end specified distributions. So, again, I'm hiding some technical details, but basically, that's the idea. It relies very much on the stand, you know, some simple, yes. Maybe a stupid question, but in RN, it's clear that you can always connect two points. But in your space here, you happily use the fact that it's convex, so you can, you have. It's convex, so you can have the possibility to join two measures. Because if not, you have to guarantee that there is one curve which joins the initial one to the final one. Yes, yes, yes. The yes, let me get a bit I mean, as an infimum, the condition I uh yeah, the Yeah, because this is convex, you're going to have, let me see, the question you're asking is whether if you want to choose to define this by the intimum of all curves, then you have to guarantee that there's at least one curve which joins the initial probability measure on paths. So, in other words, every Paths. So, in other words, every x, every location x will decide on the target point and then mass will move along a certain straight line. I think the question is, you know, is it always finite, for example? Is it always finite? But don't you need to know something of the total measure? Maybe if you have two probability measures, it's okay, but you have to normalize in some way. Otherwise, the problem is not reachable. Yeah, definitely. Definitely, you need to there are technical conditions, and the conditions are that basically they are finite second-order moments and they have equal mass also. The equal mass, that's what I'm saying. So, you need like two probability measures. Right, two probability measures, yes. Right now, we're talking about probability measures. By the way, you can extend everything we're saying here to cases that you have unbalanced measures. In fact, this is a whole story by itself. Story by itself. So, for example, if the starting measure and the ending measure don't have the same integral, then you can postulate either a way that you can supply mass along the way. So you can have creation or annihilation. And that has been done, and it's a very, very popular way of doing it in computer science. There is another, a little bit deeper way of understanding. A little bit deeper way of understanding it, going in the direction of giving a prior on killing. So you have a random trajectory and particles randomly can disappear. And you can have a prior on that. So this is a whole lecture by itself. So, but again, what I wanted to show is that intuitively, this expression is not that complicated. This expression is not that complicated. It comes from the property of the underlying space of having, which is the Euclidean space, of being a geodesic space. And the same applies to manifolds. Sorry, do you have uniqueness? You have uniqueness, yes. It follows from convexity again, yeah, you know, it's so again I'm hiding quite a few technical details. I'm hiding quite a few technical details. I'm just trying to give in simple ways the story because I have actually a lot of material. And so this is another quite insightful computation. Again, it's formal. Everything I do here is formal. I don't give detailed proofs. So if you try to see the properties of the minimizer of the problem we had in the previous page, Of the problem we had in the previous page, and you form a Lagrangian integrate by parts, and you try to find conditions for optimality. And this is somewhat routine. Again, I'm hiding. You get an expression of this type for the Lagrange multiplier, which is equivalent to, if you apply the gradient here, you can write it as dv over dt, where v is a velocity. Over dt, where v is a velocity, then it's the total derivative equal to zero. So this thing simply here tells you that the velocity of individual particles, they don't accelerate. The total derivative is zero. And that the optimal velocity field is the gradient of a function. This gives a lot of structure inside and relates exactly to the question of UI. Relates exactly to the question that you asked about the structure of the optimal transport maps. And we're going to see this. I mean, this lambda provides you for what is called the Monge map, the transport map. But equally important is a structure which is recognized by Otto, Felix Otto, that now it allows you to view the space of probability measure. Probability measures like that with second-order moments, finite second-order moments, as a Riemannian microphone. So the way to think about this, this is the continuity equation, and delta is a small perturbation from the current location. So suppose you have the states, you think of them as rho. So the manifold is, we can think of as the densities here, but you can think of Think of as the densities here, but you can think of measures more generally. So these are, let's say, functions that integrate to one. So the tangent directions are functions that integrate to zero. Assuming, of course, that rho is positive everywhere. So then the perturbation can correspond to a velocity field of the nature that we saw in the previous slide. It's the gradial velocity. It's the gradient of a lambda. So this represents a vector field on the space which is irrotational. It's a gradient of a function. And they need to satisfy this Poisson equation. This Poisson equation is a correspondence between a function here, if we are talking about densities, and a function. So objects of the same size. But again, the vector field, which is an object which is Field, which is an object which is sort of much bigger than delta, is the gradient of that. The correspondence is exact, and conditions for existence, uniqueness, and so forth can discuss. But what this gives is a way of introducing a metric on the space. So if you have two perturbations, you don't take the inner product of those two. You take the inner product of the corresponding velocity. Product of the corresponding velocity fields. This is a more kinetic energy-like quantity, and it turns out that W2 is exactly the. Yeah, I think I have it right, yes. It's the infimum of the integral of the metric. So this metric again. So this is metric again on tangent directions. So the tangent directors are perceived as gradients of velocity, of functions. Then geodesics in the Wasserstein space take this form. This is the identity from 1 to the ending point with the gradient of lambda and then push forward rho 0. Then push forward raw zero. And then it turns out that the distance increases linearly. So the spacing between zero and one naturally pulls out. And you have the velocity field at the beginning. y is t of x, the gradient of lambda x, and this is called the Moss map. So this gives a complete picture, again with hiding some of the technical details. Much of what I told you can be done with manifolds. And these are some pictures here of moving a mass from one situation to another. So these are examples of geodesics. You see some densities and you just move them along. Or you have some initial and some final and you try to interpolate on more complicated surfaces. So now another very important development in this theory is the moment you have sort of the vector field, you have the structure of Riemannian, almost Riemannian structure on densities, then you can ask questions, for example, what are gradient flows of these functionals, right? So I have a functional which could be some integral of rho, and I would Some integral of rho, and I would like to see what directions is it that I increase or decrease the fastness. So if you have a function on this Wascher's time space, the W2 gradient, it can be computed in this complicated way where this is the variations, so this is the L2 gradient, and this is a simple computation to see. Simple computation to see. If you take the derivative with respect to rho, you write it in a standard way, then you replace the partial of rho from the continuity equation. You do integration by parts, assuming zero initial condition at the end, and then you have that this derivative here is the inner product of two directions, and then you can identify from that. And then you can identify from that that the gradient is going to take this forward. So you can recover that formula there. So having this in place, there was a rather remarkable insight by Jordan, Kindle, and Otto, where they tried to see what is the gradient flow of some very well-known functions, for example. Also, some very well-known functions, for example, the entropy. So, here if you have a distribution rule, you can have functions such as the internal energy. So, if you have some potential, you can integrate against that, and you have internal energy. Then, integral role log row is the entropy, and following the The convention in physics, you typically multiply by Kbt to make it into energy, units of energy. So Kb is the Boltzmann constant and T is a temperature. So from a mathematical standpoint, you can normalize those things. Then the free energy defined in statistical mechanics and from Statistical mechanics and thermodynamics. Let me see here. I don't have it. Yeah, I just wrote it in this way. The free energy is basically the difference between the internal energy and this expression for entropy and can be written as a Kulbert Libre divergence. So you have rho rho here and then x of 1 over k B. Exp of one of a KBT UKT. I think for this audience, maybe this expression is more suggestive. And it represents the, in physical terms, represents, we'll talk a little bit more about this in the second part, the amount of energy you can extract if the temperature stays constant from an ensemble. So then you can compute the Wasserstein gradients of the free energy. Of the free energy, and you plug it into this formula, and you get this. So you can recognize that this is the Fokker-Planck equation. And I just simplified here because we don't need it right now. When the potential here is zero, so we don't have free energy anymore, we just plug over here the S, then what we get is the What we get is the Laplace equation. This is quite remarkable. It's a simple computation. You have to trust me. We can be lost a little bit in the computations, but it's very simple. So what it says here is that somehow thermodynamic dissipation relates to the first degree but to the entropy, but in what metric? You always need the metric, the Wasserstein metric. So this result connects three things that in a quite remarkable way. That in a quite remarkable way. Entropy, the Wasserstein metric, and the heat equation. So, the equation that describes this equation. So, and we're going to see this again and again later on. So, from this point on, let me see how much, oh, I have to keep moving a little bit faster. From this point on, there has been On, there has been huge development. For example, in physics, they try to find different functionals and display well-known V Ds as gradient flows with respect to Vasse-Theim matrix. For example, famously, the Poles-Miger equation was shown to be a gradient flow. And the reason this is important is because you get guarantees for convergence, speed of convergence, you can quantify properties. You can quantify properties of this. So, you study now properties of PDs. In particular, the Polish media equation was quite notorious. And there were other similar equations in computer vision that took 40 pages of very heavy math to show some results, which in hindsight, after having this kind of machinery, they were very simple. They were very simple. So there is a great advantage in this geometry. Now, there are other things that I'm not going to talk about. For example, the Weissenstein geometry has been linked to reaching curvature of the underlying manifold. You look at... let me explain this in words. So if you have the manifold, you can postulate moving a distribution from one location to another in an optimal way. Another in an optimal way, minimizing the length of trajectory, average length of trajectories in the end line. What turns out to be the case is you have this an evolution which obeys something which is called the lazy gas flow. In other words, the mass spreads out and reassembles at the axis, depending on the curvature of the manifolds. So if you compute now. So, if you compute now the entropy at every point on the trajectory, you see that how the entropy behaves depends on the underlying curvature. For example, if you try to move a mass from the North Pole to the South Pole, it's easier if you spread it all around. If you have a negative curvature manifold, you get the trajectory sort of compressed amount. Sort of compress the mass through certain, certain, I would say, yeah, I mean, it squeezes it before it opens up again. So all of that thing has been discussed and continues to evolve. And this also allows you to use the Russian geometry on discrete spaces or arbitrary metric spaces. Or arbitrary matrix spaces to define indirectly a notion of curvature. Okay? Art, I see. You wanted a question? No. No, no, no. I will have a question later. Oh, thank you later. Okay. Yes. So in control again, this whole subject took off in the last 15 years, and there's a lot of development, and many people are in the audience that have used it very effectively. People are in the audience that have used it very effective for non-linear filtering with a mirror. Ensemble control, uncertainty control, multi-agent systems, networks, and so on. So, let's leave temporarily the optimal mass transport and turn to the other big question. Does anything change as the dimension of the manifold increases? Say it again. Does anything change as the dimension of the decrease? Change as the dimension of the manifold increases, let's say from two to three? Not that I think of right now. Of course, the complexity in computing everything increases dramatically, but the underlying space, the size of the underlying space, the dimension of the underlying space, not that I can think of. At least the things we talked about here more or less stay the same. From one to two, there's a big difference. But from two to three, etc., I don't, you know, maybe someone can correct me. So let's go to the other part of our story here. It was around 1931, 32, Schrödinger published two papers. This was a very bold thought experiment. So what he thought is, let's say you have Let's say you have here a box with oxygen molecules, and you open it up, and your prior is that they behave like brownian particles. So they keep spreading around in the room. A minute later, you measure where they are, and you find them here. So you cannot tell me they are not there. You can say, well, this was Brownian motion. How did they get there? They got there because I measured them. They are there. So he started with. So he started with this assumption. Suppose I observe a very unlikely oh, what happened in between? He wanted to interpolate the flow of this brownian particle pass. How he came about, you will see, I mean he had a tremendous insight and actually tremendous technical ability. It's actually unreal that Irving Schroeding, at this time when probability theory was in its infancy, Kramer Its infancy. Kramer and Sanov, large deviations were still years away. He basically did that single-handedly. So he wanted to interpolate two distributions and make it consistent with the prior law. So here is his setting. You have a cloud of particles. They start from one distribution and they end up at another. Probability distributions. Again, we're not talking about loss of mass here. And the thing you And the thing you observe is not compatible with the parallel law. So, this is the transition probabilities from T0 to T1, moving from X to Y. And let's say this is the Gaussian curve. So, apparently particles moved in an unlikely way. There was a rare event. Something happened and they moved there. And you wanted to model exactly this flow. This problem again led This problem again led to a lot of research and it took almost 50 years before it's understood properly as a large deviations problem. It was actually Fulmer who phrased it like that first. And the problem of Schrodiger amounts to the following. You have the space of paths. All the particles at the beginning can choose to follow any path they want. And on those paths, you have a prior measure, and this is the Winner measure. Prior measure, and this is the Wiener measure, W. And he was seeking a posterior, a new measure, which is in some ways the most likely. Turns out that the rate function for this problem is the Pullback-Liebler measure, which is expected value with respect to Q of the log ratio. And so this is a schematic of what happens and what actually And what actually Schrodinger did, and I will explain more in the next slide. So, if you're faced with this problem, it's not difficult. You want to minimize these subject to constraints. And the constraints are the row goes to row one, and the probability transition has to have the right property. It has to be the legitimate colour. So, if you do this, you need two dagranch multipliers, you put them here, you add everything. You put them here, you add everything, you form the Lagrangian, you take derivatives, integrate by part or whatever it takes, and then you come up with the expression for the optimal path. And at least necessary conditions are easy. So Schrodinger actually did that. He actually went and did that, even though all those concepts were not quite understood at the time. And he came up with the following conclusion. And he came up with the following conclusion that the role, the density, as it transitions from the beginning to the end, has to have a particular form. It has to be two-factor. And these two factors have to satisfy these very interesting equations, which are known as the Schrodinger system. And his proof was, he said, this is correct because it actually makes physical sense. And it took a lot. And it took a lot of time for people to prove existence. Robert Fortette wrote a very huge traitor so proving existence of a minimizer, the existence of a solution to the system of equation. These are actually the advanced quality types of the previous problem. And this is known as the Schrodinger system. And why Schrodinger is very excited about this is because in quantum mechanics, if rho is a probability, is the probability is the square of the wave function. So in quantum mechanics you have a wave function, you have psi times psi bar, the complex conjugate. Here you don't have that relationship between phi and phi cat. That's not the complex conjugate. They're both real functions. But then he tried to draw analogies between those things. And then he perceived that maybe somehow... That maybe somehow quantum mechanics will come out of this. That was his original motivation. He wanted to understand to get a classical interpretation of quantum mechanics. That led to a program, the work of Nelson, Art here, you have contributed a lot in this direction. And again, it's quite a bit of literature that I cannot touch. And so here. So, here is a schematic, exactly what I told you. So, this is the initial distribution. This is what you would get if you apply the prior law. And these are one-time modulus. And you measure it and it's a little bit different. So, Schrodinger wanted to interpolate properly, and he wanted to find a new long path space that would give you one-time marginals consistent with these two endpoints. These two endpoints. And this is exactly what I again repeating what I just told you. So he said that you have somehow to factor the initial distribution as a product, the final distribution as a product. And these two functions, the phi and the phi hat, they have to obey these two equations. So this one is a Fokker-Planck equation, and this is more like a Hamilton-Jacobi equation. Equation. And this is the factorization of the beginning and the end, and this is the factorization of the one-time density. So this one corresponds to Foucault-Planck, and this corresponds to Hamilton-Jacob. And now, existence of this turns out to be actually very simple if you look at it from a certain angle. Some of Some of it is already in Fortette's paper, 1940, but it was not so because he did more or less kind of similar arguments, and this very relates to the synchron algorithm that they explained before. But the best way, one of the simplest way to understand this is, and this is a beautiful device, it's called the Hilbert metric. The Hilbert metric, if you haven't seen it, it's worth paying some. It's worth paying some attention. The Hilbert metric is a metric on convex sets. So if you have, in fact, convex columns here, for all that we care. So if you have two elements of a convex column, of a column, so for example, let's say the positive orthodox, you have two points. You can define a metric between these two points in the following way. Between these two points, in the following way. You compute sort of a maximum, so in other words, how much you need to scale one point. So you have a partial order. You have a partial order and you try to see how one posit point is located with respect to the other. If you have non-negative matrices, symmetric matrices, you have a partial order. This is positive definitely greater than or equal to the other. So you can compute the eigenvalue. So you can compute the eigenvalues of pencils between matrices. And the maximum and the minimum eigenvalues give you the m and the river n. If you have points in the positive orphant, then you have a suitable partial order, and you try to move them about according to this. And this gives you the M and the M. The log and border is the Hilbert metric. You use two objects. And there is the beautiful result by Burkel that tells you that. That tells you that if you have some positive invariance, that implies contractiveness in the Hilbert metric. So, for example, stochastic maps are contractive. So, here is the Schrodinger system. You start from a phi hat, that sounds like Grange multiplier, and you try to make it consistent with the situations. So, you integrate forward, that's a focal plan. Then you perform a division and you You perform a division and you compute a phi, and then you go backwards with a backward heat equation in the negative direction. And then again, this is stable in this way because you have a minus here. And then you invert again. So those are isometries and those are contractions in the Hubble metric. So basically, that's it. So this is that partial order that you have, the definition of big M, a little m? The definition of big M a little n? Yeah, yeah, this is a partial order. This is a partial order. So if you have two positive functions, you can define a maximum and a minimum. Now, there are some technical difficulties if the support is infinite and then the distributions go down to zero. And that's a little bit more technical. Now, this whole subject relates very nicely to a control problem. A control problem. So, you can ask the question again, we wanted to find the posterior, which is closest to the prior. It turns out by Gezano's theorem that if you postulate that the posterior law is, in fact, this comes out that the posterior will have an additional drift there. And the relative entropy is not. The relative entropy is nothing more than the expected value of this cost square. So that is the velocity, that's exactly again the kinetic energy, and you can see the comparison. So the Schrodinger problem now relates to this problem. We try to minimize average kinetic energy when the distribution of the particles are moving forward with a suitable drift here, but subject. Here, but subject to stochastic excitation. So immediately you can see the relationship to the optimal mass transport problem. You can do more things. For example, you can absorb the Laplacian into its integral functional, and you can view the short-gain bridge problem as an optimal mass transport problem, but with a different cost. but with a different cost. So the cost has the velocity square as before, but it also has this expression, which is basically a Fisher inform function. Here is kind of a schematic of that, and we can prove that in a suitable sense, the Schrodinger bridge, when the Bridge when you have a zero noise limit gives you the optimal transport. So, this is in either formulation when epsilon goes to zero, suitably the transportation paths turn to the one corresponding total transport. And you can see here, the Schrodinger bridge allows you more of a spread before they reassemble, depending on the epsilon. So, here is for some value of epsilon, smaller, smaller, and here. Smaller, smaller, and here epsilon zero. And by the way, this connection between the two is the method of choice for solving optimal mass transport problems, which are very notorious. So you regularize them, and in the computer science community, this kind of regularization became a standard tool. So, but this connects actually the optimal transport to control because if you saw it in the previous thing, you can see that the cost becomes, the relevant entropy becomes a control cost. So, this one actually connects with some other deep work in some of the early prophets in our field who are fortunately not with us anymore. Roger Brockett and Bob Skelton. Roger Brockett and Bob Skelton. Roger, very early on, he was advocating studying the control of the Fokker-Planck equation, and Robert Skelton, with his students, Gregoriadis, for instance, worked on something which they call covariance control. Covariance control was a static problem of shaping the station distribution in a control setting. You devise a feedback loop so that they... Now, this is very close to what we're discussing. Now, this is very close to what we're discussing right now. What we're discussing here is a slightly more general setting where you try to minimize control action and you have a Brownian excitation here. Now the B became W because we're using B's for the, in a standard way that we're using the AB in controls. And the X0, let's say it's normal starting from some covariance sigma 0. The mean here, we can change it again. There's no significant difficulty, and we're going. Significant difficulty, and we're going to signal one. So these are exactly the rows that we had before, the densities. So this is now quite natural to pursue. And Schrodinger system becomes a system of two nonlinearly coupled Ricardi patients. So you have here a Riccati corresponding. Ericate corresponding to the Fouquet Lancashire, and Ericate corresponding to the Hamilton Jacobi that matches the two ends. And the Catholic conditions turn out to be this. The optimizer, of course, is linear in the state. And when the T is equal to B1, B1, this expression here, let me show you in the previous thing. So B1 is the noise. Is the noise channel and B is the control channel. If they turn out to be identical, then the equations simplify. This term here drops out and you have two Ricardo equations like that, which are essentially Yapunov equations. You play the standard trick that you multiply with P inverse on both sides and they become Yapunov. So they are linear matrix equations. So you can get closed form expressions. Now the connection. Now the connection with the Schrodinger problem is this, that the phi's and the phi hats are exactly exponentials for the two matrices that appear in this problem. And the matching condition that rho is equal to phi phi hat corresponds exactly to these boundary conditions here. So that closes in a nice way and becomes really a small chapter within linear quadratic Gaussian theory. And sort of the idea here is that you can use control to shape densities. For example, this is sort of like a toy example, but actually it's quite serious because very similar things have been used by physicists to improve the resolution of experiments. So let's say you have here an oscillator, and somehow the circuitry that observes the current and voltage here. The current and voltage here has some resistance, internal resistance. The internal resistance brings in some Nykus-Johnson noise, thermal noise. So if you care about the frequencies that you are measuring, how this resonator couples to the environment because you want to measure something, then the noise here is a pain because it distorts your measurements. So, what you would like to do is you would like to apply control in order to In order to dampen the vibration, the effect of the noise. So here is a very simple example. Noise enters here and you have some control. So if you have a... So this is a stochastic system, and here this shows how you can shape the tube of uncertainty, where this is like a 3C. Where this is like a three-sigma curve that brings the system at the end to have a smaller variance. Smaller variance is good because you can rely more on the outcome of your experiments. I think I started a little bit late. How much more can I have? Let's see, five more minutes. Five more minutes. Okay, I have a lot of things, but I'll skip some. Yeah, yeah, right, right. But let let me go very, very quickly through some things because I, you know. Some things because I didn't want to rush through, but okay. So, this is another example, pictorial. So, you start from this is an electromechanical, let's say, system, and you try with a control to shape it in phase space. So, you have here you localize the position, here you localize the velocity, or you can local you can constrain both and apply control action in the style of uh a skeleton to maintain a tube. I didn't finish. I didn't think. Are they patients? Sorry? Are they Ito or Sritanovich? The development, mostly you can do either, but mostly we do Ito. So yeah, the stochastic differential equations I write here, they're all Ito. But again, it doesn't matter here, this is linear. In the next lecture, you will see also some stautonomies because more natural. See also some statonomies because more natural. So, here there's some more developments that you can have priors on the dynamics and you can optimize costs so that the X dot you want to maintain. For example, suppose you have particles that go against the currents and you try to optimize so that they just don't have too much headwind. So, you can solve problems of this type. Again, this sum of this can be transformed to. This sum of this can be transformed to standard OMT and numerically approximated by the counterparts. So, this is an example. Here, there is a prior on the velocity, and here is a Schrodinger bridge for epsilon large, going down to the optimal transport. So, you can, there is the theory develops very beautifully, and then you can start talking about paths on Paths on Wasserstein space. Here, I'm not going to discuss this. This is splines on Wasserstein. You want to have uncertainty profiles. So, for example, suppose along the trajectory I have snapshots. If I interpolate in the usual Wasserstein metric, I have a geodesic here, in Vasserstein, a geodesic here, a geodesic there. That's not what you want. Maybe you want to allow for acceleration. So then you want some sort of a spline. And the spline... Of a spline, and the spline turns out to be very much the same. Why do you need this? Because you want to animate images, do some more sophisticated signal analysis. And I'm rushing here. This is cubic splines in RN. And you can push this forward very much in the same way and have distribution splines where the marginals are specified. The marginals are specified, you have snapshot or partial snapshots, and then you try to minimize acceleration. This is, by the way, connects very much to Gauss's principle, which is equivalent to Newtonian principle of developing mechanics. And again, I don't, let me show you one more thing. This says that you can relate this kind of problems to a Cantorobis formulation, which you can solve with suitable regularization. Suitable regularization. So, this is exactly you bring down to the noise, zero noise limit. Now, I have something which is, I have something here which I want to just mention it. It's beautiful, but I need a little bit of time to discuss. So, this is something we tried for a long time. We had some Kantorovich version of it, and then eventually. Version of it, and then eventually we came up with a formulation which is very tricky and very interesting. How to extend optimal mass transport to transporting matrices. So, and the interest for that is in quantum mechanics, to go, to take exactly the Schrodinger paradigm back to quantum mechanics, but from a different angle. So, this relates to To open quantum systems. Open quantum systems consist of two parts. One of them is the heat bath, and the other is your system. And then you have the Schrodinger, some unitary transformation that basically amounts to the Schrodinger's equation, but then you're observing one part of it. So when you're losing information because of the coupling, and the loss of information is expressed with... Loss of information is expressed with what's called the limbladian. So, this limbladian here is interesting to relate somehow to gradient flows. And this is what we have done. So, the question is, starting off with this Benamu-Brennier paradigm that you have kinetic energy, you say, is there such thing for matrices? But to have such thing for matrices, now it's very tricky because V is going to be a matrix. V is going to be a matrix. Rho is going to be a matrix. So, what do we mean by that? We want a kinetic continuity equation. So, what do we mean by gradient with respect to x? What do we mean? There's no underlying space in quantum mechanics. So, fast forward to this. Let me take another three, four minutes. Three minutes. Sorry, I'm taking out from your break. I'm taking out from your break. So you can think of functions as operators. So you have some underlying space of functions and a function can be thought of as a multiplier. A partial can be thought of as an operator in the usual way. But if you want to take one operator acting on another, it amounts to a commutator. So in this way, when you take a derivative of a You take a derivative of a matrix with respect to another matrix, you can define it to be a commutator. And if you have many of such spatial kinds of dimensions, you can define the gradient as a stacked up of commutators. Then you can think of the divergence. The divergence is exactly a dual object when you look at the suitable metric. When you do all this and you think of it this way, let me see here. Let me see here. Yeah. Okay. Then, then, let me then you can see that the limbladion becomes a Laplacian. And then you need to deal with another thing. How do you exactly multiply rho with a V? How to make sense of this continuity equation? So there is a beautiful expression for multiplication. A beautiful expression for multiplication which comes from quantum field theory, it goes back to Feynman. And because so this is basically, because they're not commutative objects, they're matrices, you multiply a little bit on the left and a little bit on the right, and you integrate over this. So you take all possible. And this is really a magic formula, because it allows you to do computation in a very, very nice way. Very, very nice way. And having this in place, you can define a matricial Wascherstein where you minimize rho V star V, and that can be thought of as kinetic energy, subject to the continuity equation with this as a product. When you do all this, magically, you get that rho dot, the Livladian, is nothing more than the gradient of the Bonoiman entropy. Entropy because for matricial objects, this is not integral, it's trace rho of rho. You can put integrals if there's a special component. You are only looking at this one. Sorry? You're getting rid of the drift part here, right? Yeah, there's no, yeah, for simplicity. So, with that, I would like to recap and say that there is a beautiful geometry that emerges. Now, for quantum, the Now, for quantum, the rho is a density metric. So it's a positive definite metric to trace one. But rho in the earlier part were densities. So the shortgate bridge problem is a problem with stochastic control, estimation. It sort of brings the two things together. OMT and shortgate bridges relate to each other. And you can extend this in quite many different ways. And there are even more different. And there are even more directions that I haven't talked about: networks, discrete spaces, laws, creation, annihilation, vector value when you try to interpolate color, so you have, let's say, different population of species, and they mutate, and so on. So, next hour will be a little bit shorter and will be on thermodynamics. So, I'll try to make up for what I took from your break. Your break. So, thank you very much for your attention. Thank you for a wonderful one. Thank you, Arsenal. You know, we're in the balance. Let me one second. Let me. I'm happy with public sizing questions. They told us to it's your choice, actually. You mentioned sometimes. So we're in the mountains. So we're in the mountains. Most of what the mass transport you're talking about is transport of a flat space. What happens when you have to transport mass over mountain ranges? Over a manifold. It holds not a manifold. A gravitational field. Ah, yes. So you can add some sort of potential in the cost function. You can add Can you add, it's not going to be exactly optimal mass transport, but the optimum mass transport, one can see that's sort of the frame where you start thinking of this densities and leaving the space, and now the transportation from one point to another, this is now a point, it's a density, but it's a point, right? In this high-dimensional space, has to overcome, let's say, some potential or Or there could be interaction potential between the particles that keep spread them apart. Let's say, for example, you like to, that's a very interesting problem. Let's say you have an accelerator, right? The accelerators are sending a collection of charged particles on a, let's say, circular orbit that goes through magnetic lenses. Lenses that try to refocus the beam. You know, you have, they are interacting, you have potential, you have effect of other things. In the example you are saying, again, I can come up with physical situations where this is, you're absolutely right, this is a nice setting. Now, it can be thought of in this setting. How difficult it's going to be. How difficult it's going to be, I think if you add a potential to the cost function, can be worked out. And we have something like that in some special cases. I'm thinking it's just a matter of adding a constraint unless sometimes I miss something, right? Because you describe the optimal control way to look at these problems. And all you're doing is you're adding, you know, you're modifying the constraint. Adding, you know, you're modifying the constraint. If you have what Art mentioned, right? You can modify the constraint. If I understand correctly what Art said, is you, because you are moving mass from here to there, if you want to go over a mountain, the mountain will correspond to some sort of extra potential that we have to overcome. So in other words, you you still think of it on the flat space, but you add some potential. add some potential.