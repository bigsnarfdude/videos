It's a pleasure to be almost with you. So, I would like to tell you about a very specific story and problem solution that we did inspired by Weifeng Zhu's experiments. Do you see my pointer here? Yes. Yeah, okay, good. And together with two mathematicians, And together with two mathematicians, Miguel Escobedo from Bilbao and Miguel Tuniu from Maseille. So at the very beginning, there was Wayfeng Zoo's talk where he presented his experiments on protein fibril fragmentation. So protein fragmentation is something which is very important for several types of things. First, for amyloid diseases. With diseases, for instance, Alzheimer's, Parkinson's. And second, also, because some of these fibrils are very important and have specific biological functions for the human body. So, here he has beta 2M, beta-2 microglobulin. It was a paper from 2013. And what they did is that they performed an experiment where the fibrils fragmented by agitating. By agitation. So you see from left to right, you have the time evolution of the experiment. At the beginning, very large fibrils. On the bottom, it's a zoom. On the top, it's a zoom of the bottom. And then progressively, they break down and give rise to smaller and smaller fibrics. And in this paper, I will explain slightly better afterwards. Afterwards, they tried to find the best reaction system which could explain this fragmentation. And at the same time, with Miguel Escobedo, we were studying the fragmentation equation, and especially we were studying how we can estimate the division rates out of the growth and fragmentation equation. But here it was. But here it was not growth and fragmentation, it was pure fragmentation, which has a different asymptotic behavior, of course. And so the question was different. It was not to estimate the division rate, but rather to estimate the division kernel, which means Waifengzu's questions were where does each fibril break? Does it break more at the ends of the fibril? At the ends of the fibril, or rather in the middle? This was a question that we never asked before because our applications were rather like bacterial division. And for instance, for bacterial division, you can measure exactly what is the fragmentation kernel. But in such experiments, it is much more difficult because you cannot measure exactly together, you cannot have a You cannot have sufficiently precise measurements so that you can estimate both the size of the motherfibril, let's say the one which divides, and the two offspring. You can only have measurements on samples of the population. So here it is a second more recent experiment. This is for 2020 paper. 20 paper, 2020 paper, yeah. So, here it is for three different types of proteins: alpha-synuclein, which is associated to Parkinson's disease, beta-lactoglobilin, and alpha-an linozyme, which are more natural, not really associated to a specific disease. So, what was also interesting for them was to compare the division kernel for Division kernel for each of these proteins to see whether there is something specific when it is related to a disease or not. To see it's exactly the same. So from left to right, I hope to see enough. You have in the beginning very large fibrils and then they break down towards smaller and smaller sizes. Okay, so what was the model with which we were able to study? With which we were able to study this system. So, in his former paper, Weifengzu used discrete models where the size of each protein was characterized by its number of monomers included. We preferred, for mathematical reasons, stick to a continuous description. And so, our idea is that we have that we have n of tx which is the concentration of polymers of size x at time t which follows what is called the fragmentation equation or the pure fragmentation equation which is you have a division rate b so fragments of size x breaks down with a total rate b so you have like a death rate minus like a death rate minus b of x n of t x and you have also the creation of polymers of size x out of larger polymers of size y so you have this integral from x to infinity of so b of y n of t y is the total number of polymers which breaks down and you have a certain proportion k of y x which gives Of yx, which give rise to polymers of size x. And this is the equation. So here we have no non-linearity because it is clearly not obvious when you look at the previous slide. You see the concentration of polymers is not so high. So you don't have any influence of polymers to one another. So it is a linear equation with this non-local term, which arises from this. term which arise from this fragmentation kernel that we want to estimate. So typically the question is how can we estimate k of yx and the division rate b of y out of measurements. So we have a model for the problem and we also have a model for the measurements. So what do we measure? You see this very clearly here. You can measure the size of each fibril on such images. On such images, which means that you have at a given time points t, you have samples x1, x2, etc., xn whose density is up to a constant proportional to n of tx, the concentration of polymers of size x. And we assume, which is And we assume, which is we know it's not true, but we can rely on probabilistic results to say even if this sample is not identically distributed and independent, because clearly it cannot be independent, since it depends on all the process. We know that there is some propagation of chaos and that we can assume that it behaves as if it would be an is. It would be an IID sample. Okay. So the idea is that out of this IID sample, you may develop statistical methods to have estimates, approximations of n of tx at different time points ti, so n of t i x. And the question is then an inverse problem, which is you measure the solution of the equation n with noise, and you want to estimate. noise and you want to estimate the parameters of the equation which are non-parametric functions b of x and k of yx so if you stick to this equation you have too many unknowns to be able to really estimate both b and k but what happens is that already weifeng with his first paper Weifeng Zhu found that what seems to be a very What seems to be a very good approximation for this process was to take a power law for the fragmentation rate B and also a self-similar profile for the fragmentation kernel K. So what is a self-similar profile? It says that K of XY, so it's sorry, compared to the previous notation, it would be K of Y X. Sorry. It's simply because probabilists generally prefer K of YX, analysts Of yx, analyst k of xy, so I mismatched. So this is the y is the fragmenting polymer, x is the offspring, and then it says that the fragmentation kernel depends only on the ratio x over y. And we have a dimension here in order that we don't have any creation of mass out of the fragmentation. Of the fragmentation. Fragmentation process is something which conserves the mass. Okay, this is a conservative equation. And so, conservative not in the number of particles, but in the total mass of particle, meaning that the first moment, integral of n of n of t x t x is conserved in this equation. Okay, so with these two assumptions, which luckily were exactly the ones Luckily, were exactly the ones that Wiefenzu did in his biological paper. We know for a long time, I cite this paper by Miguel Scobedor, Stefan Michler, and Rodrigo Ricard from 2005, but I guess maybe there are also previous papers and many other ones afterwards, more specific, more precise, etc., which says that with this association. With these assumptions on B and K, and reasonable assumptions for the as soon as gamma here, the power law is strictly positive, we have the trend of the equation towards a self-similar profile g which means n of tx behaves it's very it's not very precise you I should have specified the norms here so So it behaves like t power 2 over gamma and a self-similar profile g of x t power 1 over gamma. So that the profile, of course, the size distribution shrinks towards smaller sizes, but not in any way. If you rescale properly, you find a steady profile G, which is the solution of this growth fermentation equation. So you have a derivative in Z of Z GZ plus one, which is the first eigenvalue, plus alpha gamma, z power gamma g. And then you have the right-hand side exactly as for the time-dependent equation. And so our idea, when we did quite similar things for the things for the growth fragmentation equation to estimate the division rate B of X. So our idea, but now we don't have a B of X, we have really a power law. And this is because you cannot say anything if you don't have a power law for B, since what you have is the behavior for small sizes. So what values B for large sizes, you don't care. You only care about the value of B for small sizes. And so the idea is to use this asymptotic profile to estimate K0 and gamma and alpha, which are now our unknowns. So this was our first idea. So here you see two examples for two different fragmentation kernels. Here you have the uniform fragmentation kernel K0 constant on 0, 1, and then it is an exponential. And then it is an exponential law for G. And here on the right, you have the equal mitosis kernel with its direct mass in one half, and then you have such steady profile at different time scales. So to study this equation, our first idea was to use this asymptotic behavior. And to do so, we did We did the Milling transform of the equation, which is for the ones who don't know the Mail transform, you may think of it as a Fourier transform in a multiplicative variable, since you define the main transform of a function f on zero infinity by the integral of x power s minus one f of x dx. And you have the formula also for the inverse Milling transform. Also, for the inverse Milling transform. And why is the Milling transform really well adapted to this equation? I'm afraid I'm a bit too long. I only have five minutes here. No? Six, I think. Okay, I will be. So it is because it behaves the convolution, you may see this term on the right-hand side as a convolution product for the multiplicative variable. So when you take the Variable. So when you take the Merlin transform, you have a kind of explicit formula like this, where you only multiply by the Merlin transform of K0. And in such a case, you can estimate the Men transform of K0 out of the Menning transform of G. So the idea is very simple. It is simply take this formula and you have an explicit formula to find out K0 out of G. And theoretically, you can measure G. Can measure G. So theoretically, this is the best what you can dream about because it's an explicit formula for your unknown. In reality, things are quite different. So first, to prove the correctness of this formula here, you have to struggle with complex analysis, and it is what we did, especially Miguel Scobedo. Especially Miguel Scobedo, in this paper, where we prove simply the existence. So we prove that given some self-similar profile G, you may have a unique gamma, alpha, and k0, uniqueness of the whole triplet, such that G is the self-similar profile of the fragmentation, solution of the fragmentation equation. But to prove only existence But to prove only existence, to do so, you need to prove that the ratio here of the Melitron sum of G does not vanish. And for this, we solve this equation explicitly, explicitly in a complex analysis, so with the Cauchy integral formula, prove that it never vanishes because you have an exponential, and then you are able to invert the Millen transform and to have an explicit formula. Explicit or... Explicits or what kind of explicits. The difficulty is that in the field of inverse problems, inverting a Merlin transform or a Fourier transform is a kind of severely ill-posed inverse problem. And so the rate of convergence, the quality of your estimate is extremely poor. If you have a noise of order epsilon, you expect a convergence typically in the order. Convergence typically in the order of log of epsilon. And so, and what we did was not so efficient. So, turning back to experimental data, we realized that we didn't use all the richness of this data, but only the self-similar profile. So, only let's say the last time points. So, we went back to data, sorry. Two data, sorry, and decided to estimate rather directly the parameters alpha and gamma by using another property, which is the time dependence of our equation. So, typically, remember the formula at the beginning, we have a power law for the behavior of The behavior of the distribution n of tx. And so the average length, which is μ of t integral of x f of t x dx, which is really easily measured experimentally, behaves when times is large enough as a power of t power minus 1 over gamma. With this formula, looking at the time dependence of the equation, we may estimate gamma. And once we have gamma, And once we have gamma, so the power law for the division rates, we may estimate alpha with this time-dependent formula. Okay, so and this method works really much better than the theoretical formula obtained at the beginning. Here you can look at the curves in a log scale for the time and in a log scale also for the Scale also for our measurement of μ of t. And we did it also not only, so here it is the formula for only the first momentum, but we can do it for several momentum. We can also estimate x power s and find the formula for the moment of order s. And then we see that we predicted a gamma which is relatively coherent for several moments around 4.2. Around 4.2 in this example. So, this is what we did for each several types of proteins, and which gave us an estimate for gamma and then for alpha. So, for our division rates. So, here you see it for the four types of proteins. What we did is at the beginning, we have not yet reached the asymptotic behavior. So, we approach the curve by a By an horizontal line, and then we looked for the best straight line because it's Loblox scale and estimate gamma as the slope of this line. And this worked very well to estimate alpha and gamma. And I will go directly to this solution. Out of alpha and gamma, we took several types of fragmentation kernel K0. of fragmentation kernel K0 departed from the only from the initial distribution and found out that they were sufficient, this couple alpha and gamma were sufficient to really estimate very, to predict very correctly the measurements at several time points. Here it is for the four types of proteins. We only used alpha, gamma and the initial condition and you see as a full line here it is And you see, as a full line here, it is our estimate for the size distribution over time. And it is really satisfactory. And Welfengzhu was really happy because in reality, it was not so much better as what he did previously, but it was extremely more efficient because we only need two parameters and they were sufficient to explain the whole dynamics. Unfortunately, whatever the our Our first question was to estimate K0, to see the fragmentation kernel. But in reality, if you look here at estimation in a specific case of proteins for lysozyme, here it is the estimation with a uniform K0 and the best alpha and gamma. And it's quite good. And if you now you take a Dirac, delta Dirac in one half, it's not so well so good, but still it is relatively. It is relatively convenient, which means that with this type of experiments, we are in reality not really able to estimate properly K0. And this is my conclusion. We still need to work to estimate the fragmentation kernel of with this data, but we know already a negative result, which is we know we will not be able. We know we will not be able to estimate it with such experiments. We need to carry out other types of experiments. And our idea now is to use, we have used long-term behavior, we have used time-dependent behavior, but our idea now is to use short-term behavior and to specify some far from equilibrium initial condition and to see how out of How out of such distributions we could have information on the fragmentation kernel because far away from equilibrium is the point where the fragmentation kernel will have the most influence. I've been too long, I'm sorry, and I think I will stop here. Thank you very much. Thank you, Marie.