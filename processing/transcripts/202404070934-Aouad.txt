I'm delighted to be here and talk about this work, this recent work on dynamic matching. This is a problem I've been thinking about for a couple of years and together with an amazing PhD student, Elireza Amani, who's at the London Business School, and joining forces with Amin Saperi, we've been making some progress and I'll be talking about our results. We're intending to post a paper in a couple of weeks, so feedback or comments would be appreciated. So the problem of dynamic matching is actually closely related to several questions and problems we've discussed in the past few weeks. And problems we've discussed in the past two days. But there's one important difference. So, the idea is roughly that when we think about matching, many matching markets, many matching problems actually resemble queuing problems, like in the sense that when you think about the supply or resources, they tend to dynamically arrive to the market or stay available for some amount of time, and then they leave the market unexpectedly. And examples, I personally started being interested in this sort of dynamic models, working in white healing. Models working in right-handing. And so, if you think about a platform like UberX, the drivers typically would be idle for about half of the time. So, over an hour of active work, they would be not working half of the time, which means two things. Which means first that they would be waiting, so they're queuing, and it means also that they might disappear because the competitor due to holding homing might actually use the resources. So, you have to be thinking about that when you're making matching decisions. Another kind of completion-related setting that Another kind of completely unrelated setting that people in the literature have talked about a lot is if you think about organ transplant, disease donor organ transplants I'm showing here for the NHS. Typically, you have quite long queues. So these are also people waiting to receive a match. And it varies depending on the condition and what kind of transplant you need. And these people might actually die while being annoying this. So the fatality rate can be something like between 5 to 10% on a yearly basis. It might take you two to three years to get the market. So this is a real kind of So, this is a real kind of dimension of the problem that we may want to think about. And so, a couple of years ago, quite a few kind of people started thinking about this question, initially more from a modeling and insights perspective. And then with my former PhD student, Omeali Pasaritach, we also tried to translate this problem into an algorithmic question. So, trying to think of how do we design matching algorithms, online matching algorithms, in these sort of settings. And there's been a healthy and growing literature on this topic, so much less. So much that's that we now have kind of a table that we can start populating with various results and different types of bounds depending on what is the benchmarks or the incompetent ratios or approximation ratios and what kind of formulation of the problem where we're thinking of minimizing costs in a metric spatial setting if we have a single server or if we have a network. And one question that kind of motivated us about eight months ago was realizing that all of the results we've known so far actually All of the results we've known so far are actually premised on looking at static policies. So, what I mean by static policies are policies that do not look at the state of the system. And this is, from an algorithm design perspective, slightly odd choice for this type of problems because precisely I said these are problems that are human problems. So there's important information available at any point in time, which is how many people are curing. If we can adapt to that, maybe there's a hope that we could improve the results that have been obtained so far in the nature. This has been kind of what drove our research. Been kind of what drove our research. So, today I'll talk about kind of progress we've done. Initially, we kind of started thinking: how do we design, how can we design adaptive policies, and how can we provide, for example, linear programming relaxation so as to be able to optimize these policies. So, that's what I'll focus on. So, we have a new linear programming framework and relaxations, and a prime module algorithm to solve that relaxation. And then, you know, as we were making progress and understanding better this issue of adaptive forces, then we were able to obtain. Adaptive policies, then we were able to obtain new approximation results. So, I'll mention here two main results we obtained. So, one is approximation schemes, so polynomial time approximation schemes for a mean cost setting and single-serve setting. So, meaning we can approximate the optimal online with arbitrary precision in polynomial time. And then the second result is a loss-less reduction of like tension resolution. So, I'm very happy that Will has already introduced the problem. So, this allows us to re-discover the one minus one over E approximation that we obtained in the. Minus one over E approximation that we obtained in the previous work, but using, I think, a cleaner and uniform guarantee. I will mention that later. All right, so roughly speaking, we kind of populate some new elements of this table or rediscover some bounds using adaptive policies and new linear programming. And we're still working also on other setups that I mentioned here. All right, so what is the model? Because I've been talking, but there's no model so far. So the idea is that we still have a network, we still have bipartite matching systems. Have a bipartite matching system, each vertex corresponds to a type of agent, and there's been not going to be rewards by matching agents. So we're going to separate customers from servers. So customers are on the right side. They need to be matched immediately. The servers are the ones queuing. They're the ones who are waiting. And we have an edge weighted by part graph. Alright, so that's the first element of the model. The second element is what is the process? How do people come to this market? Do people come to this market? So we'll assume that there is a Poisson arrival of rate time time i for each time i, and then people will stay for some random amount of time. It's an exponential distribution, you don't know the realization, but you know the parameter mu i, so this is the rate that we should leave. And then on the other side of the market, we're going to use gamma j for the customers, but they leave immediately. So customers are demoidation, think about this as disease donors for kidney, or think about the right-handing setting, these are the customers who place a request. Yes, Ali, in your original paper, customers were also able to make it. So we have other kind of, absolutely, so we have other results that are not on that table, but I'll focus on this setting. Yes. Because there's a lot of complexity that come out of that. Yes, kind of follow a question. Do our coaximation factors change if you are a low patient? So yeah, we have weaker uh results. And we're the I think our original paper is the only one that looked at that segment, yeah, so far. And we get uh lower approximations here. Lower approximations. Good. So now that we have this, I think you can think in your mind, run the system in your mind. So people come randomly, they stay for some amount of time, they leave. And the name of the game is that you have to match them before they depart because they were going to depart unexpectedly and they're going to leave and that's leakage into the system. So you can think of two types of problems: reward maximization. So in the long run, in steady state, like how much cumulative reward, average cumulative reward you're generating, or you can think about cost. Or you can think about cost, and we have results on both types of products. Usually, cost is harder. So, I've described we had by criteria approximation. So, you want to kind of essentially have low cost, but at the same time, make sure that you're matching enough important systems. So, that's going to be our solution concept for the difficult code. All right, any questions about the model? Okay. So, just giving some intuition of what are the challenges and why are these problems kind of departing from how we think about online meshing and understanding. We think about online meshing in other settings. So, the first challenge is about, you know, in a sense, we're making considering this sort of MDP and taking steady state. What we're dealing with is an average cost, infinite-dimensional MDP. So, even like formulating the problem, it requires some thinking. Look, if you want to use strong duality, for example, for the LD, you have to be careful. So, this is just inherent challenges because working by this infinite dimensional continuous time markup decision process. I think some questions: so, there's holding cost as well, or queuing? So, there's a balance. Or humans? So there's abandonment, so that plays that role. But there is no existing waiting cost, but if you wait proportionally, there's a relationship, one or more mapping between the two. So the problems are not equivalent, but yet there is a relationship between weighting. That's a great question. Then the second problem, difficulty, is that steady state. So you're running this to steady state. So in a sense, the market thickness, which means how many agents are available, how many agents are accurate, this is indulgence. Acua, this is indulgence. This is by taking your system and then taking it to a statistic, as I said, is what describes basically the availability of the. And that, you know, I want to say that even if you're fixing very simple policies, you know, actually what Renee was describing here today is really related to this problem, we don't understand what the steady state looks like and how to characterize it, how to write it. So we have product form results for very specific cases, but when you add reneging, actually these product form results will break. So we don't actually know how to characterize the statement. Actually, we know how to characterize steady state in close forms. So that's another challenge. That makes the problem quite different from other literature. And finally, there's no scaling here. So, unlike some of the recent results on dynamic matching showing kind of very small regress, constant regress, what these results, so actually Niva Ona's paper, this was Sophia's John Market paper, what they're assuming is that you can scale the system. So typically, you're going to carry inventory of agents waiting so as to be able to achieve that result. But if you think about it, when you have inventory. If you think about it, when you have inventory, these are people who might keep. So, in our system, that means that there is abandonment. So, you cannot carry a large amount of inventory so as to achieve these results. So, this rules out kind of leveraging these sort of types of results. So, the question you may ask is, do we need to be adaptive? Maybe back to David's comment earlier, if we think about just what is a good policy for this problem, do we really need adaptive data? So, I'm going to show you just a simple simulation we've done. So, if you take random instances and look at the optimality gap. And look at the optimality gap when you have only one server, so only one type of agents waiting, and compare optimostatic policy to the optimum. You can see that as a function of mu, which is how likely people are going to be leaving. So you can see that there are regimes where being adaptive doesn't help if people are very impatient or people are very patient. But there are settings where you can get a gap of 15%. I argue that this is kind of worthwhile thinking about, and this is even with. Worthwhile thinking about, and this is even without a network, this is having the same result. And why is that that we have this sort of loss? Well, if you think about the LP and the static LP, it has a high energy bravery gap. So it can have up to 30% gap with the optimum. So in other words, if we're going to start thinking about adaptiveness, maybe we need new linear programming relaxation. This is precisely what our main contribution lies in that. So let me show you first the arrival rate was fixed. The arrival rate here. Rate was fixed. The arrival rate here is fixed, yeah. So when you change, like is there any correlation when you change like lambda and view at the same time? You see? So actually, you can re-normalize time, so you can fix lambda. That's fine. You can always rescale one of those corrections. Let's start with like a LP relaxation from our previous work. This is what the LP looks like. And let me pass through it because I'm going to build on this LP or I'm going to show you a different LP. So, this LP, there's xi and j. Think of it as instead of state. What is the fraction or the flow? What is the fraction or the flow, the rate of agents from match between type I, patient agents, and customers of type J who are arriving? And here, the I to J matters in the sense that I is waiting to be matched to J. So I to J are not interchangeable. So you can, you know, this is pretty simple. You can write like draw balance. These are how many people arrive, this is the people who leave, people who get matched. And then you have, of course, you need, for example, the cost setting, you need the throughput lower bound for this problem to make sense. Lower bound for this problem to make sense. Now, the innovation in the previous work was to think about how we capture a bandwidth. And it was a very surprising, very, very simple constraint, watching family of constraint quadratic family of constraint quadratic problem, that actually allowed us to design algorithms. This is what the constraint looks like when saying that whatever you're doing, any policy, you have to include some minimum amount of abandonment. So this is leakage. And that leakage means, you know, in your flow balance, these are people you're not going to be able to. And the intuition for this is that if you have at least one person queuing in the system, then the rate of Then the rate of matches to the rate of abandonment has to be proportioned to pregnancy. That's interesting. Now, from this, we understand this is not going to be good if there are many people queuing. And this is what type of information we want to leverage in adaptive processes. So how do we assume Poisson arrivals? Yes. To change this content to something that would be Poisson arrivals. So actually, what we're going to use. That's what matters. So, and that was also something we used in the previous paper, but we're going to really use it to the fullest. So, the key question here that I want to think: so, this fast appropriate is saying that on average, when someone arrives, what they're seeing is an average state of the CTT. And we want to use this information. So, we want to first understand what is it that a real optimal policy is doing that these LPs are not capturing. So, that was the question. So, what we tried to do is we tried to write another LP that is much closer to what a real policy, optimal policy, would be doing. And that real policy would have. Input and that real policy would have access, for example, to Q information. So the decision variable that I want to use now is XISQ, and it's going to seem, the LP up on the right, is going to seem almost hopeless. And then we would be able to kind of make it tractable. But so the decision variable is XISQ. So I'm going to use this to denote the fraction of the time that time I has Q agents waiting, and I'm committed to matching an arriving agent with. Matching an arriving agent within the set S. So, S is the set of customers that I'm willing to serve right now. And you can describe any optimal policy because of PASTA property, you can describe any policy as committing to this sort of subsets. And of course, there's a decombinatorial number of subsets. So that's why I'm saying this may be rubbish. So the new LP, which is called dynamic LP, basically you have from the pasta property, this is a linear objective as a function of these variables. But now we have these variables, and these variables, We have these variables, and these variables, what they're describing is a queuing system. So we want to write some sort of queuing-adapted, some constraints that describe the queue-adapted process. So what is this PI? This PI is going to be the polyto for a single-server queue. And what it is, it's basically detailed violence. So that's basically what you need to write down the state of the sessionary measure of the queuing system, and something that just says that the probability is some up to one. Probability sum up to 1. Okay, so this is the polyto PI. And now, of course, I still have my old constraints, which is that there is no contention. So, if I think about the J's, on average, I shouldn't be matching them more than once. So, that's what the constraint that Will was referring to also in this context. And then, finally, there's a throughput target that I mentioned to you. And actually, this is not enough. We have to add some other coordinatorial constraints to this problem so that it's actually strictly better than previous relaxation problems. Previous relaxation problem. So, this is the LP framework. As you can see, it's a pretty massive LP. Q here is infinite. S is exponential. So, this is a question of can we even solve this hack, correct? Is the KSS double? Did you just set it up or they cite? Which one? So, the one that you cited on your slide. I just want to make sure if I this one. So, you have a citation on your split. Oh, it's better. Yeah, sorry, yes. It's uh, how does Yes, that's the one. How is Post Demonstrated actually? So they have Q equals 1, basically. They only have one availability constraint overall. So we're tightening it both with considering this PI. So actually they don't have the same variables, it's very different actually. It looks very fast. It is a different additional polymer. These are like the same sorts of things, the kind of the Poisson switch, like you have exponentials and stuff tighter. Exactly. We can stack. Yes. Because otherwise you could dilute the system. I'm not going to go into too much of it. You also had these quadratic constraints in your original paper in formulations. Are they captured by any of these or are they commuted? Yeah, they're actually tighter than these. Actually, I should, that's a great point. I should probably think about making that comment big. Yeah. Excellent. So now, how do we solve this whole thing? That's the question I want to answer. So, first of all, actually, we wanted to understand what So first of all, actually we wanted to understand what is it that comes out of this? It's a recent paper that also, the paper was to develop approximately near Programme. So Vossen and Hugh, so folks from Georgia technique, yeah. So it's very recent paper, it got published. So what does this LP describe and can we solve it? So I'm just going to say we're going to look at the dual quite a bit. Say, we're going to look at the dual quite a bit. Actually, we're going to use both the primal and the dual because the constraints that we have to deal with, we can separate them either in the primal or the dual. So, we have to kind of play on both fronts. You can write the dual, actually, some subtilities that I was not aware of for infinite-dimensional LEDs that to be able to formulate a valid dual, you need to have duals that converge to zero. This is a known transparent versality condition, but you can do that. What do you get? I'm going to focus on the insight. So, the insight is the dual is describing weekly. The dual is describing weekly coupled average cost markup decision processes. Okay, so for those of you who know this concept, it might be useful to know. If not, you can ignore this. But interestingly, what they're saying is that you have QLEN-dependent thresholds. The optimal policy is fixing a threshold for the notion of cost based on how many people are queuing. So, what does it mean exactly? It means that any point in time, what you're gonna do is you're gonna commit to a subset that is contained between two subsets. Contained between two subsets, which are obtained using a threshold on reduced cost. So, what you see here is all the types that have a certain reduced cost should be below a certain threshold. And that threshold is dynamically varying as the queue changes. So, what is contained in these reduced costs? Well, these are the thresholds. You can interpret them as marginal costs for matching. You have a reward for throughput for better satisfying your throughput objective. This is a contention shadow price, so it's an adjustment to the cost based on the shadow price. To the cost based on the shadow price out of the constraint. So, this gives you basically the threshold points. And the thing we can show, which would be useful from an algorithmic perspective, is that the optimal thresholds are monotonous, increasing, and concrete. So, I think one thing I want you to take away is that the policy is actually very reasonable. What the policy is doing is that it's looking at the number of people queuing, and based on how many of them you have, you're gonna subset you're gonna pick a subset of agents that you can serve, and you're gonna rank them based on their reduced cost. Break that based on the reduced cost. So, if you have only one person that is queuing, essentially you have to become very picky on how you use that resource. So, you're going to pick a small set. But if you have many, many people queuing, actually, you're going to increase your threshold, but then as a result, you're going to pick a bigger sum set. So, it's a very reasonable policy, I think, to think about. Now that we have a reasonable policy, can we actually algorithmically solve this problem? And what kind of guarantees can we get? And I'm going to just quickly tell you about that. So, the first question, can About that. So, the first question: can we sketch? If you just use these thresholds, you get a policy for a scale that we feasible in expectations. Yes, right? So, first of all, can you solve this big black box TP? And the second question, LP, which is infinite dimensional. And that's actually a lot of work goes into that. And then the second question is: how do we do contention resolutions in SSP? So, our first result is to show that we get the 40-polynomial time approximation scheme for DLP. For DFP. And it's based on two ideas. So, one is to do some sort of state-space collapse. So, we show that you don't have to be that adaptive. You don't have to look at all possible Q's. You can restrict attention to a small number of Q's. And then, with that information, you can reduce Q to be some polynomial number. And then you have to run an efficient subversion oracle with a signing ellipsoid using both the primal and the tool. I'm not going to go into too much detail, but the Too much detail, but the dual is used to get rid of the S constraint. So you have exponentially many S variables, so you can separate them in the dual because you have constraints that you can separate. And in the primal, you're dealing with the point that you're going to constantly. But anyway, I think the high-level idea is you can do efficiency. Yes. But it's like a polynomial. And that takes a bit of work, so I'm actually going to skip this for the I'm actually going to skip this for the sake of talking about the algorithmic results. But essentially, what we do is we define a notion of limited adaptivity. So we say that the policy is Q bounded, it diffuses up to Q agents in each Q. And we say that an instance is Q epsilon adapted. If that instance, in that instance, you can universally approximate any policy using arbitrary closely to epsilon closely using only Q agents in the field. But if you can do that, then you don't have to care about various. Then you don't have to care about very, very large keys. That's what we want to argue. So there's like an easy bound you can get if you just use stochastic dominance, but unfortunately, that bound actually depends exponentially in the parameter input. So a lot of the work we've done was actually to show that for every instance, you can be q epsilon adaptive with something that is actually polynomial. Okay, so that's the the first issue that we deal with. We don't have to be that adaptive, which actually in practice and in the simulation something is Actually, in practice and investimation, something is typically a small number of cues suffices to get good policies. I'm going to skip the proof, but there's some interesting ideas around how to, basically when you have a birth-death process, how do you kind of alter your policy so that you can achieve the same outcomes in expectation using a different distribution? So it's called this distribution design problem. And now I want to state what we get from this, from solving this master IP and what kind of algorithm it results. What kind of algorithmic results? The first result is that we obtained a fully polynomial type in the proximal scheme for a single server setting. So that's if you only have one agent type queue in the system, and for that setting, there was no result known beyond the performance guarantee for those static price. The second result we got, which is more surprising or interesting to us, was if you think about the mean cost setting, so the cost throughput problem, we can actually get the polynomial. We can actually get the polynomial time approximation scheme on D Euclidean graphs. So, Euclidean graphs of dimension D. So, here the dimension needs to be fixed. So, the runtime grows exponentially in D, but we can approximate the optimum industry. So, that's the second result. And actually, I would argue that a lot of spatial markets, you can think of them as Euclidean type of metric costs. So, that's something we're able to obtain. So, the idea is we're going to build a decomposition of. Going to build the decomposition of the instance into local sub-problems using a master linear program that is not as granular as the linear program I described to you. But then for any sub-problem, we can reuse this dynamic linear program and multivariate version of it. So there's a bit of work, but in essence, the policy we get has a similarity with hierarchical greedy policy by Yashkinoria that appeared a few years ago. So what it's doing is whenever someone comes in, when they look at the state. Someone comes in, you're going to look at the state of the local cues, and based on that, you're going to either try to dispatch a local agent or you're going to search for an agent that is farther away. And this is what this decomposition idea is implicitly done in here. All right, and then finally, and that's the last result that I talked about, is that we can now rediscover the 1 minus 1 over p approximation ratio using a reduction to Using a reduction to offline contention resolution. So we can round the LP solution in such a way that we can guarantee one minus one reward approximation ratio. This is for the reward maximization. Because Will has nicely kind of laid out what a potential resolution scheme is, I'm going to actually try to describe with it how much time we have left. Okay, so great. I can, I might finish on time. So I'll try to kind of explain it more than this. Okay. So another thing is that even if we rediscover this result, Is that even if we rediscover this result, it turns out that here the bound we get is also uniform. So, in the sense that we can guarantee that every pair ij, we can obtain the matching with that desired ratio, which is something that doesn't hold if you think about that previous approach. Okay, and the policy is also very different because now it's a Q-dependent policy. So, the policy is adjusting its decisions based on the size of Q using the threshold that I described here. So, I think this is also for the minimization. This is also for the minimization. This is for the reward maximization cycle. Oh, sorry. This is a flow. All right, so I'm going to. First of all, I kind of describe what we did in the first paper, which was a correlated LP rounding approach. So the details don't matter too much, but we had a weaker LP, and from that LP, what we did is basically when an agent, when a server comes in, basically that server would be initially assigned. Initially assigned to a group of customers to serve. And then it would serve the first customers that content within that group. So we call these groups compatibility sets or pull sets. So in the sense that we're kind of pulling the arrivals of all these agents and making this type of customer actually willing to serve any of the server willing to serve any customer within that point. So there's an analogy with the bipartite menu design problem. Menu design a problem that yesterday Ronet described. In a sense, we were designing that system from the solution of VLP, and it was a way of routing VLP solution. And it's correlated because, in a sense, what we want to do is we want to make sure that there isn't too many abandonments. Whenever you generate a flexible server, that server is more likely to serve someone before it leaves the system. That was very important because that's how you would control the inventory. And quite frankly, we did that because actually we didn't have a good handle of how. Actually, we didn't have a good handle of how the abandonment could basically hurt your promise because we didn't have this sort of queuing perspective on the problem. So with this, we could show a one minus one over E. So whenever a customer comes in and it's in a certain pool set, it's going to basically be served by the servers. But we couldn't basically use directly. There's no way that I'm aware of that we could use this approach or this LP to do offline contentional resolution. So in a sense, we could not guarantee. Potential resolution. So, in a sense, we could not guarantee that we could, all the matches we were doing, so if x, i, j is the frequency of matches between i and j, we could not guarantee that there's going to be some alpha factor such that the matches occur in the real system with that alpha probability, which is the notion of congestion resolution. So now, I'll describe to you what we are able to do with the new L, because essentially it gives us a more elegant and direct way through a reduction to conventional resolution schemes, but there's still like some interesting challenges in that. So, what is the Interesting challenges in that. So, what is the contentional resolution scheme? Fortunately, now I don't have to go into as much detail based on Will's description. So, we were using this result, one of the results from Frontaket out that for any matrix and for any feasible x within the matriarch polytope, okay, that satisfies the matroid polytope constraints, there's an efficient 1 minus 1 over e balanced contention resolution. So, what it means is that if each coordinate is drawn independently with probability xi, then which is Then, which is what we'll call an active, the agent being active, then this contention resolution scheme tells you which one of them to pick so that you can guarantee in expectation that you chose each element 1 minus 1 over e times xi. So that's the notion of being 1 minus 1 over e patterns. So there's a key or a classic kind of recipe inspired by recent literature that we could try to apply to our problem by leveraging. We could try to apply to our problem by leveraging this result. So, what would that look like? So, first, you approximately solve TNP, so that's our new dynamic behavior program. Then, upon an arrival of a type J consumer, what you could do is you could independently draw the service requests according to the XI vector. So this XI vector tells you, depending on the size of the queue, which is QIT here, each server will basically say whether or not they want to serve that particular customer. Or not they want to serve that particular customer. So they place a request. And we can think of these requests as the active sets that we were mentioning. So now we could, like, an intuitive kind of approach would be to run the CRS on that customer type J to decide which one of them is your manager. And then for the end-user request, you have to discard them or you have to do some sort of downsampling later as well. But this is the main challenge, actually, that arise. So this algorithmic recipe has been used recently. Algorithmic has been used recently in other papers. But in this continuous time model, there's a fundamental challenge that arises, which is that the discarding is actually not so easy to do. In the sense that here we want to maintain independence between the queues. In order to be able to use this result, we need the queues to be independent. But because it's a continuous time process, if I'm making my decisions at the same time for all the queues, I am correlating these queues. So this discarding process has to be carefully digital. So this discarding process has to be carefully executed, otherwise it induces correlations, proposed correlations between the queues, which can then mean that you cannot implement this and can hurt your performance. So the question is, how do you do discarding in a kind of principled way within this framework? So I'll just end in kind of two minutes. We propose a continuous time discarding process, which is based on basically taking our original system and then creating a bunch of co fake copies of agent types of each type of customer. Of each type of customer. And then, for all these fake types, whenever they show up, you should use the CRS not to decide who not to select. So, we call this anti-CRS. So, essentially, the CRS tells you who would have been assigned to the real time. But because you have a fake time, you should actually do the opposite of what, or something different from what the CRS was currently doing. So, we call this the continuous time discurrent. So, I'm going to just end here saying what I want you to take away from the talk. So, first of all, we've been Takeaway from the talk. So, first of all, we've been trying to think: how can we design adaptive policy for this type of problem? And I would argue that this is actually a very natural question because the problem has a skewing flavor. So, we want to leverage information about the safety of the system in the way we're making the matching. And we propose a new LT framework, which is both polynomial time solvable or approximable, and then that kind of describes very natural policies that are based on queue-led, so we call them queue-dependent policies. And basically, the more people are queuing, Basically, the more people are queuing, the less restrictive you're going to be in your matches. And then finally, with this LP, this better LP, we can get better approximations for the min cost setting, and we can get a reduction to concession resolution in the reward setting. And we're also working on, we think there might be other applications of this LB. So a couple of interesting open questions. Can we breach 1 minus 1 over E for the matching problem? There's no hardness to date for this type of problems. And then customization is actually very hard. And then customization is actually very hard. So, even for very, very simple graphs, I think this is an interesting problem to think about. So, thank you all.