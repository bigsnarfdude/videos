Right. Okay. Let me mention a couple of things right before introducing Bruno. One is to remind you that we do have access to this movie, Secrets of the Surface, The Mathematical Vision of Mario Mizarkani, that we didn't manage to find a time in the schedule, which worked to organize sort of a viewing party. But if you want to watch it on your own, you can access it through the link. You can access it through the link that I'm sharing in the chat. The other thing is, in the email you receive from Bears for speakers, there's a link to upload slides. If you are willing to share your slides, please do that. If you can't figure out how to get the link to work or just want someone else to do it for you, you can email me as well and I can upload them for you. Okay, so we're happy to have as our next speaker. We're happy to have as our next speaker Bruno Naktagali from UC Davis. And Bruno is going to tell us about dimerization and the ground state gap for a class of ON spin chains. Thank you, Jeff. Thank all of you organizers for putting this together. It's been a very nice meeting and I've been enjoying it. So I picked this topic. Because I think that in this case, maybe the techniques more than the result may sort of fit the topic of the conference best. It's about spin chains and a phenomenon we called demerization, which is breaking of translation invariance. And it's a family of spin chains for which the Hamiltonian has sort of this. As sort of this kind of structure that you can think of, and the way you analyze it, that you can think of as successive application of randomly selected local unitaries. But there's also projections. This is joint work with Jakob Burenberg, Peter Milbacher, and Daniel Ilchi. It's a paper on the archive. I think it appeared just the end of last year in CMP. And CMP. I will explain why we were sort of looking at this particular class of models. You can ask a lot of interesting questions about almost any spin Hamiltonian. But what is special about this particular class? And it has a long history, in fact. So I'll talk about that just a little bit. I will explain what the I will explain what the phenomenon of limerization is and how it occurs here in this class of models. One of our results will be the proof of a spectral gap for the model and perturbations thereof. I mean, that's how you want to look at it. So, there is a partial solution to the stability question. I'll explain also why, in this particular case, this is Case, this is kind of interesting. It's not a standard case. Connect it to the ECALT chain and discuss some phase diagrams, state the main result, and then discuss a little bit how the proof is working. So here we go. So the setup is very simple. We're going to have just been chains. So the lattice is just Z. And I think. Z and I take always finite chains in this talk. You can take limits if you like, but the results are stated for finite chains. And the Hamiltonian will be translation invariant. So there will be n-dimensional spins on each side of the one-dimensional lattice. And now, just for the introduction, I will use the spin matrices to define some. Define some interactions of very well-known models. So these are the spin S matrices, and the S of spin S is related to this dimension N by this formula. So S is half integral. Integral versus half integral S sometimes plays, it makes sort of a difference. And so also here we will see that E, which is corresponds to even versus R dimension of the local Hilbert space. Local Gilbert space. And this distinction will show up here. So we will be interested in translation variant Hamiltonian. Instead of this form, you have a salvage joint element on just two spins and you translate it through the chain. And that's the Hamiltonian we consider. And of course, the very first model of that type that was defined was the Heisenberg model. And so this is this particular choice. There were good reasons, in particular in the case n equals 3, to generalize this model. So the Heisenberg interaction for the AKLT model appears here, but there is another term for this model introduced by Aflek Kennedy-Lit and Tasaki. And I will show you on the phase diagram what's special about that. The combination of these terms is a projection operator. Of these terms as a projection operator. Maybe that's not the most important part. But the projection on spin two, so the high spin states are given a positive energy, while the lower spin combinations of neighboring spins have zero energy. And then you can, well, once you have these two terms with these coefficients, one-half and one-sixth, it's not unnatural to say, let's take arbitrary coefficients. Arbitrary coefficients. And since scaling by a positive pre-factor doesn't change any of the physics, it's just energy scale. These two coefficients are often parameterized by an angle. Call them cosine phi and sine phi, if you wish. So this way you have a one-parameter family of models for this particular spin chain with three-dimensional Hilbert space at each side. And here is a phase diagram that it sort of That it's sort of conventional to sort of present it as a pie chart. The angle itself doesn't really have a meaning, but because it's one compact parameter, it's kind of natural to put the phase diagram on a circle. And so here's a lot to say. I mean, this family of models has been studied for quite some time. And so, here is sort of a summary of some of the important facts. The important facts, I will not spend too much time on it. But just to show you that there are different phases, so there are these four different phases that are reasonably well established. Not by any means, has everything been proved mathematically, but it's with numerics and the exact and rigorous results that we have. We know more or less how the phase diagram looks. Diagram looks so this here is a very simple thermagnetic phase. We're not going to talk about you can write down the exact ground states and compute at least part of the excitation spectrum. It's not a gapped phase, and so it sort of doesn't really feature in this discussion today. And there is another gapless phase. So the ferromagnetic phase obviously has long range order in the ground state. Range order in the ground state. This is another gapless phase that does not have long-range order in the ground state, has some kind of pseudo-long range order that probably isn't really very well understood. But so these are the gapless phases. And then the other half of the circle is divided here in this red and yellow part, which are gapped phases, but they are different. Well, they're different already. They're different already if you look at the ground state degeneracy. There is breaking of translation invariance in the yellow region here. That's where we have this phenomenon called damerization. While in the red region, we have a unique ground state in the terminal limit which has exponential decay of correlation. It's kind of a disordered ground state. It's what is called the Haldane phase. And in fact, it's Haldane. And in fact, it's Haldane's prediction that set this whole study sort of in motion. Because before Haldane, there was very few people, if any, was aware that the phase diagram of these spin chains would be that interesting. And in particular, it would contain this unique disordered ground state with exponential decay of correlations and a spectral gap. So that was what Haldane set in motion in 1980. Set in motion in 1983, and then it is to show that this phase indeed existed that Aflaken, Dilip, and Tasaki came up with the ETLT model, which is not the model about which Haldane made his prediction, which was a Heisenberg model, which is sitting here. They added this other bi-quadratic term to the Hamiltonian so that they could actually construct the exact ground state and prove what. Prove what Dalden phase asks you to prove: exponential decay of correlations and a spectral gap. So then there are these points that separate phases, and they are gapless. And in this case, they also happen to be exactly solvable. And so we, even if it's not really a theorem, you know, in We know in principle what the ground state is. And this is by Beta Ansatz, sort of very different from the methods that I'm going to talk about. It applies only in one point, but it gives you very detailed information. And if Vladimir would be here, he has reminded us already on Tuesday very much that how interesting this is. And this also has a lot of applications, but they are special. Indications, but they are special points, these special points. Okay. Now, so the phase that I'm talking about is this one, and it also has an exactly solvable point there. One way to describe the solution is using the representation theory of a temporary leap algebra. This was done by Klimper and Aflak, and then generalized by other people in the early 90s. People in the early 90s. And Klumper discussed specifically the n equal 3 case, and he found that this is a dimerized phase. So there's breaking of translation invariance. There's two ground states in the terminal limit that are not translation invariant. And that was then generalized to general n. And I will talk more in detail. I will talk more in detail about that when I have introduced the Hamiltonian for family of Hamiltonians for general n. There's a question in the chat which you might want to comment on. Whether these, yes, so the question in the chat is whether these different colored phases are separated by second order phase transitions. And I think so here and here, I believe you would call the Here and here, I believe you would call these second-order phase transitions. There are exponents associated with it that can give you the full information. I don't know what I would call this. It is a very special point with an extremely high degenerate ground state. So, but yes, so for instance, here it's quite, you know, it's expected that these points that the correlation These points that the correlation length diverges, and you have power laws, and it has sort of the features of a second-order phase transition. And especially if you would look at it in space-time, it would look like a two-dimensional, there would be a conformal theory associated with it and everything. Okay, that's it. I think Ramis also has a question. Okay, Ramis? Hi, Bruno. So, this is really great. I have a very simple question. Great. I have a very simple question. So, all bi-quadratic, bilinear Hamiltonians with translation invariance and local terms fall in this circle somewhere? Well, for example, let me tell you what I'm thinking. Like, I wonder if the Motskin spin one chain is somewhere here. I just don't know. But that's, it doesn't have an X nearest neighbor interaction. No, Motskin is spin one is nearest neighbor strict. Is spin one is nearest neighbor strictly. Is nearest neighbor? Yeah. So it's the frame that has an ex nearest neighbor. Right, that's correct, correct, correct. And that's a spin, that's half integer spin. So it's not SU2 invariant then. So Motskin is U1 invariant. Right. So no, it wouldn't be here. No, this is this has these have SU2 symmetry at least, and at special points, even SU3 symmetry. even su3 symmetry i see i see right so so the su2 symmetry you can you can very easily see from from these terms it's they they are functions of the casimir operator for for su2 um but yeah no it's not all models so by by no means it's i'm going to argue it's an interesting class of models definitely yeah thank you okay so um let's talk a little bit about Let's talk a little bit about demonization. I already described it as breaking of translation invariance. So it easily occurs in a quantum spin chain if you have terms in the Hamiltonian that sort of compete. And we will see, we will be able to look at the Hamiltonian as exactly a sum of two terms that sort of had competing tendencies. But even if you only have the But even if you only have the term that wants nearest neighbor spins to be fully entangled, there will be a competition between that and another result that is sometimes called monogamy. That is the fact that if these pins choose a neighbor to maximally entangle with, then they have no capacity to entangle left with anybody else. And that means that if you have to choose a neighbor, it means To choose a neighbor, it means you have to break symmetry. And that is sort of what this picture shows here. And this will indeed occur in this class of models that I want to discuss. So these orange symbols here denote a maximally entangled state, which, of course, there could be more than one, but they're all equivalent, kind of. And if you want. And if you want to minimize your energy by entangling, then if you have a spin chain of even length, that will work reasonably well. Everybody can choose a partner, so that's good if you have an even number of spins. And there will automatically be a preference at the end for such an entangled state to form, because otherwise you leave, there's only this spin has only one part possible, right? Part that possible, right? There's no choice to make, and then if you do this for change of length to L with L odd and L even, you see that with respect to the lattice, you pick the other, the complementary half of nearest neighbor pairs to be entangled versus to be not entangled or much less entangled. And that's how this translation invariant, the breaking of translation invariance naturally occurs. Naturally occurs. Yes, Ramis? Just a very simple question. So, suppose you do have these dangling. So, you know, the minus four and five are not coupled and the orange is moved, you know, like you do have these edge modes. Is there some so clearly here you can avoid that because of the length of the chain? Just so it would not be a ground state, it would have it would have higher energy. I see. So if the energy is like, what the kind of Hamiltonian could be? Energy selections. All the kind of Hamiltonians we discussed here. Right. Okay, that was my question. So there is some energy constraint that forces them to actually. I'm going to look at ground states. So yeah. Thank you. Okay. So, and of course, the real state may not be quite as simple as this picture suggests. I mean, there is competition. That doesn't mean that entangling has to be 100% or non-entangling, 0% entanglement. There can be some trade-off between the two, and the states can. Trade-off between the two and the states can be significantly more complicated than just products of maximally entangled states. Okay. So then this phase diagram, what you see here is that these gap phases, they are with respect to the parameters you've chosen in an open region and parameter space, they're not isolated points. It's these gapless points, these transition points, they are isolated. The gap phase is tip. The gap phases typically are an open region in Hamiltonian space, depending, you know, no matter how you define it. Well, that is, if we could prove that there is a non-vanishing spectral gap, that is, that the excitation energy to the first excited state has a uniform overbound independent of the size of the system, which, of course, in general is not the case. And so, one of the things, problem. Thing problems that people have worked on a lot in the last decade or so is proving stability of the gap. So, there are a few special models for which you have some special method to show that there is a gap. And then there's a kind of relatively general argument that shows that nearby the ground state, the spectrum above the ground state will be gapped also. So, that's what's referred to as stability. Stability of the gap, stability of the gap phase. Of the gap phase. So, what's interesting in this case, and what I want to talk about, is that while we have kind of a general approach to this for frustration models, these are models where the ground state is attained by minimizing the local terms in the Hamiltonian individually, which generally you cannot do, but if you're lucky, it works. And sort of all the general stability results are from models. As stability results are from models like that. But as we will see, this is not an example here. The dimerized phase for the AKLT model and the generalization I'm going to discuss is not a frustration-free model. The energy is not minimized locally. You can calculate the expectation value of the energy, and it's actually strictly greater than the smallest eigenvalue of the interaction. The smallest eigenvalue of the interaction term. So there is frustration. And then these general stability results, they don't apply, and we have to do something else. So I'll try to explain what this something else is. But to do that, it's kind of interesting to generalize the model. And we do that by kind of looking in a different way at this interaction. So you can do chains of basis, which I'll not write down the formula. Basis, which I'll not write down the formula, it's in the paper, and it's not surprising that you can do it if you bet about the symmetries and what they mean. But you can write it as a linear combination of two sort of very simple operators with very simple interpretation. T is the swap operator that interchanges the states of the two neighboring spins. And Q is a projection onto a maximally entangled state. And sort of the simplest one. And so, in some basis, this state looks like this. And so, when we generalize, then what we do is put different coefficients in front of this. It's again, it's a two-dimensional space of interactions, if you want. And so we can take as well, instead of Heisenberg and Heisenberg squared, we can take this T and Q with our. This t and q with arbitrary coefficients. And I can generalize this to general n. So instead of this state, for general n, I take a simple, the simplest maximally entangled state I can write. So I choose some basis. So alpha runs from 1 to n, and I choose this maximally entangled state. And then the projection onto it is Q. And then the class of interactions that I want to study are of the form UT plus VQ. t plus vq. So I don't write sine and cosine. I mean I could do, but it would be kind of a reparameterization because it's not, these coefficients are not cosine phi and sine phi. That's a reparameterization of the same family. And what you get actually by doing this, I mean, when we look at this, that is now the, instead of the most general bilinear back quadratic interaction, is the most general interaction for n-dimensional spins that is invariant under O n. And the sort of the natural action of And the sort of the natural action of O on this n-dimensional complex Hilbert space. You just act with the orthogonal matrices on all the spins. And that, of course, commutes with the swap, and it also commutes with the projection of this vector because this vector is invalid. So this was the way it was presented by Tu and Zhang in a very interesting paper in 2008. Okay, and then you get a phase diagram. So now the parameters are u and v, the coefficient of t and q. But I can again normalize it if you want. u squared plus v squared is equal to one. Put it on a circle. I see the same four phases appear. You know, they are in slightly different positions. And also, I can't really draw it accurately for all n because these some of these points move around with n. For instance, the separation point between For instance, the separation point between the dimerized phase and what used to be the Haldane phase is actually also an exactly solvable model, solved by Rashidikin. But it depends on N, where exactly it is. And the AKLT point for N equal 3 is here, but actually generalizes again to a point that you find. For all N, there is a point where the model is restriction-free and you have matrix product gram states. And it's kind of interesting that. And it's kind of interesting that for Rn, it's Haldane phase type, for N, it's also breaking of translation invariance. And there's many interesting things to say about that, but I won't do that. I won't have time to do that today. What I today want to talk about is this point here and then the dimerized phase that occurs there. Ranis, another question. Yeah, sorry. So now that you're on this slide, so these are all bilinear, bi-quadratic spin one. Like spin one chains? No, no, no, no. With SUN symmetry. They have O and symmetry. I can discuss, they have also SUN symmetry in this point here. At least for odd and for even N, they are equivalent in some other way. Maybe I'll have time to discuss this. But what they all have is ON symmetry. Also, ON symmetry. All have ON symmetry. Now, there could be some models with ON symmetry and bilinear bi-quadratic that are still not on the space diagram. I'm just trying to understand. They are bilinear bi-quadratic in the generators of the ON Lie algebra, which is kind of the fundamental observables, if you want, of ON spins. They're not SU2 or O3, they're O n, right? And so if you do. Right, and so if you take the generators of that representation as the fundamental spin operators, then in those it is bilinear piquadratic. The most generator. I'm sorry. So this is a, so I was thinking about the n equals n equals one case, but you're talking about n equal three, yes. No, it's the same, it's the same family for n equal three, up to a unitary transformation. So there the symmetries are all O3. O3. Well, it's SU2, but the three-dimensional representation you got the double cover. Yes. All right. And they don't have necessarily U1 symmetry. Well, they have several U1s. They have many U1 symmetries in it. Yeah, but they have more. But they have more symmetry. That's right. But they have more sickness. Yeah, that's true. Okay, good. That's why your chain is not here. No, no, yeah, I'm trying to understand the. No, no, yeah, I'm trying to understand the relationship between the different things. It's very interesting. Thank you. Okay. Okay. So I have to speed up if I want to get to the end of my talk. So let me focus on the most important thing. So there is this separation point here. As n tends to infinity, it actually goes to negative v is equal to negative 2u. So it actually doesn't touch the South Pole. So there is. So there is an open region around the South Pole there where you have dimerization for all n. And that's what we want to prove. That's sort of the most important thing that there's many other things to say. Now, in the point, the south pole itself, we already knew from another recent work that by Isa and Dominique Copin and Warzel, which is an absolutely beautiful paper. Is an absolutely beautiful paper, and you should look at it. So they prove that indeed for all n greater than 3, you have a dimerized state there, two dimerized ground states there. That relies on something that if I had time, I could explain a little bit later when I talk about the proofs. There's a certain representation of the ground state in terms of space-time measure. That space-time measure and That's based on measure, and that point has beautiful properties that you can exploit if you're clever, like these people are, to prove that you have dimerization for all energy. So with Bürnbach, Milbach, and Ulci, we wanted to show there's an open region. And some of these beautiful properties break down. In fact, some on one part of the phase diagram, it breaks down dramatically because there's no probability measure. In fact, it's a sign measure. It's a signed measure, and so you need to use other techniques. And or maybe it's also because we're not that smart. That's also possible. It could also be a factor. But we have a result that is true for largeness and not all n. So sufficiently large n. I will state the results in a second. Okay, so this is a little bit what I explain here in a little bit more detail. There's also this issue. If you look at the Hamiltonian, that, for instance, is. At the Hamiltonian, that, for instance, is studied in many of these other papers, and also in the paper by Eisman, Dominique-Copé, and Warsaw. It's a slightly different Hamiltonian. It's the negative of the projection, not on a maximally entangled state, but it's actually the singlet, the spin singlet state. It's both SU2 and SUN singlet. And it's kind of interesting to think about how that. So this is actually naturally equivalent for odd end, but for even end is a N, but for even end is a bit of an issue because it's an anti-symmetric state instead of a symmetric state. It doesn't, you know, we can do our analysis for all n, but there is a difference between even and odd n. And by choosing this family with T and Q, the O N model, instead of the SUN model, I can sort of avoid some of these discussions. I mean, it's not very deep, but it simplifies the presentation. Okay. Okay, so let me state the main results before I run out of time. I should at least do that. Okay, so we studied UT plus VQ chain near the point V equals minus one, which is the South Pole. And small U. U equals zero is the South Pole, and I'm going to do small U. Okay. Okay, so let's so our Hamiltonian for L, actually, I should say two L spins is HL. So I'm going to only consider finite chains of even length. And I'm going to study the ground state by taking the limit beta to infinity of Gibb states. This is not a very original idea, of course, but so this is how these statements will be put. Statements will be put in the theorems which sort of come natural for finite volume to do this. So, and here are the analogs of the spin matrices. We can study all local observables, but these are kind of fundamental ones that play naturally sort of an important role. So, the generators of O n in the representation that we have, where you just apply O n on the alpha base. Apply O n on the alpha basis, they are these kind of matrices. They are anti-symmetric matrices of this type. So alpha and alpha prime are two different indices, and you have this one minus one matrix. I mean, you can make other observables, but it's sort of the most directly accessible observable also in the way that we do the proofs. So the first theorem is about breaking of translation values. About breaking of translation variables about demonization, and so it says that there are constants independent of L. So if n has to be large enough, we have not tried to optimize that. And what you find, what you would find in the paper is not very good. So it's better not to talk about it. It's a large number. So v is minus one and u is small. The t term has a small. t term has a small coefficient. So then we have the following. So if you we so this is uh you you pick some alpha alpha prime you can the the O n invariance is not broken. So you can you can take any and it will give you the same number. And so I have the sort of spin at zero and one and then this is a translate of that observable. And so if you take the limit beta to infinity, you look at the ground state. Ground state, then you see that there is a difference. The difference between these two is bounded below by a positive constant C. And that is if L is odd and if L is even, you naturally get the negative, right? The role of the pairs 0, 1 and the minus 1, 0 are interchanged. Okay, so you can. So you can put other observables there, and you will see that the translation values are broken for many of them. And of course, from the moment I find an observable, the translation invariance is broken. Okay. So that is the non-uniqueness of the ground state and the breaking of translation invariance. I will have a little bit more to say about the states that you get by taking this limit. Taking this limit. So, but it's clear that for L even and L odd, exactly like in this picture here, I get different limits, right? And these are the way you think about it, how you get different limits. Okay, the next theorem is about the exponential decay of correlations. You, in fact, can Can show exponential decay of correlations of all observables, both in space and Euclidean time. So I have written it again here for these specific observables that sort of are the most natural ones for this model. So you take a spin at X, you take a spin at Y that you evolved in time, imaginary time. And I take the expectation. I subtract the expectation of this observable. Now it turns out that by symmetry, the O symmetry is preserved. So all these generators have zero expectation. So this is really a truncated correlation function. And this decays exponentially with some rates. In principle, you can estimate again in the same regime, V is minus one, U is small, N is large. U is small, n is large. So it decays exponentially both in space and time. For the properties of the ground state in principle, it's the spatial correlation you're interested in, but if you can prove uniform exponential decay with a fixed uniform constant in time, you can use it to actually get information about the spectral gap. So that's why this is important. Why is this important? Okay, and that is the third result. So, for these finite chains, it turns out that we can show that the ground state is non-degenerate. But remember, depending on whether you take these chains of length even to L, then the grounds are non-degendered. But depending on L, even or not, you get a very different one. And then, so the gap is just the distance to the next eigenvalue, delta L here. And in the same regime, large enough n and small enough u, we find that, so the ground state is non-degenerate and there is a positive lower bound for the gap independent of system size. So these are gap phases, and the gap is stable, at least within this family. At least within this family for sufficiently small U. Okay, so these are the main results for this class of models. What about the proofs? So, I mean, the proofs are not short. They use ideas that have been around for a while, and then there's some new things that come in. Things that come in. So maybe it's worthwhile I explain a little bit what the main sort of tool is, which is a random loop representation of the partition function. So I'm going to take the limit of GIP states. So that means I'm doing this here. And it turns out, as I said, that we will be able to prove that the ground state is non-degenerate. So I will have the rank one projection. Have the rank one projection, I can write it as the limit beta to infinity of the density matrix of the Gibbs state. If I go to zero temperature, I get the projection on the Grax state. And so let's do this random loop representation first for the case where I have only one term in Hamiltonian. So u is equal to zero. It's kind of simple to explain, and then it's easy to add the u term. So I only have this q. So, I only have this Q in principle. But the expectation, the ground state of any observable is, of course, given as the limit of expectation in the Gibbs state. And because I'm going to take beta to infinity, I can just as well take two beta and write this trace like this. So in a symmetric form, it's kind of a little bit easier to see what happens. But this is irrelevant. So I'm going to do an expansion for the Gibbs state. expansion for the Gibbs state. And so one way to, a simple way is most straightforward way to introduce it is to say that this exponential e to the negative beta h L, it's a matrix, I can write it as n to infinity limit of this expression. You've seen before, I'm sure. And then I remember that Newtonian is the sum of all those terms. And so if I add a And so, if I have to take beta to infinity, I can take beta to infinity over integers if I want, if the thing converges, so that this is an integer power here. That's not fundamental. And then I expand this sum, which has two L terms. And so, if I expand, I have two L to the power beta n terms. And I'm going to represent these terms in a picture, which is this random. A picture, which is this random loop configuration. And then I will have to sum over all the terms, and that will be done considered sort of as an average over a measure, which in the case u equals zero is a probability measure, but in general is not. And so I remind you that Q was this projection on the maximum entangled state written in this basis. And so in the basis, it has a very simple representation. Very simple representation. So, which you should keep in mind because we will have to compute, to compute, for instance, the normalization factor, I will have to compute the trace of the terms that appear in this expansion. What are the terms that appear in this expansion? For every factor of which there are beta and many, I pick either the identity or I pick one over n times q. 1 over n times q at a particular nearest neighbor pair. And this is what is denoted here. So these are all these slices are the different factors. And if I take the identity, then there is nothing in the slice, like here. And if I pick one of these projections, I put this little bridge here, which says that for the only non-zero matrix elements of this operator, Elements of this operator is when you on so that you stack these operators, you multiply, say, from bottom to top, you need to have at the bottom the two states the same, and also in the top the two states the same, otherwise the matrix element is zero. And this is what expressed is in this loop picture. That if I'm going to compute the trace, I'm going to compute this product of operators to a basis vector, so that alpha one, alpha two, et cetera. So that alpha one, alpha two, et cetera. And then here I have the same basis vector. And I take the matrix element and I sum over all possibilities. Many terms will vanish because every time I meet one of these projections, I need to have the same state on the nearest neighbor pair. And I don't care whether the state is the same or not. Independently, it can be chosen after this operator, but again, you have to. Operator, but again, they have to be the same. And if you think about it for a second, this means that you can count the number of matrix elements that are different from zero. You normalize them so that they have all the same value by looking at how many loops you see in this picture. Because along these lines, what the matrix elements are required to be for it to be non-zero, I have to have the same basis state. So I can sum over one basis state for each loop that I see. For each loop that I see. And the number of basis elements for each spin is n. And that's why you get this conclusion. Maybe this goes a little fast if you haven't seen it before, but I think you can believe me. And if you're interested, look at the details yourself. So the trace will be some positive quantity. And it will only depend on the number of loops that you see in this picture that you draw for each term. And it will be, and it'll. And it will be, and it'll be n to the number of loops. And so I call the pictures omega, and I call the number of loops L of omega. And then there is one over n because there was a coefficient one over n in this expansion. And then there is also one over n here. And so if I want the matrix elements to be zero or one, then there is another one over n, and that's what is accounted for here. The size of omega is the number of operators, q operators that appear. Of operators, q operators that appear, and so this is the matrix element. And if I normalize it, I get a probability measure of all this configuration, right? So this z is the normalization. This is my measure. Okay, you can take the limit n to infinity to get the exponential exact. And there's different ways to do this. You can descale things. You get a continuous measure, it comes to the big measure. You get a continuous measure, comes the Bag measure, where you put these interaction terms. These are kind of details that are not very important. And then this sum over this discrete probability measure just becomes an integral, but it looks otherwise exactly the same. And just be careful to get the normalization right, and there you go. Okay, so now we need to generalize. We need to, we have this. We have this term negative q, v is minus one, but we also have the little u, and the little u can be positive or negative. I'm going to write it as negative ut. So that means that now in my Hamiltonian where I have q, I can have either q or I can have u t. So I have even more terms. So it means that instead of only these kind of These kinds of connections between states. Remember that T is the swap operator. So, in fact, if one of these configurations, I've picked a T instead of a Q, instead of saying that the two have to be the same before and after, now it says that what was on the left has to go on the right, and what was on the right has to go on the left. And this is what this sort of symbol indicates. So, again, we will have states that are constant. Again, we will have states that are constant along lines, but the line jumps to the nearest neighbor if the swap operator acts. And other than that, everything is the same. There's a little u instead of a 1 over n, so there is 1 over n to the power of the number of these q operators, and there is also a u to the power of the number of the trans the swap operators, the t operators. And the only difference is that the u is not necessarily. Difference is that the u is not necessarily positive, and so the measure becomes a signed measure, and that will not bother us too much. I mean, but it does change the way you approach many arguments. Okay, so now you have these kind of pictures. I have one of these loop pictures here again, and so there are these double bridges, but there are also these swaps, which indicate that. Which indicate that to have a contribution, the state has to be constant along this line and it jumps to the nearest neighbor. The difference in these loop configuration may seem minor, but it's kind of different because now they are no longer non-intersecting, they can overlap, and also the parities of the direction is not fixed. Is not fixed, and that causes some complications. But let me tell you that, nevertheless, there is an intuitive picture behind the phenomena of dimerization that appears. And to see that, I would have to tell you what correlations look like. So if I now want to compute the expectation of, say, product of two of these spin operators, here is the reason why these are the simplest observations. These are the simplest observables you can take in this picture. You can look at other ones, but it becomes a little more complicated. And it is that their correlations are entirely directly derived from the picture of loop configurations that you see. And so, what this means here, so there's two kinds of events that you consider if you have a spin at X and a spin at Y, and you follow the X and the space that y, and you follow the lines, they may be on the same line or not. And if they are on the same line, then they may be connected like that. So you have X and Y. And so you may, the line that goes out from X may come back to Y, but from the bottom, or it may do it by going from the top to the top and reverting orientation. Orientation, and then it's also there's a whole class of configurations, of course, where the two are not connected, and so the correlation function. So, there is some normalization, the normalization is the one I told you about. But what you have to do, you have to take an integral, you have to over characteristic functions, you take the contributions only from those configurations where you have one of these possibilities and they are counted with opposite signs. Opposite signs. That gives you the basic correlation function, I claim, for these spin observables for this model. This is not difficult to see, but okay, it's something you have to do for yourself in a quiet room. And you see, you have this very simple formula for the correlations. So all contributions come from those loop configurations where x and y are on the same line. And depending on how the line comes in, what happens with its orientation, the contributions. comes in what happens with this orientation the contribution is positive or negative then you have to be a little careful because the measure itself is also signed so it's it's slightly tricky but it's an exact formula so then um well why is this useful this becomes like a big mess complicated loop configurations uh maybe we can't see anything but it turns out that for small u things are quite simple Especially as n becomes larger. And to see this, you have to distinguish these different loops that you see in different classes. So first of all, there will be, in principle, there are lines that go all the way around. So I'm computing the trace. And in fact, you should really think of these loops to live on a cylinder. And so there are actually lines that go all around the cylinder. Are actually lines that go all around the cellular. They use it using the periodic boundary conditions. They're called winding loops. It will turn out we can forget about them. As we take the limit beta to infinity, their contribution vanishes. You have to believe me. And then there are long and short loops. And the short loops are the ones that have this kind of shape. They just lock the states for two nearest neighbor spins. And then everything that involves at least three spins, like this red loop here, which visits these three spins there, we call that a long loop. And for the definition, it's better to include the winding loops in the long loops, but this is kind of a unnecessary detail. And so the reason that this is kind of interesting is that if there were only short loops of this type, dimerization is. Of this type, dimerization is obvious because you have to start from the end, you can't have a winding loop, so you have to make a short loop and make strict correlations in a maximally entangled state with your neighbor. And then you go to the next one and you see there's no other choice. But of course, this is, it's not strictly speaking the case that you only have short loops. But if we can show that the short loops dominate and that all the rest is correction. All the rest is correction, then we should be able to, and we do these estimates well enough, we should be able to prove the main results that I stated: that there's dimerization, that there's only short, because there's only short loops and low contributions from longer ones, the correlations will decay, and in fact, they will happen in space-time, and you will also be able to prove that it is a spectral gap. But that is sort of a very quick summary and. And so you may wonder: I mean, is it even possible that you would not have dimerization? And in fact, yes, I mean, it's not entirely trivial. Because when you have these longer loops, in fact, they exactly provide for you the mechanism to go from one phase with the dimers in one part of the nearest neighbor pairs to dimers in the other in the complementary set of pairs. So if you have a lot of. Set of pairs. So if you have a long line like this, and then you try to fill in the rest with small loops, then you will see that you shift from one phase to the next phase. Because you have to, because it's long loop, you have to forego short loops here and I mean here. And then the only possibility that remains, at least if u is equal to zero, it's very clear. And in that case, in fact, the proof is simple. You can do a parent's argument. The proof is simple. You can do a parallel argument. We did this a couple of years ago with Daniel Ilchi. These long loops act as contours separating the two symmetry broken faces. And then, so here we go, that you know, that's all I'm going to say about the proof, really. So then to treat non-zero U, we have to do cluster expansion. And And so we have to define clusters, and we, because of the signed measure, we can't be too subtle about it. And also, the structure of these loops is not that simple. So we did what makes it simple. We defined clusters that connect everything, all the loops that share one of these interaction terms. Interaction term. So either a crossing or one of these double bars that indicate the presence of an operator cube. So we have the short loops and then we have these long loops and those form clusters and we get a convergent cluster expansion, in fact, for the expectation, for the normalization factor and for the expectations in terms of. Of clusters defined in that way. And so, fortunately, Daniel Ulchi was in the collaboration. He's a real expert in cluster expansions. And because it's signed also, you have to be a little bit extra careful. And if you want to derive that result about space-time correlations, you also have to go a little bit beyond about the results that appear in the literature, but it's something that can be done. And you get stability of the gap. Stability of the gap phase and dimerization for this model as long as n is large enough and μ is small enough. Okay, so I only have a few minutes left and I don't know whether I should say something about the model that you find in the paper by Eisenman, New Copern Warzel, and in many other papers on. And Wartzel and many other papers on this topic, which, as it turns out, has instead of the Q operator, has the so-called the minus P0 operator. It's the projection on the singlet state of spins, which is sort of the natural physical state, the maximum entangled physical state that people expect will occur. So it happens to be basically the generator of the leap temporary leap algebra that people have used. Temporary leap algebra that people have used in the exact solution. So the situation for R then is very simple. You can do a change of basis and prove that this operator is equivalent to the Q. And since the change of basis is the same at every spin, of course, the swap operator doesn't change because it just Doesn't change because it just interchanges states. It has full unitary invariance, right? Now you can do this for odd n because the singlet state for odd dimensional spins, that is integer-valued spins, is a symmetric state. Symmetric between the two spins. For the even dimensions, for the have-integral spins, it's an anti-symmetric state. And obviously, no change of basis is going to help you here. You can't map. Help you here. You can't map by change of basis the symmetric state to an anti-semitic state. But it turns out that there is a change of basis that is actually periodic, not translational variant, so that you get something good. And that's what we use. So, what happens is that if you do this change of basis here, you sort of flip the spin, you go from alpha to minus alpha, which you can do for an even number. That you can do for an even number, an even-dimensional space, and you add a sign, then you actually, and you do this only on one side. So the P operator will become the Q operator if I do this either for the second spin or I do this for the first spin. And it's kind of remarkable. So this is a non-translation invariant unitary transformation that fortunately, I would say, maps a translation invariant Hamiltonian into another translation invariant Hamiltonian. Hamiltonian into another translation of valid Hamilton. Probably it would not have been the case, but happens to be the case. But it doesn't leave the swap operator alone, of course, because now I have done this transformation only on half the spins. And so the swap operator now becomes a, picks up one of these minus signs and these flips of these spin flips. So it becomes an operator t tilde, which is really t tilde. T tilde, which is really t times these unitary operators and another sign. And maybe that's very annoying because that doesn't look very nice. But as far as the random loop representation goes, you get a different measure, but it has all the same characteristics. It's really not a unitary equivalent model. The spectrum of the nearest neighbor Hamiltonian is different. The generacies of the eigenvalues is different. They're not unitary. They're not unitarily related, but you can convince yourself you can do everything the same. The only thing that changes is some complicated sign rule that occurs. But fortunately, we were not very subtle. And when we did our cluster expansion, we actually, what we showed is that you can ignore the signs. And so, since you could do it in the previous model, you can also do it in this model. And you can prove, in fact, dimension for large n and small u. For large n and small u, not for also this class of models. So, whether you are interested in the temporary leap model or in the ON model, and both have been studied in the literature in both cases, and they're not equivalent for even n, in both cases you will find diameterization and spectral gap. Okay, so this type of proof that Proof that relies on space-time expansion of the Gibbs factor and has its own kind of robustness. And we had to use something like this because what has been done for general classes of systems before use translation freeness with which you don't have for this class of models. Now, there is actually another part of the phase diagram that I mentioned, the red part, they actually contain. The red part that actually contains a frustration-free point, and so you can actually prove you can use the standard approaches with some modifications to show that that is also a stable phase. So let's go quickly. Let's go back to our phase diagram. Where is our phase diagram? Here it is. So, this point here generalizes the AKLT point. It is frustration-free. It is frustration-free and it is in the Aldane phase for odd n. And for either n, it fact also breaks translational variance. And so you could say there's diamondization there too. But this is actually something one of my students is currently studying detail. It's a very different kind of breaking of translation variance. It is not alternating strength of entanglement, for instance, at all. In fact, Um, in fact, the entanglement is constant, this translation value, and so there's some interesting things to say about it, but the work is not quite finished. And on the other hand, my time is finished, so I need to stop and maybe let us go to questions, see if there are any. All right, well, thank you, Bruno. So, are there questions for Bruno? I mean, I do have one, I think, very simple question. Is it clear that there are exactly two extremal ground states? I mean, or is that a, or do you just have that? That is a good question. So we construct two. They are pure states, and there's two of them, and they're different. And one can be quite confident, I think, that there are no other ones, but no, we have not. That there are no other ones, but no, we have not shown that. Haven't proved I see. Okay, this is also something that is a little bit easier to do in the frustration-free case. There is sort of quite sort of general arguments. I can show if you have a unique frustration-free ground state, you're not going to have any others. But yeah, well, that's I don't think it's something to To worry about a lot. It would be nice to have an approach to prove this. So basically, if you have multiple ground states, you can always worry about domain wall states. Well, worry or be interested in domain wall states, right? But in one dimension, there are models that have stable domain walls. But it's not common. I mean, a little bit of, if there are quantum fluctuations, this domain wall will not actually be. Be a ground state. And so generically, you expect there will not be separate stable ground states that show with the main wall in one dimension. But it does happen. There are examples. The XXZ model does have the main walls. So do you know that these two are the two pure translation invariant states? I mean. That I think you could prove. You could prove or even periodic by because they have to minimize the energy density, and I'm pretty sure there's yeah, there's I see. So, okay, I think you could probably prove. So, the only thing that could happen would be like a domain wall state, right? Right, that's what you have to exclude. Can I ask a question that maybe goes in a similar direction? You, in the very beginning, when you introduced the You, in the very beginning, when you introduced the models and you motivated dimerization, you had this very nice, I think, physical heuristic of saying you have the local interaction that favors entanglement between neighbors, but there's monogamy of entanglement. And I think that's, you know, that's a very nice sort of one-sentence summary of why this effect happens. But my question is, are there any proofs of dimerization that sort of involve monogamy of entanglement? Monogamy of entanglement in a relatively explicit way. I'm asking this also in the spirit of this meeting, right? There's all these quantum information literature about different measures of entanglement and quantifying monogamy. And wouldn't it be great if this could be used in a spin chain, maybe of this kind or of a very similar kind? So if you really wanted to use monogamy, If you really wanted to use monogamy, it would have to be a model that has ground states that are exact products of entangled states. And there are such models. Yeah, okay. Right? So, because if you don't have that, it's not about monogamy. It's about, well, maybe bounce on the entanglement. Yeah, yeah. I mean, there's approximate versions of, and you would have to then maybe study sub-chains. Right. Then maybe study sub-chains, right? Um, yeah, you can you can use subadditivity or entropy and things like that. I don't know that in terms of proving ground states, I'm not sure. Um, but you know, you can use that. Simona, you think? No, I mean, actually, the thing is, at one point in my life, we also thought, wait, you know. Thoughts, wait, you know, we also ask this question, and then at least in me, sort of, I couldn't find in the literature, but I mean, this may be just sort of ignorance, anything useful for that kind of questions. You mean concerning monogamy? Yes. I mean, it's anything which is a good concept to keep in mind, but just. A good concept to keep in mind, but in these kind of questions, but but if uh so Bruno said there are models where the really the picture is really true as drawn, is that right? Yes, and then it should yes, but you know then finding the ground states of models like that is easy, yes, because you can basically write a if you know the state and so it has a little bit of you know yeah no, that's true, yeah, okay. Yeah, no, that's true. Yeah, okay. So then you maybe you can say I'm using it, but it's it's no, but then you want to start there and perturb that. I mean, but I mean, yeah, well, there is there is stability of the artificial-free models. You can, but it doesn't, no, I don't know an operational way of using monogamy or some quantitative inequality between entanglement. Marius, you just suggested that you know something where more. Something where monogamy is kind of quantify it, but it doesn't have to be true, and we sort of in this very strict stupid sense. So there is a, you know. Well, I mean, all I can think of is you can use entropy inequalities to characterize the entanglement. Sorry, I didn't want to interrupt. But, you know, that's kind of already kind of a bit of a too complicated. Of already, kind of a bit of a too complicated question for this ground state. Unfortunately, I think we have another talk that's supposed to start in two minutes. So we should maybe wrap this up and continue the discussion another time. I hate to cut it off, but I also don't want to. In an hour, there is open discussion. In an hour, there's open discussion. Here we can continue this. So let me stop. So let me stop.