Our next speaker is Rachel Wang from the University of Sydney and she's going to talk about LCTI, a unified framework for data integration and evaluation using single-site control, multimodal data. Thank you. Thank you. So, before I begin, I would like to thank the organizers for organizing such a wonderful workshop at this beautiful occasion, and it's my great pleasure to be part of it. So, I'm going to talk about Of it. So, I'm going to talk about some recent work we did on linking regulation using single-cell temple multi-modal data. So, this is joint work with the one lab at Stanford. So, all the hard work here should be credit to Ying Shing, who's sitting in the audience, as well as Tong Yoo, Shi, Shen, Brian, Jing Xu from One Lab. And I just have the easier job of presenting this. Have the easier job of presenting this work. So, we've had some really nice talks already talking about gene regulation, you know, into gene methylation and gene regulatory networks. So, I think it's safe for me to jump straight into the topic. So, with simplifications, we can think of a gene regulatory network or GRNs as a directed graph. Basically, the nodes are the transcription factors, the TF, and the target genes. And the target genes, and we have an edge going from the TF to a gene, indicating the TF is regulating the gene expression either through activation or inhibition. So there's already a wealth of literature on how to infer this kind of network using bulk omics data, either RNA-seq, chip-seq, or more recently a TAC-seq. But of course, as we all know, bulk omics data averages signals from different cells and that can obscure signals that are. Signals that occur at individual cell level. And of course, we would expect these GRNs to be different across different developmental stages and conditions. So, for example, each cell type should have its own GRN regulating the cell type's specific gene expression levels. Across different developmental stages, we would expect the GRNS to be dynamically changing, and of course the GRNS should be different between disease and healthy conditions. Healthy conditions. So, this is where the single cell data comes in and helps us infer what we call our context-specific GRNs, where the word context can refer to different cell types, different developmental stages, lineages, or conditions. So, two of the most common forms of single-cell data people use to infer these GRNs are single-cell attack-seq and single-cell RNA-seq. Basically, the idea is you're trying to extract some kind of Idea is you're trying to extract some kind of TF gene interactions from this data. So here the peak regions in ATAC-seq tells us which one of these cis-regulatory elements, the open region, the openness of the CIE regions. And then we link the CIE regions to genes through genomic distance and link them to TFs through TF binding motif. And all this information is going to help us extract TF gene interacting pairs from the RXL. Pairs from the RXSC RNA-seq data. So, from this simplified overview, we can see that it's particularly helpful to have single-cell RNA-seq and single-cell attack-seq measurements from the same cells, in other words, multimodal data. And luckily, these days, we have a number of technologies that are capable of gaining such joint profiling. This is the kind of data that we're going to focus on in the study. So, that is, we assume we have the joint profiling of SCRNA-seq, SC-ATAC-seq from the same cells. A C-Attax seek from the same cells measured at different time points. So, this kind of temporal multimodal data is very helpful if we want to study the transcriptional activities behind a certain developmental process. And the context-specific DRNNs we are interested in here are the DRNNs driving the cell state transitions in the developmental procedure. So, as we all know, the kind of single-cell resolution that comes with this type of data doesn't come for free. It also presents a lot of statistical and computational challenges associated with this kind of data set. So, the first one is sparsity. Second one is, so we often have multiple layers of biological covariance at the sample level and at the cell level. So, in this kind of data set that we are considering here, the cell types, so the cell level heterogeneity. Heterogeneity, the cell types can actually appear and disappear at different time points. And we also have these unwanted technical variations or batch effects arising from diverse experimental conditions. And it's important that we can delineate the true biological signals from the unwanted technical variations or batch effects when we are pulling data from diverse conditions. And this is known as the data integration problem, which many of us. Data integration problem, which many of us work on. So there's an increasing number of methods in the literature being developed for inferring context-specific GRNS, and we heard some talks already in the morning. Most of these methods are less focused on the integration problem itself, where the noise and batch effects in the data set can obscure the identification of cell types or cell states and affect. Of cell types or cell states and affect the downstream inference of GIM. And most of these methods use computationally inferred timestamps, like pseudo-time. And when people are comparing dynamically evolving GRNAs between two different time points, quite often you try to identify the features, which are the genes or peaks, based on differential expression or differential accessibility analysis, which means that the features you capture have marginal correlations. They have marginal correlations with the conditions, but they're not necessarily driving the developmental process. And on another front, we have a very active line of research looking at this integration problem. So all of these methods lead to more accurate identification of cell types, but most of them do not focus on inferring context-specific GRMs. These observations motivated us to develop a unified framework for integrating multimodal, temporal profiling of SCIV-seq and SCRTAC-seq, and inferring context-specific GRMs. So we develop a method that projects the cells from all time points into a common embedding space while removing batch effects. Now, in this case, the batch effects can come from within. Batch effects can come from within the same time point or across different time points. Then we directly extract biological signals from the non-linear embedding space we obtain. And then we identify features, which are genes and peak regions, predictive cellular transitions, and how these cellular transitions are defined, they can be flexibly defined, and essentially it's up to the user, whatever process the user is interested in studying. interested in studying. This is an overview of our method, a CTI, which is based on autoencoders. So the input to the autoencoder is these paired matrices of RNA-seq and attack-seq over a time period. And so the method has two steps. The first step projects all the cells into an embedding space, and we have a separate encoder and separate decoder for the two modalities. Decoder for the two modalities, and we design some loss functions to align these two modalities in the space and as well as across the time points. The output from step one will be embedding of all time points and also the transition probability matrices between transition probability matrix for all cells coming from two consecutive time points. And then in step two, the user can define some subgroups of cells that are interesting in studying. Subgroups of cells that are interested in studying, fine-tune the neural network a little bit, and find the predictive features of the transition and build the corresponding GIA. So, in the next few slides, I'm just going to go a little bit more details into these steps. So, this is the meaning batch we construct for training. So, the meaning batch basically consists of cells, same number of cells sampled from every time point. And the first loss we have is the usual reconstruction loss we need to do. Have is the usual reconstruction model. This is an autoencoder, and we're basically trying to encourage the output from the decoder to produce signals close to the input of the encoders. And second loss is modality alignment loss, and this is applied to the lower-dimensional embedding space. And the idea is very simple: since we know the pairing between the RNAs and the taxi, we have pair data, we know which RNA and tax-seek embedding should be close to each other, we just try to encourage. Close to each other, we just try to encourage these two modalities to be pulled together through this loss. And the third loss is also applied to the embedded space, and this is iterative optimal transport loss. So this is estimated in an iterative fashion like this. So imagine that if you are given the gamma, so gamma is the estimated transition probabilities between two time points, which tells you how likely a cell from time t is going to be mapped to another cell from t. mapped to another cell from time t plus one. If we know the transition probability, we can compute an alignment loss using this product here, where C matrix is basically an L2 distance matrix. So this is the alignment loss which can be incorporated into the training. But of course the GABA matrix itself needs to be estimated. And we can do the estimation if we're given the current embedding, the load in the embedding space, and we can estimate the whole GABA. And can estimate the whole gamma using the usual optimal transport. So we simply just iterate between the two processes of estimating the gamma given the current embedding and applying the gamma to a mini-batch of the data to calculate the alignment loss. And hopefully by iterating and converging, we will achieve an optimal balance between date alignment and extracting cell type separation signals. So the total loss is a linear combination of the three losses and we Combination of the three losses, and we basically have two weight parameters here. It turns out the lambda OT here, the OT loss weight, has more effect on the training results. And at the end, I will present some empirical results on how to choose this lambda OT problem. So after training, the user can select subgroups of cells that are interested in studying. So they can select a group of cells G0 from time T. Cells G0 from time T on the earlier time and two cells from a later time G1 and G2, calculate the transition probabilities between this development, this bifurcation basically, and fine-tune the neural network with two prediction nodes and we create a KR divergence loss. And then for this particular transition, we can back propagate the gradients with one regularization to select the top genes and peaks. To select the top J's and peaks, and those ones will be the ones that have an important effect in predicting the transition probabilities we have just calculated. And after selecting the genes and peaks, we can link them to TF and genes in the usual way using genomic distance and TF motif binding information. And then that allows us to construct a specific RGRN for this kind of transition. So, and then I'll just go through some real data results. So, the first part of our real data result is something to do with benchmarking the integration performance. So, here we are using a synthetic data based on the real data, this one here, which is paired temporal profiling spanning five time points. And we artificially introduced. And we artificially introduce the noise in RNA-seq, heterotax-seq, and also battery effect. We have different settings in the paper for introducing this kind of noise effect. So the first column here is the embedding for this is the UMAP for RNA. Second column is the UMAP for attack seat, and the last column is the embedding space output by SC type. So we can see here the batch effect in RNA is removed by SC type and Type and so the cell type separation is preserved, and the days are well, the time points are well aligned and mixed, and the two batches are well mixed after applying C-type. And we have some evaluation metrics, comparing cell type signals, mixing of the time and the mixing of the two batches. So basically all these metrics here, the higher the better. And overall, so we're comparing with integration method designed for paired data. Method designed for paired data for fairness' sake. And we can see that across the three metrics, it has the best overall performance. And the next data is an in-house data, where we're looking at about 11K cells from mouse embryonic stem cells at three time points generated over six days. So, we did the full pipeline of integration data using SETI and annotating the cell types by looking at markers, clustering, and when we are in the total in this real data set, we identified 17 clusters, including subclusters of definitive anoderm and epiblast, and all these subclusters are supported by marker analysis and multi-enrichment analysis. So, as a case study, we looked at these. We looked at these two transitions. So, from anterior primitive streak on earlier days to endoderm on later days, or the cells can remain as anterior primitive streak. Alternatively, they can grow into mesoderm in later days or remain as anterior primitive streak. So, here we can extract three lineages: the primitive streak lineage, a definite endoderm lineage, and the mesoderm lineage. And what I'm showing. And what I'm showing here is the IMSE, the prediction done using cross-validation, using the top features we have selected using SCTA versus differential expression analysis. And we can see that we improve the prediction performance of so this here we're trying to predict the transition probabilities of these three lineages and you can see that the SC tie gives you better prediction than the marginal method of temper. Um then the marginal result of the T and uh and can construct uh the corresponding GRNNs based on those selected top features from genes and peaks. And this is just a slide showing that we have identified the TFs supported by the literature. I'm not going to pretend I understand all the biology, but we do in the mesoderm lineage in particular, we identify some key We identify some key transcription factors related to this lineage, and those have insignificant voltage, a lot of voltage if you try to use the DV analysis. And finally, just some robustness study showing the robustness in our result with respect to that lambda OT parameter I was talking about earlier and the number of nodes in the hidden layer in our neural network and the frequency of update when we are doing the iterative. When we are doing the iterative OT estimation, how frequently we update the gamma matrix. So, as I said, the lambda OT does have an effect. The first row shows the metric in terms of the pairing. Remember, we have paired attack-seq and RNA-seq data, so the lower this number, the better pairing you have between the two, because we know the ground truth. So, you can't choose the lambda OT to be too high. If it's too high, then you kind of disrupt the pairing because it's too competitively. The pairing because it's two competitive losses competing against each other. But as long as it's reasonably low, the performance is quite stable. So we can actually use this metric as a way to choose an upper bound on lambda OT. And for the other two parameters, it's pretty stable. And the second row shows the mixing of the time points. And so we can see that most of the time, so if you choose a reasonable lambda OT and the The other two parameters are pretty robust, have a pretty robust effect over mixing type. Okay, just to sum up, so we proposed a method SEType, which is a unified framework for integrating, visualizing, and inferring context-specific drives for temporal multimodal data. Our integration benchmarking results suggest that it achieves. Marking results suggest that it achieves a desirable balance between time alignment, modality alignment, and cell type separation. And we can allow the users to define which subgroups of cells whose transitions they're interested in studying and we can construct these lineage-specific GRFs using regulatory elements with a high prediction power of cell phones. So, future work, so because of our design, it's actually pretty easy, it should be pretty easy to incorporate. Be pretty easy to incorporate unpaired attack-seek and RNA-seq, provided that they are measured at sort of sampled at the same time points. If they are sampled at different time points, then it poses more difficulty for the integration step. So we can combine zero time with real time to achieve a finer temporal resolution. Although the bottleneck here is a computation of OT. If you have so many pairs of OT matrices to estimate between every pair of time points, Between every pair of time points, the computation bottleneck that we're going to resolve. And we can also think about incorporating information from an increasing number of perturbation essays, either as a way to validate GI lines we find or as a prior knowledge to incorporate into the structure of the neural network. So, our manuscript is available by our archive, and we have the code also to draw available on GitHub. So, that concludes my talk, and I'll Concludes my talk and I would very happy to take it. Alright, we have time for possible questions. Can you give us some more insight as to what information is being leveraged across the time points as opposed to analyzing each time points? Oh yeah, that's a great question. So yeah, because we are doing this joint embedding across time points, because of this iterative OT, that gives us a transition. That gives us a transition probability matrix, which will lead to, and then based on whatever subgroup of cells you select, you can calculate these transition probabilities. And these transition probabilities is telling you how likely a group of cells is going to become one group in a later time or another group at a later time. And then this is the thing that we are trying to predict by fine-tuning the embedding layer. So, yeah, then this is the joint modeling part that the other. What are we talking about? That class is to be. But we are not putting any constraints on, you know, time points that are next to each other. There is an implicit constraint, which is when we are estimating the iterative OT loss. So these matrices, the gamma matrix, is always between two consecutive time points. Thanks for the talk, Ratio. It's pretty wonderful. Um the my question is about like your My question is about like you know for this star say like the um maps and regions as well there are a lot of simple omics available as well and particularly for like final time points within the time course. So you know if there is like a sudden question of like can you interpolate when you only have one modality map? Could you interpolate? That could you stabilize perhaps? And how might we go about doing that? Yeah, that's a great question. That's one of the things we originally planned to do, but then this paper just, the content just overfilled, and so we decided to do it in the next paper. Yeah, that's definitely possible. And I mean, all you need is some kind of overall embedding. So if they're not, if the single, this extra modality is not paired. This extra modality is not paired with any of them. So you first need to embed, you need to construct a common embedding that allows you to incorporate that one. But then, because you have the estimated gamma between different time points, supposedly you could apply that gamma just to the extra modality as well. So that will give you sort of the prediction forward and backward, at least in the embedding space. And then, because of the auto-encoder structure, we have the input and output to reconnect. Input and output to reconstruct the signal. So that should allow you to do some kind of imputation across different types. Really cool talk. I have a question about this sampling time versus pseudo-time. So you're, I guess what I understand is you use the sampling time for this probability transition matrix. I'm wondering if you looked at pseudo-time, what's the relationship between the two? And if something looks different, there's like a conflict between the two. There's like a conflict between the two, which one do you believe for? Yeah, that's a really good question. So I think actually it's ultimately down to the resolution of optimal transport this method can capture. Because supposedly this method is only good if you don't have too big a transition. So if the sample time points are too widely spaced apart and then you have too big a change in your gene expression level, then this obviously Expression level, then this optimal transport point doesn't work too well. So we need to check the stability. So we have not incorporated the pseudo-time point yet. That's what we plan to do next. But we want to check the stability of sample time points. But the sample time points typically are also wider than what you need to do. I could imagine also like very fine sampling points could also be problematic 'cause 'cause the cells aren't necessarily synchronized, right? Aren't necessarily synchronized, but that's right, that's right. There's also like something tricky that's very, but at the moment, those typically only have, say, five, six time points, sample time points, due to the cost and other reasons. So I think somehow combining the two different things. Okay, so my questions is answered in the middle of the morning. 