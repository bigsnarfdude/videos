Yeah, so while Zhang Wan spoke about the hard problems in higher dimensions, I will talk about maybe not so hard problems in low dimensions, but hopefully still interesting ones. So the question we want to address is basically, you know, dynamics in nature, especially in data systems, is often local, but not exactly local. So we have light cones that are fuzzied out. I'll talk about this more in a second. More in a second. What does this mean for the structure theory of QCAs? QCAs have this beautiful simple classification by an index in one dimension. And sort of, I guess it has implicitly been used or explicitly been used, you know, also the literature that this classification would be robust, that it would also apply to dynamics with fuzzy light cones, satisfying the problems and bounds. And that was the motivation, one motivation for this work. So this is joint work with Dan Renard at MIT, who will, I think, join us later for the discussion. I think join us later for the discussion, and Maisie and Friek, who I think I saw on the list of participants. And so they will also hopefully be here for the discussion session. Great, yeah, so let's get started. Let me try. Yeah, so as I was saying, QCA is quantum cellular automata, they are beautiful models of strictly local dynamics. So, roughly speaking, if we have a local operator, so these are automorphisms of outer observables. And if we have a local operator, then it will Local operator, then it will get mapped by this dynamics to a strictly, still strictly local operator. And that's, of course, a nice structure. It arises, for example, in quantum circuits. They would be a prime example of finite F quantum circuit, but also things like shifts. And in some sense, those are all examples, but we'll talk about that more in a moment. Now, in reality, of course, there are many situations, as I was saying before, where we have dynamics that does not obtain such strict lockout. Does not obtain such strict locality. So, for example, if you evolve an operator by a local Hamiltonian, then typically we'll have something that you might call an approximate light cone or a fuzzy light cone. Or we could say this dynamic satisfies AD province bound. And there's many ways of formalizing this. I mean, a typical way would be to look at the local operator here and time evolve it and then study the size of its commutator with another local operator sitting somewhere else. And then we would say, Operator sitting somewhere else. And then we would say this operator is small until sort of you know enough time has passed for the you know this fuzzy light cone to meet the support of the other operator. One can also dualize this notion a bit and one could say try to phrase it as follows. One could say well suppose I have a local operator B again sitting here. Again, this is this time of operator B of T in the Heisenberg picture. Then we can imagine there's existed a velocity called the Liebrox. There's existed a velocity called the Lee-Brodens velocity, such that essentially the support of this operator grows linearly with time, so proportional with a speed that's exactly this velocity, up to exponential tails. And what that means now is that I can well approximate this evolved operator by a local operator if I allow for a support that's at least V times T larger than the original support on both sides. So I sort of blow up my support a bit, and then I get good approximations, some better and better approximations. I get good approximations, some better and better approximations. So I could maybe try to visualize it like this: right, I could say I start with some observable B, I time evolve it. B of T is the time-evolved observable. That's going to be, you know, in principle supported everywhere on the whole lattice generically. But we can find it in an operator C that's localized on a somewhat larger region. So we extend the support by R on the left, by R on the right. And then one, for example, for short range or finite range. For short range or finite range interactions, one has decently problems and type tailbones. So this will be an exponentially good approximation if R, sort of the support that we allow ourselves, or the size by which we allow ourselves the support to grow, is larger or of the order of magnitude, some constant multiple of the Lee Ramsen velocity times the time that has passed. And so that's very nice. And that's sort of what happened. That's very nice, and that's sort of what happens in many systems. I mean, here, I guess I gave you one specific rendering, but there's many generalizations. But what I want to ask is, independently of what exactly these tails look like, can the theory of QCAs be generalized to the setting? So that's really the starting point, the motivation for this talk. And I'll discuss all these things in more formality in a moment. It's more like a teaser. Now, why would one like to do this? What kind of Would one like to do this? What kind of questions would one like to ask? For example, we could ask the question: suppose you have any local dynamics defined in some pseudo sense, perhaps those are always generated by local amatonins. So we know that for QCAs, again, it is the case that, for example, a shift or a lattice translation cannot be generated by a circuit, right? These are really two different things. And this index that we'll recap in a moment actually captures exactly this obstruction. Captures exactly this obstruction, but maybe we have more freedom if you know for local Hamiltonian evolution. That's something more general, you say time-dependent local Hamiltonian, so that's a generalization of circuits. So maybe we can do it then, right? Or another way of saying this would be, well, you know, local Hamiltonian satisfy Lee-Robinson bounds. What if you have a dynamics that satisfies some kind of Lieb-Robinson bound? Can we always generate it by local Hamiltonian? And if not, what is the obstruction? Are there new obstructions? Are there new obstructions? Does somehow this whole classification break down? Does it become like some fuzzy mess instead of this discrete moduli space? So that's the kind of question one might ask. Yeah, I mentioned lattice translation is one example. Can one find the Hamiltonian generator for them to arbitrary accuracy, kind of like a lattice momentum density, if you want? Another question might be: so in some situations, which I'll also mention later, one has a situation where there's some bulk local Hamiltonian, then under some conditions. Bulk local Hamiltonian, then under some conditions on this bulk dynamics, for example, if it's a many-body localized, there's a corresponding dynamics on the boundary, kind of a fuzzy dynamics. And one could ask, you know, is that one also generated by Hamiltonian or can something interesting happen? Of course, you would expect something interesting happens. We kind of know it already, right? There can be like some chiral motion going on. That should not somehow be something trivial. But all these questions, somehow to tackle them, really, one needs one, we think one needs a theory of, you know, approach. We think one needs a theory of you know approximately local dynamics and the structure and classification, so that's sort of one side of motivation. And then, of course, from sort of a more structural perspective, it just seems interesting to classify these things. I mean, it seems an interesting to classify local dynamics satisfying the problems and bounds, try to understand a bit what the impact of the tails is on and so on. And in some sense, our results are perhaps not surprising, although it was surprisingly non-obvious to us how to prove it. Namely, that in Namely, that basically the structure in the index theory of QCA sobrieties to this approximately local setting. And what I want to do in the remainder of the talk is basically explain this. So I'll recap the structure theory of QCAs, present our results, and then talk a little bit about how the proof goes. And in this way, we also obtain a converse to Lebronson bounds, basically saying that again, there's an index which is quantized, and this index is the only obstruction to lifting a dynamics or to generating a dynamics by. Generating a dynamics by a local Hamiltonian, time-dependent quasi-local Hamiltonian, to be precise. And in particular, if one does this, I mean, I'll always talk about infinite chains, but a lot of the techniques that I'll talk about will also go through on finite chains. And on a finite chain, this index will always be zero. So there, indeed, one can always lift such a dynamics. One can always, so on a finite chain, in a sense, this converse really holds without conditions. So that's sort of a short summary of the things to come. Summary of the things to come. All right. Yeah, so that's sort of maybe the intro. So maybe let's talk a little bit about QCAs. And before defining QCAs, maybe talk a bit about the mathematical setup, which has already been, I think Kuno talked about quasi-local algebra and related things. I'll give a very brief, not very precise recap. We'll define QCAs and then talk about what is known about QCAs and give maybe a bit of a new And give maybe a bit of a new spin on some of these well-known notions in their structure theory. So, the setup for us will be infinite spin chains in one dimension. So, everything I'm going to talk about will be in one dimension. For simplicity, I'll take all the local dimensions to be the same. Some CD sites will be labeled by n, right, because that's like the integer lattice, and arbitrary regions all denote by x. Backs. As we already saw when we discussed early Robinson bound, I mean, it's useful to work to think about operators evolving rather than states in such a situation. So we'll work in the Heisberg picture. To each site, N, we associate the D by D matrix algebra as the algebra of observables. If we have a finite collection of sites, we can just tensor those together in an unambiguous way, get the ultra of observables localized on that region X, on that finite region X. Let's say. Region X, let's say net of algebras, we can look at their union. We could call this a local algebra of strictly local observables that carries a natural norm, but it's not complete for that norm. So we can complete it and the resulting object is called a classy local algebra. So CC star algebra. And I guess this audience is extremely familiar, more familiar than I am, probably with lots of the subtleties that one could talk about. But in case some In case someone is not, they could simply think of this as an infinite tense product of lots of these local observables. Okay, so once this is set up, one can also look at quasi-local algebras of, say, something like a half chain, say all the observables that are localized to the right of some site N. So I'll use notation, so suggest this notation like this. So a subscript something will always be sort of the sub-algebra of things that are localized in some finite or infinite region X. All right. All right. So now with the setup, we can ask how should we model dynamics? And we are going to be interested in invertible dynamics. So the natural thing is to look at automorphisms of this quasi-local algebra. So I'll always denote those by alpha. One may ask, you know, are those unitarily implemented? And for that, one would have to deal with the Hilbert space. So I think it was mentioned that there's always a traitial state here. One can look at GNS representation and by some. DNS representation and some uniqueness properties lift things to unitaries, but that will not be important for us. I wanted to briefly say that in, I mean, in some of the things to come, we will mention phenomena algebras, and that will be a useful proof tool for us, but it's not necessary to state the results. Very good. So that's sort of the mathematical setup. So we have the quasi-local algebra, sort of the key dragonist, and we'll study its automorphisms as to model dynamics. So with that in mind, we can define a QCA. A QCA, and the definition I'm going to give here is not going to be the most general one, but it's going to be sort of suitable for our generalization to tails. And maybe if you have questions, feel free to interrupt me or we can discuss later. So again, we have the quasi-local algebra here. We want to define when an automorphism of that quasi-local algebra is called the quantum cellular automaton, QCA. And we say it's a QCA or a locality-preserving unitary LPU. some unitary LPU, that's what the other community half of the community calls them LPUs, with some radius R. If whenever we have an algebra supported on a operator supported on a single site and we evolve it by this automorphism, we obtain an element that's supported in our neighborhood of that site. So in the interval from n minus r to n plus r. And if that holds right for a single site, that also is going to hold for an arbitrary region, just by composing things. Things. So for any subset X, it will then be true that an observer localized in this region X or supported in region X will after evolution by alpha be supported in our neighborhood of X. And that's visualized in this picture here. Okay. So just, I guess, mostly to practice notation because this will be used as a way of later generalizing to approximate tastes, because we want to think. Approximate takes, okay, because we want to think about approximate inclusions of algebras at the moment. So, in other words, yeah, the support of any local operator grows by most R as we avoid. So, here are two examples, which in some sense are all examples. So, if you have a quantum circuit, right, of some, say, finite depth, by some, you know, sort of bounded locality here, that will clearly satisfy these definitions, right? There's sort of a PLI cone in the circuit. There's sort of a peer light cone in the circuit. Like if I have an operator, say here, I mean, that can sort of spread out like so. And I guess like so. So that has some bounded radius given by the size of these individual gates. And also a shift or a lattice translation on, again, the infinite lattice, right? Clearly, it preserves locality. Say this guy has radius R, for example. And so what the beautiful theorem by GNVW course, Nesma-Fox, and NVW course, Nesmel, Fox, and Werner proved this that basically that's everything. So any QCA is a composition of a circuit and a shift or a product of shifts. I guess usually people define a shift to be a product of many such translations of like systems with different dimensions and so on. So that's their classification result. In particular, what they also showed is that this shift cannot be implemented. This shift cannot be implemented by a circuit. Okay, so these are really different things. And there's different shifts that cannot be, you know, one cannot be implemented by the other. If you have a shift of a qubit or a Qtrit, those are somehow incompatible. And to really classify things, what they showed is that QCA is modular circuits. So circuits, right, are subset. If you have a QCA, you can compose them with a circuit and you can so you can quotient this out. And that's this group that Jean-Wan spoke about yesterday. That Jiang Wen spoke about yesterday, and that's classified by an index. And this index is actually quantized. And how quantized it is depends on the dimensions of these local Hilbert spaces. In my case, I had only one local Hilbert space dimension D, and so this index would be quantized in integer multiple linear combinations of log of the primes that enter this D. We'll come to that in a moment. So, this is their result. So, let's talk about this index. So let's talk about this index a little bit. So, actually, in their paper, they gave several definitions of this index. There was sort of an axiomatic approach, sort of, you know, by demanding what would one like to demand from such an index. There was an algebraic definition in terms of what's called support algebra, so where one kind of decomposes sort of sort of say neighboring cells into a part that flows to the right and a part that flows to the left in some sense. There are also analytic definition. Sense there were also analytic definitions in terms of overlaps of certain algebras, but intuitively, um, this index is basically measuring how much quantum information flows to the right minus how much quantum information flows to the left. So I'm just gonna sort of do three examples and then we'll actually turn this, you know, intuitive non-definition into a rigorous definition. Suppose you have again a lattice shift, but each local Hilbert space is C D1. So that's log D1 qubit. So that's log d1 qubits. That's a log log2, log d1 qubits. And so we should define the index of such a thing as log d1. Okay, it's flowing to the right, so it has a plus sign. Likewise, if you have a d2-dimensional lattice, but now we shift to the left, we might assign to this an index of minus log d2. And now we could also take the tensor product of those two QCAs. So that looks like so. So we're grouping together, right? So this is now the local bit space. Together, right, so this is now the local bit space is d1 times d2 dimensional. Well, here that's now a sort of a same lattice, but so the local bit space dimensions are second, so it's d1 times d2. So, and we could look at the tensor product QCA. So, some stuff is flowing to the right, some stuff is flowing to the left. And here the index should just be the difference, right? It should be this net flow of quantum information. And that's indeed what you get, okay? So, this index is, you know, it's not, we sort of get a hit. We sort of get a hint already that maybe there's something quantized going on because there's a logarithm of these dimensions entering. And the other thing that I guess we see from this example is we would hope or expect or maybe would like to demand this in an axiomatic approach that the index should be multiple additive under tensor products. And that in these examples, at least, I showed you was true. Okay. It turns out that this intuition here, this amount of sort of net amount of quantum information flowing. Of sort of net amount of quantum information flowing, definition of the index can be made precise. And I want to talk about this briefly because that's actually going to make sense beyond QCAs. And usually, yeah, sort of the quantum information way of sort of, you know, sort of studying how information flows and, you know, in dynamics as we model a dynamic by, say, an automorphism or more generally by a quantum channel. I guess here it's a completely positive. Here it's a completely positive Yonetal map and the Heisenberg picture. Suppose we look at the corresponding transformation of states, that's a completely positive trace-preserving map. Then, what we can do is we can take a maximum entangled state and into half of this maximum tangled state, so a maximum entangled state of two copies of the system. On one side, we apply the dynamics. And then this gives us a quantum state where we can compare both the input with the output. So that's what I want to do here to define this net flow of quantum information. And so that's a picture. And so that's the picture I have here. So, the thing in the middle is again the cartoon of my QCA. So, this is the input system, that's the output system. What I want to do is I want to split this in half. I have the left half and the right half, and I want to measure the quantum moisture flow across this cut. So what I'll do is I'll take again a max entangled state of two spin chains. We could think of it as the bottom and the top spin chain, the input and the output spin chain. The input and the output spit chain. And then on one of these spin chains, we apply the dynamics. Okay, and maybe now we should think of it as the top and the bottom spin chain. And so, what you can then do is the corresponding thing is a quantum state of two copies of the spin chain, and each spin chain is split into two, right? So, it's a four-pi-tide quantum state. It's a quantum state with left, right, left prime, left, right prime. In general, such a quantum state was called a choice state, at least in my community. And here we have partitioned this choice state now into four systems. This choice data now into four systems. And so, what we can do now is we can look at the mutual information between the left input and the right output. And we can look at the mutual information between the right input and the left output. And well, we normalize by one half because the max entangle state has mutual information twice the local space dimension. So we normalize that away. And that seems like a good candidate for computing this index. And this mutual information, just to remind you, in finite dimensional context. In finite dimensional quantum systems, it's simply the entropy of the joints. So, if I have two subsystems A and B, the mutual formation I of A between A and B is the entropy of A plus the entropy of B minus the entropy of AB, the joint system. That, I guess, makes sense if these entropies are finite. There's an alternative way of defining this using relative entropy. That's what I wrote down here. So, mutual information one can also define as a relative entropy between the joint state and the product of its. The joint state and the product of its reduced states. That's something that makes sense more generally, but also makes sense in such an infinite system. Of course, for a QCA, because everything is local, and if you're interested in this cut, really, we only have to, you know, and it has some finite radius, we really don't have to worry about the, you know, the left infinite and the right infinite and parts of this chain. We can basically compute this quantity purely locally and we can really use this entropic definition of mutual information. But if we now, you know, sort of already think ahead of your slides and maybe. Of already think ahead of these slides, and maybe we'll want to talk about approximately local dynamics, then actually this definition would still make sense, right? I mean, the mutual information makes sense, and you know, maybe we can guarantee that these things are finite, and then this would give us a candidate for defining an index even for a quasi-local dynamics, an approximately local dynamics. Okay, here are some properties of the index. I already mentioned this before. So, it's quantized. So, the index is an integer linear combination of the log of the prime dimensions that appear. Log of the prime dimensions that appear in this local dimension d. One can write down similar statements if the dimensions are allowed to vary. In that case, actually, one can take any local dimension. It's additive under tensor products, also under composition. I think Jean-Manha mentioned that as well. Maybe he even explained how the two things are related. And there's a kind of robustness, namely, if one has two QCAs that are nearby in a certain sense. I don't want to be super precise here, but basically, if they're locally similar. So suppose you're They're locally similar. So, suppose you have two QCAs and their nearest neighbor, so radius one, then basically their index will only depend on local data, say around, you know, say sort of the morphism restricted to two or three neighbors. And if alpha and beta agree on these small, you know, on some like, you know, constant size neighborhood to some at least constant precision, then they actually must have the same index and they must be, you know, one can relate things. So that's something we studied as a We studied as a technical tool for what is to come. So, this index is also robust. Okay. Yeah, so that's all I want to say about QCAs as a bit of a recap. Maybe good time for questions. All right. So now then let's move on to ALPUs. So, yeah, the big question is: why is my talk titled Approximate QCAs? And now I'm going to talk about approximate local persummy units. About approximate locales for some unitaries. I'm not sure. So I decided to stick with the convention that we picked in the paper rather than maybe what would be more uniform. But I thought I would get more people hooked by talking about approximate QCAs. In any case, approximate locality-preserving unitaries, which we want to define now, are basically what one gets by taking the definition of a QCA and replacing this demand of strict locality, finding a finite radius, to some more fuzzy tailbounds. So replacing strict locality by Lee-Bromanson tailbounds. Strict locality by Lee Bromenson type bounds. And I want to be general, so I'll just have some notion of a tail, and that will be part of the definition. Just like before, we had a radius that was part of the definition of the QCA. So what do I mean by Lee Robinson type bound? Well, the same picture as we had initially. So suppose I have some local operator B and I apply this automorphism alpha. Then what I wish is that, you know, for any sort of radius by which I Sort of radius by which I allow myself to enlarge the support, there will be an operator supported on that enlarged radius, the C. I'm not sure where I'm drawing a box around the box, there will be a new operator C, that is close to alpha of B, to the time-involved operator, and how close, well, that should depend on R. So the larger R, the closer it should be. So there should be a function f of R, which we call the tails of our approximate locality-preserving unitary, that tells us how well this approximation works. This approximation works. So that's exactly the definition. So we say an automorphism alpha is an approximately locality-preserving unitary LPU with f of r tails for some function f. If for all x, which will be the support of b, and for all r, which is the choice of this radius r over here, the following is true, and that's a bit of a mouthful, but it's actually exactly what we just said. Whenever we take an operator b localized in this region x, there will exist an operator c in the r. Operator C in the R neighborhood of X, so just like here, such that the time above operator alpha of B is close to C. Well, how close F of R close to F of R at these tails. And that should hold for all R. And F should be a function that decays as R goes to infinity. But I don't impose any specific convergence speed at this point. And then to get a nicely normalized definition, we should normalize this by the norm of B so that everything makes sense and scales in a good way. Good way. So that's the definition we play with. Okay. And so since this is a bit of an annoying structure, but also really not so complicated, we have some notation for this. And the idea is the following. What are we really doing here? We are looking at the image algebra of this local algebra AX under the automorphism. And in some sense, we are saying that this image algebra is almost included in this algebra. That's almost included in this algebra, in this R of neighborhood of X algebra. So it's useful to have a notation for an approximate inclusion or a near inclusion of algebras. And that notation we will now introduce. So we'll write inclusion with a little subscript to denote exactly this. So if whenever we have two algebras B and C, we are writing B as epsilon nearly included in C. If for any amount in B, the existence to C, that's epsilon nearby, and again we normalize by the norm of B to have a good definition. So that's sort of a, I think, a standard notation. So that's sort of a, I think, a standard notation going back to the 70s: operate algebra community. And it's a nice way of encapsulating this, right? Because in some sense, an exact QCA is one where this holds with strict inclusion for some specific choice of R, which we call the radius. And here we have we sort of have approximate inclusions for any R, which get better and better. Right. So what would be examples? I mean, QCAs would be examples. I mean, QCAs would be examples, but also now local Hamiltonian dynamics, where they're the automorphisms corresponding to evolving by some local Hamiltonian for some fixed time t. That would now also be an example thanks to Liebrobinson balance. If our local aquasy local Hamiltonian has sufficiently decaying tails for us to have Lee-Robinson bounce, then that would be the case. And this F-L-depend, right? I mean, could be exponential tails, that would be very nice, but for short-range interactions, it could also be power. Short range interactions could also be power law tails or something else. Okay, so with this setup, we could now ask, you know, for a classification of these LPUs. Now, I already gave you a bit of motivation before, but maybe we can recap also to connect with the results. So why do we care about this definition or why do we care about classifying these LPUs? Okay. I mean, now, you know, sort of after the 10 slides of motivation, we could say, well, a theory of local dynamics should really, you know. Theory of local dynamics should really, you know, allow ourselves to talk about dynamics generated by local Hamiltonians, but that would be nice. We already mentioned this question: can we establish a converse to the Bronson bounds? Now we saw in a very precise way that a local Hamiltonian evolution that satisfies LeBrons and bounds gives rise to a ALPU with certain tails or certain problems and bounds. How about the converse? In particular, can we generate shifts now? Right now, we have sort of more space. We know circuits are not good enough to generate shifts. We know circuits are special. Generic shifts. We know circuits are special time-dependent Hamiltonian evolutions. How about general time-dependent evolutions? And then there's also other examples. For example, there's this situation I mentioned before. In some situations, you can have, say, interesting two-dimensional systems, 2D flow systems in a many body localized phase where somehow there's nothing moving in the bulk, but on the boundary, you get some rotation, for example, some motion. And to classify such things, everything here is fuzzy, right? In principle, I mean, under. Is fuzzy, right? In principle, I mean, unless one studies toy models, right, these are Hamiltonian evolutions, everything has tails, like things leak into the bulk. What does that strict light counts? And it seems like understanding something like LPUs should be a good intermediate step to making these classification completely mathematically rigorous. So that was also motivational. So there's still some gaps because it's not so clear actually how to define this ALP on the boundary. But that's maybe something we can also talk about later in the discussion. Later in the discussion. So that was another motivation, right? Sort of having sort of a more rigorous handle on this. So, why is it not obvious now that maybe we care, why is it not obvious how to classify these LPUs? I mean, an operational answer could be, previous work did not do it. But in fact, the techniques that were used, they are somewhat sensitive to perturbation. So they're rather algebraic. So it's about exact commutativity of certain sub-algebras called support algebras. Sub algebras called support algebras. It's not so clear how what would happen. So, you know, generically, like if you have, you know, say, you know, if you perturb, say you have an operator space, it generates some algebra. If you perturb the operator space slightly, it's going to generate the whole algebra. So these are the kind of things that you run into because things are, in those proof techniques, people look at dimensions of algebra and so on, which is a very rigid motion. It's a bit like looking at ranks instead of looking at entropy. And in some sense, now we have more of this entropy mindset. We hope that makes us. More of this entropy mindset, we hope that maybe this gives us something new. Um, yeah, well, we wish to answer questions about local Hamiltonians, yeah, still not circuits, just as they weren't on the previous bullet point. Um, and also the previous definition of the index did not apply to LPUs. But of course, local Hamilton damage can always be approximated by circuits, by trautorization, for example, or other simulation techniques. Uh, and it's actually an interesting question that we could now ask: is it always possible to approximate since Always possible to approximate since any local since local Hamiltonian dynamics can be approximated by finite F circuits, can we also systematically approximate ALPUs by QCAs? That would be one way of getting an index theory set up, right? We just find better and better QCA approximation of ALPUs. So that's something that indeed worked, turns out to work. The other thing I mentioned is the previous versions of the index did not apply to LPUs, but the one I gave you on two slides ago did. Two slides ago did make sense, right? This mutual formation definite mutual information definition makes sense. The question rather is: does this index still remain quantized, right? Because now we have a limit of things. I mean, it's just a mutual formation. Mutual formations are never quantized in reality. So why here? Or are they quantized here? So that's kind of basically some questions you might ask or some directions you might be interested in. And now I can maybe. And now I can maybe report our results in a bit more precision. So, what we found is basically that exactly what one would be hoping for is true. So, LPU's modular local Hamiltonian dynamics behaves exactly like QCA's modular circuits. And one has to allow time-dependent Hamiltonians here. And we'll talk about what the Hamiltonians look like. They're a bit of a cheat, but I hope you'll allow. Time-dependent makes sense because even Independent makes sense because even because, say, even if you want to approximate, well, yeah, even for circuits, somehow, if you want to realize a circuit by Hamiltonian, kind of you need time dependence. Otherwise, you don't get these exact tails. I mean, these like strict, the strict locality circuit. So, more precisely, we find that LPUs are also classified by an index that just generalizes the index of QCAs. That's again quantized, additive, and robust. Um, uh, two ALPUs have the same index if and only if they differ by quasi-local Hamiltonian dynamics, always time-dependent, um, or if and only if they can be blended into each other. So, blending means I have an ALPU on the whole spin chain, and on the very left it looks like alpha, on the right, it looks like beta. So, for QCAs, this is easy to define. You can literally cut the chain half. You can say, I want to just interpolate from the, I mean, you just can say, I want it to be exactly alpha on the left, exactly beta on the right. For LTU, it's more subtle, right? The right for LPU, it's more subtle, right? Because you have this infinite tail, so you do have to truncate. So, the best thing you can say is somehow the more you move, you know, if you look on the very right, you know, say at distance r from the cut, then you look, you know, f of r close to beta and you look f of r close to alpha on the left, something like this. Okay. In particular, because this index is quantized in the same way, we can, for any, you know, log of integers, we can find corresponding shifts. It turns out. Shifts. It turns out that any LP is a composition of parsing local Hamilton dynamics and shifts. Okay, so instead of circuits, we just have Hamiltonian evolution now. And the thing that makes it all work for us, so the approach that we managed to pursue is that any LPU can be approximated by a sequence of QCAs. So this approximation result holds in a controlled quantitative way. And so as a consequence of this theorem, we can state A converse to a Leigh-Bromson. A converse to a Liebrondson bounds in the following sense. If you have an LPU with certain tails and its index is zero, well, then beta is the identity, and you find alpha is actually generated by a quasi-local Hamiltonian. Okay. And well, it's even only if. So the index is the only obstruction to lifting dynamics or to generating dynamics by Hamiltonians. And in particular, if one does this theory on a finite chain, this index is always zero, but one has to be a bit more careful because then But one has to be a bit more careful because then now epsilons and deltas become more important than here. Okay, and we can say that indeed a shift cannot even be approximated by Hamiltonian dynamics, so no exact lattice momentum density. So that's basically a summary of the results. And maybe the rest, the remaining 10, maybe 15, depending on if our chair people allow, I would talk a little bit about the proofs and the proof ideas. On the proof ideas. The chair is soft, so you can go ahead. Fantastic. You have five more minutes if you wish. We can also have a discussion about proof techniques. Great. Yeah, so that's the result. And now basically I want to talk a little bit about the techniques. And I mean, basically, the key thing will be this approximation here. Once one has this approximation, one can use it, for example, to define an index. And one could hope that the index of these. One could hope that the index of these QCAs, so the old, the known index of QCAs somehow stabilized, becomes constant at some point, and then also things remain quantized and so on. And that's exactly what will happen. So question is how can we approximate LPUs by QCAs in a principled way? And maybe we can attempt to do that, you know, and maybe have a first attempt and see what might be a difficulty. Okay, so suppose we have an ALPU and I focus on a single site for now. Focus on a single site for now. So it has these fuzzy light counts. So, what I could always do is I could always just, you know, sort of project on the algebra of local observables support on some finite size. Say I pick my favorite R, and then I can always slightly, you know, so I restrict alpha to the nth algebra of observables that will map into the entire spin chain, but I could project and define a map, a linear map that maps into this finite region. That maps into this finite region. This will, of course, no longer be a morphism. It will no longer be homophobic. It won't be multiplicative, but at least it'll be localized, strictly localized. And the error I make, I can control in terms of these tails using the definition. It turns out that near any such... Can I quickly interrupt you? When you say project here, do you always mean the partial trace or do you mean any projection? Yeah, good question. Good question. Maybe orthogonal project on that sub-algebra, on that fine-dimensional sub-algebra might make sense. Yeah, good question. Yeah, maybe a partial trace. Yeah, good question. Maybe the partial trace is the right thing to say here. Yeah, good. Thanks. Yeah, thanks. Thanks for the question. So suppose you had such a thing, okay? So you deform your map slightly. Deform your map slightly. You have now a linear map from this algebra to that algebra. It turns out that there's, I mean, I guess there's many results on something called Ulam stability, which is about basically if you have an approximate morphism in some category, deforming it to an exact morphism, such a category. So it turns out that in various contexts, for example, here for finite dimensional matrix algebras, one can find an exact morphism. So I'm an exactly multiplicative map nearby, this one. We can map nearby this one. Okay. And I'll talk about a related tool in a moment. Okay. But the problem is kind of that, so now we can do this for any fixed end. So we have lots of local maps. But the problem is, of course, that, you know, whatever, however I do this projection, for different ends, these things will not commute. The image will no longer commute because we apply this projection and things don't overlap, right? So it's not clear how to patch these together. That's basically. That's basically, I think, the trouble for the most naive strategy. So you can sort of localize any region, any preferred region, but sort of gluing these things together to get a single QCA, that's not so clear. And so that's kind of what we have to fight. So what I want to do now is I want to basically tell you a version of such a stability result that we use. It's a stability result not for homomorphisms, but for approximate inclusion of ultraviolet. But for approximate inclusion of algebras, which we slightly extended, and then maybe give you an idea of how this problem can be overcome. So the main tool is a result by Christensen from the 80s. And what he showed is that if you have two algebras, B and C, one is approximately included in the other, and okay, for certain class of phenomenal algebras, and that's why we kind of have to extend things, as I mentioned earlier. If you have such an Mentioned earlier. If you have such a near inclusion, you can rotate, say, the algebra B by a unitary U near the identity such that you have an exact inclusion. So that seems like a useful tool here, especially given the way I set up the definition of an LPU. So in some sense, that makes that sort of a different spin on what I said about changing an approximate morphism to an exact one here. So like, I guess an approximate inclusion, or well, I guess the. Or, well, I guess the inclusion is exact, but not into the right thing. And now we're deforming it to be an exact inclusion. So that's a result you want leverage. So if you're constantly close, epsilon close, then you have a unitary that's both epsilon near the identity, and you can rotate this approximate sub-algebra into an exact sub-algebra. And what's important here, and maybe we'll see why in a moment, this unitary is not an arbitrary unitary. Is not an arbitrary unitary in some ambient space or whatever. I mean, for this thing to make sense, but B and C have to live in some large algebra because B is not exactly included in C, right? There has to be some ambient phoneme algebra that includes both B and C. So you might be afraid that U only lives, you know, some unitary in this large algebra and you have no control over it. But in fact, U is generated, is in the phenomenal algebra generated by B and C. So if B and C are somewhat localized, you don't lose too much. That will be important to. Will be important to resolve some of the challenges. We slightly extend this result in the following way: that if you have an element X that is already in B and C or near B and C for some delta that may be much smaller than epsilon, then it doesn't change much under this unitary. So it's almost left the same. And similarly, if you have something that commutes with both B and C, then that also will not move a lot. Okay, that seems like Will not move a lot. Okay, that seems like a technical thing, but basically, what it allows us to do is if we use, you know, basically, what we're going to do is we're going to take an LPU, we are going to rotate it a little bit to make parts of it exact or some light cones exact. We still want to preserve tails. So, you know, and tails, preserving tails is a bit like, you know, preserving commutators, and this is related to preserving commutators in a way. So, just, I mean, just the high-level idea. So, that's the main tool. So, whenever you have an approximate tool. That's the main tool. So, whenever you have an approximate inclusion, you can in our setting rotate it an exact inclusion and you kind of understand where this unitary is. So, the way by which we want to use it is the following. So, what we're going to do, and it's somewhat, it looks very similar than the first attempt a few slides before. And I mean, now I guess maybe it's also more clear how this projection plus rotation thing, we can now just use Christensen's result to do it whenever sort of being evasive. I was sort of being evasive in the question that Swan asked before. So, the key idea is that we are going to do the following for any fixed cut. So, it looks very similar to before. We are going to slightly modify the LPU to obtain an LPU alpha n. And this alpha n will look locally like a QCA. So, we will localize the image of these two sides. So, it looks like radius one or here. Those two sides, they will, you know, map, have a light conduct low. This will have a light conduct. cone like so this will have a light cone like so but then on the very left and on the very right we don't worry i mean we just we just want that the left and the right doesn't talk to each other so we want that this this part should not get mapped here and this part should not get mapped to should not get mapped uh to the left right so that's the key so we want something that looks like a qca near a near a cut and we want that the left and the right are decoupled so this left environment doesn't talk to the right one and vice versa and that's for example something that wouldn't wouldn't have been clear in our first attempt Something that wouldn't have been clear in our first attempt. So that's stronger than what we had before. And it turns out that is strong enough to allow us to glue different such alpha n's together. So we can do this construction for each fixed cut. So we can do it for this nth cut, or so the cut between n and n plus one, but we could also do it for the cut between n plus two and n plus three. And you know, any n and n plus one. And one can show because here essentially things look like QCAs. Essentially, things look like QCAs. And if we study another one that's sort of shifted by one, we can sort of compare these QCAs. We can use the rigidity in this finite-dimensional, you know, strict locality situation of QCAs to patch things together. That's basically the high-level point. And so what we can show using this is that for any one-dimensional LUPU alpha, we can find a sequence of QCAs beta r of increasing radius that converge, say, strongly. So alpha of x converges to beta r of beta. Alpha of x converges to beta r of beta r of x converges to alpha of x for any fixed x. And we can be a bit more precise and say how fast it converges, and that depends on the tails. And here is one statement, and it's not the complete one, but this one that's maybe illustrative. So if we look at the difference between alpha and beta r, so alpha is this LPU, beta r is approximating QCA in the sequence, and we restrict to observables in some region X, then we can upper bound the difference by Upper bound the difference by some constant that depends on this class of tails but not on anything else times f of r, where r is now you know the radius of the QCA approximation of choose. So f of r will go to zero. And then we have the diameter of the region x divided by r. And so that's diameter by x kind of useful because if you say if you want if you care about the index of a QCA and this QCA has some radius r, you need to look at something like two R or three R many sites to really figure out this index. To really figure out this index. So that's the diameter that you have to understand. So the diameter that you have to control is some of scales with R's. It's good that this is divided by R. So this is constant, constant, and F of R goes to zero. So in this sense, this is a strong enough approximation for things to stabilize. Okay. Right. Yeah. So there's two things I could be talking about. One is how does this actually work? How does one use this Christensen result to rotate in clever ways? Rotate in clever ways to achieve this. The other thing I could talk about is how to patch things together. Once I would have, well, once both of these items have been discussed, we get this approximation theorem. Once this approximation theorem is in place, it's sort of clear how to define the index. We define it as a limit, and we can sort of inherit lots of properties from it, stability results, multiplicativity, and so on and so forth. And then the remaining things that one should still And then the remaining things that one should still discuss is where does the Samiltonian come from if the LQ is index zero? Okay, so that's sort of a disjoint question. So maybe in the last two minutes or so, maybe I want to give you an impression, just maybe the first, like how this works, just like the first two steps, because I think it's kind of nice if one sees this Christensen result in play. Okay. And it feels a bit magic lessons. This is Baron Winschausen, for some of you who know him, so he's kind of pulling in. Some of you who know him, so he's kind of pulling himself out of the swamp. So the proof feels similar and the magical still to me. So this is also why I have no idea how to generalize it to high dimensions. I think it's part of the problem. Don't really understand it, but it works out. Okay, so the idea is the following. So suppose we start with LPU, and let's just assume it's almost nearest neighbor in the sense that, well, in this sense, that if I look at the observables here, they are the image algebra is epsilon near. Is epsilon near the image algebra on one side to the left? So we have a fuzzy, you know, epsilon fuzzy light cone like this. Okay. So by Christ's theorem, therefore, we can find a unitary that's epsilon close to the identity that rotates the image algebra of, again, of this chain, such that it's strictly included, so that we have this situation. Okay. So this unitary, we have no idea about its support because remember the support of this unitary was in the algebra generated by left. This unitary was in the algebra generated by the left and the right, and this thing is supported everywhere. Like, we have no idea. Okay, so we can visualize the situation like here. We have this QCA that we started with. We apply a unitary that's just supported everywhere. But once we apply that, we have strict locality in the following on for one half-infinite subsystem, namely everything on the right of n gets mapped at most one to the left. Okay, so far, so easy. How to proceed? Okay, so. Okay, so this new APU, which is close to the old one, epsilon close to the old one, will still be nearest neighbor, you know, maybe four times epsilon or something that's still small. Okay. So in particular, what that means, and now we're looking at it a bit the other way around, is that the image of this algebra browser, this half inner for everything to the right of n, which we know is in here. We know is in here actually almost contains this algebra, okay. And the reason why that is so is because if alpha prime is an LPU that's almost nearest neighbor, its inverse is also an LPU that's nearest neighbor. So this guy by the inverse gets mapped roughly to here. So that's why this algebra is approximately inside the inverse of that algebra is approximately here. In other words, the image of this one, of everything to the right of n, is Is contains almost contains nearly contains this algebra. So now the clue is the following. We already know that the image algebra is contained in here. And the smaller algebra, of course, is also contained in here. So this tells us there exists a unitary that's only localized to the right of n minus one. Okay. And this unitary we can now use to rotate, you know, either the small algebra into the large one, or we can, of course, equivalently rotate the large. One, or we can, of course, equivalently rotate the large algebra such that it exactly contains a small one. Okay, and now if we dualize this thing, if you go to the commutant, then we'll have, well, what we'll find is that instead of saying that this algebra here will be contained now in this rotated image algebra of everything from the right of n, sort of looking at commuters, we'll find instead that we can apply a unit. That we can apply a unitary that's now only supported on this side, like I was just explaining. And this unitary maps the half-chain to the left of n minus one, at most to the right here. Okay. So, and what's important here is that the unitary we applied, it's supported here, right? So it does not mess up this locality we achieved in the previous step. So it's still the case that everything here gets mapped to here and then that stays the same because the unitaries only support in this right infinite strip. Okay. On this right infinite strip. Okay, so that's the key idea. So the second unit does not destroy locality achieve the first step. And then we just continue, we rotate back, forth, back, forth, and we grow kind of, you know, the locality. And at some point, you know, by looking always at half infinite systems, suddenly we are in this situation. We find, oh, we actually have this little finite diamond or like a trapezoid, I guess. So, like a really finite, something that looks like a QCA, at least for those, for the purpose of those two sites. And then we do those, you know, I don't know, four more steps, and then we. Know, I don't know, four more steps, and then we get the saturation over here. So that's kind of the idea. So, um, and you know, we really crucially use somehow decoupling the left from the right environment, maybe already gives some indications why it's not so clear how to go to higher dimensions for this kind of strategy. But I guess that was also true for the original, you know, GNVW approach to dealing with these problems that, you know, people managed to overcome. So, okay, so that's kind of the thing. Then we can discuss why conven glue. Maybe we don't do this. The index can be defined as a limit. It can be computed by mutual informations, everything. Be computed by mutual formations, everything as you expect, and Hamiltonians we don't talk about. Okay, so maybe this gave you a little impression. So, kind of what I try to convince you of is that these LPUs, they have a nice structured index here, which is precisely analogous and generalizes to one of QCAs, but it's not a richest. But happily, neither the index collapses and it all becomes the same because of fuzzy light cone tails. But there's also no new structure. So, it's really the same structure. New structure. So it's really the same structure and things generalize in the appropriate way. In particular, we have a version of AA kind of a possible converse to the Robinson-Bouncing 1D in this way, the only obstruction being the index. And the main techniques are the stability results for the inclusions of phenomenal algebra. Here are some open problems that we might discuss. And yeah, thanks very much for the attention.