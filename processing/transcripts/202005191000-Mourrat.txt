Okay, so welcome everyone to the second day of the online open probability school. Thank you all for coming. It's a pleasure to have our second lecture from Jean-Christophe Mouat on disordered systems and Hamilton Jacobi equations. Hamilton Jacobi equations. Just before we get to that, I'll remind you that the lectures are being recorded and posted on YouTube and on the course homepage, as well as being live streamed both on Zoom and on YouTube. So, if you don't wish to be recorded, it's best to turn your video off and refrain from using the chat. That said, That said, we welcome discussion in the chat, in particular questions for the speaker, which either he'll respond to directly or the moderators will keep an eye on and flag to his attention if we see something important being raised. As with yesterday's lecture, we will probably have about half an hour followed by a short break, a small question period, and then the Period, and then the second half of the lecture followed by breakout rooms for participants. We ran, as promised, a couple of breakout rooms before the lecture as well. And I'd welcome any feedback from participants about how that went. I didn't pop into any of the rooms myself, so I'm not sure. Okay, so having Okay, so having said that, let me also remind you that there's a Zulip server for which you can create an account if you haven't already designed for discussion about the various OOPS courses. The link is on the OOPS homepage. And that is a good resource for posting discussions that you maybe want to have less. Discussions that you maybe want to have less transients than the Zoom chat, which is not saved as part of the stream and disappears forever at the end of each lecture. All right, so once again, it's a pleasure to have Jean-Christophe Moura for his second of three lectures. And over to you, JC. Thank you very much. So, yeah, I'm very happy to be back here and to see that. Here and to see that there are still many people joining. So, I hope I thank again the organizers for making this possible. It's a real pleasure. And I'll try to start sharing my screen. Yes, it seems to be working. All right. So, so yesterday what we have done is We have done is so first I try to introduce the motivations behind what I want to discuss and you know speaking a bit about this spin glass model but only briefly and also like waving my hands around this rank one estimation problem that I want to discuss later and then I started to discuss or make some calculations about the current Make some calculations about the QA bice model. And what we've done is see that there is. So, if we look at this function I call the capital F sub n, it solves an approximate, it solves an equation which has some part that has a 1 over n in front. And so we were wondering, or it's kind of, it feels kind of plausible that in the limits, the limit object will solve. The limit object will solve the equation where instead of this one over n times second derivative, there is a zero. And then, so we have to pause a little bit and think carefully about what it means to solve this equation. So, let me rewrite this here. So, we need to think about what it means to be a solution of What it means to be a solution of this equation, which is the one that we found for Curry Weiss, except instead of zero, there was this one over n times second derivative with respect to this h parameter. And remember that in the setting of Curie weis, this derivative respect to h, we can interpret it as the mean magnetization of our system under our Gibbs measure. All right, so the first attempt I described at the very end of the lecture yesterday is: what about we just ask for our function to be a C1 function and that it solves the equation pointwise? What I try to argue is that this is not going to be a good notion for us because if we kind of use our previous intuition about easing models in general, we expect that there will be phase transitions. We expect that there will be phase transitions for the magnetization, and so we expect that there will be jumps in the derivative. So, although our functions are all lip sheets with the same constant, it's not plausible that they will be C1 functions. The derivatives will have jumps. So, we need to lower our expectations about what being a solution to this equation should mean. And so, I said again that our functions are lip sheets. You remember that what Lipschitz. You remember that when we computed the derivatives, I pointed out that they are all bounded by one. And so there is this theorem of Ademacher, which says that any function that is Lipschitz is differentiable almost everywhere. So we could say, what about we ask that the equation that is on display here is satisfied for almost every point. That sounds like something we can ask. We can ask, and it sounds, you know, a second, perhaps more reasonable guess than our first guess. So, let me write this. So, what about we ask that F be Lipschitz. So I will not write it, but bear in mind that this means in particular. Bear in mind that this means, in particular, that f is differentiable almost everywhere, and then we can ask whether or not the equation is satisfied almost everywhere. And solves the equation almost everywhere. And now the problem is that we are facing the opposite effect as our first attempt, which is As our first attempt, which is so initially with our attempt with C1 functions, we discovered that there is no existence, you know, there will be the function we actually want to see is not C1. And now it's kind of the opposite problem, which is that this condition I wrote down will not provide us with a uniqueness criterion. There will be many solutions for a given equation. So let me illustrate this. Let me illustrate this. Let's say this is the problem. No uniqueness. So to really clarify this, let me start by forgetting about initial conditions and observing that there are some simple functions we can write. Some simple functions we can write down that are solutions. So, for instance, zero is a solution. Okay, that's pretty clear. Also, the mapping which to TH associates T plus H is also a solution because the T derivative is one and the H derivative is one. So, when you do this computation with the partial T F minus partial F partial H squared. partial h squared that that will be one minus one squared that's also zero and and also if i look at t minus h that's also a solution right because the derivative in h will be minus one but still the equation will be will be satisfied and the claim i'm going to make now is that for from these uh three solutions i can already make like new solutions that are going to contradict the uniqueness statement so so consider the the following So consider the following. So again, I'm going to draw a graph for a fixed t and this is the age variable. And then what I draw is the value of the function. And so I'm going to draw it like this. Okay, so it should be symmetric. It's like a tenth function. And the value here is The value here is h equals t. The value of the function on the top, like at h equals zero, is t, and this is t as well. So you see what I've done is that on this part, it's the function t minus h, on this part is t plus h, and outside of this tenth part, it's the zero function. So away from the corners, this is actually one of these three solutions I wrote down. I wrote down, and yes, so James, you're right, but then you see now I'm combining them, and so okay, so let me close this and then I'll answer the question. So I hope you're convinced that this function, as I drew it, is a solution almost everywhere, because it's just at these corners that there are difficulties, but we're allowed to throw away. To throw away a set of zero Lebesgue measures in these th coordinates. So it's a solution, and you see that at t equals zero, it starts from the zero initial condition. But zero is also a solution. So from the zero initial condition, we have the zero solution, and we also have this tent function with this triangle that goes like this. And you can, in fact, decide to make this triangle appear at any time, and you can. At any time, and you can, you know, in fact, make it be anywhere in space. So, you have an infinite number of solutions like this. So, yes, so to answer Jen's question in the chat, he was asking if the solutions I wrote down here are not C1 solutions. So, indeed, they are C1 solutions, but at least these ones, they don't have the same initial condition. So, when I speak about uniqueness, I mean in a given a value fixed at t equals zero. Fixed at t equals zero, will this propagate into a unique solution, or will there be many? And you know, a good counterexample is the one I drew because this one starts from zero and is not the zero function. Okay, is this clear? Are there further questions? So we need to, you know, it's a bit frustrating, we have to find the Find some equilibrium between these two situations. But one thing that we can notice is that we can be pretty sure that the function I drew here is not the function we care about. And the reason is that we know that the function we care about, you remember, its second derivative is the variance of the main insulation. So in particular, it's It's non-negative. So, in other words, we know that the function is convex in the edge variable. And here we really have a breakdown of the convexity, okay? Not convex. And now the hope is that maybe if we add this further requirement of convexity, then this will finally select for us a unique solution. And I'm going to And I'm going to argue that this is the case. So it's not obvious a priori, but I'm going to discuss with you that this is true. So this is my proposal for the definition of the notion of solution. Let me read it. So we say we say that ellipsis function. F so it's from R plus cross R and then valued in R is a weak solution. Let's call it like this, okay? Weak solution of the equation. I'll call it Hj, okay? So Hj is the equation we are going to focus on. It's the one that is here. The one which so we're going to say this if the following two conditions happen. So, first of all, that relation, Hj is satisfied almost everywhere. And second, we have this concept. And second, we have this convexity image. Okay, so for every T the mapping H gives F of T H is convex. Okay, so so now I it's a very good So that it holds out at least the counter example I gave. But what I'm going to argue next is that indeed this selects a unique solution for us. So proposition. So I guess we can call it uniqueness. Let's phrase it like this. So, so if F and G are two weak solutions of the equation hj with the same initial condition. So the initial condition I'll write it like this zero dot equals g of zero. Then they are equal. Yes, so Peter is asking what's the intuition behind asking for complexity, and we'll see it in a moment when we do the proof. So I'm going to prove this proposition because I think it's really, in some sense, it's the powerhouse of the whole argument. So first, before I go into the proof, So, first, before I go into the proof, I want to take a step back and explain why I really want to insist on this proposition. Because maybe you think, ah, why do we bother with this? This is a PD question. It doesn't talk about my probabilistic model. I want to, that we come back to our probabilistic model. You know, before we pass to the limit anyway, everything is finite, everything is smooth. So, why should we worry about this? Should we worry about this? But the point is that ultimately we want to understand the limits, and what we want to do really is a perturbation of the statement that is written. So what is written is that if we have two solutions with the same initial condition, then they are equal. But what we really want to have is, you know, when n is very large, we have something which is almost a solution, and we want to compare it with the true solution, and we want to say that they are close. Solutions, I won't say that they are close. Okay, so you see that is going to be just a refinement of the statement that is written. Instead of two solutions must be equal, we are going to say one which is almost a solution and one a solution, they are close. So really this is in some sense a simplification of the problem we're trying to do. Yes, so ah yes, so yeah, good questions. So, yeah, good questions. So, Sho is asking what do I mean by this? Do I mean almost everywhere? So, in fact, here the functions are our lip sheets. So, each time we speak about the functions themselves, we should really think of it as if you want a uniform type of, or at least locally uniform type of information. So, here I mean really everywhere, in fact. If you have it almost everywhere by continuity, you can have it everywhere. So, each time there are, as a rule of thumb, let's say. know as a as a rule of thumb let's say each time when we each time we write identities involving derivatives we will under interpret them as almost everywhere and each time we write identities involving functions we will interpret that is actually everywhere okay all right so I hope you're on board with me that this is a useful statement to worry about we we should find a proof of that thing We should find a proof of that thing. So, I'm going to give a slightly incomplete proof. So, I'm going to call it a sketch of proof. And I will suggest that you think about how to make it fully rigorous. So, let's study the I want to study the difference between these two functions, and I want to show this difference. You know, I don't have much to do, so I have an equation for f and g, so I'm going to try to write an equation for the difference between f and g. For the difference between f and g and see what it looks like. So if I differentiate in t, the difference essentially by definition, it's this derivative squared of f minus the derivative of g squared. And I'm going to try to make the difference appear again. So I can simply write this as This sum and then the derivative of the difference. Okay, so if I give a name to this, let's call it B, this is like by definition I call it B. Then what I just displayed is that dtw minus B dhw is equal to zero. Okay, and so in other words, when we look at the difference between words when we look at the difference between two solutions we can always think of it as you know the difference is solving some sort of transport equation the equation that that I wrote here so it's it's almost everywhere again I don't write it each time and now the perhaps to to start to answer a little bit the the question of of Peter in the in the chat like why do we require convexity here what will be of help really is that Of help really is that its derivative has a sign. You see, the derivative of b itself, it involves the second derivative of h and the second derivative of g. So the derivative of b is positive. And in general, if you were doing the higher dimensional version of this argument, you would find that the divergence of this vector field, so there would be a vector field in place of B, and you would find that the divergence of this vector field has a sign. This vector field has a sign. And the fact it has a sign, it means something about the lines of the vector field being either convergent or divergent. Anyway, this is what will allow us to figure out how to prove uniqueness. All right, so that was still kind of sketchy, but very sketchy. So let me start with a Start with a rough idea, and then I'll try to give a more precise, but still with a tiny gap argument. Okay, so the rough idea is that we're going to look at the integral of w in H, and look at how this evolves as a Yeah, maybe I could. Yeah, okay. Let me do this calculation and see if you find it convincing. So, right now you may worry that this integral is not well defined because it's infinite, et cetera. But I just want to give the idea. So I kind of pretend everything is well defined in this step. So what happens if I differentiate in T this expression? Well, I will get the integral of the derivative of w. I won't write the I won't write the variables again, but remember t is fixed and we're only integrating in the h variable. And we've said that this time derivative is b times the h derivative of w. And now if I integrate by parts, I can rewrite this as, and now I pretend there are no bound returns, you know, they are at infinity or something. Or something. What I get is this. And what we said is that this has a sign, it's non-negative. So if you imagine for a second that w starts to be positive, which means f starts to be above g, then naturally it will want to come back to being smaller, right? Because if w is positive, then this integral will want to be smaller again. And if w is negative, this integral will be able to be able to be able to be And if w is negative, this integral will want to be positive, you know, to go back to being close to zero again. So, so you know, there is this kind of effect of trying to come back to zero in this relation. So, there's a lot of things that are still very murky in my argument. For instance, I'm kind of pretending a W has a fixed sign, which is, you know, there's no reason appropriate to believe that. And also, I integrate over the whole space, which is kind of. Space, which is kind of probably not well defined either. So I'm going to now try to fix the argument, but I hope that this kind of very rough one-line chit chat gives you at least a taste of why having this convexity assumption will be of help for us. All right, so now this was perhaps what I wrote down in my draft. Now I'm going to Down in my draft. Now I'm going to try to do a read proof. So that's the closure of the rough idea. Now I'm trying to do the reproof. So first I'm going to try to fix this aspect with the sign. I want to force a sign on w. And because, okay, you see that transport equations are nice for this. So let me define a function. Let's say x squared. Let's say x square over 1 plus x square. So, you know, it's a nice like smooth function which has maximal slope equal to 1 and it's always non-negative and is 0 only at 0. Oh yeah, w is the yes. Yeah, okay, perfect. And I use this function to set v equals phi of w. Okay, so that's phi of f minus g. phi of f minus g so so now at least v is non-negative okay and our goal is to show that f is equal to g so it's to show that w is equal to zero but you see it's equivalent to showing that this function v is equal to zero um so so let me remind you what's the equation solved by w it's here um now what happens for Now, what happens for V? Well, I claim that in fact, that's the magic of transport equations. The same equation is satisfied for V as well. Okay, so if you think about it for a second, the time derivative of V is the time derivative of W times phi prime of W. of w and here it's the same it's like the the h derivative of w times phi prime of w so so this phi prime of w is kind of you can factorize it it's showing everywhere and so it simplifies and this this relation is also valid okay every everyone is fine with that so okay i i i already kind of uh cleared out one aspect of my uh fake proof which is that now v has a fixed sign it's Now V has a fixed sign, it's a non-negative. Now, the second part I have to deal with is that I was integrating over the whole space. So I just have to instead take an interval. And the problem with if I'm not paying attention is that when I do my integration by parse argument, it will produce boundary terms. And so I have to cache them back in some way. In some way. So, the way I'm going to do this is that I'm going to, instead of integrating over a fixed interval, I'm going to change the size of the interval as I move along so that it will produce me some extra good terms, if you want, that will allow me to catch back whatever shows up in the boundary terms in the integration by points. Okay, so that was still perhaps a bit tricky, but. So, yeah, first one is asking why this function phi is really, I just want a function phi which is zero only as zero, is non-negative, and has bounded derivative. So, you know, I just picked that one, but whichever is fine. Um all right so so let me let me go forward and and try to find this uh interval. Find this interval. So I introduced some notation before. So you remember the functions f and g are Lipschitz. So I'm going to, these are the Lipschitz constants in the variable h for f and g, and I just turn them up and I add one. And I will use this constant to Use this constant to fix the speed at which I change the size of my interval. And also, you know, I keep making this movement with my hands. I hope you see it. So the size of the interval over which I integrate is going to shrink as time moves, and I'll just do a linear thing. So at some point it will just be a point, and then there will be nothing. So I have to fix a finite time and then I start from there. And then I start from there. So I fix a finite time. I'll call it capital T and instead of this function that I have written capital I above, I propose that we study this thing. So J of T the integral from minus L times capital T minus T to L times minus t to L times capital T minus T of V of th dh okay so so it's I hope you you know I try to and oftentimes I'll just write it like this so so minus R T to R T I'll just shorten this capital L ta capital L times capital T minus T as R T. Minus t as R T. And then I just write V. You know, implicitly, I understand that there is a T and H. Okay. So T is fixed in the integral, and I only integrate over H. And then we let T vary and see what happens. Oh, yeah, so first I should say this function J is Lipsheets in T. J is Lipschitz in T, and so I can compute its derivative almost everywhere, and it is equal to the integral of this almost everywhere time derivative. And so let's minus Rt to RT of dTv. So so that's uh one part of the time derivative. Yes, yes. And um And that's so so, yeah. Ultimately, I want to show that this function v is zero. Okay, so what I'm going to end up, I want to control the derivative of j. So what we're going to show is that the derivative of j is negative. So since it's a non-negative quantity, it starts from zero, will be done. All right, so the time derivative of this integral is okay, one part is just differentiating under the integral, but there's also a part. integral but there's also a part related to the fact that the the boundaries of the interval are moving okay so there will be minus l times v of t r t plus v of t minus r t okay so so they they both appear with the minus sign in front because the the interval is is shrinking uh as time moves Shrinking as time moves. Okay, so I produced these terms so that they would help me. I want to show that j does not decrease. And so I'm very happy if I have that the time derivatives of j is something with minus some positive terms. So these are just good for me. All right, and now I'm going to try to do my integration by parts thing in this term. thing in this term. Okay, so let's do this. So you remember the time derivative is B times this H derivative. And now I do my integration by parts. So it's minus integral from minus RT to RT of dhb times V. And I have these boundary terms. So maybe I'll write like this: B times V and bracketed between minus RT and RT. Okay, and these are kind of more annoying for me. There will be at least one term which is not of the right sign. Yeah, so I'm not paying attention to passing. To passing integrals below the derivatives below the integrals. So, yeah, sorry about that. It's not a fully rigorous proof. But I think it's okay. You can just find it. Yeah, but this part, you don't know a priori. At least there is one of these two terms which does not have the right sign for you. It may have. It may have the tendency to let j increase, you know, the one which comes with a plus. You know, there will be plus B this B V evaluated at T comma R T. But the point is that, at least my hope, is that it can be compensated by these minus terms that we had here. And do you see why this is true? It's that, okay, so we have V of T and R T, which is also here. V of t and R T, which is also here. And now the claim is that B is bounded by, is smaller than this coefficient L. So I chose this L so that this happens. So let's verify that I did not mess it up. So remember, the definition of B is a bit further above. It's here. It's the sum of these derivatives. And the way I chose. And the way I chose L is an upper bound on these things, you know, I sum the L infinity norm of these guys. Okay, so long story short, if I take this minus this guy, it's a negative quantity. I say negative in the sense of maybe it's zero or it's in a wide, I mean less than or equal to zero. Okay, so in other words, So in other words, these boundary terms don't bother us, and what we have is just this. Okay. And now finally, as promised, this is non-negative. And this also is non-negative. Or maybe I should say just positive. I never know if I should say positive or non-negative. Anyway, it's greater than or equal to zero. Anyway, it's greater than or equal to zero. And so the whole thing is less than or equal to zero. And that's what I wanted to show. So dtj is less than or equal to zero. And why do I say that's all what I wanted to show is that j at zero is zero and j is non-negative. And j is non-negative, right? Because it's the integral of this v function, and v is non-negative. So, what we have shown is that we conclude that j is constantly equal to zero. Okay, so that means that v is equal to zero, and you know, perhaps initially you can only. Initially, you can only conclude that it's true almost everywhere because we have this integral, you know, we integrated against the Lebesgue measure, but it's a Lipschitz function. So, as we discussed before, by continuity, you can complete and you just conclude that v is equal to zero, and this means f is equal to g. Okay, and that's the end of the argument. Argument. I draw a triangle because some parts were not completely rigorous. So Fardal was pointing out that I was not really paying attention to interchange of derivative and integral. That's true. And also another aspect which I was kind of careless about is that if you look at B, it's not really different. Differentiable. So I was using this. I'm sorry, I want to display the definition of D again. Yeah, it's here. Let me square it. You see, in the argument, I use this derivative of B with respect to H. And it's not clear approval that it makes sense because I only know that F and G are lipsheets. and G are lip sheets. So in particular, they are not twice differentiable. So my proposal for as an exercise, and I think some of you are taking this for credit also, so the exercise is to make this proof rigorous. And yeah, so let's say this is part of the credit assignment for the school decoration. Of the credit assignment for those decreases. And if you so, so the idea, I think, if you really want to make it rigorous, is to convolve a little bit B by a smooth corner. And if you struggle, you can have a look in the book of events on TDs. It is done there as well. So I think it's already almost late for a break. So anyway, let's take a break now and at the end. Let's take a break now, and I'd be happy to take questions maybe before we turn to them. So, are there questions on this? Question on the chat. Hi, yes. So, Andrew is asking if this is uh equivalent to the notion of viscousity solution. Coastity solution. So, in the case when the initial condition is convex and Lipschitz, then the answer is yes. But so, what really makes this proof work? So, you can weaken the proof in several ways. You don't really need to assume that the function is convex in H. It would suffice that it's semi-convex, you know, that it. Semi-convex, you know, that it's you just have a lower bound on the hash. Maybe it's negative, but that would suffice. And yeah, so maybe I just should not have scored it. It's too long now. So in general, you can try to see what happens with more, you know, even in higher dimension, like if you try to make sense of equations of. Make sense of equations of this form. And the thing that really makes the proof work here is that this nonlinearity is convex. So if you think carefully about how we argue in the proof, this is really what is necessary for the things to work out nicely. So really, the power of the motion of disco-stiff solution comes mostly when comes mostly when this non-unity is not convex, or I should say, neither convex nor concave. But whenever the non-unity is convex or concave, the two notions will coincide. So, Partan is asking what does it mean from the physics point of view? I mean, for starters, it's not perhaps completely easy. What it means, this function. Easy, well, it means this function fn. Okay, or maybe you can. Yes, so this function fn, okay, so free energy. And yeah, the fact that it's convex in this H parameter is a very robust feature of the models. Each time you construct this free energy like this with the parameter times some quantity when you differentiate twice, the second is. Otherwise, the second derivative will be a variance. So you will always have this convexity property. So I'm not sure exactly how to phrase it best in terms of the physics, but I guess you could say that it's the convex conjugate of some other reasonable function of physics, which, okay, what should it be? Yeah, okay, I'm not sure. I think one could do a reasonable argument, but. Argument, but Francesco is saying Legend transform, but I guess the question is: it's the Legend transform of what, right? And maybe it's the Legend transform, yeah. Okay, maybe it's the Legend transform of the Large Devils function or something. Okay, so maybe that's a good moment for just a two-minute breather, and we'll resume very shortly. Does that? Very shortly. Does that sound okay, Jean-Christophe? Yeah, absolutely. Great. So there is another comment in the chat from Peter. Yeah, but maybe, I don't know. Maybe people need to have a break. I don't know. Also, I'm not entirely sure how to comment on this. Comment on this. I think maybe it's a it's 12:45, so it's a good time to uh to pick up again anyway. So everyone has the energy. Yeah, so I don't know what for me a Legend transform means when you do this differential Legend transform and by definition it gives a convex function. So in my opinion, if it's a Legend transform, it means it's going to be convex, but okay. Okay and um yeah so then I'm I'm not super I'm too much of a mathematician to be sure about what free energy means when I don't write a formula. So yeah, so it's possible that in some cases it makes sense to speak about the free energy which is not convex. I'm not going to dwell too much on this because I'm not sure if I would, I think I would probably say stupid things. All right, so so I All right, so I have perhaps one more comment. I won't insist very much on the existence aspects for these equations, because in some sense, for us, this comes for free. We're studying a model and we are wondering if it converges to something. So the only thing we need to worry about is to show that this thing is converging. So the fact that we will produce some solution is almost given because any limit point basically. Any limit point basically should be a solution if we are not giving a bad definition of solution. So, perhaps another way to say it is that you could try to run the proof that I just gave you. Just instead of speaking about solutions, you would use it to try to show that this sequence of functions fn is a Cauchy sequence. Okay, and you would manage to do that argument. So, you would not know the existence of solutions, but you would show that this is a Cauchy sequence. But you would show that this is a Cauchy sequence, and so therefore it converges, and then the limits you would show it's a solution, I think. Um, so yes, but in case you're I think it's still, you know, despite the fact that I think it's not critical to worry about existence aspects, I think it's useful to have in mind that we can write down a formula for the solution. So, I'm not going to dwell on this too much. Solution. So, I'm not going to dwell on this too much, partly because time is running short. So, in the settings that we are exploring, the function so if I if I take the supremum of psi of supremum of psi of h minus h prime minus h prime squared over 40 then I claim that this is the weak solution and I say V because we've shown it's unique So here I'm assuming you just let let's just say that psi is is convex and Lipschitz. And then so the claim is that if you write down this rational formula here for f, then it's actually the solution of the equation. Okay, so in general, what appears here is related to the convex dual of the non-linearity of the equation. Convex dual of the non-linearity of the equation. So in our case, the non-linearity was just the square function. Maybe I should write with a different colour. Maybe I write p gives p square. And the convex dual of this function is, let's say q gives q square over 4. And so you see that there is some q square over 4 showing up in there. So in general, it's the, yeah, this expression is relative. Yeah, this expression is related to the convex dual. So I'm not going to prove this, but again, the fact that a formula like this, you know, one can write a formula like this is related to the fact that the non-linearity in the equation is convex. So yeah, I'm not going to prove this, but see evidence if you want to see a justification. And And yeah, so let me propose another exercise. So, not necessarily for credit, but just for your, I think it's a useful exercise. So, in the setting that we have, we have a specific definition for psi. But, okay, what I really want to use about psi in this exercise is just that it's a smooth function, it has zero derivative. It has zero derivative and it has a positive second derivative at zero. So we show that for t small, you have still a zero derivative for the solution at zero. You can use the Hofflex formula for doing this as a. For doing these exercises. And for t finites, but large. On the other hand, you have that the derivative on the positive side is positive. And it's kind of implied that the derivative on the other side will be negative. Okay, so for using the Hoff flag. Okay, so for using the Hopflag formula, for instance, you can show that there is a phase transition in this derivative. Okay, so maybe I call this the third part. So I hope I'll try to. My goal is to wrap up the statement. try to my goal is to wrap up the study of the Kerryvice model from what we have now and perhaps before before I so what I really want to show ultimately is that this sequence of functions fn converges to f I think this by now has become clear but I've always I've often emphasized that you know the physics you know the information that we perhaps most care about is this mean magnetization which is encoded in the derivative of the function Derivative of the function. And it's not here a priori that by knowing the convergence of the function, we understand something about the derivatives. Oh, yes, there are F's missing in the thanks for the F's here. Thank you very much. Yes, I think you can compute the, but then so Fuswani is asking if we can identify the precise tea at which. We can identify the precise t at which the transition happens, but this requires a more subtle analysis. But this is possible, yes. I mean, you have to, this exercise is more, you know, showing the other side is easier than showing what you ask, but it's also possible to do what you say. All right, so yes, I want to first explain that indeed we understand, if we understand the convergence of the functions, actually we do understand the convergence of the derivatives as well, which is perhaps not obvious. Which is perhaps not obvious a priori. So let me state this. So if th is a point of differentiability in H of F. Okay, so we have Of f. Okay, so maybe this is not. So by this, I mean at the point th, the function f is differentiable. And you know, if you want to be precise, differentiability only as h varies would be sufficient. And if fn converges to f, then actually the derivative at at this point th converge to the limit derivative. converges to the limit derivative then dh fn at th converges to dh f at th so so really if we understand something about the derivatives of the limit actually we do understand something about the derivatives before passing the limit all right so let me try to prove that statement so now i'm back into the So now I'm back into the setting of the Kerivise model, right? Fn is the function that was defined in this setting. And the engine of, you know, the reason why the statement is true is that the function is convex in h. Okay, so if I look at fn of t prime h prime, this will always be above the tangent at the point th. H oh no, I just mean sorry, I just mean to move h I just fixed it so okay, so you always have this property because the function is is a is convex yeah the convergence is for this Yeah, the convergence is for this locally uniformly. Okay, so this is by assumption because the function is convex. And now assume that, you know, so this is bounded. So take a subsequence along which this converges. Yeah, let me call the limit along this subsequence P. Okay, so then what happens when I let n tend to infinity? So as was asked in the chat, the convergence is pointwise. So yeah, so pointwise or uniformly will be the same. So let's say pointwise. Sorry, as I pass to the limit. Sorry, as I pass to the limit, then it becomes f of th prime is always above f of th plus this slope p times h prime minus h. And so I found an affine function which touches f at the point th and which is always below the function f. And if the point is a point Um if the point is a point of differentiability, there's no other way that than for p to be the derivative of f okay so so p must be dhf at th okay and that completes the proof okay this one is actually fully regulated it's a so so really yeah we we we do understand what happens for the true problem What happens for the true problem, even at the level of the derivatives, if we understand the convergence of the function, all right? And yeah, in the short time that I have left, I want to complete the convergence of this function fn. Okay, so now I hope I so someone named K asks why such a subsequence can be found. The derivatives are bound. Be found the derivatives are bounded. Okay, remember that the function is lip sheets, so I can always extract the subsequence. Yes, so I hope I convinced you that the convergence of fn should be like some sort of more refined or like a perturbation of the uniqueness argument. Because now we're dealing with a function which is almost a solution and we won't say it's close to the true solution. true solution. So let me recall you the equation. So the dc fn minus dh fn squared equals 1 over n dh2 fn. Okay, so now it's not exactly a solution. There's this extra right hand side. And I want to still say that it's close to the true solution. I'll still call little f the true solution. The true solution. And so, really, I'm trying to mimic the same argument. I'm defining the difference. And when I define the difference, it solves an equation like before. This also will be a B times dhw. So I don't write sub n, but it depends on n, also w and b. And then on the right-hand side, And then on the right hand side, I have this extra second derivative. So where B is, as before, is the sum of the derivatives of the function. So dhfn plus dhf. Okay, and now what else did I do before? Yes, I took then I applied this function phi to make the apply this function phi to make the difference be have a sign okay so so now then I set v equals phi of w and before it was really nice it solved the same equation but now I have to be a little bit more careful so I have dtv minus b d hv equals and now okay I have this phi prime of w which is still you know kind of around so it's phi prime of w kind of around. So it's phi power over w times one over n dh2 fn okay so you see again it's it's it's really very close yes n file x square over one plus x square so it's really very close uh the argument is really very similar to what we've done before uh except that there is this you know this bit of right hand side that we want to see is smooth and so so we define again this j of t which is of t which is integral from minus r t to r t of v of th th and r t is defined as before you know there is this constant l inside but l is the sum of this these l infinity norms of uh fn and so so you can you know we know that these h derivatives are all bounded by one so if you want you can you know the way i defined l was a sum of three terms so you can just Of three terms. So you can just take L equal to three in this proof. Okay, and that's what L is. And you know, we run the argument again. And so before we found this, but here the novelty is that there is this extra term which comes from this junk on the right hand side. So I'll just write it. So phi prime of w times one over n. times 1 over n dh to f n. Okay, and so it's it's of th dh yeah I should have written w of th also and now we have to deal with this term and the nice thing is that so phi prime is bounded by 1 and this is non-negative okay f fn is convex so I'm using this again here to deduce that the time derivative of j That the time derivative of j is bounded by integral from minus rt to rt of okay, maybe I put one over in the outside of the second derivative of fn th and you see I don't put absolute values because I know it has a sign and it's very convenient for me because then it's the integral of the derivative so so this is one over n times 1 over n times the derivative only one time, the first derivative of fn between the two bounds, minus minus rt, 2r. And now we've said several times that this h derivative is bounded by 1. So this whole quantity is bounded by 2 over n. So what we have proved here is that the time derivative of j is bounded by 2 over n. bounded by 2 over n. And recall that the initial condition is, they coincide, right? The initial condition of fn is constant and is the same as that for L F. So J of 0 is equal to 0 and its time derivative is bounded by 2 over n. So what we have shown is that J of t is bounded by 2t over n. Okay, and then I can No, I kind of close this here because I'm kind of running out of time a little bit, but you see that this should kind of close the argument. At least in this L1 in H and L infinity in time, we have a good control on the difference between Fn and F. And now if you want to have really point wise control on the difference between Fn and F, you can upgrade because you know that all the functions are Lipschitz. You know that all the functions are Lipschitz. So, you know, if I tell you that two functions are close in L1 and they are both Lipschitz functions, then you can deduce they are close in L infinity. Maybe you lose a bit in terms of the rate, but you can still do that. So maybe I'll add as an exercise, again, not necessarily for credit, but just clean up this. Okay, so there were a few. Okay, so there were a few things that were not very rigorous. So again, I was kind of, yeah, okay, so that's. I think the thing that is most important to clean up is how do you get pointwise convergence from this kind of L1 conversions. But in any case, so now, okay, we can breathe. That's the end of the argument. And I really want that we I really want that we bring with us for the last lecture an important message, which is the following. So key point. So when we are going to face the problem in the rank one matrix, again we will find some quantities similar to Fn are sorry, there's a question. Ah, sorry, there's a question in the chat about where does this bound two over n comes from. So this is the difference of two, you know, the evaluation of the derivative at two points. And each of these guys is bounded by, is between minus one and one. So I just sum them up and it gives me a two. Okay, and you remember this H derivative is the mean magnetization, so it's between minus one and one. Yes, so in the future we will have a very similar situation with a function which almost satisfies the same equation, in fact. And we are going to try to show it converges to the true solution. And the key point to remember is that what we need to, you know, if I write an equation for fn or some variant with some, let's call it some errors on the right-hand side. Some errors on the right-hand side. Ultimately, what I have to do in this argument is to understand some L1 estimate, some integral over H of this quantity. So the key point I want us to remember is that, so let me write like this. So if there are error terms on the right-hand side, Right-hand side. I hope you see what I mean by this. Like whatever shows up on the right-hand side of the equation that we kind of don't like and hope goes to zero, we need to estimate it in L one in L one in the edge variable. In the age variable and uniformly in H. And all this I mean locally, okay, so locally in L1 and locally uniformly in H. So if you want a short summary of that statement, I want a local L infinity in time, L1 infinity. In time, L1 in H, estimate. Okay, so the claim I'm making here, which you can play with this if you want, is that you can write down a more general version of that statement we just went through, in which there is something that sort of an equation with some right-hand side. And if the right-hand side is small in this sense, like locally L infinity in time L1 in H, then the One in H, then the argument will work and we will manage to show closeness with the real solution. Okay, so that's that's the main thing I want us to remember for next time. And I'll stop here. I think it's a good time for questions. Okay, great. And just before we go to questions, I think I don't know how the rest of you felt or how all of you felt, but as the organizer, I think it's very nice. But as the organizer, I think it's very nice to unmute everyone and give a round of applause before we go to questions. So, thanks again for a lovely lecture, Jean-Christophe. Okay, so I've just muted everyone once again, but I've now at this point given you the ability to unmute yourselves in order. Mute yourselves in order to ask Jean-Christophe questions, or you can continue typing them in the chat if you prefer that. Over to you, JC. So I see a question in the chat from Noaf. You're still muted. Perhaps I have unmuted. Perhaps repeat the question for video. Ah, sorry, I was muted, so I had not paid attention. Muted, so I had not paid attention. So, the first question is about the Hopflax formula and what conditions there are on the initial condition psi. So, I did not try to find optimal, like if you want a nice, you know, like a nice statement that that kind of will be completely sufficient for our purposes, you can just take side to be convex and lip shift. But if you want to. But if you want to make a more kind of robust theory, you can in fact justify it for any okay, maybe you have a little bit of regularity, okay, maybe continuous would be even enough, but at least you can completely drop the convexity assumption. Then you have to reword a little bit the notion of resolutions. So the way I wrote it, the way I wrote what it needs to be a resolution. What it needs to be a weak solution. I said that it's convex in age, but if you start from an initial condition, because for us everything is convex in age, so I didn't want to bother. But if you want to make sense of solutions for initial conditions, which may not be convex, then at the very beginning, it will still not be convex. It will not just completely tilt over the function. So, one way to fix it would be. So, one way to fix it would be to ask for the function to be locally semi-convex, which means so okay, so let's say for every delta there exists oops there exists uh C delta. C delta such that for every t larger than delta, the mapping h gives f of th plus c delta h square is convex. Okay, so if I wanted to just say it in words, you will have a you will have a lower bound on the second derivative, but maybe this lower bound becomes degenerate as you approach t equals zero. So that was the first question. The second question is, is there a modification of the Hoplax formula for the prelimin PDE in FN? And the answer is yes, and it will involve a little Brownian motion part. Motion part. So, really, what happens in this complex formula is that you're optimizing of a path. And if you have a bit of viscosity, or if you have some viscosity, this second derivative, if you have some of this second derivative, then instead of having this kind of deterministic path, you would have a Boolean motion path that you're trying to steer in the right direction somehow. So it would be some. Be some how does it work exactly? I think it would just be some expectation of some exponential of volume motion. I forgot exactly the formula, but we can work here. But in the setting of tomorrow's lecture, we will not have a completely closed formula for fn, so we will not be able to write a formula of this sort before we pass to the limits for fn. Okay, so not hearing any uh further questions, at least uh not instantaneously, I'm going to um recreate the