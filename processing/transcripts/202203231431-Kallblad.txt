I tried. Okay, and Sigrid is going to talk about on an E2 formula for measure-valid multiples and some applications. Thank you. And yes, first of all, big thanks to the organizers for inviting me and in particular for giving me the opportunity to be here on site. So this talk is going to be then partially a continuation of the talk by Alex. So today's then I work with Alex and With Alex and Martin Narson, and Saraswati Ferro, but it's also going to be some components, which is Jonathan with Alex and Matthias Beigelberg and Martin Hussman. And the very first slide, it's going to be a lot of repetition from Alex's talk here, right? So in this talk, I'm going to dig a little bit deeper into this SDE we looked at. I'm also going to dig a little bit deeper into the EDA formula and then give some other applications as well. So if we just start by, so you already see a version of this slide on Alex talk. But so measure-value martingale is a probability measure-value process. If you project it onto real-value martingales for some kinds of test functions, you're getting martingals. And also in this talk, then I'm going to be concerned in particular with this, the formula in blue, which is a particular class on our controlled ambience. And also, as you already heard, I mean, one way to Already heard, I mean, one way to obtain this formula is to try to derive it for some kind of first principles by looking at measured martingales in a filtration driven by primary motion. So then we have this representation. If by the Martingale representation theorem, you know that you measure Denny Martingate, once you project it to a test function, it's going to be written as a stochastic integral with respect to prime dimension. And then that integrand is going to be linear in the test function, and you can expect it. Test function, and you can expect it to be represented by some signed measure. And then you're using the properties that because you preserve mass, if you integrate the signed measure over the real line, you should get zero back. And you might also then say, okay, let's restrict to the case when we actually have absolute continuity of the assigned measure with respect to Ïˆ t. You don't always have this, but let's suppose it was implicit here, then you can really log time this lower line here. So raw here. line here. So rho here is then effectively v the density of sigma with respect to xi. So it is a fairly general class of measurable processes and to get some more examples here, so as we also already heard by Ali's talk, the typical example to have in mind is this prediction process. You look at the conditional distribution of a random variable. And a lot of these examples appeared, for example, in the literature on enlargement of iteration. In the literature on enlargement of iteration. So you can think about your court in Europe. They were interested for various reasons in knowing the conditional distribution of a random variable. They actually derived these kind of expressions, like this STE we saw in the previous slide, for various random variables. So if you look into the lecture notes, you can find like lists of random variables with a corresponding. And this is actually from where we borrowed the notation. Um the fact that we can assume that the sigma t is not so we cannot so once you have a measured by the martingale you know that the support is decreasing. You don't know that the sigma t does not have to be absolutely positive with respect to xi t. That was just like an heuristic argument to arrive at the S D E. So the derivation of the S D E on the previous slide was heuristic, but to moderate it, well now we're starting with that class. But now we're starting with that class, and I'm going from the other way around and trying to show you that this class actually includes some relevant examples. Okay? And there are also connections to filtering theory. So in particular, there are these Sakai and Koshno-Stratanovich equations there, which we can also relate to these ST. I mean, there are similarities. And then once again, I want to mention then, so there is work by Verwonan Elder. We already heard that he had some construction of a solution to this coronavirus. Construction of a solution to this core embedding problem, which can then also be represented via an SD of this type. And there are also more recent works. So for example, works, so there's like a stream of literature, but works using these pathways methods. And a lot of the arguments in there also rely on the use of measure-value martingals and very clever choices of measure-value martingals. But most of the examples I've seen there. Most of the examples I've seen there, if you extend this STE again to more burn emotions and look at measures on RD, you can still plug many of these MMs into this framework, right? So just to illustrate that, you know, you can go beyond this, but it's still a relevant class. And one key example, which is going to be very dominant in this talk, is then maybe the simplest. Talk is then maybe the simplest one. So just take the Bernie motion and look at its conditional distribution given the current position of the Bernoulli motion. I'm doing everything in this talk in one dimension. So now everything is just explicit in terms of the density of the normal distribution. And if you carry things out, you see that this then has exactly this representation. For rho b in the identity function, same what are some scaling? But scaling model as I'm scaling, but scaling effectively corresponds to time changes here. Okay, so the first thing I wanted to dig a little bit deeper into is this proof of this fact that you can find weak solutions here. So we already saw this result in Alva's talk. Of course you need to prove that there exist solutions to the SD and it's then non-trivial because you have this feedback thing here of Feedback thing here of the NVM properties. And there are some results in the literature which choose particular functions raw and actually prove solutions here, existence of solutions. I just want to show you that if you want to find a weak solution, if it's sufficient for you to find a weak solution, and you want to find it for a fixed choice of this rule, so choosing rule to be given by a fixed deterministic function. Fixed deterministic function, it is, you know, after all fairly easy. And I just want to sketch this argument so that we we're confident that we have solutions. So the idea is that you start by just fixing the probability spice with a Browner motion. And once you have that, you can define a process in the y, which is written here. And so the curly E is a stochastic exponential. So you define some measure-value process here, obviously. Once you know Here, obviously, once you normalize it with respect to the Zt, it's clear that it's probability measure value. But we also want it now to satisfy the STE. And the idea is, so priority, this is not going to be a marking game. And the idea is to make a climate change of measure to obtain the properties we want. So in order to know how to change the measure, let's just look at the dynamics of this thing. So you look at the dynamics of this and Of this, and effectively using stochastic Fubini arguments, and this is where you would need to work a little bit to justify this, you can obtain these dynamics. And you see that everything would be fine if we can change measure just to obtain that this is a brand measure. And the D is to do this via this process Z T. And you can verify that you can change measure with respect to this Z. And it's pretty clear that if you do so, the psi will. The psi will, under the new measure, be a marking k. But we really want these representations, we want this to be a Bernamotian. And a priori, it's not completely clear that the Z is the right thing here. But you can actually rewrite this, I mean, once again, applying Stoccas-Fabini arguments, you can see that this Z is really of the form you need, so this will all work out. So you can obtain existence fairly easily weak solutions to this STE. Solutions to this STE. And yes, so this is the class of MVMs we're working with here. And the next thing I then wanted to talk a little bit more carefully about is the eto formula. So again to formulate it, I also need to define the derivative, right? So this is again once a copy of Alex side, right? But so what we choose to do is to, we need some version of a derivative of functions on probability measure. Of functions on probability measures. And we choose to borrow, so to speak, from the mean field games literature, this derivative, which is called the flat derivative. So in an actual, if you have a function, it's differentiable if there is another nice function, which depends on the argument, of course, but also on the argument of the underlying space, such that the fundamental theorem calculus property is observed. Really exploiting that after all this set of probability measures That after all these other probability measures, I mean, you have convexity here, right? And then some kind of growth properties, etc., need to be imposed. And it can also be noted that, so there is this Lyons derivative as well, which is used in many contexts. And for, you know, in nice spaces, you obtain the Lyons derivative by also differentiating this with respect to. By also differentiating this with respect to the spatial variable. So it can be good to know the relations. Okay, so using this then, we do have an ETA formula. So it's the same ETA formula we saw before. So you need some nice, you know, the MBM you're working with needs to have some kind of interoperability properties for things to work out, and this is this assumption here. This assumption here. So P is fixed in the sense that P is the MVM starts off in a measure having finite P of moment. And then that's also a property which is going to be preserved. So the MVM P lives in the P Basenstein space. And you then choose some Q for which this integrability condition holds. And you can actually show that the bigger Q is, the bigger the class of functions for which you have to. The bigger the class of functions for which you have the result. And then you have a need to formula, and it looks great like you would expect. You have a first-order term with a first derivative, and you have a second-order term with a second derivative. I should say here that, of course, there are also many ediformulas in the mean-filled games literature. So people have been working on similar questions, wanting to get ideas. And the formulas look a little bit different because the processes we're working with are different, right? So, coming back to the question in the previous talk. So, somehow to specify the ETA formula, you need to specify the dynamics in some way of the process you want to apply it to. And you know, here is specified via this STE. In the mean field games literature, one can think about the typical example there. The typical example there, so the simplest example in the mean field games literature, you have an underlying ether process, and the measure value process you're looking at, at time t, returns the law of the underlying ether process. So that is a process, so if you think about the underlying ether process just being about a mesh, for example, that is a process which starts in a point and then grows out. Whether the measure value martingales have a quite different Martingales have a quite different structure, right? In that we're starting and supported somewhere, and as time goes on, essentially the support shrinks. So the prisons are a bit different, and that's also the eto formula. So in particular, if you look into the mean field games literature, this eto formula appearing, typically the function, the derivatives appearing here will, you know, the form will be a bit different, but also the derivatives which appear will typically be differentiated with respect. will typically be differentiated with respect to the spatial variable as they appear here. Okay. But let's briefly sketch the proof here. So there are various ways to prove the Edo formula. You could try to think about some classical version of the Edo formula and how you prove that. And you could try to kind of discretize time, make some summation of the small increments and try to pass to the limit. This could work but turns out to be quite This could work, but turns out to be quite cumbersome. So another idea is to really try to use the classical EDA formula which we have. And this can also be done in different ways. So in the meanfield games literature, so I will comment on some literature in a second, but in the meanfield games literature it's kind of common to approximate the measure value processes by some empirical process. And this is very natural when you're And this is very natural when you approve when you know that the distribution you're looking at is the distribution of a given iter process, because you already have an underlying process to play with when you want to do the empirical process. Here, this is not so clear, so we rather choose to play around with the functions of the measures, so to speak, and try to approximate a general function by nice functions. And the nice functions are then going to be the cylinder functions. The cylinder function The cylinder function is composed, you just take a finite number n here, test functions, and you apply the measure value, the measure to those. And then you take a nice differentiable function from R into R and plug in these components. So this is what's called a cylinder function. We also saw them in a big talk by Christa. And what's worth noticing is that if you differentiate this, That if you differentiate this, it's very easy. You're getting this expression. So you just differentiate the function, and then when you differentiate mu of phi, say you're just getting back phi. And again, if you were instead interested in the Lawrence derivative, for example, you would have a phi prime over here. But okay, so once you have these or work with the cylinder functions, it's very easy to prove the ido formula here because the Because the if you're thinking about so if you're thinking about plugging in the measure value martingale here and applying it to test function, this is a real value process and the dynamics is given by the STE. So that is some of the input. The way we characterize the dynamics of the measure value process is by showing how it applies to test functions. So you heard the dynamics of this. And so I've written And so I've written the full argument here for Zoolet functions, but the point is just that you have the dynamics of these one-dimensional processes now from the SDE, and you have the classical eta formula. And you also have the expression of these derivatives for single-linear functions, cylinder functions. If you just put all of this together, you're getting that for cylinder functions, the formulas I wrote it down, is satisfied. And then what you need to do is that you can. And then what you need to do is to try to approximate a more general function. And so the idea is like if you have a general, so let's fix some n, fix a fixed number of points, and then when you take a general measure, you somehow want to accumulate the mass around each point to direct mass at the point. But you're trying to do this in a smooth way just to make everything smooth and nice. Smooth and nice. And there is then a way, like a concrete way, how you can approximate a function by a cylinder function. And it's not so surprising that you can approximate a function by a cylinder function in a nice way. Maybe the most critical thing is that you need to ensure that not only the function converges, but also the derivatives. But this also works out. And also the growth points are preserved, etc. are preserved, etc. So when you pass to the limit, really all the formulas or really all the terms in the formula, in the data formula, do converge. And this is using then once again that when you're working with MVMs you can easily localize them to remain in compact sets. So this is, you know, having all these growth points on compact sets, all of this breaks out. So that is a way of proving this e to formula. And as I said, the As I said, the MVM version of the IDA formula is a bit different than the meanful games versions, but if we think more about just the approach to proving it, there are still connections. And there are particular, maybe two factors I wanted to mention here. So first of all, in the work of Persona and all, they do have an eto formula for cylinder functions, but they never pass to the limits. It's not so closely related to that bit. But there are two papers. But there are two papers which we learned about not so long ago then. So one is by Golf and Wei in the mean field games context, but proving the uto formula in a very similar way. And the other one is the one by Martini, which we also heard about before, which is then in the context of filtering theory, so then having a needle formula for these Lakai equations, but also using a very similar approach, actually. So, yeah, there's been a lot of. So yeah, there's been a lot of interest in this question, let's say. Okay, so having now showed you the STE and spoken a little bit more about the ITA formula, I wanted to show some other applications at the very end. So I'm just gonna start by picking a function and applying the eta formula. And some of you might guess where this is leading. But so let's take this function. But, so let's take this function up here. And the first thing you should note is that if you plug in a measure which is concentrated on a point, this is going to be zero. So if you now pick a particular measure, let's say psi naught, and you want to evaluate this function at psi naught, one way to do that is to pick a measure in Martingale, which Martingale, which starts in psi naught and at some point terminates. By termination, I mean it's concentrated, it's on a direct measure. And then if you just plug everything into the eta formula and suppose that this expected stochastic integral vanishes, you can express this via the expected value of the drift term. And now I'm just going to plug in a few things and do Now, I'm just going to plug in a few things and do a few trivial inequalities here. So, first, the first line is just by actually computing the specific derivative in this case. And I'm also using that, the particular measure-valid martingale I'm choosing here is that I take eta to be the one we saw in the very or the second slide of the talk, so the normal MVM, which you can explicitly express, and let's take H. And let's take h push forward of this. That is essentially looking at the conditional law of h of w1. Now, everything is explicit now. So you can plug this in and you can use the expression from the STE and you know compute things. So there's one inequality here and this is Jansen in two variables. So you need of course the phi to satisfy that you have convexity here to apply this. Have convexity here to apply this. But if you do this, you're getting this expression over here. And now you can then make particular choices of these functions. So the first one I want to show you is you just choose phi to be x squared. Then what you're getting from this expression is the PoincarÃ© inequality. So I should repeat, I'm only doing this for probability measures on R. For probability measures on R. So it's simple, well-known results. So the point is more the method. And you can also choose by to be x log x, and you plug in what I had on the previous slide, and what you're getting is a log sofal of inequality. And I'm going to comment a little bit more on these, but before doing that, I'm going to show you one more example. And again, some of you. And again, some of you might see where this is leading. If not, you can try to guess. So let's pick this function, again, the function defined in blue, where this squared u is given by phi prime phi u inverse, where phi is the normal cumulative distribution function. Then in the second point, I'm just computing the derivatives. Second point, I'm just computing the derivatives. So that's just purely monotone work, just computing the derivatives using this relation here. And then at this stage, I mean this is not zero if you have a direct measure, but you can of course still look at the difference. So when I wrote Ïˆ 2s here, I mean the point at which the MVM terminates. So you can look at this difference, and once again, you apply the And once again, you plug everything in. I mean, this is just repeating the drift term from the ido formula, and you just plug in the derivatives, and you're getting something which is clearly non-negative. I'm not very happy with these point terms. You're getting something which is clearly non-negative. Okay? And now, just copying from the previous slide what we had, so what we got on the previous slide was this. Was this inequality here? And then you can just rewrite this, and you see that you're immediately getting the second line. So the second line is just, you know, square root of a square plus p squared is smaller than a plus b. And now this is actually, again, it's a simple result in one dimension, but it is the Gaussian isopermatic inequality. It's a functional form of it. functional form of it but you can think of so if you're having a set A you can approximate that by a sequence of nice functions and when you're having like a nice function what's gonna what this is gonna pick up here is just gonna integrate the function where it has a slope and so effectively what you're getting is the right hand side here and that this is always greater than or equal to And that this is always greater than or equal to the left-hand side. And, I mean, the interpretation of this is, right, so if you take a given set A and you know the mass under the normal distribution, the rec, or the normal mass here, this is always going to be greater than or equal this quantity which corresponds to choosing A to be a half plane. And if you choose A to be a half plane, it's very easy to see that. It's very easy to see that this is exactly what you get in the and this was the two examples I wanted to show you and I should now comment a little bit. So there's first of all there is a paper from 97 by Capitan Su and Ledou and I think it's called simple proofs of functional inequalities or something like this. And the computations in there are very very similar in some ways. Are very, very similar in some way to what I showed you. So, if you look at that paper, you will recognize a lot of things. The difference is some of the dead paper is relying on Maliaving calculus and Clark-O-Kuhn expressions, the Clark-Kuhn formula, whereas here we're now relying on the Ito formula, so the use of the MBMS and the Ito formula. But of course, sorry, of course, there are links. And the other thing I want And the other thing I wanted to mention was I wanted to mention once again, so there is this, I mean, there are probably many papers, there is, in particular, one recent one by Elda, when it talks about this pathwise method, I think I mentioned it before, which effectively uses also measure-value margin case. Of course, point in these papers, or one key point, or maybe the key point, is that you manage to look at things in higher dimensions. To look at things in higher dimensions and reduce it to a one-dimensional case. And this is not at all what I'm doing here, right? This has just been a one-dimensional. So the point I'm trying to make here is somehow a little bit different, right? So when you think about this, you should think about it also in context or in relation to Alex's talk, right? So what we've shown here is that if you make particular choices of rule, you can relate these expressions to functional in a... To functional inequalities, etc. And of course, the idea then with this control framework, which Alex presented, is that hopefully there should also be a systematic way of choosing these rules in case you want to obtain or have a certain goal in mind. So that is somehow the illustration I wanted to make. Having said that, thank you very much for your attention. Okay, questions, comments? Hi. So you mentioned Sado Pehram used the Calco Conformula. But the sign measure you use in the marking of a presentation is also related to the Calco Knowledge. Of course. So is there a way to just fight the Like the the initial derivative terms in this even though there could be. Yeah. I I don't I cannot give a clear answer, but there should be in relations, yes. Any other questions? Some people from Zoom, can you hear me? I can hear you but I will have a question. So thank you for helping. Thanks for the nice talk, Katie. was also in R D, right? So this they said in nine dimensions. But your applications are in one dimension. Was this just because I haven't tried. Alright, okay. If there are no other questions, let's thank Sigrid. There are no other questions. Let's thank Sigrid for a very nice talk and everybody in our afternoon session.