Based on what we have seen up to this point, this is going to be disappointing. So, I'm not going to be talking about assortment optimization in this talk. And some of you might have seen some of this work before, so that I also know actually when I decided to present this. So, any question, please refer to Varun, just a little bit there. It would be awesome. So, this is work that summarizes some of the things I have been doing on this type of program for some time, and here are some of the people that I want to mention that have contributed to the ideas that I'm going to be presenting today. The most recent thing was some papers that were worked with by Wonnet Visa, who um graduated from a booth and she's now a professor at uh in New Zealand, the New York City of Book Right, so Use your book. Alright, so let me just walk you through what I would like to discuss. So this is a matching problem. It's a QA matching problem. So this is what I'm going to be talking about. And so the picture is really this one. It's very self-explanatory, I would say. We have customers coming to a system looking to be served by a bunch of servers. And it's a queuing matching problem because there's going to be congestion, so there's queues. Congestion, so there's queues. So these people come and they join a particular queue looking to be served by one of the servers, right? And these servers have different scales, have different attributes, and so there's some sort of a compatibility that is represented here by this topology in this graph. And so, what we're trying to do in this work is really to look at this system and ask ourselves a question, which is what is the What is the relationship between the matching that I'm going to be selecting here and the performance of the system? And there's two aspects that we're going to be looking at. One is the one that comes from the queuing side, which is the congestion, so delays. So how long people would wait before they are served. So this is one thing that becomes important. And the second has to do with the quality of the matches, right? So we're going to be able to control that, or we're going to pretend that we can control. That or we're gonna pretend that we can control that matching somehow, and by controlling the matching, we are gonna be somehow controlling the quality of the matching, right? And so, we would like to be able to look at the system and try to see how the choice of this topology will impact those two things, right? The speed at which we serve these customers and at the same time the quality of the matching that we can offer them. Okay, now we're gonna do this in a very specific, under a very specific assumption, which is the one that I'm pointing out here, which is that we're gonna restrict ourselves to Is that we're going to restrict ourselves to first come, first serve, and add. So, in other words, customers, so we're going to try to be fair in some sense. You can think about this using some sort of a notion of fairness embedded in this. So, customers are coming to the corresponding queues in this picture, and they should be served, first come, first serve. Okay, so we are fair in that sense. And the second part of this is that if this server, for instance, get idle and there's a customer from class. And there's a customer from class two and three waiting, he would go and serve the customer who has to be waiting belongings, right? That's that, I should say the other way around. If a customer comes and there's two servers idle, so three and four has been idle, that customer will go to the server has been idle the long. So we're trying to be fair on both sides. So we're trying to be fair to customers and we're also trying to be fair somehow to service. So we're going to make that assumption and we're going to look at this system in a And we're going to look at this system in a stationary environment. So, we're going to let this system run for a long time, and we're going to look at how the system performs in a stationary system. All right? Now, to kind of give you a little bit of the history of why I got into this, so this is hard to read. It's Ed Kaplan's thesis, right? Back in 1884, I think. 1884, right? He preferred the section. Yeah, right. For the century. Yeah, right. Looks very old, right? It's called Managing the Demand for Public Housing in the Boston area. So this is the thing that Ed was looking back during his dissertation. And so if you think about that type of application, the notion of first come, first serve and fairness is very important, right? And so what he was looking at this system and he was asking himself, well, if these are how And he was asking himself, well, if these are housing projects, right, and there's families or individuals that look at public housing and they come to the system with different needs, well, this is roughly how the system is going to be looking. And then the question that he was trying to understand was, well, if I let this system run, what fraction of these individuals here will be matched to you know this type of project versus this one? So kind of the quiet of the matches. He was not really looking at the congestion in the question that he was looking at back then. In the question that he was looking back then. And so eventually he made some progress, but when I met him at some point, we started talking about this, and so I got interested in this project. And so this has been a long time ago, so I have been sporadically making progress, especially when I work with smart people. All right, so a bunch of applications in public service, healthcare, online matching markets, manufacturing. So there's a connection maybe to process flexibility that one can start making when you start looking at these systems. Can start making when you start looking at this system with a bit more of a broad perspective, called center object, and so forth. So there's a lot of different applications where you can potentially look at them with caveats, of course, that will match this framework. All right, so let me move a little more specifically about what I'm going to be showing you. So I have these different customer types. So we have survival rates for these types. For these types, and every type will come with a vector of valuations. So every customer has preferences over servers. So we're going to encode this in this vector d theta j that will tell me how much a matching from a customer theta with a server j would look like. Alright, so we have that. And now what the platform or central planner will do is to put in between these two sides of this matching, what we call here service menu. What we call here service menu, right? So we're going to say, all right, maybe what we need to do to think about this question is to create these classes so that when customers come, they see these different menus and they choose which one of these classes they would like to join. So joining a class, meaning joining class I, for instance, means that you're going to join this queue and eventually you're going to be served by one of the servers that that class I is offering. So you don't know for sure which one, right? So you know which is the Sure, which one, right? So, you know, which is the subset of servers that you can potentially be served by, but you don't know exactly which one is going to be at the end of the day the one that it's going to serve, right? So, I'm going to operate that logic. So, what happened then is that consumers will look at that menu and they will decide which one of those I want to join. And so, they will solve this optimization problem, utility maximization problem, you would say, and they will join this. Problem, you would say, and they will join this cues, and then the system will operate with those demands. And so, what individuals are doing when they solve this problem, these choice problems here, is to look at the different menus or service classes here and try to evaluate what is the expected payoff that they're going to get in terms of the matching and will penalize by the delay that they will experience by journeying a particular case. And so they trade off the And so they trade off these two sides that we're trying to balance when they make their decisions. And so, as you can see, there's a lot of different menus. So, if you have M servers, you have about 2 to the M different ways in which you can bundle them. And then out of all those bundles, you can put 2 to 2 to the M possible ones, right? Of course, some of them will not be feasible in the sense that maybe it's just one server that you are. Maybe just one server that you are offering, right? Most of them will not be stable from a queuing point of view, but there's a lot of different things that can happen in terms of how you can offer these menus to consumers. All right. So let me pause here and see if there's any questions about the kind of the framework if you want to. Yes. So why uh okay, so this is both in practice and in theory. Why do I need service classes at all? What if like each customer type is just its own service class? Type is just its own service class. Each customer has its own service class. Right, I could do that. Well, I mean, you're going to offer, you know, some compatibility. Right? So the question is, what does it mean to offer... So I can offer all of them. That's what you're saying? No, no, I'm just wondering, like, I'm just confused. Why do we have to merge the customer types in these service classes? Like, what if we just have a separate queue for each customers of each type? Customers are just telling you. Because I, well, the assumption that we're making is that I cannot, you know, individually say, you will go there, right? And this is the queue for you, right? And for RAD, I have a different one. So what I can do is to offer a menu to all of you, and each one of you will self-select which one of these menus you want to. So if I could discriminate in the way you want, of course, I could try to target this in a way that I could actually achieve better performance. That I could actually get to better performance with that, right? Is the gap understood between the discretionary setting and decentralized setting, like the setting where you can force people? To some extent, right? Yeah, I would say so. If I have full control on how I can route people into queues, then I would say that, yes, you can, you can, I will show you a picture, I will show you what kind of a delivery you would expect to see if you were to do that. Yeah, right, so that becomes a little bit more trivial in some sense. Trivial in some sense as a problem, right? What's the cost of having more classes? Isn't it always better to have more classes? Well, it depends, right? So at the end of the day, if you're trying to balance, right, you want to do it in such a way that you maybe restrict choices to people. Because by restricting choices, you're going to be able to get better performance. I mean, more classes will add more constraints. Constraints. Constraints to the policy. Right, so my policy is to find a menu, a set of service classes, right? And I'm free to pick as many as I want. The question goes back to Antoine is, do I want to do that? Do I want to just put everything in front of people and say, you go and choose, right? Um because that's best and the answer is not necessary. What's your dream? Unnecessary. What's your dream? Right, so let me let me go to uh the objectives. Alright. So if you offer like two service classes, one is nested. So is it automatic to offer two classes that are nested or not? Like a subset is could be. You could. So let me give you an example so you can kind of maybe see some of these questions at play. A play. So here I have two servers. So potentially you have seven menus, really. But there's two of those menus will be menus where you only offer a service class for one server and the other server is kind of disposed, right? So that's not very interesting. We're going to be looking at systems where you do need all the servers and all the service capacities, right? So if you restrict yourself into that type of operations, within servers you have this fibrin. With two servers, you have these five units. And so you have the dedicated, so let me point this one. So this would be where you have one queue for every server. And you just go and say, I like server one, you go to one, you like server two, and then you leave with that, and that's your, that's the menu that I offer. The alternative would be a single line. Everybody goes through the same process, and there's no, I don't separate any of them, right? There's the full menu, right? The full menu will be, in this case, where I offer you all the freedom, right? Where you can go to superwatch. Where you can go to server one and just be served by server one, or you can just be the cube of server two and just be served by server two, or join this middle cube where you might be served by one of the other, right? So, in this case, that would be the full menu. And then you have this N1 and two, this kind of queue terminology, they look like N systems, right? Where you might do an alternative combination of this, right? And so, here I'm showing you the performance of these systems. Again, it's probably hard to read the back, but I'm showing you how they But I'm showing you have a look in terms of rewards, right? So, what's the average reward that this system will generate in terms of the point of the matching and the average delay of an individual in this population, right? And as you can see, there's something, and I'm looking at this at different level of congestion, and the reason why I'm showing you this plot is because we are going to look at this as the intergraph. So, we're going to be moving into the right portion of this plot as I move forward. As I move forward. And so, what happened here is that you see that, of course, the surface line, the signal line, pulls all the resources together. And you know, that pulling resources means efficiency in terms of delays, and therefore you are minimizing the delay of these customers if you do something like this. But what happened is that the performance in terms of the quality of the matching is very important. On the flip side, you can pick this dedicated menu where I just let each one to pick the What I just let each one to pick the server that they like, and that will actually maximize. So, we can show that you can maximize the average reward that a customer will get, but obviously at the expense of making the system more congested, right? And therefore, it's going to be less efficient. And so, really, what we're trying to do in this work is really to look at this from the perspective of this trade-off. So, that's why I'm plotting this line here, which is somehow reflect the fact that we would like to. The fact that we would like to understand this trade-off as best as we can. And there's still room in terms of answering that question, I would have to say, but we have some ideas of how to think about that. Now, going back to your question, to some extent, we are not really looking at one metric, we're really looking at how we can trade up these two metrics, right? And so that's really the objective, right? As opposed to just pick one point in this particular efficiency. In this particular efficient frontier, if you want to avoid it a little bit more. Okay. All right. So, all right, so just to give you an example of what can happen if you have, I can't remember exactly. I was trying to remember how many servers you have. I don't know if you remember what one of these pictures. Either five or seven. Yeah, it's five or six servers, right? And then you ask yourself how many possible menus I can actually come up with with that very. With that very limited number of searches. The point, really, at the end of the day, is to show you that there's a lot of combinations in terms of options that one can potentially think of. Most of them, of course, dominated by this frontier that I'm pointing here, which is really the one that we would like to understand as peasant. And going back to your point, Ali, I mean, if you have control, you pretty much can put yourself here in some sort of a first best when you start looking at the system interventions. When you start looking at the system, you can hear it traffic. Oh? Yeah, you have no waiting because oh, because you are scaling the system. Yeah. So I'm very sorry here the technical difficulties. Are you able to exit the first stage? Yeah, then I'm not able to clean it. I think that's why the slide showcase. Alright, so we'll just move it like this and the colours This is interesting. All right, now we're going to see the teak the recording. All right, so let me speed up. I mean, I think I'm going to. So this is the I mean, I don't think I'm going to. So, this is the model. So, we're trying to figure out how to figure that matrix M, the matching, the menus. Consumer has strategies Q, which is the choice probability of how they join a particular menu. We want stable menus, so the queue has to be stable, of course. We have delays in each queue as a function. There are strategies in the menu, of course. We have matching properties, which the probability that server will be that's served by vector server. We have the utilities, we have a delivery profiles that we're trying to characterize. Files that we're trying to characterize, which is the choices that the consumer has to satisfy an equilibrium. We have a set of equilibriums that we can produce as a function in a particular menu, and then we have service providers, which is trying to, in this case, maximize particular performance. As I said, we're really looking at the efficient frontier, but you can think about characterizing that efficient frontier by looking at this type of performance. And we're assuming that we're looking at some sort of the optimistic service provider. Optimistic service provider that picked the best equilibriums out of all the equilibriums that we have, right? So now we need to make a choice there. Now, these are the two things that we're going to look in heavy traffic. So let's explain why. So the heavy traffic is just standard conventional heavy traffic. So we're going to make the traffic intensity close to one, right? So we're going to keep the same number of servers. So we're just going to scale that up. So the arrival rates will look like this. There's going to be some sort of a nominal arrival rate and some term that depends on x. Arrival rate and some term that depends on epsilon, think of epsilon going to zero, so that the traffic intensity of the system would look like this. Now, the assumption for heavy traffic is that the sum of this is equal to the sum of the capacities, and that's why you get this heavy traffic, and this is how fast you approach. The waiting times, of course, will blow up in heavy traffic, so that you need to scale them by the same epsilon, so that this quantity remains bounded as you take epsilon quantum, right? And then you have the utilities where we have now the scale waiting time. Now, the scale waiting time there so that we can preserve the structure of the drone. So, again, very standard heavy traffic analysis, compression heavy traffic analysis for this class of systems. All right, now why we need this? Because if you go and look at what the alternative would be to say, can we characterize the state-state distribution of the system for a regular system, not in a heavy traffic, what's going to happen is that you're going to have to have state-state descriptions that are actually combinatorial. And this is my combinatorial aspect. This is my combinatorial aspect for the topic of this workshop. There's a combinatorial structure in the state-space descriptions of the systems, right? And so you can have product forms, so you can, to some extent, theoretically, write these things. The problem is that compute these things really blow up. And what you need to remember is that this is just computing the performance of one dot on that prototype. That is already combined. That is already combinatorily hard, right? And what we want is to do optimization on those. So it's pointless in some sense to try to go this route. So that's why we want the heavy traffic. And so what happens when you go to heavy traffic is that that cloud of points that I showed you before that represents all the different systems collapse into this kind of lattice type of structure when you move into heavy traffic. And so by doing this, now you have the hope that you're going to be able to say something. Then you're going to be able to say something a little bit more meaningful about the systems when you start seeing that there's a certain underlying structure that is emerging when you take this system into heavy drawing. So let's try to see what that structure is. So let me do this just through an example. So take this system. So suppose I fixed this menu, right? And now what I need to look is how the system will look, will perform for a given menu. So for the moment, I'm kind of putting aside the I'm kind of putting aside the equilibrium conditions that will lead to something like this, right? So you look at a menu like a system like this, and if you pay a little bit of attention, think of rho going to one, just look at the first portion of this, right? So there's a server with capacity two, the demand class with capacity two row, makes row goes to one. Well, since that class is only served by that server, some extent server one has to be dedicated almost exclusively to class one if you want to preserve the system. If you want to preserve the system, the stability of the system, right? And so, if you go through that process of trying to figure out what happened, you will see that some of these arcs will have to have zero flow if you want, in heavy traffic. And so if you do that, you can remove them to some extent. And once you remove them, the system decomposes, as you can see here, and decomposes in what we call CRP components, complete resource pooling components. And so each one of these components somehow has. And so each one of these components somehow has a set of classes and servers that are balanced, right? The arrival rates kind of equal the service rates component-wise. And so with those components, what you can do, you can create a DAG. And the way you create this DAG is by representing the CRTs by nodes and connecting those those with those parts that you remove. And to some extent, this DAG kind of captured the way in which congestion builds up in the system. Congestion builds up in the system as you take this system into head traffic. Now, each of these DACs that we compute will have a collection of topological orders, and so these topological orders are the one to some extent that we're going to exploit to compute waiting times. And kind of the idea, intuitively, is that, and I know these topological orders are written in the non-conventional way. There's a reason for that. The reason for that. And so, but take the first one. So, if you look at a system like this, you can see what this system is actually saying is that if this class is heavily congested, meaning that there's a lot of customers that are actually sitting in this red class, that means that class one has to be heavily congested because you can send flow from the red to the blue through these arcs. So, this is really what. These arcs. So, this is really what is encapsulated in this DAC here. And so, to some extent, what is happening is this DAC are telling you how congestion, different excursions of congestion, can actually be built up in the system as you go through this. So, you can have a situation where the level of congestion in the system have this order, right? This one is always going to be the more congested because this is the one that is receiving flow from everyone, in some sense, right? But it's possible that four is not very congested, so you have some sort of a way to. Congestion. So, you have some sort of a way to order or partially order the way in which congestion is going to be building up in the system as it goes. And so, you can use that to really exploit that structure. And now we can compute the waiting times of its different classes using this more aggregate information, in which the only thing that we need is what is the DAC associated with the problem. What is the DAC associated with the problem, and what are the slacks of each one of these DACs? So I can, to some extent, throw away the initial match problem and just reduce it and collapse it to that DAG that I showed you before. And with that information, it's enough to compute the performance of the system in terms of waiting times. The performance of each CRP itself is easy to characterize. So if they were not connected, well, that's going to be. Well, the waiting times is given by this, right? So there's still going to be. Given by this, right? So there's still gonna be some combinatory structure embedded in these calculations. It's much more reduced, obviously, because we have collapsed these things, right? But these terms here that I'm explaining, I don't have the time, these are some sort of slacks that are building up for each one of them. So in other words, the only thing that you need from a CRP to compute this is how much slacks you have in heavy cloth, right? What's the slack that you have? And if you know that, you can just compute this waiting times. And you can also use. These waiting times, and you can also use this type of results to start asking questions which are relevant to what we are doing, which is now I need to design these systems, right? So it's not just computing performance, but also think about how can I design this system. And so what happened, just to give you an example, is that if you want to implement a particular vector of waiting types, so now I'm thinking more as a central planner, I want to implement delays, right? How can I think about implementing a particular vector of right? And so one thing that happened is that always. And so, one thing that happened is that obviously, we're going to be efficient, so the smallest delay that you want to have in the system could be equal to the delay of a complete resource spooning, which in this case can be written in terms of this one over A in the slides. I know I'm saying a lot of things that need to be thought carefully, but the point of this slide is to say if you want to implement a certain vector of delays, which is somehow optimal, right? Optimal in this, right? Then you can always do it through systems that look like this: chain tags, where you're actually going to have a collection of CRPs that have these layers, right? You can see that there's layers here that you ordered them. And so these layers are the one that you will be creating depending on how many of these classes you want. So in this case, I have capital K, different delays that I want to implement. I can do this by having capital K layers here and then order. Capital K layers here, and then ordering them in a particular way like this, right? And I can always implement this vector of delay. So, this gives me a lot of flexibility now from the point of view of trying to design these menus so that I can control the delay that I would like to see in the different classes. Is it just a sufficient condition, or do you all have a necessary condition? No, it's a sufficient condition. Now, I'm running out of time, so for the probabilities of matching, this is an aspect. This is an aspect of this project where there's still some black space. We don't know exactly how to compute matching probabilities precisely. We have a quadratic approximation that looks and works very well, but this is a place where there's potentially, we have spent a lot of time thinking about this, where there's room maybe for trying to fine-tune even more this, right? But for the purpose of the analysis, we actually work with this quadratic programs. All right, so this is. Alright, so this is going back to the two server keys I showed you before, just to kind of show you how the menu itself translates into the stacks of CRP components that I was showing you before, right? And so you have this type of systems. And it's also a curiosity, but it's nuisance really. You might have situations like in this example where you have a CRP component that essentially has zero flow. Nobody joins that. You offer a class, but nobody joins it, but you still want to offer it. Joins it, but you still want to offer, right? But you need to also compute the waiting time. Although nobody joins, there's a waiting time attached to this because you're solving for an equilibrium. So you want to make sure that your equilibrium is able to become an equilibrium. You have a surface class that is offered even if there's no flow going into that location. So you can do that. Alright, so All right, so a couple of theorems. The single line that I showed you before, where you have just one queue, gives you, of course, the best performance instead of delays, but also gives you the worst performance instead of matching reward. That was not necessarily obvious, but that's the case. The dedicated menu, the one you have one key per server, gives you the highest possible matching, but also has not necessarily the worst, but had very bad performance in terms of delay. So these are kind of extreme. Interface. So these are kind of extreme menus that we want to think of. Then you can start thinking about designing, right? So, which is really at the end of the day, what we want to do. And so we have different types of designs like partition menus where we take the servers, we partition them, and then the question, what's the best partition, so that you can create some beneficial frontier like this. And so this is something, I think this is not the bomb. So you can really at the end look at this different type of strategies and write mixed. Write mixed integer programs that potentially can be used to solve and characterize these frontiers using this particular class of menus. It's also something called Taylor menus, which is kind of a magnetic design type of... Anyway, so I'm running out of time, so I just want to give you a picture of what we have been doing, the type of systems that we are trying to study, the type of performance, and how the use of heavy traffic can bring the problem. How the use of heavy traffic can bring a problem that looks very complex into something that has some structure and it kind of unveils some of that structure that you can exploit for the design of the system. All right, with that, thank you very much.