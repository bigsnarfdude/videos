So today I'm going to talk about a joint assortment pricing problem under a recently proposed, considered and choose choice model, which is called the picture of bond erosion model. I'll explain what the model is. This is joint work with Sajyad, who is a professor at UNC, and my PhD student, Amin, at UTIS. Okay, so I don't really need to give a lot of motivation for considering two choice models. I think almost everyone in the audience has some work as The audience has some work, as Daniel showed the related work section. But basically, what these models say is that customers do not consider all the products on offer, they only consider a subset and then choose from one of the products in the consideration set. So, this is called the consideration set. And again, there's been a lot of work that showed that these models can more accurately explain customer choices in practice. She and Gustavo and Dimitri also had a recent paper where they had a sophisticated estimation framework for fitting. Estimation framework for fitting considered in choose choice models and showed that these models are more robust to noise in the offer set information. So, when you are not able to construct the offer sets precisely because they have partial information and also better for long-term forecasts. Okay, so these models have been gaining in popularity, the operations literature, and so we also want to add to this literature. In particular, we study a joint assortment and pricing problem under this mature bondelogic model. Mixture bonding logic model and prior work showed that this model can give you better out-of-sample predictions compared to the LCML model. Okay, and you'll see like the sort of similarity between LCM and L and nature of boundary logic. But of course, they did not look at the decision problem, so that's what we wanted to do with this work. So our contribution, so first I will sort of motivate the model primitives based on how customers make choices in online video products. Make choices in online media platforms. Okay, so the model that was originally proposed was based on an interpretation to handle a technical issue when you estimate the mixture of low-check, the standard mixture of low-check choice model. But I'll show how it can actually be viewed as a natural considerate and choose process in online platforms. And then we're going to propose efficient solution approaches for both a single type in this model as well as a model. As well as a model with fixed number of tables. Okay, so let me sort of jump right in with the model. Okay, so how should I think about this? Suppose you want to search for any product. So I was looking for shaving brushes recently. So I go on Amazon, like I search, and I might get a search page like this. Okay, so the first thing that we see is on the search page, I only see a few features of the products. I do not see all the information, right? I do not see all the information. So I might see, of course, the price, I might see the average rating, I might see, it's probably not visible, but how many of this product was bought in the past month. And then, of course, whether there's free delivery and so on. So you have some set of key features that are visible on this page. And then what the model proposes is that customers choose to focus on a subset of all these products by associating a concentration utility, so that's the term we use, with each product. With each product. Okay, so the utility is denoted by u bar j for product j and it's given by this theta transfer z j. So theta captures the domain on each of these features and z bar j is my set of what we call again consideration features which are the features that you see only on the search page. Okay and then basically they form a consideration set based on these utilities as follows. So they include all the Folllows. So they include all the products that have their largest concentration here from everything that is offered, and of course, it should be preferred to the no purchase option. Okay, so that's how, so S is here the offer set, CS is the concession set. And if you look at this form, this is a special case of this compensated decision heuristic that has been proposed in the literature as a sort of cognitive heuristic that people use to form. Heuristic that people use to form concentration sets. Further, the way we have defined the concentration set here, the formation is endogenized, right? Because whether or not a product is included in the concentration set depends on what other products are on offer. You need to compare the at least with everything else on offer. So it is a double space. Yeah. So just a simple clarification. As written there, the consideration set can only have size one, like only one j. Like on one j. So so basically if there are no ties then yes, but basically uh when we see the uh sort of decision problem, we would kind of induce ties in the utilities. Yeah, but without ties it would be this point. Okay, so okay, so that's the first way. So right, so based on this, sort of you come up with a subset of products that is a reconstruction set and then you would sort of go and inspect the product pages of each. Sort of go and inspect the product pages of each one of them. So, as an example, you pick one of the products, you go to their product page, and now you see more information about the product. So, like you can see the product description here, you can see also the reviews, answer questions, and whatnot. So, the customer learns more about each product. And then we're going to assume that the customers associate another utility, which we call the purchase utility, again, with each considered product. Again, with each considered product, which has the following form. So now I have another set of parameters omega that capture again the weight on the features. But now I would look at all the features, right? So of course the features that I knew from the first stage, as well as these additional features. And Epsilon JI captures idiosyncratic behavior of customers, right? So this guy right now looks at we have a standard animal. Yeah, and I have no pride on the CJ's. Say that again? I have no pride on CJ's. I don't I don't cost in the first stage at all. Yeah, yeah. So, yes, we are not assuming any prior or like search cost or anything. Okay, so the way the model is defined, so one sort of unique features of this model is that customers are allowed to re-evaluate the utility for the construction fee. Utility for the consideration features. So, this omega, if you look at let's say price as an example, price was there in the first stage and also in the second stage. Customers are potentially allowed to choose like different things. So, once I form the construction set, maybe I become more sensitive to the price or for some other feature. Okay, and then of course, like the customer chooses the product with the largest utility or leaves without a purchase if it is too low. And if you assume that these epsilon are IID standard terms, Of Silon IID standard gumble, then in the second stage I would get hominal choice properties. Okay, so that's the model, basically. Okay, so what I described was the choice process for a single customer type, which is called a boundary logic model, and I'll talk about sort of why the terminology or where the terminology comes from. But basically, the mixture of boundary logic model would just be defined as a distribution for what these kinds of types. Covert these continuum types. So each type would be described by a pair of parameters theta and omega, first stage, second stage. And then the two-step process. In the first stage, you form your concentration set with all products that have the largest concentration utility. And then the second step, you choose amongst the products in the concentration set according to an M and L model. So, of course, if the product is not in the concentration set, the choice will be zero. So, this is the notation I use. Notation: I use FjS is the probability of choosing product J in of a set S as a function of parameters. Otherwise, you have this MNL form, and this product one comes from the no-purchase function. Z bar be a subset of Z, basically. But we sort of don't want to impose anything on this. Okay, now where does this terminology bound? Now, where does this terminology boundary logic come from? So, as I mentioned, like this sort of choice model was discovered in one of my earlier papers. And basically, the customer type that I talked about was discovered as a limiting case of your standard logic model when the ML parameter becomes unbound. So, typically, when we think about utilities, we think of finite utilities. But if you have data sparsity issues, we don't observe sales for all the products. Sort of sales for all the products, then what could happen is that these parameters could sort of become unbounded. And then what that paper showed was you can interpret these parameters becoming unbounded as this natural two-step choice process. Okay, and basically show that it was like a boundary solution, so that's why we termed it like boundary loadship model. But we sort of sort of formalized that process, motivated by how customers make their choices not all the problems. Choice is not a problem. Okay, so that's the model. Any questions? Okay, so then, of course, as I said, our objective in this paper is to study the joint assortment pricing problem under the Mitchell-Bond leadership model. So, suppose I have K customer types, type K as proportion alpha K and parameters theta K only K. Right, so because we're just solving price optimization, we assume all other. In price optimization, we assume all other features are fixed. So the choice probabilities only depend on the prices. So I can sort of simplify the notation. Remember, this was the notation for the choice probability. I would just denote it as a function of the prices. Okay, and then this is your standard joint assortment and pricing. So maximize over S and P, the expected revenue, which is the revenue from each type K times the proportion alpha K, and this is the revenue from type. And this is the revenue from type. Okay, so that's the problem we want to solve. And before I sort of talk about how we approach it, I just wanted to quickly discuss some related literature. As I mentioned, conservative use models are being sort of studied in sort of, I've been receiving increasing attention in the literature. So I want to mention that there are models that have explicit search costs in how customers sort of make choices. So of course Geely has a paper. So, OSG has a paper, one of the seminal papers in that field. We do not model any search costs, so our model is different from those work. So, if we think of ours as these traditional considerations models that have been looked at in the literature, which are typically motivated by the cognitive limitations or that customers cannot consider everything that you have. Okay, now in this line of work, there are basically two types of models. So, one models that assume homogeneous preference. So, one model set assume homogeneous preferences. So, you just have like a single customer type. And most of this work is on looking at variants of the ML model. As I said, you can see your names here. And I apologize if I missed any work. I try to be as thorough as possible and list all of the papers. And then there's also this random concentration set model of Menzini Mariotti. Recently, it was published in OR. But basically, all of these models assume that reference. All of these models assume that preferences are homogeneous, whereas we look at a mixture model, so we allow for heterogeneity. There is some work which also looks at considering those models with heterogeneous preferences. So here I can categorize the work into two streams. So one is work that does focus on assortment optimization under ranking preferences. And again, we have people in the audience who have worked on this. For the joint assortment and pricing, to the best of my knowledge, I was only able to find one table. I was only able to find one paper by Rushdie Canton Pat which looks at these price thresholds so they assume that every customer has like a budget and they will not purchase anything any product that exceeds the budget now so one difference from that work is in in that work the concentration sets are exogenous okay so these thresholds do not depend on the specific offer set but as I mentioned in our work concentration sets are Constructions that are in logic. Okay, so then let me sort of get into the roadmap for how we solve the problem. So first I will present an equivalent formulation based on concentration sets of different customer types. Then I would have a reformulation based on concentration legalities of each of the types. And then finally, I'll talk about the solution approach using that formulation. Okay, so first. Okay, so first let's do the easy bit. So here, if I introduce this notation, that CK is the concentration set of type K customers, right? And because we know that the choice probability is zero for any product that is not in the concentration set, I can basically write this expected revenue as the following. So any J that is not in the concentration set will not contribute to the revenue, so I can just replace both these S's by the concentration set. Okay. And then any offered product is not in the consideration set of any of the types. So I have a J that is offered but is not considered by any of the types. Then basically I can drop it without impacting the revenue because it did not give me any revenue. So, what this means is to solve this problem, we can directly search over the consideration sets of each type, of course, and the prices. Of course, and the prices. So, I can come up with this formulation where I search for the concentration set of each type as well as the prices of all the products. But of course, I need to make sure that these concentration sets are consistent with the price. Okay, because construction sets depend on the price. So, I need to add constraints that they are consistent. But if I solve this, I get a bunch of construction sets. The offer set is nothing but the union of all the construction sets. So, that's how I. All the constructions. So that's how I can recover my office. Okay, so that's sort of straightforward. Now we're going to come up with a reformulation based on the concentration utility, which will help us sort of simplify solutions. Okay, so if you recall the concentration utility of a product J in type K, where we use this notation, so we just had u bar j in the slides, but now We just had u bar j in the slides, but now I also have a type, so I will use a superscript. It was theta transpose zj bar, right? So that is theta k. And now what I do is I split this into two terms. So this entries all the non-price features and j is of course the price. So since we assume all the non-price features are fixed, basically this utility can be written as follows. So it is beta j k minus theta k times v j. K times V. Okay, so that's the form that we assume. So theta k is the price sensitivity for type theta. And then if you remember what was the model, the model was that all products that have the largest potential utility are part of the concentration set. So that would mean the following, right? That all of these utilities are equal. Suppose we call that u bar k for the pencil. For the concentration utility of the type, right? Okay, so this is by definition, right? So if I have a bunch of products in the concentration set, they should have the same utility. Let me just introduce a variable for that. But what this does is actually it allows me to compute the price as a function of the concentration utility. Basically, you set this thing is equal to u bar k and then you solve for the price. So what this means is I can compute the price. Me, it says I can compute the price from the constrictions. Now, so that means I could replace this pj by this term, but then I also need to worry about these choice probabilities, but I can do the same thing there also. So, the mean positionality in the second stage was omega transpose Cj. Again, I can split this into two terms. But now this part in general could be different from the first, right? Because these have additional products, or sorry, additional features. Products, sorry, additional features. So we call it lambda jk. And here we assume that the price coefficient remains the same in both the first thing and second state. This is just for like notational convenience because you see this cancels out and I get a nice expression, but you can also look at the case where the artists just like the notation. Okay, so again, I can write the second stage utility also just as a function of the As a function of the concentration utility of the type. Remember, these are all kind of model primitives, these are parameters that are already estimated. So the only kind of decision variable is the concentration utility. Okay, so basically the bottom line is instead of searching over product prices, I can search over the concentration utility. And then I know how to determine the prices. Okay, so basically what I do is I reformulate the problem. I'll reformulate the problem where I'll replace the price by the price based on the concentration utility. And again, I'll replace the mean utilities that we derived in the previous slide. And instead of the prices, I search over these vector of concentration utilities u1 bar to uk bar. So now what is the benefit of this? So now you have reduced the search space from N prices to K utilities. Prices to K utilities. Now, in practice, if there's only a little bit of heterogeneity or like K is fixed, then we see that this helps us. Now, of course, we have to be careful because unlike the prices, which I have freedom to choose any price for any product, these utilities are not independent. So, we have to again ensure that these utilities are consistent with some underlying setting of the prices. I cannot arbitrarily set these utilities. Arbitrarily set this to do this. Okay, so again, you have to worry about constraints, but you'll see that those are easy to handle. Yeah, sorry. The constraints are the ones for the consistency of peak. Of the utility. And gold. So both, these have to be consistent, but also the fact that in the original formation, I could choose different prices. There's no constraint on that. Of course, the price have to be consistent with the construction sets. But here, I also have. Sets, but here I also have to introduce additional constraints to make sure that my use are also feasible because the u's depend on the prices, so I cannot arbitrarily set use. But yeah, basically it's like consistency constraints. Yeah. So this might be a nice question. So you asked capital K is produced by constant. Yeah. So then why can't I just, for any type, I look at the winners of the consideration shows that they have maximum UR. Now I have a essential Now I have essentially a distribution of south class suggestions that is a small subport problem with our outpost K, and then I just consider and choose an outsourced optimizer product. So I may have missed this. So you're saying forgetting about the endogeneity and just saying that, hey, so for every choice of type, there is actually a particular configuration associated with that, so that they have maximum impower j. They have maximum power change. Right. And then that defines the distribution of the concentration. So it's now assuming the first situation is a realization of the distribution and the short problem within the process. So I'm not sure if fully follow, but I we looked at an earlier version of the model where in the second stage, as long as the continuous set is non-empty, you make a purchase. So then we could come up with an MIP formulation for it. But here, like the component. But here, like the complexity was this kind of no purchase. So yeah, but yeah, they have you talking about that. Suggesting converting this into standard instead of change model, then it would be a hard problem. Oh, if k is a constant, oh problem. Okay, so okay. Okay, so those were the first two steps, and then in terms of how to solve this, so for a single type, basically the solution has a very nice structure. So, for a single type, suppose that products are indexed in decreasing order of these betas, the first stage attractions. Then you can show that the optimal consideration set is beta order, right? So, analogous to revenue order for MNF. And also, the revenue function is unimodal in the consideration. function is unimodal in the concession divided. So if I only have single type, I only have one integrity. So basically I need to solve order n unimodal pricing problems. Similar to linearity. Now for multiple types, basically the problem is more challenging because of the non-linearity in the objective function as well as of course this combinatorial structure of the concentration sets. So we have to make some So, we have to make some assumptions. So, we are currently working on proving the hardness result. Currently, we don't have one. But existing literature on pricing under LCMNL also typically imposes some structure on these utilities. So, our current model was very general that these could depend on both J and K, but existing work does have to make some assumptions on type independent utilities or type independent price sensitivity. Type independent price sensitivities. Okay, so that's what we have done to get some tractability. So we make this assumption that in the first stage, your constituency from the non-price features is homogeneous. So this is sort of a big assumption, but this allows us tractability and also kind of allows us to isolate the impact of prices on the consolidation advantage. On the conservation cell for much, right? Because the non-price features are the same, so the only way the types differ is sort of based on the prices, which products they consider. Okay, so what do I do? Basically, in that formulation, I replace beta JK with beta J. And this is the problem I want to solve. So basically, we have three key ingredients for solving this problem. The first stage, so if you of course naively try to So if you of course naively try to enumerate all the concentration sets, it will be like 2 to the n k for each type I have exponentially many concentration set. But based on this structure, we can significantly reduce the search space from 2 to the nk to n to the 2. So I don't have time to go into the details of all the results, but I just want to give some intuition. So imagine I have this matrix where each column is a product and products are indexed in decrease. And products are indexed in decreasing order of data. Each row is a type, and types are indexed in increasing order of price sensitivities. So if I assume that suppose product 4 is in the concentration set of some type here, this means that all of these products cannot be in the concentrations. Okay, so these become infeasible. So if this is 1, so suppose this is like a binary matrix, 1, 0, which tells me which product has included the concentration. Which product has included the concentration set. So, if this is one, all of these have to be seen. So, that allows me to sort of prune away a lot of these sort of infeasible concentrations. Similarly, again, if this is one, I can also show like for the previous types that have smaller price sensitivities, none of those products can be cancelled. Okay, so these are feasibility results. We also have some optimized results saying that any constituent of any type cannot have any gaps, so it has to be contiguous. Any gaps, so it has to be contiguous. Something like a revenue order with like eigenjutoes. Okay, but sort of I don't have time to discuss all the details, but bottom line is it allows me to decrease the complexity. So again, if k is small, k is constant, then sort of I can get point-only make illustration sets. This is the slide about the constraints on the utilities. So the first thing is you have to ensure that these are non-negative. The first thing is you have to ensure that these are non-negative because the construction set is formed by products that are preferred to the no-purchase option. I have to ensure non-negativity of product prices, so these utilities cannot be larger than the product attractions. I have to ensure that the constituency of products that are not included in the concentration set is less than the constituency of the type, right? So if I have a product J that belongs to some other type, but not. But not type K, then its utility should be less than right by definition. And then for this, you can substitute the price that you get from APAC. And similarly, this is another important message that you need to ensure that the price of the product in the constitution set of two or more types must be the same, right? Because this is not personalized pricing, this is the same prices for all the types. Same prices for all the types. So if I have a product that belongs to both the construction sets, then their prices must be the same. Okay, so I would get a constraint like this. So the key thing to note here is that all of these constraints are linear. So basically, we can show that at most there will be order nk constraints, linear constraints. And the final part is actually concavity. So we only need a minor assumption to establish that the revenue function is actually strictly concave. Is actually strictly concave in the construction. So, all we need to assume is that for each step, there is at least one product such that the second stage attraction is at least the first stage attraction. Okay, so all this means is that you are not kind of disappointed or your utility does not decrease for all the products when you learn more information. Okay, and we believe this is sort of like a minor assumption that you are not kind of disappointed with all the products. With all the products. And with this assumption, you can show that the revenue function is strictly concerned. Combined with these polyhedral constraints, we can leverage the existing convex solvers. So we leverage the Frankfurt algorithm, which allows us to efficiently compute the optimal transition. Okay, so those are like sort of the two key steps in the solution approach. How much time do I have? One month. Yeah. Yeah. So I'll skip this one, but I just wanted to show like some numerical insights. So here we want to compare how the prod how the prices that our model prescribes compare with LCM and L. So you saw that the utility, the revenue function is very similar because of the M and L form in the second stage. So we are interested in comparing the optimal prices that are no prescribed and L C M L prescribes. So to ensure like it's not fully absorbed. Sure, like it's not fully apples to apples, of course, because these are different models. But to ensure that they are as close as possible, we assume that the utility for product J in class K customers in LCM and L is of this form. Again, epsilon J is your IIB dumble. And in our model, we assume that the second stage utility is equal to the first stage for all products and all types. Okay, so what this means is that the constitution means is that the concession utility is the same as the mean purchasing utility. And what this does is basically ensures that the utilities in both stages of my model is the same. And LCMNL of course just has a single utility. So this is just kind of making them as close as possible. Because if I have this flexibility in one of the models then it kind of becomes harder to get any insights. Okay, so then we sort of plot the optimal prices here. So here each row is one problem. Here, each row is one problem instance, and each column is a product. And of course, the cell shows the price for that product. So, these are prices from like 0 to 6.4. And so, on the left, you have the MBL model, and any selling byte means that that product was not part of the Akuna solve. So, on the left, we are solving joint assignment pricing. On the right, we currently just solve pricing. Currently, just solve pricing because we are not aware of any work that does joint assortment pricing under LCML. But what we observe for this model is that LCMNL basically prescribes very similar prices. So if you look at any row, all the prices are close to in general, like you would have in an MNL. And the reason for that is we can show that similar prices is a stationary point for the objective concept. So we are still working on showing whether it is optimal. Whether it is optimal, and I'm not aware of a result that shows that. But if you look at our model, of course, there is more variation in the prices, and we prescribe larger prices for products with larger beta values, which seems more reasonable. Okay, so yeah, I'll stop here. Just sort of some ongoing work. So we're currently revising the paper. So one thing is we want to establish some hardness results for the general problem. We are seeing whether we can extend some of these spectrums. Seeing whether we can extend some of these structural insights to more general versions, such as product-dependent pricing. So, currently, we just have theta k. So, what if we have like theta j k? That also depends on the product, and of course, like a more expensive type of thing. So, I'll stop here. Sorry, I'm going to break over.