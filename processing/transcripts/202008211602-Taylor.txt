Activity. So there's five different levels from just over, say, 16% up to nearly 54%. And connectivity is really the number of links as a fraction of the number of links in the fully connected network. And we implemented just a static allocation with the optimal allocation number of circuits. Of circuits, which was the blue line here. And then we implemented this reallocation, just taking circuits away when they were getting full and reallocating, sorry, finding extra capacity when you're getting full. And it brings the blocking probability down dramatically. In this case, here with the connectivity of about 33%, say, it 3% say it more than halves it. So, as I say, we don't have any analytical way of working out what this curve should be, but we do know by simulation that this idea works. So, but there are still some questions. The trigger of an attempt to reallocate capacity was that a link became full. And is that the best trigger? And if we're doing transit rerouting, as I mentioned before, the choice of donor routes is given, it's fixed. But direct routing, the choice of bona routes is not fixed. And so are we making the best choice? And the answer is we probably are. So maybe we can do even better than what we've done. So, our next thought was to design a method which the network can monitor its own capacity requirements and reconfigure its capacity as required. And so, instead of letting the trigger happen when one of the routes gets full, periodically each transit route publishes what it calls buying and selling values, VASI per unit capacity. Capacity and the direct routes also know they're buying and selling values. So, this isn't a market, but we're actually sort of so it's not like that the routes are individual entities trying to take part a market. But what they do do or what the manager does is work out the value to each route of extra units of capacity. So, the value of an extra unit given your current state is the buying price and the value of an extra. Buying price and the value of an extra unit, given the value of giving up an extra unit, what you would want to do that is the selling price. And then what you do, it's quite simple at these periodic points. If the buying price on the transit route is bigger than the sum of all the selling prices of the links on the direct routes corresponding to the links on the transit. Routes corresponding to the links on the transit route, then you take capacity from the direct routes and you give it to the transit route. On the other hand, if the selling price is lessening with some of the buying prices, then you transmit capacity from the transit route back to its constituent direct routes. So you just basically keep monitoring and saying, well, given your current state, what's the capacity? What's the capacity worth to you? So, if you're a long way from being full, capacity is not going to be worth very much. If you're close to being full, then your capacity is going to be worth quite a bit. So, you just keep monitoring these prices and you make these transfers according to whether these inequalities hold or not. And how do you set these things? Well, that is a whole separate line of research. But if you start thinking about the loss. But if you start thinking about the loss network or even just a single MMC queue, MMC loss queue, the capacity is only important when a route runs out of it. It doesn't matter what the band is if you're not close to it. So the way we think of the value of capacity when there are any connections currently present is to calculate the expected loss revenue that would occur over some time horizon if the route's got capacity Y. If the route's got capacity Y. So you imagine if you've got a link that's almost empty and a capacity Y, then you're unlikely to lose very much revenue in the short term because the thing fills up. So this requires a transient analysis of the revenue, but we've actually worked out a way to do that. So we, Belinda Care and So, Belinda Carey and I showed how to evaluate this thing called the capacity value function, and Belinda and Tony Krasinski and I wrote another paper that looked at a lot of its properties. Okay, so in this loss network, capacity is discrete. We're thinking of integer numbers of circuits on each of them. But let's just forget that for a moment and imagine the capacity. Forget that for a moment and imagine the capacity is continuous. Then our optimization problem will be to maximize this revenue function, the amount of revenue we get, subject again to the capacity being non-negative. And we want the sum of all the capacities, the sum of the capacities on any of all the routes going through a single link to be equal to the To the available capacity. And I've got equality here because you've got to remember one of these routes is a direct route. So if there's any leftover capacity, you might as well give it to the direct route. So it can have equality there. So now let's split these sets of routes into two. Early T is the set of transit routes, and early D is the set of direct routes. So we're just going to split the previous sum, the sum of all the Sum of all the revenues earned into two. So I haven't done anything complicated there. But what I'm going to do is use the fact that we give the capacity allocated to the direct route, J is whatever's left over once you've allocated the capacity to all the transit routes. So we rewrite this just in terms of the capacity on the transit route. Just in terms of the capacity on the transit routes. So there's the revenue earned by the capacity on the transit routes. And this other thing, we look at it for each link and we look at the revenue earned by the direct route on that link, which is the difference between the capacity, well, the capacity it gets is the difference between the total capacity of the link and what we've already allocated to the transit routes. So that then again, these allocations have got to be non-negative, but now we have less than or equal to here because we're actually only doing this optimization of the transit routes. And in some sense, the allocation to the direct routes is what are slack variables. They're the slack variables in this inequality here. This is getting a bit more complicated, but it's a Complicated, but it's a constrained optimization problem. So we use a Lagrangian formulation. So there's our original objective. We'd introduce Lagrange multipliers lambda j, which we've got for capacity constraint on each of the limbs. And we've got another Lagrange multiplier, eta, which is to do with the non-negativity constraint of the capacities. So there's a Lagrangian function. Function and we can write down some Karashku and Taka conditions. They're getting more and more complicated, but roughly speaking, this is a condition that says the derivative with respect to R of the capacity minus the derivatives of all the RJs on the links which are used by radar. So, this is everything that's got a YR in it. Well, that's got to equal zero with the complication that, of course, the Lagrange multipliers that come into play at the boundaries are there as well. But I want you to think of it: what this really is trying to do is make these two derivatives equal to zero, and the Lagrange multiplier. And the Lagrange multipliers are there. This is the complementary slackness, the product of the Lagrange multiplier and the constraints got to be equal to zero. So either the Lagrange multiplier is equal to zero or the constraint satisfied with equality. And of course, we want the Lagrange multipliers to be non-negative. So what does that do? Well, you can think of this. You can think of this now. Go back and think about our capacity relocation scheme. What it's actually trying to do is to attempt to satisfy the KKT conditions for that optimization problem. As I said before, this is, we had an estimate of the buying price for the transit route, which is really a derivative with respect to the capacity of the revenue it's going to. Of the revenue it's going to learn. And this is the sum of the derivatives with respect to capacity of the revenue that's earned on all the direct routes. So if this is bigger than this, we want to move capacity that way. And if this is bigger, we want to move capacity back the other way. So what we're really trying to do is make these two capacities equal. That's what our reallocation scheme was doing, at least in the middle of the state space, where we weren't hitting the boundaries, hitting the capacity boundaries or the non-negative. Hitting the capacity boundaries or the non-negativity boundaries. So if you imagine this is zero, out in the middle of the state space, we were actually trying to satisfy the KKT conditions. In fact, what our support minus hill climbing algorithm to try and solve that optimization problem that I just defined. So that's okay. We know what to do in the middle. And putting the Lagrange. The middle and putting the Lagrangian view tells us what we should do on the boundaries when one of them is equal to zero or when we hit the capacities of the links, which we have actually sort of therefore modified what you do with that capacity reallocation scheme when you hit the boundaries. Okay, so that's all I want to say about that, but I just want to move on with one more bit, and I've got what? Bit and I've got what maybe 15 minutes to tell you about a slightly more complicated version of this problem. So let's go back to our loss network. Now, it can be that as a request, you're completely indifferent from the resources you use. So here's an example: you want to connect A to F, and you don't, none of us actually even know what. Actually, even know what routes our electronic communications actually use. So, I'm zooming you guys, and I've got no idea where the various bytes are going between Canada and Australia. So you could be indifferent. So, a request requiring connection from A to F, it could go via E, C, and B, like it did there, or it could go via D and B. And if you're an ANF, you don't care. So you can be indifferent. So that makes this problem. This is an previously we said that requests occurred on routes and you actually, and what that really did is specify, if you think about it, it specifies the resources you need. But in this case, and in a lot of cases, we're completely different. Can you just excuse me? I've got to go and stop my dog doing a bad thing. I've got to go and stop my dog doing a bad thing. This meeting is being recorded. I'm back again now. Sorry about that. Again, now, sorry about that. Um, we've never had to do that in the middle of a talk before. So, okay. Um, so you the situation is that requests for a particular service could be indifferent to the resources that get used. Um, there could be equivalently good sets. So, in this case, we've got a problem of choosing which set of resources to use, if any, because we might still want a bucker request, it might still not be worth it. Bucker equation. It might still not be worth accepting it. So, how are we going to think about this situation? So, this is going to slightly change our stochastic assumptions. We still have requests of type L arriving on the Processing process with rate lambda L. So, the type of request is now going to replace what we previously had as a root. The durations are the same as before, exponentially distributed. Exponentially distributed with mean UO inverse. There's a set P L of roots that are capable of accommodating a request of type L. And if root R dashed is chosen, then we take AJR dash units of capacity on every link J of the root and hold it for the duration. And we are going to want to allow the possibility of blocking. So for every different request type, there's an empty route, which means that we just don't. Empty route, which means that we just don't accept it at all. As before, the expected revenue earned by a request of type L is theta L. And the cost per unit time of unit capacity on link J, this is a new thing. So we're imagining that there is actually a cost for a particular link. Doug mentioned bandit processes, and I'm going to mention them too. We're going to think of this. Think of this. Well, to analyse the situation, we're going to take some inspiration from the literature on multi-companded processes. I've got to say, a bandit in America is a slot machine, a gambling thing. We don't use the word bandit for that in Australia. So when I talk about multi-armed bandits in Australia, people say, what do you mean? And I have to explain what it is. It's what we would call a poker machine. I'm assuming you've got the American terminology in Canada. Anyway, this is a multi-armed bandit, and the problem with the multi-armed bandit process is that you've got a certain number of, in the bandit literature, these things are Markov decision processes with an action, a binary action. You can either pull the handle or not, and there is a restriction on the total number of bandits you're allowed to pull. So here it is. So here it is. Bandit processes a special type of market decision process, in which there are just two possible actions. And the first one is equals one, which is to continue. That produces an instantaneous reward and the state changes according to some Markovan transition matrix. That should be say A equals zero, freeze, and A equals one, which means that the Markov chain stays in the same state it was before, produces no rewards. Was before produces no reward and the state doesn't change. And a multi-ambanda of n of them. So if you like, it's a vector whose states are given by Markov chains. And you can get to choose which chains to activate. So at each time T, one in the classical multi-combanded situation, only one bandit process can be ever activated. Activated. There's a reward for that one. And all the other bandit processes remain passive and they remain the same state. And the objective is to choose a policy. So you look at the states of all the bandits. And what you want to do is maximise the expected discounted reward. And Kittens was mentioned by Doug again. He showed that the optimal policy for multi-ampander problem is an index policy. What that means. What that means is there exists a function for each bandit. So it's a function of the state of that bandit. It's called the Gitton index, and it can be computed separately for each bandit. And the optimal policy for the multi-armed bandit process is to continue the bandit with the highest index. So you pull the arm of the bandit with the highest index. So it's a beautiful piece of work, getting to work. Piece of work, getting some work. And yeah, so that's the way it works. I will say, just before going on, there are a couple of things about the Gittens index. There are a couple of assumptions in this multi-amband that make the Gittens index work. The first is that, in fact, there's only one amyloic pool, and an obvious generalization is where you can. And an obvious generalization is where you can pull some number of arms which are bigger than one. And also where it's possible for one where the arm didn't get pulled to still change its state. And those things are called restless bandits. And if you have restless bandits, there's also, in some cases, under some conditions, an index called the Whittle index, which you can calculate separately, just like the Giddens index. And it's not always provably optimal, but at least a good heuristic is to continue the bandits, the number of bandits, however many you're allowed to pull, with the highest indices. So the Gittens index is provably optimum for the multi-arm bandit problem. A Whittle index is at least a good heuristic for a restless multi-arm banded problem, and in some cases. Problem and in some cases it's proved to be optimum, at least asymptotically. Okay, so what has this got to do with our loss network allocation? Well, let's assume for a moment that we don't have any capacity constraints on the resource pools. So that means that every arriving request of Type L should be clearly accommodated on the route that gives it the best value for money. And the best value for money is. And the best value for money is the difference between the rate of earning revenue and the rate of incurring costs. So you just find the route that's got this. If that maximum is non-negative, it means you are actually making money from accommodating this request, then you accept it on the one that's the maximum. If the maximum is zero, well, then you don't make any money, you might as well accept it. If the maximum is negative, then That if the maximum is negative, then you don't do it, you just reject it. And it's really this thing here is actually an example of a very, very trivial Gittens index. So once you take the capacity constraints into account and worry about the possibility of reserving space for more profitable future arrivals, this gets much more complicated. But what you can do is you can. But what you can do is you can relax the optimization problem. And that's what Jing Fu, Bill Moran, and I have done recently. And by doing that, essentially assuming what you do assume is that the acceptance rejection problem is not binary. You just do it with a certain probability. So it makes the thing continuous. And that allows you again to use a Lagrangian formulation where there are Lagrange multipliers. And you can think of them as prices for. And you can think of them as prices for capacity and another price for actually having to make an allocation decision. So you have this same thing we had before, this sort of the best value root, but it gets modified by Lagrange multipliers. But once you've done that, you get an index. And then you do the same thing as we did before. When you get an arrival of a certain, on a certain request of a certain type, On a certain request of a certain type, you look at the indices of the routes that the alternative routes it could possibly be on, and you choose the one with the highest value. And that's the end of my talk. So thanks very much for listening to me. Thank you very much, Peter, to give us a very interesting talk. Any questions? Any questions? Shall I stop sharing my screen? I'll do that. So we have some time to take questions or comments. Peter. Hi, Shimmy. How are you going? I'm good. Now, when you want to reallocate capacity, To reallocate capacity from or you move capacity from one place to another, there's always a cost associated with that. Have you considered that cost in your model? No, we didn't put the cost in the model. I mean, we're thinking this is entirely happening in software. The whole thing is logical. So it's not like you're picking up any piece of physical infrastructure, but of course. Infrastructure, but of course, there might be some still some cost to doing it. But even if you're thinking, like my gardening example, you're a gardening store, and you might say, well, I've reserved a certain group of, you know, two shovels, a spade and a fork for people who want exactly that allocation. That's really what it is. And now I can just as easily say, no, instead of reserving three sets of those resources, am I going to Of those resources, am I going to reserve two? So you can do this logically. You don't, you know, it's not like actually moving physical stuff. So it depends on the applications, right? Yes, that's right. But you could put it in. You could actually put the cost of that in. As I say, I don't know a way to analyze, to actually derive the blocking probabilities for a network where this capacity relocation actually happens. I mean, we can do it. Happens. I mean, we can do it, we can simulate, we can see that it works well. We can decide what the best allocations of decisions are, but you've still got some work to do to get the actual value. I guess you could do that via the micro decision process framework. We haven't done that yet. Any other questions? If not, that's a thank you. Can I ask a question? Do you call them bandits in Canada?