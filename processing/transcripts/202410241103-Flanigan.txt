Wait for the next version of the democracy. So I generally, my research work on facilitating direct participation in democratic governance. So we're going to see some applications learning Siri for that domain today. Okay, we're going to focus on one particular application. This is joint work with Carmel Bahara, Angulos Asos, and Ariel Pekache. Asos and Ariel Pacatche, who all of you probably know, and Carmel, you probably don't know her, but she's applying for PhD programs this fall. She's absolutely fantastic. So, look out for her application. Okay, so the particular application we're going to be thinking about mostly today is called Sortition, which is the idea of randomly selecting people from the population to serve as political representatives. I'm seeing some scared faces. We're going to just drive right past that. This is being done whether you like it or not. Doubt whether you like it or not. So, okay. I mean, I'm. It's fine. This is a longer discussion. Lunch will be fine. Okay, so the way that this random selection actually works in practice is that we have some reference population whose views we want to represent in a decision. And what we do is we send out a bunch of uniformly randomly selected households to receive letters that invite them to participate in this democratic process. Those who say yes form what we're gonna call the pool. Form what we're going to call the pool. And we're going to say that this pool is of size added. And these are the people who've agreed to participate. And it's from these people from which we're going to choose the final panel, which is the group of people who are actually going to partake in the process. We're going to call this size K. After this panel is chosen, they go through this pretty intensive process, which we're going to call a citizens' assembly, although this goes by a lot of different names depending on the application domain. And what this looks like is something like this, where you've got these people who are. Something like this, where you've got these people who are on the panel sitting around tables, learning from experts, discussing the political issue over several days, and oftentimes coming to some kind of recommendation that's then considered by government. Okay, so this isn't just like a made-up application, it's something that is like really happening and having impact on policy globally. This has been especially true over the last 10 years. So in the 2010s, Ireland used a Citizens Assembly to legalize same-sex marriage and abortion. Marriage and abortion. It's been used at the national level in France, France, in France, most recently on a referendum about assisted dying. There's a permanent citizens' assembly in Brussels, which is consistently replenished with randomly chosen citizens, and they advise the government. Other examples of this kind of models, like a permanent assembly, also exist at the regional level, for example, in the German-speaking part of Belgium. But you don't have to look very hard to find headlines talking about how people are pretty excited. Talking about how people are pretty excited about this kind of democratic paradigm as an antidote to things like distrust in government, polarization, misinformation, that sort of thing. Okay, just a few more notes about the setup, which will be important for this talk. The panel that we choose has to satisfy quotas, which we're going to think of as like specific numbers of people that have to be on the panel from different groups. So these quotas have a very particular structure. They're not the kind of quotas. They're not the kind of quotas that you would use, for example, in stratified sampling, where you have a whole bunch of mutually exclusive strata and you sample for no strata. Instead, the quotas are marginal, which means that they apply to like individual attributes at a time. So, for example, we might say the panel has to be half high education, half low education, half older age, half younger age. But we don't really care about the combinations of attributes that compose those particular quotas. And this is not because we don't care about those combinations of attributes, but it's just because they want at least marginal. Because they want at least marginal representation on so many attributes in these assemblies that you just can't protect all the strut. It's just not possible with the size of the panels. So, typically, you can think of there being like seven of these categories, and each of them has between like two and ten possible variable assignments. Quotas make sense? Okay, cool. And so these quotas are specifically chosen to enforce that the panel looks demographically like the population, and the reason that we need to do this is that the pool. To do this, is that the pool generally looks nothing like the population because this stage, even though it's random, it's based on an opt-in filtration. So the people who sign up tend just to be like more highly educated, more male, older, more wealthy, etc. And so the important takeaway here really, because the pool will be relevant a little bit to this talk, is that we're not really going to assume anything about who's in the pool. It can kind of be whatever it is. And so for those of you who have seen me give a talk on certain before, I will just Give a talk on sortition before. I will just contextualize this talk a little bit by saying that usually what I talk about when I talk about sortition is the algorithms that are used to choose this quota-compliant panel from the pool, which is an NP-hard problem, and there's like a whole bunch of work on how to do that randomly in computer science. But today we are not talking about that. We're going to actually look at what happens after the panel is selected and we've satisfied our quotas, all good. And we're going to have a different problem, which is that between the time that the panel is selected, Between the time that the panel is selected and the beginning of the assembly, there's typically about like three months of time, and people are going to drop out in between that time. So, what happens is we're going to say that people are going to drop out independently with some idiosyncratic probability PI. Is I each person? Yeah, good question. Yes, and so then at the end of this, we're going to end up with our panel, but it's going to have a hole in it. It's composed of everybody who left. And the biggest problem with this is that our quotas are no longer going to be satisfied. Quotas are no longer going to be satisfied. Yeah, so originally, when they choose people from the tools, they over-select because they know something drop out? So, sometimes people do that. That is going to be like one application of what we're going to talk about today. I think a simpler way of thinking about the problem, though, is where we don't overselect. We just choose our panel, people are going to drop out, and we're going to have some alternates then that are going to take their place. So, but we can talk at the end about how, like, solving this problem that I'm going to solve is basically the same. This problem that I'm going to solve is basically the same as the problem of over-selecting. Okay, so the idea then is that we're going to choose some alternates that are going to replace the dropouts in a way that restores the quality. That's the goal. So to give you just a little bit of intuition about what kinds of people can replace what kinds of people, the first thing to know is that exact replicates are not needed to replace dropouts. So let's say our dropout set is composed of these two people. The first person is highly educated and older. The second person is less educated and older. The second person is less educated and younger. We, of course, can replace them with exact replicates, people who look exactly like the people who dropped out. But also, we can replace them with people who have different combinations of attributes but which sum to the same thing. So the punchline here is just that like one alternate set can be useful against multiple sets of dropouts. Yeah. Are you allowed to drop out people who haven't dropped out if it helps you? No. You were collateral damage. You were collateral damage. I'm so sorry. That would be very helpful, though, so good intuition. So, yeah, it's a really good question. It wasn't clear whether you have a quora, like you have to have at least three old people, or you need the percentage, like you have to have at least half of your population in your family. So the percentage versus the exact number shouldn't really matter, but the difference is more like whether you want, are you asking if you want like a lower bound or an exact quantity? Well, if. Quantity? Well, if the number of participants is fixed, then yeah, it's the same. The number of participants is fixed, yeah. So then the question is: is it a lower bound or is it an answer? It's an exact number, yeah, yeah. Yeah, I mean, in practice, it can actually be lower and upper bounds, which makes the problem a little bit more complicated, but let's just think of it as exact numbers for now. You look confused. No, yeah, because you think that you just want one representative for every not that it should be the number of representatives. The number of representatives is proportional to the high education versus low education population. So, what I said: you want just one highly educated and one lowly educated, or would you want that the proportion of high and low in your representation would be the same as the low population? Second one. Yes. Yes, that's right. Exactly. Okay. And the second piece of intuition is just that there may be dropout sets D that are possible to happen for which the pool contains. To happen for which the pool contains no perfect replacement. And this is really coming from the fact that we're not assuming anything about the pool's composition. So if this person is the only dropout here and we don't have an exact copy and our quotas are exact, there's just nothing we can do. We can't fix them. Okay, so just to simplify our diagram slightly and remove some of the extraneous stuff, one other piece of notation I want to define is that after people drop out independently with these probabilities, this induces a distribution over dropout sets from which our Dropout sets from which our dropout set is actually drawn. So the support of this distribution is every possible dropout set that could fall out of the panel. So every subset of the panel. Okay, so the challenge here, really, is choosing the alternate set before we actually see the realization of the draw from that distribution. And you might be thinking, why do we have to do that, right? Why can't we just wait until everybody drops out and then just replace them? You know the PIs and you don't know the PIs. Next slide. But yes, you just spoiler alert. Slide, but yes, you do. Spoiler alert. Okay, so you, but you don't see the actual realization of D. And the reason is that people typically drop out right around the very last day of participation. It's very adversarial in that sense. And sometimes they actually drop out on the first day of the panel. So they just don't show up. And so you can't just call people from the pool who you talked to three months ago and you're like, hey, can you just come join this panel? So you can imagine doing something where you kind of You can imagine doing something where you kind of try to do it online, but really, I think in practice, that won't get you very far because most of the dropouts are going to happen so late that you really need to just plan to select them right after you select the panel without seeing any realized dropouts. And do all of A have to participate? We're going to assume that they do, yeah. Got it. Is it like jury selection or the alternates where you have to go with any drop? Yeah, it's kind of like that. Yeah. Yeah, that's true. Except, I mean, those alternates are not chill. I mean, those alternates are not chosen on the basis of being good replacements necessarily for the people who. No, no, but here your alternates are initially you add into the pattern. Actually, well, you can kind of, I mean, it doesn't really matter, but in practice. In the Jewish case, it's not. It's a situation. Oh, sorry, sure. Yeah, there is like a practical domain difference there. Mathematically, there's yeah. But no, in practice, you wouldn't add them to the panel. They're just kind of like on retainer. Okay, so to your question, you do get to know the PIs. You do get to know the PIs. And so this will disappear in a second, but you just remember that these PI's are an input to the algorithm. And you might be thinking, how do we know these probabilities? Well, you can just predict them from historical data. So if this is our data set, we have all these attributes of people from past panels, and we have some y variable indicating whether or not they actually ended up dropping out. These predictions will not be perfect, but that's what we're going to do. And for now, we're just going to assume that they're not. Does that make sense? Make sense? Okay, so our goal then, because we don't actually know the realization of D, we just know the distribution, is to choose the alternate set with the highest expected success over D as randomly drawn from the dropout distribution. So to be a little bit more formal, our expected success of A is just equal to the sum over all possible dropout sets of the probability that that dropout set drops out times the indicator that A can replace that dropout set, which means not That dropout set, which means not that A can just be plugged in as is, but that there's some subset of A at least. You need to limit the size of A, right? That's the next slide. Yes. That'll be the next slide, but yes, we're going to limit A. Good intuition. Okay. Maybe the first question that you might be thinking is, like, is this really the right measurement of success, right? Because maybe, you know, I've got two alternate sets and neither of them can replace D, but one can get much, much closer. So you can think of more continuous measurements. We're going to just Continuous measurements. We're going to just think about the binary measurement here, but like everything that I'm going to talk about is going to extend it. Our budget is A, good. And exactly for the reason that you said, which is that if we can just choose as many people as we want, the problem just gets easier and easier. But the reason that you actually do have a budget in practice is because you often have to pay the alternates a little bit to keep them on retainer, and especially if you need them to attend the first day. So practitioners can't just choose as many as they want. Okay, just to give you a little bit of a sense of like what Okay, just to give you a little bit of a sense of like what are the scale of these numbers, you should think of the pool size n as like a thousand, the panel as about a hundred, and the number of dropouts as around the scale of ten. Okay, so this is our algorithmic problem now, just written in mathematical notation, finding the alternate step that maximizes that expectation. Okay, so this is feeling like a little bit NP-hard, probably. There's a lot of combinatorics going on, so let's like unpack the combinatorics here a little bit. Unpack the combinatorics here a little bit. So the first combinatorial aspect of this is that if you want to brute force this search over all possible alternate sets, you're going to need to look at all sets of size A within this white region here, which is n minus k choose A of them. If you want to brute force the search of whether A can replace D, you're going to need to look at every subset of the alternate set of size D. And this should be really properly restricted to be less than 0. Properly restricted to be less than or equal to A, because of course, if B is larger than A, then like it can't replace it, and you already know that. Okay, and then the last thing is that when you actually go to evaluate an individual A, you have to potentially look at all possible dropout sets that are in the panel, which is 2 to the K. Okay, so the one of these that we're actually really worried about is this one. And there's a few reasons for that. First of all, A is like not typically that big. So these are like... Typically that big. So these are like integer linear programs, but they're like not super bad. And in practice, you can solve them pretty fast. So even though that's going to contribute to NP hardness in A, we're not actually practically that worried about it. So to understand whether this problem is actually really algorithmically hard, we're going to assume that we have polynomial time oracles for those and see if the problem is still NP-hard. And unfortunately, it is, and that's exactly because it's NP-hard to compute the expected loss of any individual A. Any individual A. Okay. Does that make sense? Can you repeat again which parts you assume you have an oracle for? The pink ones. Which are just dependent on an A. So just given an A, can it replace B, this part? Yeah, that's part of BR. It's a partition function, so it should be. For any probability distribution, you want to find a normalizer, you have to do exactly the same thing. It doesn't PR. Cool. Okay, we have a different proof, but yeah. Okay, we have a different proof, but I didn't know about that proof. Great. It's exactly that. If that helps anybody, in physics, it's very common to talk about the partition fraction and how it is. Good. Well, apparently that result is correct, so glad to know. Okay, so this is annoying. Like, primarily because we can't even evaluate an individual alternate set. And this is not just a problem algorithmically, but practitioners are choosing an alternate set. Engineers aren't choosing alternate sets, right? They're just like picking the ones that they feel like are probably going to be the best based on their past experience. And we have no idea how to even tell what is the probability of that being successful. Yeah. You're okay with the slide approximations. Please just send them a couple of times for the propaganda. Everyone is too smart. Yes. I was going to say any ideas, but you already did the idea. Okay, great. Yes, this is the application of like learning theory, but it's like not groundbreaking learning theory. In fact, it's like chapters one. Learning theory. In fact, it's like chapters one through six of chapters. Okay, so great. Okay, so we're going to do empirical risk minimization. So you can draw samples from this like inaccessible distribution, and the reason that you can sample it is because you have access to these independent PIs. So you just draw the PIs, that's equivalent to sampling this distribution. You're going to get some empirical distribution, and then you're going to compute the optimal alternate set on that empirical distribution. Okay. Yeah. Is it reasonable to assume that dropouts are independent? Reasonable to assume the dropouts are independent because it seems like this is a rising front, assuming independence. But you could just build a distribution over dropout sets if there's like correlations between chemicals. Yeah. You don't need independence, it's just like kind of an intuitively easy way of understanding how you sample that distribution simply. But I think the independence assumption here is actually kind of innocuous because the decision to drop out is kind of like based on like idiosyncratic shocks that people experience. So it can certainly be related to people's attributes, and the predictions would capture that. But like, yeah. Predictions would capture that, but like, yeah. Okay, so then the question, of course, is how big does S need to be for these to have similar expected success? So we're going to formulate this as a path learning problem. This is not a new trick, by the way. The same one was used by Peters, Prokacha, and Sue in a recent paper in a different domain. So, just to kind of walk through the mapping, the hypothesis class here is all valid alternate sets A. And any individual hypothesis will map. map each dropout set to the domain 0, 1, which encodes whether the alternate set A can replace the dropout set D. So the correct, but like almost certainly unattainable labeling is all ones, which would mean that you have some kind of alternate set that can replace every dropout set. That would be the dream, but it's not realizable. Okay, and the last thing to know is that with this formulation, minimizing the expected 0, 1 loss is the same as maximizing the expected success. Maximizing the expected success. So to see this, here's the expected 0-1 loss, which is just the indicator of whether A of D has the correct label. This is exactly the same thing as the complement of the event that, the indicator that A can replace D, because this just means that A can't replace D. So nothing fancy going on here. And this is just the same thing as 1 minus the expected success. Okay, and so then the question is. Okay, and so then the question is: how many samples do we need? Probably not that many people are surprised to find out that we only need polynomially many samples because our hypothesis class is finite. So our hypothesis class is all of these subsets here. Its size is bounded above like that. And so then we apply, for example, Cheeky's theorem here, 2014, and we get that the sample complexity is bounded above by the law of the size of the hypothesis class plus some deltas and epsilons. And so we just plug in the size. And so we just plug in the size of our hypothesis class, and we get an upper bound of the sample complexity that crucially is polynomial in A and M. All right, great. Cool. Okay, so cool. So now we have a polynomial time algorithm with an asterisk there because it's not polynomial time without the oracles that I assumed, but with the oracles I assumed we're good. Okay, so what are we going to do? We're going to draw our S samples to get our empirical. Draw our S samples to get our empirical distribution. We're going to solve the entire problem, pretending our empirical distribution is our real one, so we're going to find the best alternate set over our empirical distribution. And now, solving this problem is much easier because this sums over only polynomially many dropout sets. And then we're going to output the empirical risk minimizer. And this gives us the guarantee that with probability at least one minus delta, what we have produced is nearly optimal within epsilon. Within epsilon. And as a bonus, because of uniform convergence, we can evaluate any alternate set within a known tolerance. So now we can evaluate other alternate sets that are also not necessarily very good. And so this allows us to actually compare whatever algorithm we ultimately go with to what practitioners were doing before. Okay, so zooming out very, very slightly, all of this falls after the first step, which is learning these dropout probabilities PI. Is learning these dropout probabilities PI, but this is really the whole pipeline of the solution. So the sample complexity bound that I showed you was like very simple for the purposes of this talk, but you could get more fine-grained complexity bounds in terms of parameters of the problem, and this can actually be really useful. The techniques that I was using were like pretty simple, but there's certain structure in the quotas and attributes of people that can allow you to get better sample complexity bounds. And this can be really useful because it can make the algorithms faster. You also want this whole pipeline to be. You also want this whole pipeline to be robust to errors in these estimates, which is kind of like a different type of proof technique, but kind of interesting. We're still working on that, though. And then finally, the data from which we learned this is historical data over many panels where there were kind of heterogeneous attributes, but many of them were like kind of similar. And so this is kind of an interesting empirical learning task where you want to make the most out of pretty messy data. Okay, that was pretty fast. But. But this was a problem that we solved today, which is an application for addressing dropout in the selection of citizens' assemblies. I have other work, in particular, this one project which I'll tell you about kind of briefly, that uses learning theory in a completely different way. So this is a project with Madeline Kinch, who's also applying for PhD programs right now. She's also absolutely fantastic, super interested in learning theory. And so what we're looking at here is how to elicit people's preferences in things like a delivery. Preferences in things like a deliberative context when the set of options that they can choose from is really large and really hard for them to access. So, for example, let's say that I want to learn some kind of function that measures, or like let's say that I want them to decide on like some function that measures how vulnerable a population is for environmental risk. Okay, so this is like a complicated function with like many numerical variables. And I can't just like ask people in the room, what function do you think is the best function? What function do you think is the best function? Even if you show them a function, they can't necessarily tell you, like, is this a good one or not? And so, a lot of voting assumes that people can just rank alternatives or kind of give you their direct preferences. And here, the space is too big, and people can't even engage with the alternatives. And so, what this is trying to do is design queries that allow you to ask people simple questions that, in very few samples, you can learn a lot about which kinds of those functions, for example, people think are the right ones. So, this is kind of The right ones. So, this is kind of interesting because it's a little bit different than active learning paradigms that I think people often think about. The queries here are significantly richer because you have people in a room. So you can ask them a lot of questions about what they believe and why, but you don't have that many samples because you can't necessarily ask them that many questions because the cognitive load of like considering different examples is really high. So, anyway, it's just a slightly different regime. So, anyway, that's one example. Yeah. So that's one example. So what are some examples of the kinds of questions that Sure, so in the example of environmental risk measurement, you might say, okay, here are like three communities, and here are some scores that I could give them that measure their environmental risk, and here are some of their attributes, and they would differ on some of those attributes. And then you would ask people, you know, which of these communities do you think actually experiences higher risk and why? And so then they can tell you, I think that this score is wrong. I think this community's risk is being undercounted. I think this community's risk is being undercounted. So you're learning something there not only about what is the absolute score that should be output by the function, but you're also learning what are the mistakes that the current scoring function is making. One example. Oh, cool. I'm looking forward to it. Okay, and then one other application of learning theory that I haven't worked on, but I think would be interesting, and a lot of practitioners are pretty interested in. And a lot of practitioners are pretty interested in is designing multimodal recruitment methods for recruiting people into the pool. So just sending out a bunch of letters is what people often do, but there's other ways, right? You can call people, you can text them, you can email them, you can also go to their door. And all these have different costs, and they also have like a higher yield of certain populations. And so making decisions about how to balance these different modes when at the beginning you don't actually know what the response rates are going to be can be really important. Are going to be can be really important. And an interesting twist on this is that at the end, your goal is to get a pool that's represented in a way, or representative in a way that is good for the combinatorial optimization that's involved in going from the pool to choosing the panel. And so the kind of the downstream application of the output of your sampling is combinatorial, which is that. Two stages. First, choosing the pool and then picking the panel itself. That's right, exactly. And so this is considering the recruitment process for selecting the panel. So is it then? So is it then that the response rates aren't really about the features of the individual, but also the topic of the panel in some sense? Yeah. And that's something that you don't, we can't predict. I mean, you may be able to have some priors, like at the start of any process. Like I'm sure that an expert in any context would be like, here are the people that I think will be harder to reach by these methods due to the issue. But there's still some uncertainty, I would say, because every time you're in like a different population, it's a different issue. Like a different population, it's a different issue, the timing of the assembly is different, so you still need to do some kind of like updating of your priors. Sometimes people think about this type of uncertainty as combining two uncertainties together very simply, like, oh, this multiplied by that. Like, these are independent processes. Is that a common way that... Does that make sense for this application? You mean like combining uncertainties where like you're uncertain about the effects of this recruitment method and you're uncertain about this? No, more like there's an attractive level. More like there is an attractive level of the topic of the panel, and then there is individuals, there's something inherent about their faces. As these two combine in a predictable way to a degree, is that natural assumption in the same? I would have to think about it. My first instinct is kind of no, but I mean, the answer being right, it could be approximately no, and that would. Right, it could be approximately no, and that would be good enough. So, like, yeah, I don't know. That's a good question. Is it often in like physical domains, biological domains, these are natural assumptions? So, I was wondering if in behavioral there are swell or I would have to check, yeah, I don't know. This is like a practical question. Yeah, for the assembly, you mentioned that you have like experts who like consult the people. Do you also do sortition of the experts? I can imagine where the population pick highly influenced to get into the publication. Totally, no, they do not use sortition. Bootaline, no, they do not use certification to select those. There's a lot of conversations going right now about how to do that in a principled way because everybody just kind of does it in their own way. I think right now the people organizing these processes are like pretty careful and pretty principled, which doesn't give you any guarantees. But I think the worry is that as they become more mainstream, they may be done with an agenda, in which case it is crucial to have that kind of formal process. So the answer is currently no. But people are worried about that too. Yeah. Yeah. Like how much we're losing by having a finite finite as opposed to. Sure, like how much better, like what is the marginal benefit of adding one additional person to your available? So it totally depends on the instance. I don't think that you can ever give a balance that applies to like all instances because it really just has to do with It really just has to do with the kind of like the combinatorial structure of the pool. Let me think if you can say anything interesting. Interesting, even in practice. Oh, I mean, we haven't done the empirical analysis yet, but that's like definitely something that we would investigate in practice, yeah. Yeah, yeah, please, yeah. For the adaptive multimotor recruitment, could you also apply that's because that's. Could you also apply that? Because that's like a similar problem with like polling. Or is the fact that you're doing like a different downstream task like specific event paint how? Like, how much role is that paint how you're doing it versus? I think that that's the right question. So like the way that you measure success is going to be very different in polling versus this, because in polling, you're trying to get some like estimator usually of like a population level statistic, which is like a really simple task. So you can just be like, how biased is this? How much variance is there? Is this how much variance is there? But here, when you look at the quality of your sample, what you're evaluating is like how well a combinatorial algorithm performs on that sample. And so that's just like a much higher dimensional evaluation of the quality of your sample. So what you want out of it certainly might be different. Yeah. Does that make sense? I still don't put it. Because in pulling, you still have this. Because in polling you still have the same sort of thing where like different like polling you just take statistics of the answers. And here you want to have a composition with certain structure and not just that every answer will be good. Oh I see I see a concern about how I would bore selected that could be sounds to work. Um Okay, sorry, Cathy who equals large enough and some functional. You're saying, like, is there a, can you prove something that, like, if the pool is large enough, then what is the question? I guess I'm wondering, like, how, like, how. Choosing the quotas is like a very political decision, and it's done by the people running the assembly currently. I think that there's a lot being left on the, and I don't just think this, I know this actually, there's like a lot. I don't just think this, I know this actually. There's like a lot being left on the table in the fine-tuning of the quotas, even. Because if you just change a tolerance by one, it can really change the potential behavior of the algorithm that chooses the panel for the pool. So there's definitely, even within like micro changes to the quotas, a lot to be done. But then like the macro question of how do you choose the groups to protect, it's like a fundamentally political question. But some considerations I would say are which features are the easiest to misreport. Are the easiest to misreport, for example, because you do have to worry about that. Where, like, when people join the pool, they can try to guess which groups are going to be really, really rare and are going to have to be chosen with a very high chance for the panel, and then they can just misreport those attributes. So, beliefs and opinions, even though a lot of people use them, there's definitely like some considerations based on the nature of the manual ability. I see you creepy hands with the skate, so I will. 