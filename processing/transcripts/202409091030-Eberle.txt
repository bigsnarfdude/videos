And all the other organizers for setting this up at this very beautiful place. It's really very nice. And yeah, I would like to talk about non-reversible lifts of reversible diffusion processes. And mainly I will tell you what that is during the talk. And actually, And actually, it's closely related to what David was talking about at the end, so I don't know if I have enough time to explain the connection in detail, but otherwise I'll have to discuss afterwards. Okay, so yeah, all this is joint work with Francis Verda, who is a PhD student of mine and Bonn. And well, it's also strongly motivated by something by Markov change. By sampling, by Markov-Chain, Monte Carlo methods, what people recently are doing there. I mentioned people look now at non-reversible processes, but then convergence to equilibrium is not very well understood in these cases, non-reversible processes. Okay, so we assume we have some probability measure with density e to the minus u, as we saw before, on R D, could also be on the Riemannian manifold. Be on a Riemannian manifold. And well, if we are interested in sampling from μ, then we would like to set up some Markov process that has μ as its invariant measure. And it should be such that the convergence to the invariant measure happens as rapidly as possible. And classically, one has looked at reversal remark of processes. And then, of course, we saw that before in the last talk, simplest one in continuous time. Simplest one in continuous time would be the overt and Langeman dynamics or stochastic gradient flow. And well, so this is also looked at a lot in connection with algorithms, of course. So somehow this very simple MC-MC method would be just you take an Euler discretization of this equation. That's called the unadjusted Launchman algorithm. And then by then you And then, but then you make a mistake, it doesn't have exactly the right invariant measure, and so then you can correct, and then that's called the metropolis-adjusted Langevin algorithm. But also classical things like random walk metropolis on a continuous space would have some relation to something like that. So, that's all reversible, and then of course, the convergence theory is quite well understood in that case. That case. So you know, this is the generator. You know, we have the corresponding Dirichlet form, which is just this gradient Dirichlet form. And then you can look, for example, at the relaxation time. Relaxation time would be now measuring the convergence in L2. And that would be just the inverse of the spectral gap of the generator, or just like the Poincaré constant. So are you thinking about? Constant. So are you thinking of just starting at a little deterministic distribution, just start at a single point and run it? Yeah, no, if you talk about relaxation time, you cannot start in a single point. So that would mean somehow you have a warm start, so you have a start which has a nice density with respect to the equilibrium measure. Otherwise, you would be talking about mixing time. But for this talk, I will only consider relaxation time. I mean, we would like to have something similar for mixing time, but we have that. Similar for mixing time, but we are not that far in the normal case. Okay, and then for the spectral gap, you of course have this variational characterization and so on. Okay, but what's the problem with reversible processes? Well, they are often slow, and that's because of random walk-like behavior, diffusive motion, which is slow. And let's just look at the very simple examples. Look at a very simple example. So, just take a flat torus and take, for example, the uniform measure on the flat torus or any measure where this lock density is uniformly bounded. Then the spectral gap will be like one over the size squared, and so the relaxation time will be of order L squared, and so it can be quite large. So, you would hope to have something that's maybe only of order. To have something that's maybe only of order L, but yet of order L squared. So the same happens if you have potential on Rd and say you're in a nice case, even convex case, so you have some lower bound on the second derivative of u by a constant m. But typically in applications, the constant m will be very small. And so then you know that the spectral gap is also. Is also of order m. And so the relaxation time is of order 1 over m. And since m is very small, this bound can be very large. And of course, it's not that you lose something, the bound is sharp in the Gaussian case. And if you think about discretizations, it's not really this n that enters, because if you discretize, then Then you also meet an upper bound on your second derivative of u, which tells you how large discretization steps you can take. And then at the end, what happens is that your bounds rather depend on the condition number instead of this m. Condition numbers somehow the ratio between the upper bound for the second derivative and this lower bound. And again, of course, this can be very huge, and so your bounds can be quite bad, even in situations where things. Bad even in situations where things are convex. Okay, so then the idea is to look for non-reversible Markov processes and so to look what call a lift. And so you could set up now a non-reversible Markov process on the same space, but it's somehow more practical to move to a larger space, namely to move to the tangent bundle. So that means you replace your R. You replace your Rd by Rd times Rd. So that means you now have position x and velocity v both in Rd. Well, if you would want to remind a manifold, you could just take the tension bundle. Okay, and then you take a measure on the tension bundle and well, in this R D case, it can be just the product of your measure mu with a standard normal distribution. So you just take the measure mu and it. So, you just take a measure in the x component at the standard normal distribution for the velocity. Now, you have a measure on an extended space, and of course, if you can sample that, then you can also sample the measure mu because it's just your first component. Okay, and of course, this extended measure, again, has density e to the minus h, we saw in the previous talk, where h is the Hamiltonian, so the sum of the potential energy that we make. Energy. Okay, so now which non-reversible processes do you have that leave this measure invariant? Well, there's a very simple one, which is just the Hamiltonian dynamics, so just dynamics of classical mechanics. So if you just take your derivative of position is velocity, derivative of velocity is minus the gradient of the potential. Minus the gradient of the potential, then this is a deterministic Markov process which leaves the measure invariant. And that's somehow the basis of molecular dynamics. This is the generator of the process. But of course, this process on its own, it's not ergodic because it just keeps the total energy constant. So in phase space, it would be just on the level sets of. Just on the level sets of your Hamiltonian. Okay, so to make it ergodic, you have to add noise. So, what you do is you add noise in the velocity variable. And there are now different ways to do that. The easiest way is somehow you just run your Hamiltonian dynamics for an exponentially distributed grand time, and then you draw a new velocity from your standard normal distribution. Then you run, starting with this new velocity. You run starting with this new velocity again for some random time, then you draw again a new velocity, and so on. So, in this way, by drawing these new velocities, you jump to these level sets, and so you get the motion that is erotic. And so, in MCMC, that would be called randomized Hamiltonian Monte Carlo, but it's just this very simple piecewise deterministic Markov process that I described. System like spread team. And there's a parameter which is the refreshment rate, which tells you how often you do these velocity refreshments. So, this parameter you can choose as you like. You always have to write in the velocity measurement. Okay, so now the generator would be what? It would be the sum of your generator of the Hamiltonian flow, which is the first order vector field, and then this generator for the junks, which is just this projector. Just this projection pi e minus the identity, and pi e is just, if you apply it to a function f, it integrates out the velocity variables, it takes the average velocity. Okay, so that's one possibility. Another possibility, so here you just add noise from time to time. Another possibility, you can add noise continuously, and then we have Lorenz-Rahman dynamics. So you would add some Ornstein-Uhlenbeck noise. Would add some Bonstein-Uhlenbeck noise, for example, in the velocity here again. So then we have the Langevin equation we have seen a lot in the previous talk. And the generator is again the L hat, but now it's perturbed by gamma times this Lonstrig-Woldeneck operator in the velocity of the L hat. Okay, and here you see that it's really very helpful to do that. Helpful to do that. So, what I've shown here is on the left-hand side, this is overdamped Langeland dynamics, and on the right-hand side, this is Lange-Land dynamics. That's Baus for a Gaussian target measure. And it's run for a very long time, so t equal to 20,000, but it just shows one trajectory after a very long time. And then you would hope that the ergodic average of that trajectory would give you some approximation of your. Some approximation of your invariant measure. And if you look to the left, the approximation is not very good. It's very patchy asymmetric and so on. So it doesn't look like a Gaussian measure. But if you look here on the right, Langevin dynamics, it's a pretty good approximation of the time. Also, you see that for the Langevin dynamics, of course, the trajectories are differentiable, which is also nicer if you think about the... Which is also nicer if you speak about this with these actions. Andre, sorry, could you go stand on the other side? Sometimes it blocks the slides. Can you speak? Ah, okay. I'm not sure about it. Works with the camera? Yeah, maybe it works. Yeah, yeah, yeah. Thank you. Okay, so it's really useful. And well, in the Gaussian case, you can compute the spectral gap exactly. Compute the spectral gap exactly for Langevin dynamics. If you have a Gaussian potential, then the spectral gap is just given by this expression where gamma is this friction coefficient. And then you see if gamma is zero, of course, the spectral gap is zero because Hamiltonian dynamics doesn't mix on its own. And if you add noise, it increases linearly, but only up to a certain point. And if gamma is very large, so if you add a lot of noise, then again, So if you add a lot of noise, then again the mixing properties are very bad, because then it mixes in the V component, but you don't have time to transfer the noise to the X component, it's just the holiday spot. And you see that the most rapid mixing happens somewhere in between. So you sum out of two regimes. This regime where gamma is very small and where you approach the deterministic dynamics is called the under-damped regime. And the regime where gamma is very large is called the over-damped regime. Very large is called the overdamped regime. And well, you can show if you let gamma go to infinity and do some rescaling, then you recover actually the overdamped Longstream dynamics. So the over-demand Long-Mann dynamics would be somewhere here. Samma goes to infinity. Okay, and then you see if you choose gamma proportional to square root m, then you have the largest spectral gap, so the most rapid mixing. The most rapid mixing. And actually, if you do that, if you choose, for example, gamma such that this quantity vanishes, so then you see you get here the spectral get exactly square root m. So that means you have moved from m to square root m. So you have improved your mixing properties by square root, which corresponds to moving from diffusive to ballistic motion. Okay, and so. So a lot of questions now arise. And so one question is, is there a relation between the two things I described, the reversible dynamics and the non-reversible ones? Okay, there's one relation if you take gamma to infinity here, then you recover the overden, but that's not what I mean. Lange-mer, but that's not what I mean. What I want to show you is that there is a relation between the two for every fixed thermal. So you take Langemer dynamics or randomized H and C for fixed thermal, and then it will be related to over Lange dynamics. And actually, what I want to show is that all these processes, these non-reversible processes I mentioned, they are all what I call a lift of overland Cauntron dynamics. Dynamics. And so over them, Technology dynamics is a collapse of these two instances. So I will define what it is. And then once this has been realized, you can ask what does it mean for the relaxation times? And this connection somehow immediately gives you a lower bound for the relaxation time of lifts. So what you can show is you only can improve by the square root. More than this is not possible. Not possible. And actually, that's quite interesting. So, for example, we and many others tried for a long time to get something better, but it's not possible. That's shown by here. And actually, discussed with Werner Kaut, the physicist, and he always said you can only get the square root. And he actually got it from mathematics papers, but on finite Markov chains. But I didn't find the argument so convincing. I I didn't find the argument so convincing, but in the end he's completely right. Now verify it. And yeah, then in the other direction, now you realize there's a certain limit of how much you can gain, then you can ask, of course, can we really achieve that optimal lift? So are there optimal lifts? And what can you get with that optimal lifts? Get with that optimal lifts, and to do that, you need exactly upper bounds for relaxation times, and that's exactly what David has been talking about. And yeah, it's not enough to get some upper bounds to do that. You really need very, very good upper bounds. And actually, we tried a long time with these twisted metrics and so on by other people, but it turns out there's a certain limit. A certain limit because you always have to design the metric so that it fits to your problem. And so we now also moved to this space-time encourage approach, which really allows to give us sharp underbounds. Okay, so then now I come to the main thing to explain to you what the lift is. And lifts have been introduced more than 20 years ago, but only for Markov chains on fine. Only for Markov chains on finite state spaces. And there are basically two main papers: the one by Diacommelis, Holmes, and Neal in 2000, and one by Schenlova-Spark. So in the first one, they considered many specific examples, and this was also partially motivated by the question to understand Hamiltonian Monte Carlo, but through a very simple example. And then the Chenlo-Rashpak gives some general. Was Pach gives some general results for finite Markov chains. Okay, so what is the lift of a finite Markov chain? So here's the example that's very well known. So you have just a symmetric random walk on a discrete circle. And then now the lift is the following. You now have two copies. One corresponds to velocity plus one and the other velocity minus one. So on one you move only in this direction, and the other one you move only on this direction. Direction and the other one you move only on this direction. Both with probability one minus gamma and then with probability gamma you switch between. So that's the lifted process. So more generally, the state space of the lifted process is the product of your original state space and the velocity space V. And the measure in the first component is your original measure, and then you have some kernel giving the measure V. Kernel giving the measure in the second component. Could you explain again? I didn't quite understand the lifted model. So on the left, you're just doing a random walk around that circle. Yeah. I will give you the definition what a lift is in a moment. So what is it doing? It's just doing what is shown in the picture. So you have two disjoint copies of the circle. So in this case, the velocity space is just two elements, minus one and plus one. So that means this S head is just two disjoint copies. This S hat is just two disjoint copies of the circle S. And on one copy, you just move with probability 1 minus gamma counterclockwise and with probability gamma you jump down. And on the other one, you move with probability 1 minus gamma clockwise and with probability gamma up. And so okay, so you have this extended state space S hat and then Space S hat and then you have a Markov chain on S with the transition kernel P that has invariant measure mu and now you have your lifted Markov chain. So that's the Markov chain on S hat, it has invariant measure mu hat, and it has some transition kernel P hat. Okay, so what does it mean that it's a lift? It basically means if you take p hat and integrate out the velocities, then you get p. So in the following So, in the following sense, so we say p hat is lift of p if you take p hat, you start at some state xv and then you move to some set A and to an arbitrary velocity, and then you integrate that also over the initial velocities with respect to the equilibrium distribution in the velocities at x, then you recover your transition column B. So that's the definition. Definition. And well, if you see that, then you could maybe be tempted to think this does now give you also something about the n-step transition kernel, but that's not true. So it does not imply that you have a similar relation between the n-step transition kernels. So the two dynamics can be very different. It's just a relation between the one-step transition kernels. That's the lifting property. It's the lifting property. Well, for us, of course, from an analytic perspective, that's telling us that lifting is an infinitesimal property. Okay, so now to generalize it to diffusions, we first give some equivalent ways of rewriting the same thing. So I denote by pi the projection on the x component. Component. And then we can rewrite, if you look at here, we can rewrite this by applying p hat to some function, but which only depends on the x variable. So then it's just saying that if you take p hat applied to a function depending only on the x variable and then you integrate out the velocity, then you get pf. Okay, then if you have that, then you say, okay. Okay, then if you have that, then you say okay, but then I can also multiply with another function in the x variable and integrate over the equilibrium measure in x, and then I get this. So the integral p hat f of pi g of pi with respect to mu hat is just the integral pfg d mu hat. Okay, but then we said it's an infinitesimal property, so we should rewrite it in terms of generators. Well, that's easy for Markov chains. That's easy. For Markov chains, generators just p hat minus identity. So this is equivalent to saying that the integral of L hat, f of pi, g of pi, mu hat, is the integral L F G d mu, and this is just minus the Dirichlet form of the process downstairs. Okay, so that's what we call a first order lift, but it will turn out that the lifts of the fusions will not be first order lifts, they will be second order lifts. Okay, so now let's think about how to move from discrete to continuous time and again start with a very simple example, which is just the same example but now in continuous time. Okay, so now we take the continuous circle. For the velocity, we now allow arbitrary real velocities. So that means we do not just have two copies of the circle, we have infinitely. Of this circle, we have infinitely many copies, one for each velocity. And then we take down here, we take Brownian motion, which is the analog to the random walk. And then up here, we would take a process which is moving with constant velocity on one of these here. And then after some random time, it changes to a randomly drawn new velocity, and then it's again moving with the new constant velocity. Moving with the new constant velocity for some random time, then it's changing to another one and again moving with this velocity and so on. So that would be the exact analog to what Diaconus Holmes did. Okay, and so then we have here the transition semigroup of Brownian motion, Pt, and we have the transition semigroup of this Markov process here, Ptat. And now you would like to have. And now you would like to have that this Ptat is lift of Pt. Okay, so what should that mean? So, okay, then we can again start with somehow the same thing, but now applied to PT. But we should keep in mind that the property only held for the one-step transition kernel. Now we don't have a one-step transition kernel, so what should it mean in continuous time? Well, it means it should hold for It should hold for small t, it should hold approximately up to some higher order errors. Okay, so let's see what happens for small t. So we take pth and then we integrate out the v variable. So what do we get? So pthat is just the expectation of f of xt hat. So remember f is a function that only depends on the first component. So we only have xt hat here, no velocity here. Here, no velocity here. And then we start at a fixed point x and at a randomly drawn velocity. Take the expectation. Okay, so what is xt hat? Well, you now start at point x and then you move for time t. And if you do not have these velocity refreshments, then if you start at x, move for time t, then you're just at x plus t times the initial velocity. times the initial velocity, so x plus tv and x plus tv will be normally distributed with mean x and variance t squared. Okay, now you have these refreshments, but if you think about it, they will only produce higher order jobs. So they will not be relevant for the argument you can know. So can I ask another question? So you said that the it's a one it's a relation about the one step transition. About the one-step transition kernel. Okay, but is it true to say in this example or the previous one that if I just start somewhere on the right side on the lifted model and I just ignore the velocity variable and just look at the position variable, will it be doing, say, Browning motion? No. That's important. Okay, well, I'm just fine. Okay. Just got it. Thanks. That's what I thought. That's what I thought. I met what I just said. Yeah, many people think you're tempted to think that, but it's not true. Okay, so that will be approximately have this normal distribution, but we know this normal distribution is now the distribution of Brownian motion at time t squared, not at time t. So that means this is, if f is in the domain of the gen, but this is, yeah. Of the gener, well, this is, yeah, if f is a function in the domain of the generator of Brownian motion, then that's the expectation of f of xt squared, where xt is no Brownian motion, plus some perturbation term of order little o of t squared. And so that's the Brownian semigroup applied to f, but at time t squared, plus some higher order perturbation. So that means your averaged p t hat does not behave. Had does not behave like Pt, but it behaves like Pt squared. And that's because you move from this ballistic to diffusive. And so this is what defines a second water lift. Okay, so now we just rewrite this definition in terms of generators. How do you do that? Well, the data. See that here. So, to get to the generator of Brownian motion, you just subtract f, divide by t squared, take the limit as t goes to zero, and then you do the same on the left-hand side. So then you get this, which now looks a little bit strange. You might think you've made a mistake, because now you have here pt hat minus f of pi, but divided by t squared. But to get the g. But to get the generator, you have to divide by t. And then you take the limit as t goes to zero. So it looks quite strange. But this only holds for functions f that only depend on the first variable and then averaged in the versatility. And this is correct, this really holds. So if you expand that, then you see that this is one over t times the generator applied to f of pi plus one half generator squared. generator squared by 2 f of pi plus a term of order little law of 1. And now to be a lift the integral of this term has to vanish and the integral of this term here times one half has to give you the generator of the Brownian motion. Okay, so these are the two defining conditions in terms of the generator for lift. Okay, and that's basically our definition. Just we still rewrite it in a little bit more convenient way. So in general, we have a symmetric Markov semigroup on L2 mu with generator L, and then the lift is the Markov semigroup on L2 mu hat with generator L hat. And then we say P T hat is the second order lift of P T if the following holds. Function f is in the domain of L. f is in the domain of L, then the function of the position only is in the domain of L hat. Then if you integrate L hat f of pi g of pi d mu hat, you get zero for any functions f and g in the domain of the generator L. And then here we multiply by some g and then we bring the l hat to the other side. And well that's clear that you can do it if it's anti-symmetric, but not only that. Anti-symmetric, but not only that, you can do it up. It only gives some higher order corrections also for all of these processes we look at. So that means we do not use exactly this condition, we use this condition here, which you get by doing the integration by parts. So you say that one half the integral L hat f of pi L hat G of pi d mu hat is minus the integral f L G du. The integral F L G dμ, which is just the Dirichlet form. So the definition is that the Dirichlet form you can write in that way. By the way, so does this still work for like, you go from overdamped to monitorment and then to adaptive, it gives all those layers, is that correct? Yeah, it turns out the generalized laundry is also a lift. Okay. Okay. Interesting. Can I ask another question? So, would it be the case that the oh, so it was important to get the dynamics of the V variable right? Yes. For the simple example to be correct. Not to be a lift. Not to be a lift. Is that kind of correctness of the dynamics of the V variable? Of the dynamics of the V variable, one that's underlying second equations. Is that you mean? Okay, so we need that mu hat as an invariant measure for the lift. So that's assumed. Is that what you mean by correctness? I'm not sure what you mean by correctness. I mean, could you choose just any old dynamics in the V variable? Not any. Not ND. Provided it had the current dynamics. Yeah, but it's quite, you can, you have a quite broad choice for dynamics in the V variable. Not ND. It has to be stationary with respect to the variable. So if it only acts in the V variable, yes, then you can basically add what you like. As long as it preserves the stationary distribution, that's right. Okay, just a side remark. Somehow, my feeling is that this has also some relation to Europe operators. So I mentioned, because yes, you know many people who know a lot about such things, so maybe you have an idea. So it's somehow like drawing a square root of this operator L, but it's a little bit different than for Europe operators. But in the analysis, we see also things like Boffman message and so on showing up. There was just one really definite market, but I don't know. It's it's just some vague feeling. Okay, so here's the definition again. And then, yes, so all these processes, Hamiltonian dynamics, Lange Verne dynamics for any gamma, randomized Hamiltonian Monte Carlo for any gamma, and actually in MCMC, people in the last years have. CMC people in the last years have produced a lot of non-reversible part of processes. PBMPs, for something, turns out they are all lifts of overland function. Okay, so then we know what the lift is. Now we can ask for relaxation times. What does it tell us? And as I said, you can quite easily get a lower bound on the relaxation time of lifts. Lifts. So, but first we have to say what the relaxation time is, and that's already a bit tricky, and it's not completely agreed maybe in a reversible case. Because in a reversible case, you have many things that are all the same. You have the spectral gap, you have the L2 relaxation time, you have the decorrelation time, and you have Poincare constant, and they all agree by the spectral theory. But in the non-reversible case, it's not. But in the non-reversible case, it's not true, they are all different quantities. And so you have to agree on a certain definition. So now we use the following: we use a non-asymptotic definition. So we define the relaxation time as the first time where the L2 norm has gone down by a factor one over m. This, of course, you can discuss. We thought it's good because for MCMC, you really only run a finite time into. Only run a finite time, and we would like to know that the norm has decreased after a finite time. We don't want the asymptotic decay rate, which is a difference. But there's a warning, so in general, this is not, so the inverse of this relaxation time is not the asymptotic decay rate, because usually in a non-symmetric case, if you look at your norm of pthat, it's something, for example, bounded by a constant times e to the minus r t. So the asymptotic d. So the asymptotic decay rate would be determined by the lambda, but our relaxation time is also affected by this constant C in front by the box. Yeah, and it's also not the same as the asymptotic decorrelation time, and it's also not the same as the inverse spectral gas. Okay, so what we can show is with this relaxation time, it's always bounded from below by the Bounded from below by the square root of our relaxation time of the collapse process, so of the overdamp Franchmann dynamics, for example. And this is now quite easy to prove. So how do we prove that? I should mention before, so this was somehow for Markov chains, you have a similar result by Schenlovaspach, but it involves. But it involves a quite strange time. So it's not the true relaxation time. It involves some set time, which is a quite strange thing. And the proof uses conductance. So the conductance argument is very simple, just tells you that the conductance of the lift may not be better than the conductance downstairs. And then this is related to the set time. So here I think it's nicer because we don't need this strange set time, we really have a relaxation time. Okay, so how does it work? Well, just take any lambda that's greater than the spectral gap of L. Then we know there exists a function in L2 with mean zero such that the Dirichlet form is bounded by lambda times the squared norm. Okay, but now by the lift property, the Dirichlet form is just the norm of L hat f of pi squared. So this is bounded by 2 lambda squared. Of pi squared. And that means this quantity here, the infimum overall function g of norm of L hat g divided by norm of g is bounded by the square root of twice the gap of L hat. Now this is not the spectral gap in that one reversible case. This is the spectral, well this is the singular value gap, so that's the spectral gap of L hat star L hat. So you can bound immediately the singular value gap of the lift by his. The lift by this square root. And now the singular value gap is also not directly related to the relaxation time. It's related, but it's not the same. But the point is it gives you immediately a lower bound on the relaxation time, and that's what we need here. So that's a little argument in a few lines, but not too difficult. And from this, you immediately get things. Okay, so now we really understand that by lifting we can only gain this square root. For our long efforts of gaining more, that's hopeless. But if you do two lifts, can you gain more? No, that's the part. That's the point that's weird. That's what we tried for. We tried to have third order, but you cannot. You cannot. You can only have second order. You cannot you can only have second order. So that's a multiplayer not being easy to say. I that's what I think. Okay, once you've understood that, then you can ask, okay, then if that's the best we can, so how can we achieve it? And then we maybe achieving it exactly is a little bit asking too much because we made some definition where it's more or less immediate. Definition where it's more or less immediate that in your arguments you will lose some factor two somewhere or something. But we can maybe produce an optimal lift up to a fixed constant. So we fix a constant C, a fixed number, maybe five, and then we say lift C optimal if the relaxation time is less than the C over two square root two times the square root of the relaxation time of the other process. Time of the other process. So that would be maximal acceleration up to electric C. And then you can just compute in the Gaussian case, where everything is explicit. So you see that if you take Langevin dynamics with the right damping, where you have the optimal oxygen property, then it's a 5.46 optimal lift of overdamped Langevin. And if you do the same for randomized Hamiltonian Monte Carlo, it's pretty much the same result. Carlo, it's pretty much the same result. Maybe this number changes a little bit, but it's pretty much the same. So, both, if you choose the gamma the right way, give you an essentially optimal in the Gaussian case. Okay, but now you would like to understand, of course, can that be true more generally? And now comes exactly the approach through space time from Cave inequalities into play. Have the inequalities into play, which can give a positive answer to that in some cases due to the results of Nu and Bang, which are based on the approach by Armstrong and Moua using space-time comparable inequalities. What you get is the following result. Basically, this is the Louvang result, and we just reformulated it in the language of lifts, and this allows to state the proof a bit more. To state the proof a bit more transparently to separate the different steps that we're doing in the proof. So we assume the following. So we assume the measure mu satisfies the Poincaré inequality. So our original measure satisfies the Poincaré inequality. Then we assume you have a lower bound on a Hessian of U which can be negative by a constant times. By a constant times m. m is the constant in this Poincare inequality. And then we assume that your gamma, you're somehow close to critical, so the gamma is of the same order as square root m up to some constant a. And then you can show that randomized Hamiltonian Monte Carlo is a C optimal lift of overdamped Mongeau with some explicit constant C. Okay, and we're losing, of course, some factors here, so this is. Of course, some factors here, so these arguments are not so easy as in the reversible case, so we maybe lose the factor 2000. But I mean, it's pretty clear that we do because there are several steps, and in each step you lose the factor 2, then in the end you lose a factor of 3,000. But up to this, you can really get this. There's a similar result for long. There's a similar result for Langevin dynamics, and there's also we can extend it to convex domains in Rn if you do reflection in the boundary, and we can extend it to the setup of Riemannian manifolds if you assume lower curvature bounds. So, this is still work in progress again, with Francis Euler. And yes, the proof is adaptation of these arguments of UN1 and Arguments of Un1 and Xiao-Luwang based on space-time from Carrie inequalities, which saw in David Stock in here. But in order to prove these space-time von Cabrin inequalities, that's then somehow the work you the difficult work to show that such a space-time von Kavin inequality holds. From Parain equality holds. And what you use is what is called a divergence lemma. And so you have to restate this divergence lemma and so that it gives you quantitative bounds and really explicit bounds with explicit constants. And you can do that. You can simplify the arguments a bit, rewrite them with lifts, and then you get that upper bound. That upper bound. Yes, I probably think my time is over. I would like to tell you more about these proofs for those who are interested, but that would be on the Blackboard and I cannot do now, but maybe we can talk about it afterwards because I think it's also very, very much related to what we saw in the end of the last talk. Okay. Jonathan, do you have a question? Are there any questions? That's funny, Hi. I wasn't going to ask any. I felt bad enough because I interrupted. I can't see if people have their hands up, so it's a little weird. Do I have a question? Um do I have a question? I guess I've lots of questions, but I mean my my question would be can you give us your summary of how you think of that proof, but um maybe that takes up too much time. Yeah, this may be better to shift after the public discussion, otherwise it would take not much time. But I'm happy we can do a fourth meeting afterwards to discuss that. So maybe my question is, you don't see a benefit from doing two lips, but is there like a numerical, is there a benefit in the numerics from going from going up to the dapple marshmallow, so to speak? Now, I don't know. I mean, you could imagine if it's smoother. Yeah, sure. So that might help you if you do this critization and improve your bounds a little bit. I mean, here I talked about diffusions. Talked about diffusions, so about optimal methods for diffusions. Of course, the next thing would be what does it tell you now about the Markov chain discretizations? And then you have to look at the number of steps that you need for your Markov chain. And that, of course, also involves other things. And then somehow the question would be, can you somehow lift such that you preserve these nice properties that optimal lifts in the diffusion context to your Markov chain? Lot of check. That's widely open. But I expect that some of the differences that we see or some of the gains like we see in physics event chain works very well. But from this, I mean, we see that Langevin or randomized HMC are already optimal lift, so that that should be an artifact if you do the discretization. If you do the discretization, because then you just need too many to compute too many steps if you do the discretization of sample H and C. So you had this vague remark that this L hat somehow looks like a Dirac operator, but I think that you can't reduce it if you just lift to the vector bundle, uh to the tension. It's a little bit different. It's a little bit different. Yeah, that's my point. I cannot really make it precise. It's not like a direct operator is defined classically. It's a little bit something different. Yeah, but I don't understand why. But there are these structural similarities still. It's but it's a slightly different setup. But you always want the setup where you lift to that. It's about the setup where you lift to the vector bundle and not to some other like. Just this thing here, just the thing that the Hamiltonian flow say is lift of over damp Langevin dynamics. And you give some interpretation that the generator of the Hamiltonian flow is something like a Dirac operator for your generator of Obadian Brunswick or something like that. I don't know. So I think I understood the definition of a lift, and you have some results for, all right, under these conditions, this constitutes a lift. Under, can you always find a lift for a given diffusion? Is there always some acceptable kind of distributions that, and how does one choose a best distribution? Yeah, well, usually. Yeah, well, usually there are many lifts, because you see here I talked only about lifts of overdamped Langevin. I mean, we're talking about reversible diffusion. So if you talk about reversible diffusion, it's not so far from Ovademp Langevin. X and you put it on a manifold and you have a metric that gives you diffusion coefficients. But then you already have a fairly general reversible diffusion, at least if you assume regularity of your coefficients, right? Coefficients, right? And then all these approaches need to lift second, and there are many others. I mean, if you have another process, which is diffusion plus something else, then one maybe would have to think, because for the something else, if you j have jumps, then you have these first order lifts, for the diffusion you have these second order lifts, so I don't know how that would work together. If there aren't any other questions, we'll thank Andreas again. So that's the end of our boarding session. And three And where you're lunch, mostly co-directive alongside? Yeah, well I think lunch starts in 10 minutes. You can go in as early as 11.30. We can meet in the FOIA of this building at 2 p.m. for a good photo. And otherwise, he has a good photo. Otherwise, if it has the facility