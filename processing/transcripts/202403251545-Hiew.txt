So, the next speaker for this afternoon is Jo≈æo Hugh. You're going to speak about an ordinary differential equation for entropic optimal transfer and its linear constraint variance. Gorge, you're going to be able to use the musicians. Hi, everyone. I'm Los Ra. And this work is joint work with Ruker and also my supervisor Benempras. And for this project, we try and use ODE to criterize the We prioritize the entropy optimal transform on a discrete domain. And originally, we just want the first motivation only on Q marginal. But actually, we found out that this method can be extended to multi-marginal and actually the optimal transport with extra linear constraint. So let's talk about voice. Other methods of you, guys, no voice optimal transport, but voice, the optimal transport with extra linear constraint. The setting is quite similar to the optimal transport. The setting is quite similar to the optimal transfer. We have the, this one is the multi-marginal one. First of all, you have the corresponding exponent marginals. We have the corresponding space for the marginal and the corresponding marginal, the mu1, mu2, and mu n. And also we have the coupling, this set of all coupling. We also have the cost. This is just general cost. But we have one extra thing: it's this Q. Is this Q? This Q is this Q is a linear subspace of the bounded continuous function defined on the product space of those X1 to 100xm. So, after resetting, so we can talk about what is the optimal transport in the extra-minute constraint, is that they have also tried to optimize this one because integrating with respect to the coupling. But now, the feasible set is a little bit smaller, not only. Stored, not on the whole or every coupling. But we request that if this of gamma, this coupling, is inside this visible set, we request that for each Q inside this linear subspace, the integral has to be equal to zero. Actually, this setting is including many interesting variants of the safer support, including the martingale automotive transport, which has application. Which has application in finance. Also, it can relate to the adaptive optimal transport. So, some people are, I think, AI also learning about this. And the most important, actually, is optimal transport itself. The marginal constraint is the linear constraint that makes catalog when we're trying to generate moving from launch to this so successful because it makes the marginal, it's a linear constraint. The marginal is a linear constraint. So, therefore, in some formulation, people treat the multi-marginal optimal transform is the two-marginal optimal transform with extra-linear constraint. They treat the extra dimension that is in extra constraint. So, we say we try to work it on the entropy optimal transport. So, we define what is the entropy optimal transport. So, we have, assuming we have the india the important measure. Uh, the indie the important measure, which is independent coupling, then if we have some epsilon which could be positive, then we assume, and eta has a strictly positive, then the entropy optimal transport problem with extra linear constraint is that, okay, we have still have this integrated cause, the C integration with respect to the gamma. We have it restricted on this smaller set, coupled set, but we're also interacting this. Affecting this relative entropy charge. This is the formula, the character of the relative entropy charge. And this is the primal side. And this is the so-called dual side. It's just like the optimal transform, we have the potential, but also we have this exponential. And if you are familiar with entropy optimal transform, you will see that originally, usually there's only one parameter for the entropy recordization stator. For the record, it's data. But here, I introduced one more extra: it's the epsilon. But actually, epsilon, introducing this new epsilon is in some sense equivalent because we think about if we fix the eta, just on this picture, if we fix theta, when epsilon goes to zero, then the first term vanishes, right? So this is equivalent to when we fix the epsilon and then we try to make the eighth term go to infinity. So usually the solution will be. Usually, the solution will be the measure which has the highest relative entropy, right? And on the other hand, if we fix the agent, letting the epsilon go to infinity, which is equivalent to the agent, we fix the epsilon and make the agent go to zero. In this case, this is going back to the original optimal transport, original optimal transport problem. So, this is the entropy optimal transport. Optimal transport. And now we said that we are working on the discrete k. So this marginal to be the discrete marginal. And in this case, also the constraints of space also become only a finite dimensional space. So we can read it as this form of the linear programming problem with the entropy cause. So you can see that this is the original cause, this is entropy terms. This corresponding to the marginal constraint, this corresponding. Constraint, this corresponding to the extra-linear constraint. And to me, this work, why I can say that, okay, this extends from two-marginal, multi-marginal, and we've also extorted marginal, because actually, if we rearrange it, define it well, actually, we can look at this platform. Just a matrix, inner matrix, and then this form, and the corresponding dual problem. The corresponding dual problem originally of this problem, and we can adapt the condensed notation, we can also add this form. This in general is a concave, this function is a concave function. In general, it's not a straight concave, this is a concave function, also. Yes? So it can have a solution, but it may not be unique. But we did in this form, and in this particular kind of problem, I mean, the optimal transfer problem. Problem, I mean the optimal transfer problem with extra linear constraint. Actually, we can make this A, the A, to become a full column matrix. Not only full column matrix. Actually, this is a very common trick in the original optimal transport problem. In the original transfer problem, the dual problem usually is the potential is not unique until we fix some of them to be excellent as, like, say, for example, at some point is equal to zero. This is one way to make the dual potential to be. This is one way to make the dual potential to be unique. This is one trick. And this trick, I find that we can extend to not only the multi-marginal, but also all those extra-linear constraint detection. So we can have this manager just saying that, okay, this target extends to different linear string constraints. And now we're going to the main focus is about the ODE itself. So So we have this UOFON function. I twist a little bit, I put a negative sign to it, so it becomes a convex function. Previously, it's a concave function. I'm putting it in a convex function. And we are trying to minimize this convex function by this convex function, which corresponding to minimizing the dual formula functional. And one property about this one is, as I said in the previous page, I can do some trick to make A to I can do some trick to make A to be a full column web. After using this trick, then this functional is not only commerce, but strictly commerce. And this is crucial because we only want to have one solution. If it's multiple solutions, it's difficult for us to parametrize it. Actually, by the first order optimal condition, obviously the function is differentiable, so you can try to differentiate by the first optimal conditions, the gradient should be equal to zero, right? Should be equal to zero, right? It's obvious. And as I said, because it's straight concave, so straight, so it's straight convex, so it should be unique. In the sense that for each epsilon, there should only a unique corresponding dual function, dual potential. And then this, and then it means that actually by the implicit function field, they can be written as a function, a small function, this phi can be written as a function of alpha. Written as a function of epsilon. And then also we try to differentiate again actually, we can deduce the corresponding Couchy problem. This is the ODE we want to have. In general, this is also capable, we can find it from the influence functional field. Say that if SOA, this is a solution of this optimization problem, it should satisfy this ODE. But actually, we also go even further. We prove the real problems. It's saying that, okay, this ODE has. Saying that, okay, this ODE has one unit solution. In a sense that if you want to understand, we're trying to prioritize the dual potential, we can actually study the ODE something because ODE, you really determine the potential. So therefore, this is give us one application. Like the entropic regularization problem, usually in the optimal transfer problem, it's many times using for the numerical method. Is many times using for the numerical method. It's trying to solve for it using the entropy regularization to approximate the original OT, optimal transfer. Usually, people use this single method to approximate. Now, we provide another way to approximate. We can use solving this ODE to approximate. So, this is one of a new numerical method to solve this entropic optimal transport problem. Later on, I will give you some examples. And one more thing. And one more thing is actually quite surprising. Actually, I say that originally last week, I said, okay, people are using Syncard, I'm using ODE. But if doing the proof, actually, I can extend the SINCAR algorithm not only to optimal transport with two module. Previously, there are some uh o uh a single method for optimal transfer is famous. Uh recently people also said, okay, or for the multi-marginal. Okay, or for the multi-martinal. But for the single method, with the expedited constraint, at first, I know I see two papers using Synchron on the multi-wheel transform and also the adapted martinial transform. But they need to be only two constraints because they rely on some convergent result that is worked only on two margins. And in our project, actually, we find that the convergent result can extend to multi-marginal and also extend. Multi-marginal and also extend to different whatever extra linear constraint. So, actually, we accidentally, although we only want to automate the ODE, we actually contribute also to the single method. So, this is, and actually, for this is the numerical part, we can actually have all for the numerical, and we also have some contribution to the theoretical part. Is that actually thinking if we are the optimal cost? The optimal cost for each epsilon corresponding to optimal cost, different epsilon, we expect that they will just give the different optimal cost. And for the ODE actually give us the way to interpolate between when epsilon equals zero, which corresponding to the fully recognized, and that when epsilon goes to infringing, which corresponding to the original optimal transfer problem. And especially when epsilon equals zero. Especially when epsilon equals zero, when we do it here, working on the classical two-marginal optimal transform, we know that when it's only two-marginal, then for a fully organized one, it means that it has a minimum attribute respect to the potential. Then, in this case, the optimal solution is just the potential itself, which corresponding to the U and V should be equal to zero. So, actually, we can calculate the C0, but not not only C0, we can actually calculate Not only C0, we can actually calculate the higher ordering. So, actually, we can do the T expansion of this course around the C0, and actually, we can using the ODE, we can calculate the higher order. And we can, key observation is that because the derivative of the potential no longer exists inside on the right-hand side, actually, it's just a derivative. So, actually, we can calculate it for every order we want. We want. I have worked with an explicit solution. Exact solution. We have here just demonstrating this first two theory. So this is some new for failure contribution. And next, I'm talking about the numerical example. Yeah, the numerical example. Here, in this page, we just want to demonstrate. In a very classical, the two-marginal case, with the descent cause here. The descent cost here, we are assuming the both marginal just identical to be uniformly distributed through and one. And everyone should know that when it's fully regularized, then the solution is just for the measure. When it's the original optimal transfer problem, then the identical map, the identical map is also the solution. So actually, this picture was simplistic. It's like this, by solving this ODE, we can see the interpolation between The interpolation between the full recognization to the unrepolized unrepolized one. Actually, I would call it some sort of like entropic interpolation between them. This is for the own for the transporting or transport two marginal. Another example I want to demonstrate is that, as I said, this works with the electronic constraint. This is a multi-period martinical, or multi-period martial optimal transform. Period, martin for automotive transform. And I said that there's people before this only working on the martial transform with only two multiple. But as far as I know, no one is working, do not know that it's a single method, it's a five-to-multi-bar. And this will be, let's say, that the upper one is the coupling given by our ODE method, the lower part is the coupling, given by the single method, actually the aggregate. So that's. Yeah, okay. That's all for my presentation. And if you just ask any questions.