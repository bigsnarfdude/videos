Wonderful location. So, yeah, today I want to talk a little bit about how you actually characterize non-Markovian processes in practice. And so, kind of what we're thinking about here is especially in the context of controllable quantum devices. So, I'll sort of put it in the context mostly of IBM quantum computers, but in general, we're interested in any kind of generically controllable open quantum system. And so, as a high-level overview, I want to kind of dig into I want to kind of dig into the process tensor framework for describing non-Markovian systems and then give a high-level overview of how you actually characterize non-Marcovian processes in an experimental and in a practical setting. And then if there's time, I'll go into some more elaborate directions. So we had this non-Markovian workshop in New South Wales back in December, and there was a lot of fierce debate as to what actually constituted Debate as to what actually constituted non-markovianity. And it's been a lot more civil here, but the kind of takeaway I had from that is that you have to be really clear about what you're talking about when you're describing as non-markovian. And so I think in the first instance, that's something that Basano and Angel described, which is whether you're considering a system as it idly evolves versus some kind of a controllable or a driven quantum system. And so we'll be mostly focusing on the latter just because, in a controllable quantum device, in a quantum computing setting, In a quantum computing setting, that's kind of the relevant sort of setup. But to kind of break that down a little bit further, there's maybe three or four things that could reasonably be called non-Markovian in a fully general setting. So to kind of consider this diagram here, the first thing is that there's always a process happening. Suppose you have your qubit is coupled to some environment, and there's some always-on interaction, and that's happening no matter what you do, and that's a lot of. Happening no matter what you do, and that's that's a lot of what we've seen so far this week, which can generate non-Markovian correlations. But we also have the fact that we have possibly noisy experimenter-chosen controls, and these can themselves be correlated. So, an example is suppose you drive your system with a laser, and the laser is kind of has this quasi-static power spectrum, so that in some circuits it's a little bit too bright, and in some circuits it's a little bit too dark. Then, every gate in that circuit is going to be. Then every gate in that circuit is going to be coherently either over or under rotating in a correlated way. And so this is kind of qualitatively different to the above. You also have the instance in which the control actually changes the environment. So say in a transbond you have the bottom two levels of an anharmonic oscillator constitute your qubit, but you also maybe have some frequency errors that drive a transition. Errors that drive a transition into these higher spaces, and so that the act of doing the control is actually affecting your environment. And then finally, some people somewhat reasonably call time-dependent Markovianity or the drifting of things non-Markovian. Predominantly, we kind of focus on these first three, but in this talk today, I want to just, for the kind of straightforwardness, just mostly focus on this first scenario where we have First scenario where we have just an always-on process and the environment mediates some temporal correlations. So, as we've kind of seen, the difficulty in taking classical notions of non-Markovianity and generalizing them to the quantum setting is that we have non-commutativity of observables at different times. And so, if you want to track the state of the system, you also need to be cognizant of the fact that measuring the system, the way that you measure it, is collapsing it and will affect it. Is collapsing and will affect its future evolution. And so, to kind of change perspective a little bit, we can consider that in a lab we don't actually have access to a quantum state. We only have access to a set of controls which manipulate that state. And so instead, we can look at, well, asking the question: how does the system respond to a set of control operations? So you might drive your system at each given time, you apply a control operation, and that's You apply a control operation, and that sets it on some different trajectory. And you can measure the response to that system at some final time, conditioned on whatever those were. And the nice thing about the linearity of quantum mechanics and the linearity of stochastic theories is that if you measure a few of these kind of responses to control operations, then through linear combinations of these, you can infer other control operations. And so, because the kind of space of the super operator space of things you can Of the superoperator space of things you can do to a qubit is finite-dimensional, then you can fully characterize multi-time correlations with only a finite number of experiments. So, this is done using an object called a process tensor, where the kind of opaque definition of a process tensor is that it's a multilinear mapping from sequences of control operations at different times to a final state density matrix at the final time condition on whatever sequence that. Condition on whatever sequence that was. But really, what it does is it represents everything which is uncontrollable, which is the initial system environment state and subsequent unitaries, and partitions it from the controllable, which are the experimenter-chosen interactions. And so crucially, it doesn't average over any of the environment, which means that it's quite a powerful framework to describe any arbitrary open quantum system. So anything which is arbitrarily strongly correlated and has nice properties that it. And it has nice properties that you can define a necessary and sufficient definition of Markovianity, which coincides with the classical definition in a classical limit. So to kind of unpack this picture a little bit more, what we really have is we have a sequence of times. At each time, we apply some operation to the system. And so you can imagine that at each time the state of the system is coming out, being fed into this operation as we manipulate it, and then being As we manipulate it, and then being fed back into the process. And so if you zoom in on a single one of these time steps, this is exactly just a quantum channel. And so you might feed a state in, and then you get a state out, which is dependent in some way on the state that came in, as well as the open dynamics. But if you kind of zoom out to a few times, then what you might find is that the action of this gate here, or this operation here, by virtue of the system-environment interaction, has some. Has some back action on the environment. So it unlocks maybe some degrees of freedom, and this is carried forward in the environment memory. And so then at the second time, when you apply this gate A1, what you get out depends not only on the state that got fed into the process, but it also depends on the decision you made, the A0 that you applied at this point in time. And so this is a quintessentially non-microbean setting because future statistics update condition on some choice of paths. Condition on some choice of past action or past event. And so the process sensor is able to describe dynamics essentially by it can propagate the state along as well as being fully cognizant of how the control affects that state. So this partitioning of control and process is kind of crucial to being able to do that. And so what you can think of this is every time you apply a different sequence of control operations, the environment The environment responds in a different way to your choice. And so these sequences of control operations can really be seen as observables of the process. So we have some underlying process which exists as its own kind of ontological object and controls the sort of known events that we can choose to sort of probe this. And in the most general setting, the way that you can probe a process is to apply a quantum instrument. Apply a quantum instrument at each time. So, some kind of a measurement with some post-measurement state, which then feeds back in. And so, what you would get from that is these joint statistics where you obtain outcome xj at time tj, you know, as well as xj minus 1, all the way up to x0 at time t0, conditioned on the actual instruments that you chose. And so, the way to think about this is exactly the same as if you have a quantum many-body state, you pick a basis. Any body state, you pick a basis in which to measure it, and you obtain a series of joint probability distributions conditioned on the basis that you chose. And so, in a formal way, the process sensor framework generalizes classical stochastic processes to the quantum setting. And it also has this really nice property that there exists a generalized Choi-Jamiarkovsky isomorphism, which allows us to exactly map this process onto a many-body state. Process onto a many-body state. So this is kind of realized by if you send in one half of a bell pair at each time and let it participate in the dynamics and then sort of rearrange all these systems, then the subsystems of the multipartite state you get at the end is element by element associated with the legs of this process. And so crucially, what this means is that it allows you to map temporal correlations, which are maybe not so well understood, onto spatial correlations. Onto spatial correlations, which we understand pretty well. And so you can come up with things like notions of temporal entanglement, temporal discord, like what separability means in a quantum stochastic setting, which is really useful. And so importantly, in this framework, the notion of a Markov process is when this choice state is a product state, because it means that you can subdivide the dynamics. So, this is broadly speaking what I mean by the term many-time physics in the title, which is to say that these correlated quantum processes actually exhibit really interesting physics in their own right, which is that temporal correlations can be structured in the same way that many-body physics is structured. So, we can associate any multi-time process with a many-body state through this isomorphism. Through this isomorphism, and that allows us to, this connection allows us to probe non-Markovian processes and to learn interesting things about the underlying physics. So concretely, I want to kind of go through how you would reconstruct a process enter in an experimental setting, which is that you want to reconstruct this mapping for any arbitrary sequence of operations and be able to predict what the final state is. Predict what the final state is. And since this is just a linear mapping, it's uniquely fixed by the input-output relations on a complete basis. So, one way in which you might do this is to say, well, I could pick some basis for my arbitrary sequence by just picking a time-local basis, so a basis of operations in each position of this comb. And then to reconstruct the whole thing, it suffices to measure the final state of the system conditioned on all. State of the system conditioned on all combinations of basis elements in position one, as well as all combinations of basis elements in position two, all the way up to all combinations in position k. And so you can see by this nice linear expansion that everything about the underlying dynamics is fully preserved. And so if you trace over all of this input information, you're left with an expression for the final state of the system, which is for this arbitrary sequence, in terms of some known. Sequence in terms of some known expansion coefficients and some measured basis states. So we did this a few years ago on a set of IBM quantum devices as a sort of proof of principle that you could do this in an experimental scenario. So we kind of generalized this notion of quantum process tomography and tested it out. Now this expression here is a nice figure of merit as to the quality of your characterization because you can pick a random sequence, ask the question, Pick a random sequence, ask the question: what final state would I get? And then just go away to the device and actually run that sequence and then compare your prediction to the output. And so that's what this box plot sort of summarizes is across a series of different devices in different setups, the y-axis here for each of these dot points is the reconstruction fidelity, so the fidelity of states between the prediction and the actual. And so the median for each of these. So the median for each of these is about 99.9% kind of thing. What are the resources required to perform tomography? In terms of number or physical? Resources in terms of number of trials, find for a supernatural qubit. Yep. So in this fully general case, this is exponentially scaling. So a single qubit has a 16 As a 16-dimensional super operator space. So, for a fully generic stochastic process, this would scale like 16 to the power of the number of time steps that you do it, which sounds bad, and it of course is bad, but in general, you don't expect these non-Markovian processes to be as complex as possible. You can often, and I'll talk a little bit about it, but you can really compress it down and make the characterization efficient. Characterization efficient. One way to think about this is you do the choice type and you just do tomography on the choice state, right? So you get two qubits for every time step. Exactly right, yeah. So it's, yeah, for a d-dimensional system over k time steps, it's a d to the power of 2k plus 1 many-body state, and it's equivalent to doing tomography on that state. So, in full generality, much like state tomography or process tomography, it's exponentially costly. Temography, it's exponentially costly, but in the same way that you have compression tools for these things. So these particular experiments were across four times, and that's about 3,000 experiments. Is it clear that you shouldn't use also correlated testers, like you plug one column into another column? So you can do that. Experimentally, it's really tricky because a correlated tester would be. So, a correlated tester would be maybe you have an ancillary qubit and you interact that ancilla qubit with the system at each time and then measure at the very end. The difficulty with this is that you require some assumption about the knowledge of these control operations and in general for these devices that's going to be extremely noisy and a fairly bad assumption. But you can always do time-local tomography, which is informationally complete. So, in the same way that you can reconstruct a quantum. In the same way that you can reconstruct a quantum state by just doing local power measurements, you don't need a correlated tester to reconstruct these whole objects. But if you do time local operations, that would give you information about what a tester, what the statistics of a tester would do, if that makes sense. And so this is sort of like a linear inversion protocol, but in full generality, what we want to do is you don't You don't want to be reconstructing unphysical models for the process. And so we developed a set of algorithms that allows you to take experimental data and compute the maximum likelihood process tensor, which is as consistent with the data as possible, whilst also being positive. So it should be completely positive, produce only positive probabilities, and it should be causal in that future choices of operations shouldn't update part of the system. Shouldn't update parts of the systems. There should be a clear kind of arrow of time. And so this is done by this sort of generalized Born rule here tells you a connection between the model prediction, so some probability based on your model of a process tensor as it's projected on whatever sequence of operations you have here. And so this gives you a much better prediction, so you kind of reduce resources quite a lot. So these are sort of the basics of The basics of process sensor tomography, and as I sort of said, you can really compress a lot of these requirements to make it only a linear or a polynomial number of experiments based on noisy quantum settings. The noise is relatively sparse. Again, you don't really expect typicality in a generic open quantum system. But I just want to kind of go through a series of maybe applications of this, reasons why you would do something like processing. You would do something like process sensor tomography. And the first is that it really allows you to know with confidence how to manipulate your process. So it's kind of an example in terms of noise suppression, so canceling out correlated errors. Once you've characterized a process, you know exactly what the output is going to be for any sequence of gates. And so you can then classically optimize to essentially transform that process. Transform that process into something more desirable. So, in this case, this is essentially like optimizing for a dynamical decoupling sequence or something like that. So, you characterize, you optimize, and then you sort of say, I want maybe these four gates to bring me as close to the identity channel as possible for this sort of thing. And so, this is kind of a selection of results for this, where we have a random sequence of unitary operations, and on the x-axis, And on the x-axis on an IBM device, we have a comparison between the fidelity with which the machine is able to produce these states. So on average, it's about 0.82 for these things. And on the y-axis, we have essentially a noise-aware recompilation of the circuit to try and cancel out as many of these correlated errors as much as possible. And I won't go. As possible. And I won't go into too much detail, but the different colors, what they indicate, is accounting for different levels of non-Markovianity. So accounting for a single step in time versus two times back versus three times back is the blue, orange, and green, respectively. And so kind of the upshot of all this is that we're not only able to increase the total fidelity, but the average fidelity, I don't know if you can see that from about 0.82 to 0.93, but there's a clear delineation between accounting for different orders of correlations. Orders of correlations, which is perhaps not surprising, but it at least kind of indicates that you get more bang for your buck if you account for these higher-order memory effects in a practical setting. We can also do things like play with the entanglement of a process. So you can transform your process to make it either more or less complex. Where here we've generated some interaction, like a Heisenberg interaction with an ancillary qubit. Silicubit. And we're looking at the entanglement between the first half of the comb with the second half of the comb, conditioned on some modifiable unitary operation here. And so this kind of gives you an indication of, well, you have sort of a natural complexity to the process, but if you use the experiment to transform the process to something else through a sequence of operations, you can either increase or decrease the kind of complexity of that. And so you can see as you go from identity to As you go from identity to Y gate to Z gate to X gate, you get a very different amount of past, future kind of temporal entanglement. So, just to clarify, past, future, temporal entanglements, you map it to the choice text for the. Exactly. So, everything here is, yeah, it's all operationally from the choice state. You reconstruct the choice set, you compute the entanglement. A kind of subtlety of this is that we have like a restricted entanglement witness. So, these devices we don't have informationally complete control, we only have. Informationally complete control, we only have unitary control, and so we had to define a sort of class of unitary-only entanglement witnesses and create like a restricted kind of monitoring for which you could witness entanglement, but only using unitary operations, which in itself was kind of surprising because unitaries are totally deterministic, so the fact that they can tell you about quantum correlations between past and future, I think, was unexpected to us. Cool. The next thing that you might like to do in terms of looking at quantum devices in generality is to actually diagnose correlated noise. Because, well, so if you have some kind of a circuit and you have correlated noise, then that noise essentially propagates throughout a circuit. And not only does it violate a lot of the noise models assumed by quantum error correction codes. By quantum error correction codes. But it just introduces a lot more error in general because you're sort of saying if you have correlated error, then everything has an error rather than maybe IID depolarizing noise or something like that. So this kind of motivates, but if you have correlated error on a device, you want to really understand it and you want to maybe either seek to eliminate it through more active control like what we saw, or perhaps design maybe more perspective. Perhaps to design maybe more bespoke quantum error correction codes around the actual character of the noise model. Because if you don't do that, then you require a much larger overhead of physical resources in terms of the codes. So not to go into the details too much, but we sort of generalized classical shadow tomography, which allows you to extract a large number of observables of many body states. We adapted this to this setting that allowed us to compute for large numbers of processes. For large numbers of processes, sorry, large numbers of steps in a process, the correlations that exist between different times. And so this left heat map here, the lower triangular tells you the total non-microbiality that exists between, say, step one and step two, or step four and step six, and so on. The upper panel is the entanglement that exists in a naturally occurring setting. So this kind of suggests that not only is there correlated noise in these devices, Is there correlated noise in these devices, but it's genuinely entangled, so there is a quantum memory which is actually responsible for it. You can also extract other bits of information, so the probability of, say, having correlated Z errors at different times, correlated X errors at different times, and so on. So this sort of information is something that could readily feed into like a probabilistic error cancellation model, where you, instead of canceling things in a Markovian way or a time-local way, you would instead cancel the joint probability. Cancel the joint probability distribution of stochastic errors. The other thing, so sort of turning away a little bit from the first plot, right? Yep. So I had to understand that, let's say, like the degree of nomatogeneity between 0 and 1 is 14, and then it's 01, 02, 03. So is it surprising that, I mean, in most of them you have a decreasing order, but then in the first column you see 6.3, 5.2, but it's right. So it is, I mean, my expectation would always be, an idea expectation is that somehow that these the correlations decay over distance, but it seems that really is not that well. It seems not so much because I suppose say if you have say if your correlations are entirely classical, so you've got some magnetic field which is fluctuating, and the time scale of that fluctuation is on the order of the circuit, then the kind of correlation between the start of that circuit and the end of that circuit versus the start of that circuit and the middle of that circuit is going to be relatively equal to one another. So I think that would be true maybe for. For a quantum memory with a dissipative environment, you would expect you maybe have high, strong oscillations at the start and then they kind of damp out over time. But yeah, for these sorts of systems, I think it's reasonable to expect that the correlations don't really decay over time. But if you were to say condition on, they wouldn't be genuinely multi-time. So if you were to condition on, say, a middle time, you probably wouldn't get. Middle time, you probably wouldn't get any past-future correlations. So to turn away a little bit from noise, and not sure how much time I have left, but maybe five minutes including questions. So to be kind of quick about this, we've talked a little bit about noise and applications of this to say improve. And applications of this to say improving devices. But one way in which you might like to use this sort of characterization of this sort of approach is to think about obtaining some kind of a quantum advantage by looking at open quantum dynamics in general. So we had a recent result where we sort of looked at the complexity of dynamically sampling from an open quantum system. So typically, these sort of sampling exercises are sampling from some complicated quantum state that you can equivalently sample multiple. You can equivalently sample multi-time scenarios where you get a separation between the complexity classes of something you could do classically versus something that you could do quantumly. And so the general idea, the sort of motivates this general idea that maybe a good avenue for quantum advantage is to perform some kind of a sampling problem of open quantum systems. And so we've seen a lot of kind of exciting results recently. Exciting results recently, where you take data from a quantum computer and then you process it with some classical machine learning algorithm, and that tells you sort of properties that you couldn't reasonably compute with a classical computer. And we might imagine doing this equivalently with the quantum stochastic setting. So, not that this is that, but to kind of look at a step towards To kind of look at a step towards that, we have a simulated spin chain where we're looking at probing a single one of these qubits as kind of an open environment. And we reconstructed essentially a matrix product operator representation of that, where we're now really looking at multi-time instruments. So, at each, this is a 21-time scenario where we're dynamically sampling and we want to say, can we actually characterize this? Characterize this, characterize these temporal distributions in a high-fidelity way, which, as it turns out, we were able to do. And so, we can extract information like I suppose more conventional settings of non-Markovianity. So you see recurrences, say, in system purity as it's idly evolving, or recurrences in the distinguishability of different initial states. But we can also collect sort of multi-time statistics as well as look at things like the negativity and these sorts of properties. In these sorts of properties. And so, this obviously isn't so complex that you couldn't simulate it, but you might imagine using, say, the techniques that Koday was talking about, taking an open quantum system process, simulated on a quantum computer, and then performing a sampling problem, which was dynamic in time rather than dynamic in space. To understand more about that particular process. And so, lastly, I just want to kind of highlight, to kind of bring up. Highlight to kind of bring it back to the start, which is that we have all these sources of non-Markovianity which come not just from the process but also from the controls. And maybe in a practical setting, you can't reasonably assume that your gates are high enough fidelity. Say if you have mid-circuit measurements or things like that, these tend to be extremely noisy. And so our approach to make this a lot more efficient and make this also self-consistent. Efficient and make this also self-consistent is to model both process and control with the use of nicely parameterized tensor networks, and then to estimate everything in accordance with whatever the experimental data is, to estimate these tensor networks with no kind of prior assumption about the perfectness or the knowledge of the input operations. And that allows us to estimate both non-Markovian process in an Non-Markovian process in an efficient way, supposing that the dynamics are relatively sparse and that the environment isn't, say, exponential in size or anything like that, as well as the possibility that you have some kind of correlations within your instruments. And so I won't go too far into it, but we have a set of experiments where we are able to characterize this sort of spatio-temporal models on IBM quantum devices where you're looking at space-time. Devices where you're looking at space-time correlations as modeled by these tensor networks for various numbers of times and qubits. And we can reconstruct these to quite a high fidelity. So that allows you to obtain much more precise models for the particular errors that kind of propagate through both time and space within a device. So, yeah, in conclusion, this is process sensor tomography in kind of a nutshell. In kind of a nutshell, this is how you really can get to the nitty-gritty of experimentally looking at multi-time non-Markovian processes, as we've sort of demonstrated both in simulations and on IBM quantum devices, to look generically at open quantum system dynamics, but also in particular looking in a more specific setting at noise on quantum devices and how that's correlated. So thanks for listening and let me know if you have any questions. I wish we had more type of discussion, but let's have a few questions. Thanks for the nice talk. So when you were optimizing these unitary gates to, let's say, have good fidelity after a certain specific final time, have you played around at all with the time step that you're choosing? Like between your gates? If you make that smaller, Your gates, if you make that smaller, on the one hand, does the optimization become much more difficult? And on the other hand, does the fidelity get way better if you allow it to optimize for like a second? Yeah, it's a good point. So we haven't played around too much with the different time steps, just because in this kind of experimental setting, you need to kind of collect a lot at sort of fixed intervals. In principle, you definitely could do that, and certainly in simulation, that would be. In simulation, that would be really straightforward. The efficiency of the optimization isn't too problematic if you want to go to a large number of time steps, as long as you model them with tensor networks. And so the representation only sort of scales linearly or in some cases logarithmically. Maybe you have a much larger optimization space, but we've done, say, optimizing eighteen step dynamical decoupling sequences and that's still totally fine. And that's still totally fine. And I'm sure you could go to much larger settings with the aid of GPUs or an icon cloud system. Thanks. So I have actually a curiosity more than anything else. So have you ever tried, let's say, applying quantum causal model? Have you ever heard of that stuff, like the other by the group in Oxford, Perimeter, and so on, to the study of non-Mark reality? Mark reality? Because in some sense they are similar to the process tensor, however, they reason in slightly different terms. Yeah, I think it's more or less equivalent. So quantum causal modeling, I think, doesn't need to respect causality. Like you can have superpositions of different causal orders and that sort of thing. But I think once you trace over your effective environment in that sense, that is equivalent to process sensor modelling. Sensor modeling, but that's not like a thing that I'm saying with a lot of confidence. That's just that's my understanding of quantum causal modeling: is that it is very similar, and that maybe in the open system setting it's identical. Yeah, I have a question, I'm not sure if I understood what kind of interventions are you using for this noise reduction. Um, just unitaries or a more general interventions? Or another more general interventions? Or what is the limit? Because, of course, interventions are something which could be whatever thing, right? So, what is the limit to have something really useful in a practical setting? Yeah, it's a good point. So, in that particular scenario, we're looking at just optimizing, say, dynamically decoupling sequences, and for that, we just explored the unitary space, so only unitary operations. But in principle, so we're able to. I didn't go into this too much, but what we do for looking at, I don't know what I've done, sorry. Person of having an up-down rather than a left-right. Yeah, so what we do for more general interventions is we use an General interventions is we use an ancillar qubit and we drive a short interaction with the system and kind of change the system and then projectively measure that ancilla to get more general interventions. And so we're able to kind of reconstruct all these sorts of processes as well. And so you could equivalently say you weren't just interested in error suppression in the form of dynamical decoupling, but rather you were interested in error correction in the form of syndrome extraction. This sort of Extraction, this sort of approach would allow you to do that because it could tell you exactly how the system responds to measurements as well. So, yeah, that leaves me a quick question online. If you went to this full picture, all error correction protocols should be writable, sort of expressable in this framework, right? Because all data is a sequence of interventions, they're different time steps, so they are just transforming a dynamical process. I think that's true in principle. I think that's true in principle. I think, in practice, constructing error correction protocols around more sophisticated noise models is actually a really hard problem. And so that's why they're all like, you know, you have some. Perhaps they could derive some fundamental balance in the capability. I think probably, yeah. I think that would be a good step to doing something like that. And actually there's a uh I can show you later, but there's a nice paper from people at Johns Hopkins where they look at the effects of different temporally correlated error models on different error correction codes and how you need to increase the distance. And they sort of show that actually in some really pathologically correlated models, that no error correction code is able to kind of correct this. And the way you optimize these things, what? What sort of optimization algorithm do you use? It seems very natural. This is kind of reinforced with learning framework, right? You've got the agent attacking the environment every time step. You put in a reward function, then off you go. Is this something that you've got to think of? It's not terribly sophisticated. It's kind of you just do like gradient descent with basin hopping kind of thing. And that, you know, it seems to, it doesn't seem to be a particularly hard landscape to kind of traverse. Hard landscape to kind of traverse. So, currently, the unit tree is this: is there adaptive operations in the sense of you apply one unitary, and then depending on what you apply, you apply the next one? Is there correlations in time? So, I guess maybe two ways of interpreting that. So, it is adapted in the sense that you are cognizant of everything that you've applied in the past, and so you know, but that's still time local, that's still like you're. That's still time local. That's still like, you are accounting for these things, but that's sort of uncorrelated. But you could also optimize for, say, you had more general interventions and you had measurement outcomes. You would then have some kind of, you could optimize over testers where you conditioned on certain measurement outcomes and that sort of thing. So, you know, it's really as far as your imagination tends. I mean, the most general sense of the common sense. Well, exactly, yeah. Cool, I guess we're probably all hungry now, so. I guess we're probably all hungry now, so I feel bad about the online guys, so maybe one more question from the online audience. Is there someone from the online audience? That's clear. Thank you very much. So it's all just a different stuff. It's too bad. Like what people say about it. It could be uh just uh stuff with you with uh solution. So this could be actually identical. But but we can't get your assets and you think it's the 20 step, but then you're wrong. You said it was your thing. But the no one, I want to talk the night one. Yes, since. Yes, six and one. One next topic. But that's going to be more than just a message.