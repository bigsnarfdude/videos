Now, it's Tim Dochester from Bristol University on reduction types of auto-breakers. Thank you. Yeah, thank you very much. Thank you for the organizers for inviting me, given an opportunity to speak here, even though I can't be here physically. It feels a bit like 2020 giving an online talk after bedtime. I haven't done this for a long time. So, what I want to talk about is basically regular models of algebraic curves. So, let me just quickly tell you what my setting is going to be. You, what my setting is going to be. So, as I'm sure you know, if you have a family of curves, and by which I mean, let's say that you have a two-dimensional scheme over a one-dimensional base. The one-dimensional base could be P1, if you want to think geometrically, or spec Z if you want to think of arithmetic applications like Perswund and Dylan conjecture, and so on. And if you have a curve over such a base, in other words, you can think of it as a family of curves, fiber by fiber, then even if you're genetic. Then, even if your generic fiber is smooth, then this is not necessarily true of the special fibers. They can be reducible, they can be non-reduced. And the problem that I'm interested in is basically classifying what sort of reductions you can have and how to compute them in practice. So, just to give you an example, suppose you have a scheme like this: surface xy times x minus y. surface xy times x minus y equals 2t over p1t, or you can replace t by p by prime and think of it as over spec z. Then this is a family of, you can think of it as a surface, in which case it's regular, so two-dimensional regular scheme, regular, because it's just a graph of a function. You can solve t as long as the residue characteristic is not two. You can solve t in terms of x and y. So it's a nice sort of smooth surface, but when you fibrate by curves, these curves are not. When you fiber it by curves, these curves are not necessarily smooth. So, if you now look at it fiber by fiber, so value of t by value of t. So, if you put t equals one or two or whatever, you get a cubic curve in x and y with a point. So, this is actually a family of elliptic curves. But when t is equal to zero, then you can see immediately that this becomes x times y times x minus y is equal to zero, which is three lines, x equals zero, y equals zero, and x equals y meeting at a point. zero and x equals y meeting at a point. So we say that this smooth family degenerates to a configuration like this. And in the theory of elliptic curves, this is called a type 4 reduction of an elliptic curve. Now, this is not how you normally write down a family of elliptic curves because it's not in Wei's transform, but you can put it in Wei's transform over the field of fractions, over the field of rational functions here, over Q round brackets T, let's say. Brackets T, let's say, or C of T, if you want. And then, if you do that in the usual way, then you can convert this to a Weierstrass equation like this, over exactly the same P1 of T that I had before. So the base doesn't change. So the curve is now y squared is x cubed plus t squared. And this is now an elliptic curve in Weiers transform. And you can think of this as a different model. In other words, it's a different surface, a different scheme in X, Y, and T. In x, y, and t, which is in fact birational to the old one. Because by putting this elliptic curve in Wyrge transform, I need to invert some t's and so on. So, in fact, what happens here is that all the fibers above non-zero elements of P1, they remain unchanged. And over zero, then something changes and the surface changes. And in fact, the surface becomes single. So, I mean, I can't draw single surfaces. It's the only one I can draw. But imagine something like this. But imagine something like this. As you can see, this particular surface doesn't have any linear terms at 0, 0, 0. So 0, 0, 0 is a singular point here. So you can think of this as a family of curves varying fiber by fiber, but it's not a nice family in a sense that their overall ambient scheme is not regular. And the problem is very often to go the other way. Normally, you do start with an elliptic Kerben-Wars trust. Do you start with an elliptic Kerben-Wars transform, let's say this one, and what you want to do is to recover sort of a regular model of this curve. In other words, a regular scheme, if you want, by rational to it, which doesn't change the base and doesn't change most of the fibers, but it may change the fiber you're currently looking at, but in such a way that it's regular, and analyze what it looks like combinatorily, geometrically. Geometrically. So there are two main questions in this area. There's also some others or related questions. What happens if you do allow base change? What happens if you just want to compute what's called semi-stable reduction? And I'm not going to go into this at all. I'll just look sort of over the base that I'm given. So there are two questions: one which I call C for classification and one which I call D for determining. One is to classify possible reduction types. Possible reduction types in a given genus. So you look at all families of genus 1 curves, and then you try to see what sort of degenerations you can get in regular surfaces. And then the second question is how to actually determine it explicitly for a given curve given to you by an equation. And as you can probably imagine, this is a purely local question. So you can really analyze it fiber by fiber. So if you want, you can restrict to the following setting where the base is not. Setting where the base is now not a P1 or spec Z, but it's a spectrum of a discrete relation ring, let's say a power series in T or Z P, again, if you think arithmetically. So it's just a scheme which is still one-dimensional, but now just has two points, a generic point and a special point. So the way you phrase then the problem here is that suppose you start with a curve over K, over your field with a discrete variation. Your field with a discrete variation. In other words, you start with a generic fiber, if you wish, and then, so that's given to you. And then, what you would like to do, you would like to compute a regular model. So, this can be by some equations, but they are not likely to be regular. Yeah, sorry, was there a question? Oh, I heard something in the background. That was a problem. No question. Oh, okay. All right, sorry. But if there are questions, by the way, though, feel free to. Questions, by the way, though, feel free to stop me at any time. So, the question is: you know, can we compute the regular model? Or maybe you don't necessarily need to compute it explicitly, but what you would like to predict is what the special fiber of it looks like, what sort of configuration you have there. And ideally, so for the second question, you would like to do it explicitly. For the first question, you'd like to just classify what sort of things could possibly occur. So, for example, if So, for example, if, and that's your typical example when you study things like Burr Schwinden-Dye conjecture for curves over the integers, what you need then is for every prime p is to determine this reduction type. And you can do it prime by prime again. It's sort of locally. So in this case, if you start with this particular equation over zp, y squared is x cubed plus p squared, and let's say p is at least 5, just in case, then what the answer to the second. The answer to the second question is: Is that this is a type 4 reduction curve? In other words, if you were to compute a regular model of it, then you would find, which I just did on a previous slide, if you replace T by P, then this you would find as its special fiber. And for things like Tamagava numbers, other invariants in the Burch-Swinten-Dye conjecture, like differentials and reduction of points, this is something you actually have to do. So, for example, if you are interested just in this curve over Q. Just in this curve over Qp, let's say, so over a field now. So it's just an elliptic curve, there's no similarities of any kind, but you just want to understand its rational points, then one way to try to understand rational points is to see how they reduce to the special fiber. So you take a point, you think of it as a section going here, and then you see where it hits the special fiber. And you see that if you do it on the original Weierstrass model, then so again, you take a point in the generic fiber and you see where it reduces. Fiber, and you see where it reduces, you'll see that one-third of your points reduce to this caspital curve here, to the non-singular part of it, and two-thirds of your points reduce just to the point 0, 0. So it's not a group law of any kind. It's a bit of a mess. So it's very difficult to work with if you want to think in terms of additional elliptic curves and doing things like descent and so on. And because what happens is that if to study Is that if to study one reduction of points, in other words, reduction of sections, you really need some sort of intersection theory. And for that, you need a regular model. So, what happens here, in fact, is that if you were to compute the regular model and you study how points from your generic fiber reduce the special fiber, then you know one-third of them would reduce to this component, one-third to this one, one-third to this one. And this fiber here, if you remove the point 000, which is called now special fiber of the neuron minimal model in the setting of elliptic curves. Minimal model in a setting of elliptic curves is actually a group and everything behaves very well. So you need to compute these things, even if your original interest is just in curves over fields. All right, any questions about this so far? So let me tell you a little bit of the history of what we know about this problem. So Genus 1 is very classical. So let me just say that. So let me just say that I'm not just talking for genus 1 curves, but for elliptic curves. It's a slightly different answer if you study all genus 1 curves. All the types that I'm talking about here in genus 1, you have to allow to multiply by an arbitrary integer. So take this, for example, with a curve of good reduction, and take it with arbitrary multiplicity n and simulate on all the other cases. And that gives you a complete classification for genus 1. But then there's infinitely many of these because there's infinitely many n. Many of these because there's infinitely many n by which you can multiply. So, genus one is a little bit exceptional. Let me just stick to elliptic curves. And then, in that case, codira and neuron independently, they prove that there are 10 different types that can occur. Or perhaps if you want to be a bit more careful, you should call them families of types. Because, so if you look at one of them, this is just in Codiris notation, I naught. That's an elliptic curve with good reduction. Next one, which is an elliptic curve. Next one, which is an elliptic curve with multiplicative reduction, is called in. In other words, it's the n-gon of p1s, all meeting one another, each one meeting sort of the two neighbors in an n-gon. And you can have these configurations for arbitrary m. So in other words, this is, it looks like one type, but it has a parameter in it, which is a length of this chain. And generally, whenever I will use the word family, unless I forget to do it, but there are always sort of families. It but there are always sort of families of types that you want to classify. When you put two types in the same family, if they're exactly the same, is the only difference that the lengths of chains of P1s that you see there, they can vary. And there's always a one parameter n, which you can let off if you want to infinity. So that's the only difference. For elliptic curves, there is another type I n star, which is again a family where you have a chain of p1s of multiplicity two. Chain of P1s of multiplicity two and some other sort of stuff of multiplicity one hanging there. There is type four, which I had before, and there is dot, dot, dot, which means five other types that didn't fit. And then up to the worst one, which is type two star reduction, where you have this sort of reasonably complicated configuration of P1s with very multiplicities. But in any case, it's a wonderful classification used all over the place, and there's only 10 types that can occur with this little sort of caveat that you have to look at families. That you have to look at famines. So that settles the question C for elliptic curves. What is the classification of things that can happen? And for D, there is a famous algorithm of date which determines what happens with the DVR, perfect residue field, and arbitrary residue characteristic. So you start with a curve in a wash transform, and it tells you at the end of the algorithm a lot of invariants like the conductor and so on that you want to know. Conductor and so on that you want to know. And one of these things that it spits out, it's the codirotype. So for genus one, we completely understand what happens. Now, for genus two, there's a similar classification by Namikavo and Duiano. They're a little bit phrase it a bit differently, and they also throw in sort of semi-stable type in tame residue characteristics. But these are sort of minor details. Minor details. They did classify all genus potential, all genus types. And algorithmically, it's a little bit more difficult. There is an algorithm by Liu, which is implemented in PariGP and so used in Sage as well, therefore, but I'm not sure there has been any implementations. Oh, no, sorry. Yeah, I don't think there are any implementations anywhere else. And it does not work in RASDIC Characteristic 2. So embarrassingly enough, for hyper-literal. Interestingly enough, for hyperelliptic curves of genus 2, so anything beyond genus 1, really, we don't have a method that would start with a hyperelliptic curve and would compute its reduction type at 2, even though we do have a classification. And that's really bad because, again, for things like Burschwin-endyer conjecture verification, for example, which you need to do at all primes, you really have to know it at all primes and not just primes, which happen to be odd. So this is actually quite. So, this is actually quite a bit of a problem in databases like LMFDB, for example, which try to compute these things and tabulate genus two curves conduct or discriminant up to something and tabulate their reduction types and so on. We don't know how to do this at two. At least, not in all cases. So, that's already quite difficult. And in Genus 3, as far as classification is concerned, so there Is concerned. So there is a, I guess, third generation of Japanese mathematicians, so students of Kodaira, going up to genus 3, Ashikaga and Ichizaka, they don't quite list all the types and they don't count them in genus 3, but they give away, together with Yomatsu, how to construct them from some sort of building blocks. And I don't think anybody has attempted to do any sort of algorithm in general for arbitrary. In general, for arbitrary genus three curves, at least not so far. And sort of for a while, until I think the 70s or so, it stayed there. And nobody, I think, even dared, I think, to look a little bit further because the number of types explodes and it seems that it's very difficult to perform these blow-ups and to compute these reduction types. In principle, it's a solvable problem in a sense that there is a famous theorem of Artemis and Winters, which they did because. Which they did because they were proving Dylan-Mumford semi-stable reduction theorem in a different way. And they use this result to prove it, give an alternative proof of that, which is quite a bit simpler. It proves that in any genus greater or equal to two, again, with a little caveat, it's also true in genus one, there are only finitely many families in every fixed genus. And so, in principle, you could ask yourself You could ask yourself what they are and how to count them. And as part of what I would like to present today, I would like to tell you a bit of a possible classification of these things and in particular computing these numbers for genus up to six. And I think you could push it a little bit further if you have time to spend looking at the screen. So these are the numbers for genus up to six. They grow super exponentially with the genus, even if you assume your curve is set. Even if you assume your curve is semi-stable, so you allow all multiplicities to be one, even in that case, they grow superexponentially with the genus, the numbers will be much smaller. They will sort of look like much smaller on paper. But because essentially there's a large number of graphs you can construct with a given number of vertices and edges for large g, at some moment this kicks in and you'll find out that it grows faster than sort of at least g to the one-third to the one-third. At least g to the one-third to the power g, and that's, I don't, I'm not sure that's the right growth. Um, in any case, it is it is super exponential. And these are the numbers for genus two, so for Lemikarov Oyano case and the genus three case as well. Okay, so and now, but interestingly, in the last decade or so, there have been a lot of advances, not in the classification, but in the algorithms that actually compute reduction. That actually compute reduction types. So I know of three different strong. So let me mention them here. So, one, there is an implementation Magma, which has been there for a long time and has been improved already a few times by Steve Donnelly, which does the canonical thing. You give it an equation of a curve, it thinks of it as a surface, possibly arithmetic surface. I think his implementation is over Z, and then you blow it up. And then you blow it up until it becomes regular, and you keep track of the patches, and you glue everything together. And sometimes it works, sometimes it's harder because you need to blow up at points that aren't defined over your ground field. So there are some technical issues, and also because some of these reduction types have quite a lot of components. You see already for elliptic curves, this type 2 star thing, it's very difficult to do this. It's very difficult to do to do this sort of thing in general, but it certainly works in small examples, and it works in small examples in any residue characteristic, which makes it extremely useful if you have a specific example in mind, especially if you're willing to wait for a little bit until you get your regular model. Then there is an algorithm by myself, which uses the machinery of curves, which are called delta V regular, which don't have to be hyper. Don't have to be hyper elliptic, and it's an arbitrary genus again, but there is a rather strong restriction on the singularities that you allow. Because what this construction does, it essentially does some sort of toric resolution of your equation. And for that, the equation has to be nice. All the singularities have to somehow tend towards zero or infinity in every direction. And in that case, it works. And if they don't, then it doesn't. So again, It doesn't. So, again, it works in some cases, but not always. And there has been quite a lot of progress for hyperelliptic curves. There's been again an earlier work of Selene Maestre, Adam Morgan, me and my brother on machine learning called clusters, and it has been pushed further towards regular models, which we haven't really looked at very much there, by LUD students, Faragi and Noel, and lately, most Lately, most lately, by my student Simono Muselli, and he pushed it very, very far. So his methods can handle arbitrary hyper elliptic curves, so that's arbitrary genus, except that like in Leew's algorithm, P is not true. So you can think of it as a massive generalization of Leew's algorithm, which goes up to an arbitrary genus, and it's very fast. You give it a hyper elliptic curve, and using a machinery, sort of a mixture of two things. Sort of a mixture of two things, one which is called Maclean variations, and one which is this thing of clusters. He coined his own term, which he called Maclean clusters, which use both of them. And they're general enough to handle, as I said, hyper-elliptic curves and arbitrary characteristic. And I have a strong feeling that this is sort of a good way forward toward understanding arbitrary curves and their reduction types. But what I thought, what I pointed out. But what I point out is that these algorithms, because they work in our arbitrary genus, it's not very clear what sort of output they should produce. Because if you are coding Tate's algorithm, then one of the pieces of output that you want to output is one of the 10 cadira types, just a symbol, 2, 3, 4, you know, 2 star, and so on. And in this case, it's not because there's no classification in arbitrary genus, there's no labor. There's no labeling convention, there's no way to sort of name these types in a canonical way. It's not entirely clear what you should do. So both Steve Donnelly's algorithm and Simone's thing, which hasn't so far been implemented, at least officially, they give you in their own format collection of charts and how you have to glue them together and things like that, which is quite an unwieldy bit of information. My code gives you a PDF file. My code gives you a PDF file with a special fiber, which again may be useful if you want to put it in a paper, but maybe not if you want to study other things with your curve. So I think it is a good time to at least think about could we write down a classification and some sort of labeling convention that works in RB2 genus in that you could compute these things in small genus or at the very least in any genus given a curve you can associate to its reduction type economic. Associate to its reduction type a canonical label, and given this canonical label, which you would then call a label of a reduction type, you can reconstruct what the special fiber looks like. So that's what I want to talk about for the rest of the talk. So one thing is that, as you probably know, you have to be a little bit careful if that there's a choice involved, regular models for a specific curve C. So you start with a curve over a field and you A curve over a field, and you I talked about its regular models, model, in other words, some smooth scheme which has that curve, the generic fiber, and has something interesting as a special fiber, which is what we're after. But these things are not unique because, as I mentioned in the beginning, the way to obtain them, for example, we start from any equation and blow up until it becomes regular. But of course, you can continue blowing it up and you will continue getting regular schemes. And each Regular schemes, and each one of them is a regular model of your curve. So, because you can blow up smooth points. So, for instance, if you have this type 4 reduction elliptic curve, in other words, if this is now your special fiber, then what you could do, you could take this point here, which is, remember, it's a smooth, now it's a regular model, so it's a smooth point on a surface, you could blow it up. And then what happens? You get an exceptional fiber, which is going to be one extra P1, which you didn't see before. In this case, Which you didn't see before. In this case, it was multiplicity three because of the properties of the intersection pairing. And remember how BLOAP works on a surface, it introduces this extra P1. And what it does, it separates all lines which meet transversally. In this case, these three lines which meet transversally, they become parallel on the new surface. So the new surface would look like this, and it's still regular. But the special fiber has now a very different configuration. And you can continue this process. And you can continue this process. For example, you can take this point, which is perfectly nice, smooth, there's no reason to blow it up, but you can blow it up anyway. Then you get an extra component of multiplicity one. So this tail kind of became longer. You can take this point of intersection, you could blow it up. You get an extra component of multiplicity two. So you get this sort of whole tree of possible configurations for a given curve. And when you want to class, when you talk about classification, you have to pick a canonical representative in that class and say, In that class, and say, this is what I will call now the special fiber for this particular curve. This is what I call its reduction type. And now there are two choices. I mean, there may be more choices, but there are two that have been looked at quite closely. One which is historical, so that's the one which was used in the classification of genus 1, 2, and 3, is to look at the unique minimal regular model. The unique minimal regular model. So it's this thing here. It has a property that it's first of all regular. And secondly, it has a universal property is that it's dominated by any other regular model. Any other regular model in this construct will be higher in this graph or tree, graph, I guess, or tree of possible configurations. It sits at the very bottom at the leaf, so it has a very nice universal property. But it turns out that it's not. But it turns out that it's not as suited for classification purposes, which is perhaps one of the reasons why this classification hasn't been pushed before to arbitrary genus, because it's not particularly hard once you do it in the right setting. Because once you study curves of arbitrary genus, you get into a classification of all possible horrible singularities, like these ones. For example, we can have three lines meeting at a point, but you can have the same but with multiplicities, and you can have them not meeting transparency. And you can have them not meeting transversely, and so on and so on. Any type of singularity you can think of will occur in such a picture. So it turns out that for classification purposes, what's much better suited is what's called a minimal regular model with normal crossings, which is again regular, but it has an additional property that the only singularities you allow are transversal intersections of two components. So simple ordinary double points and nothing else. So, the reduced sub-scheme underlying the special fiber is a semi-stable curve. And so in this case, for example, it's this one here, where you can, this is the minimal one, which again satisfies the same universal property that's dominated by any other regular model with normal crossings. And you can obtain it in the same way by just continuing blowing up single. Same way by just continuing blowing up singularities which you don't like until you get one which is regular with normal crossings. And you may need to blow down something if you started with a bad model, both in this case and in this case to make it minimal. But the point is that these things now have very simple combinatorial description. It's just a collection of components, to which one of them you assach its genus and its multiplicity, and that's it, and how they intersect one another. And how they intersect one another, and they intersect one another with simple intersection points. So you just have to count how many of them each pair of the components has, and that's it. That completely determines the special fiber. So they are much easier to write down algorithmically, if you want. And it turns out that they're more suited for classification purposes. Because the sort of situation that can occur, and which I want to give you here in this example, this is type 4, 4 curve of genus 4, which is obtained. Of genus 4, which is obtained if you want by gluing two of these type 4 reductions together. So it looks like one of these, so a component of multiplicity 3 and 1 components of multiplicity 1 sticking out of it, the same thing on the right. And between them, there is a chain of P1s, each of them with multiplicity 3. And that's a type of reduction which occurs in genus 4. And in this case, you can compute all the self-intersections. You'll see that they are all not equal to minus. They are all not equal to minus one. So, this, in fact, is a minimal regular model with normal crossings. And you can see from the inductive, if you want, perspective, how it has been obtained. We take two of these guys and you glue them together with a chain. And it turns out that you can build a whole classification of curves of arbitrogenous in this way. You have to understand building blocks, which I'll talk about in a minute. They're called principal components. Talk about in a minute. They're called principal components and the multiplicities of things that stick out of them. And then you glue them with chains of P1s, and that's it. That's how you obtain every reduction type. But to do that, you really need to talk about minimal regular models with normal crossings, because although in this case, this one is both minimal regular and minimal regular with normal crossings. If you were to cut this chain of P1s and break this into two original types, then remember these types that are not mixed. Remember, these types are not minimal regular. This component here has self-intersection minus one. It's a blow-up of a smooth point. That's how it has been obtained. So this thing can be blown down. And the minimal regular model looks quite different in that you don't even see this component of multiplicity 3 anymore. So you would not recognize, if you wish, that this is glued from smaller building blocks because the smaller building blocks can have a lot of things blown down. So it turns out that. So it turns out that this is really better for classification purposes. Yes. How would it look again? So if I blew down everything that could be blown down, what would this signal look like? So if you blow down, sorry, if you blow down in the genus 4 curve at the bottom. It's even more regular. It's both minimal and low. Oh, it's both. It's like an upload. So this one you can't blow down. This one you can't blow down. So, the way you compute self-intersections, if you want to compute a self-intersection of this component, for example, you have to look at all the numbers of the components which meet, in this case, three plus one plus one plus one. That's always a multiple of its multiplicity. And if you divide one by the other with a minus sign, it gives you self-intersection. So in this case, because of this chain, it has self-intersection minus two, so you cannot possibly blow it down. But if you were to remove this chain, I don't know if I can do it, and maybe I should. Chain. I don't know if I can do it, and maybe I shouldn't use an eraser on a Zoom call. But anyway, if you remove this chain completely, then this component now has self-intersection minus one, and then it can be blown down. Are you happy? Are you happy with that? Yes, thank you. All right, great. And similarly with these things, basically, once you get such a picture of a special fiber and it only has normal crossings, you just compute the self-intersections, you take any The self-intersections, you take any one of these components and you add this plus this divided by this, you get a one. You're like, oh, this component can be blown down. So you blow it down and then you get a picture, which is this one. Then you compute self-intersection, this one, and you say, okay, this can be blown down. And until you get something where, which is now minimal regular with normal crossings, in a sense that there is no component. I mean, this one you're not allowed to blow down because I. This one you're not allowed to blow down because then you have three components meeting at one another. So it's not regular with normal crossings anymore. So the only things you can blow down are components in chains, the components which meet your special fiber in only one or two points, and they have self-intersection minus one and genus zero. So these things you can blow down, and if you can't have and if you don't have any of them in your picture, then it's already minimal regular with normal crossings. All right, so basically this. All right, so basically this proposes a solution for this to the classification problem for reduction types. There are things which are called principal components, which in particular could never ever blow down in a minimal regular normal crossing. The definition is that they either have positive genus or they emit a special fiber in at least three points. If you have a component with a self-intersection, which is allowed, the self-intersection counts as two intersections. Intersection counts as two intersections, otherwise, in that you just count where it meets the rest of the special fiber. And if there are at least three points, so like this one, for example, meets a special fiber, at least three points. This one, well, actually, only in two, but hopefully it has positive genus. And this one also has positive genus. So these three are called principal components. And all the others in this picture are what I would call chains of P1s. They're components of genus zero. They emit a special fiber in only one or two points, and therefore. One or two points, and therefore they form chains like this between principal components. These chains can be on two different types, then can be link or open, they can link to components like this one, or they can just hang and go into nowhere like this one or this one there. But that's basically it. And to such a picture, you can associate a reduction type, which is just a graph, or more technically, a multi-graph, because it can have loops or multi-graphs. Multi-graph because it can have loops or multiple edges with markings where you mark each principal component with its invariance. You mark every edge with its invariance of the corresponding link chain. And this will give you what you could call a reduction time. And then there is an old theorem of Winters from the same Artem and Winters time that says that any configuration you control like this, it actually does occur as a special fiber of some curve over a discrete variation. Curve over a discrete variation ring in residue characteristic zero. It's a very interesting question to which the answer is probably yes, that whether you can realize any one of these reduction types in any residue characteristic. And the answer certainly is yes in genus one and two because we know how to write them down. But the sort of the kind of deformation theory, which Winters does, he remarks it doesn't work in general. So I don't think we have methods at the moment to prove. At the moment, to prove the same result in arbitraries characteristic. But you can still classify them, you can still classify all the reduction types, and you know that they all occur at least for some curves. Okay, so let me just briefly say something about these principal components and what sort of invariants you associate to them. So, suppose you have a principal component, one of these thick lines which I had before, which either has positive genus and it or it meets. Positive genus, and it, or it meets a special fiber in at least three points. So its genus is G, germatic genus, its multiplicity is M. So these are two main invariants. And then you can look at the chains which lead from that component, and you can look which ones of them are open. In other words, this is the beginning of a chain which goes to nowhere and it has initial multiplicity D1. And there is another chain which again goes nowhere and which stops at some moment. stops at some moment and it has initial multiplicity d2 up to dk and then you look at the other multiplicities dk plus one up to dn which are initial multiplicities of link chains so they're chains which lead to other principal components and you package this into what you could call a type of the principal component which is just a four-tuple multiplicity genus set or multi-set because there was multiplicities of multiplicities of open initial multiplicities of open chains and initial multiplicities Multiplicities of open chains and initial multiplicities of linked chains. And then, if you fiddle with it for a bit, then you find out that there is a quite natural sort of Euler characteristic associated to it, which is given by this formula. You take multiplicity times 2 genus minus 2 plus n, where n is a total number of chains. And then you take away the sum of GCDs of m multiplicity of the component n di, but only for the open chains. And this sort of looks like oil. And this sort of looks like Euler characteristic. It behaves like Euler characteristic. I think it is an Euler characteristic of something. There is some sort of orbifoldi or stacky graph with markings or something, which has this number associated to it as an Euler characteristic. I don't know exactly what it is, and if anybody does, I would very much want to hear it. But there seem to be sort of similar things in Orbifolds with these GCDs and so on. So I have a feeling that there is a geometric object associated to. Geometric object associated to such a principal component, which has naturally 'eula characteristic. That I don't know. But what I can prove is that, first of all, if you sum these things over all principal components, and importantly, this is independent how they glue together. You can glue them in any way you want, once you have the sort of these Lego blocks, these principal components, and you put them together by deciding which link chains you're going to join. And there are necessary and sufficient conditions, which are not very hard. Sufficient conditions, which are not very hard to write down and go basically back to Hirsch Brucken Jung, which tells you when this is possible. And then, whatever the special fiber configuration you get, the genus will always be the same. The genus of the generic fiber is given by this formula. The two genus minus two, if you want, the Euler characteristic of the generic fiber is the sum of the Euler characteristics as given by this formula here. So that's the first thing. Secondly, there are always non- Thing secondly, they're always non-negative, and again, I would love to have a slightly nicer proof of that. Mine is a bit of a sort of case-by-case analysis of what happens when you have exactly three of them. And it turns out that this condition is basically essentially equivalent to this component being principal. But it would be nice to have a bit more conceptual proof of that fact. And then you can show that, and that's not very hard, to prove that there are only finitely many component types with a given. Component types with a given Euler characteristic between zero and any given down B. And you can include zero here if you're a little bit careful again with genus one types, take multiplicities into account. And this, together with necessary and sufficient conditions for the chains, basically gives you a classification. It gives you an algorithm how to construct these things in RB2 genus. It turns out that there are not very many of these finitely many component types with any given chi, much smaller than these large numbers of the reduction type. Than these large numbers of the reduction types you've seen before. It's just that there are many ways to put them together, but these ways are easy to control. And apart from classification, what I would like to get out of it as well is a canonical label coming out of the reduction type. So, if you think of a reduction type as a graph, or multi-graph, if you want, so it has its vertices, principal components, as I said, they come with their markings. Said they come with their markings, M, G, O, and L. The edges, which are linked chains between them, they come with their own markings, which are essentially initial multiplicities and the length of the chain. So the only three invariants you need to know about it. And then the chain can be reconstructed uniquely. And then the question is, suppose you have a graph with markings. So every vertex is marked, every edge is marked. Can you give it a canonical label? Now, I looked a bit at whether graph theorists looked at this question. Theorists looked at this question and I didn't find anything. So, if people know something about this, I would very, you know, if there's a canonical convention about how to label graphs, I would definitely like to hear about it. But basically, what I do is that, well, if you want a label which reconstructs a reduction type uniquely and canonically, then at the very least you have to print every vertex and you have to print every edge. And ideally, you'd like to print every edge that. Ideally, you'd like to print every edge. There can be a lot of edges only once. So you have naturally looking for what you call Euler paths or Euler circuits in a graph. So in this particular graph, for example, which has only two vertices of odd degree, there's what you call an Euler path. You can start with either C1 or C3, and then there is a path which traverses every edge exactly once, like this one here. So you can look at all such paths. You can order them lexicographically if you decide how you. If you decide how you order your vertex labels and how you order your edge labels, then you get a natural ordering on this path. And then you can choose one which is smallest. And then you print it. You say, this is going to be my canonical label. There are polynomial time in genus algorithms how to compute these things. And in any case, for genus, which is small, this is not an issue. And then you print whenever you see a vertex for the first time, you print its. You print its invariance. Whenever you see an edge, and every edge you see only once, you print its invariance. Whenever you see a vertex again, you just say, well, this is again vertex number one, this is again vertex number four, this is again vertex number three. And you have to introduce jumps in case your graph is not Eulerian. Like, for example, you have an edge here, and to say that, well, I have to jump here to vertex number two and add an edge to vertex number four. In any case, it's the shortest possible path you could think of. Possible path you could think of. And among those, you choose one which is lexicographically smallest. You decide how to name your components, and then you get your label. So, and finally, I don't know. I think it changed a few times. Can somebody tell me how much time I've got? 19 minutes. 19 minutes. Oh, okay, because I thought I had 45 in total. So, okay, I don't. Yeah. Well, I'll try to keep. Yeah. Well, I'll try to adjust the schedule so you recovered those last 10 minutes. So, yeah. Okay, thank you. I don't think I need this much, but I will. But maybe if there are questions or somebody wants to compute specific examples, I'm quite happy to do that. So let me maybe close this. So can you see my MADMA screen? Okay, great. So what I would like to do is to implement now everything that I talked about so far. Everything that I talked about so far in a sort of a magma package, which, and ideally, because these things are quite easy and combinatorial, I would like to somebody to maybe help me to port it to other computer algebra systems. And my packages are always on my website, so anybody can look at them. So, one thing that you could do is to, as I said, start, but maybe let me look first at labels and reduction. But maybe let me look first at labels and reduction types. So, as I said, if you start with a label, and the label could be something like just a codira type, for example, this is two. The building blocks which correspond to elliptic curves, I kept the codira neuron classification, so I just called them with their types. But you can glue some of these things together. So, for example, this is a reduction type, which occurs in genus three, and you can probably imagine without me showing you. Imagine without me showing you what such a thing looks like. Let me see if it works. Yeah. So, this is the picture of the special fiber. This is a graph. This is the label in tech that it's going to have. And this is how it's going to be eventually magma as a plain ASCII label type in, which is what I did. And what it looks like is a type 2 elliptic curves that you see here, minimal regular models, component format 263. Component multiplicity three and things two, three, one sticking out of it, and then a type three elliptic curve, and then another type four elliptic curve, and they're all glued to one another in a chain of P1s, which by default has minimal length. And you can make the length bigger by putting, I don't know, five here or something. Hopefully, it still fits in my PDF file. Then you get exactly the same picture, except that you see here there's a longer chain now of components of multiple. Longer chain now of components of multiplicity one. It's the same family of types, so if you remove all these round brackets, you still get the same family. The label changed slightly, is that it has this subscript now, which says that this length is not minimal possible. It's five in this case. And that's it, really. And conversely, if you, and maybe let me show you one, which is maybe a little bit more. Well, I do the same thing with elliptic curves, maybe, but I put an ion star in between, which is two principal components and show it to you as well, where the graph is a little bit more complicated in that it's not just one line anymore. And so you don't see it here, but you will realize at some moment that at some moment you do need this convention for graphs, which are a little bit more complicated. For graphs, which are a little bit more complicated, you can't just stick to labels which are completely linear. But in any case, you can reconstruct from a graph, you construct its label, and from a label, you can reconstruct its graph. And as I mentioned before, there are these methods now to going back to the other problem, not the classification problem, but the determination problem: how for a given curve you can compute its minimal regular model, how you compute its. Minimal regular model, how you compute a special fiber and what to determine and how to determine its label. So, let me give you one example, one, or as many as you wish, in fact, because I have a lot of time. But one is, let me take something hyperelliptic, which is quite bad, but not two. So, this would use Simone Musellis code or algorithm for computing hyper elliptic curves. So, this is a hyper elliptic curve which has quite bad wild reduction at three. Bad wild reduction at 3, which, as you can see by this polynomial on the right, it's highly ramified over Q3. And then, but it's instant to compute. And then you can look at its reduction type. And I don't know, it's some GDUS for curve, y squared equals a polynomial of degree 9. This is its full label. This is its full graph, which looks in this case exactly the same. And this is what it looks like. And this is what it looks like. When you go beyond cadirotypes, you run out of Roman numerals, or at least I don't use them anymore. So you have to use just basically a simple numerical notation by saying I have a component of multiplicity 12 whose things of multiplicity 1, 5, and 6 going out of there. And 5 you can see here in a chain, and 3 here in this chain. So it means that this chain here starts with the 3, this chain here ends with a 5, and this is again. The five, and this is again, unless these numbers are minimal possible and therefore default, you have to print them as part of the label. And again, this label, once you know it, you can look for it, you can Google it, you can look for papers which use which found out such a reduction type, and you can use all other nice things you can do with the label of a reduction type. So, this one uses Simone Musellis code, and I think I taught myself never to do this on the spot, but let me try to. On the spot, but let me try to push it in a larger example and see if it can do that where you can take something even more ramified. Yeah, so you see, when you go to hygiene, these things, they do become more and more complicated, but hyperlitic curves away from two, we know how to handle them quite well. And you can see this computation is completely instant, which is really wonderful with these Maclean valuations. They only use arithmetic over the graph. Arithmetic over the ground field. Essentially, it's Newton polygons that you're computing. You know, Newton polygons, you know, when you factor polynomials over p-iadics, there are two basic algorithms. One is when your Newton polygon splits, it breaks, then your polynomial factors. And one, when your polynomial is, let's say, Eisenstein, then it's irreducible. And if it's neither of these two, then you have to look a bit further. And this looking a bit further is provided by the theory of Maclean variations, which is kind of an inductive process. Invaluations, which is kind of an inductive procedure, which in particular gives a factorization method for factoring polynomials over local fields. But in the case of hyper elliptic curves, applying it to the right-hand side of the polynomial in the hyperelliptic curve and merging it with what Simone Musalis called Maclean cluster machinery gives you all the principal components, it gives you all the chains, it gives you all the charts, it gives you completely the reduction type of this component. Of this curve. And let me give you another example, maybe, which is, as I said, there are some other methods, one which is this delta V regular machinery. Let me pick one of these, where, as I said, you can have some sort of toric singularities, which are not. I'll just strike a curve which is large genus and not hyperelliptic, but it's not too bad in a sense that if you take its Newton polygon, you will. you won't have any faces which are which are which have in several polynomials on it. So let me do this at two. I think it worked, I think, if I remember correctly. And show it to you as well. Yeah, again, this is some sort of reduction type. And what can I say? It's genus 15, so you probably do expect some pretty. Expect some pretty nasty and largish principal components showing up. But in any case, they form a graph. This graph in this case is just a triangle. So you go from vertex number one to vertex number two, vertex number three, and go to vertex number one. And you can see it in a label. It decided like psychographically that this component here is smallest or largest or whatever it is possible. And then it prints a corresponding chain. Second component prints a corresponding chain. Component, prints the corresponding chain, third component, and then it goes back with the default chain back to component C1, meaning component that you occurred first one in this list, which had some, so not to reprint these markings and not to think that this is now a new component. And from this reduction type, in fact, it's even sufficiently human-friendly. Well, I mean, you can see all the principal components here. You can see all chains of P1s here. And in fact, you can even using this Euler characteristic. You can even using this Euler characteristic formula, you can even reconstruct this genus and compute it by hand on a piece of paper, and you'll find out that it's 15. And finally, as I said, what you could do, you could just combinatorially try to classify and compute all reduction types of a given genus. So, for example, here are all the reduction types in genus two. Well, I'm not sure it'll be very useful because there's 104 of them. There's 104 of them, and it just computes them and labels. As you can see, in genus one, lots of this label, or in genus two, or in fact, in any lower genus, these labels are quite friendly. They are not very cumbersome. A lot of these are just elliptic curves merged with one another. Some of them are a little bit more complicated, but they're all quite short. And maybe to end with, let me compute, not the whole, I won't give you the whole list because it's too long, but. Whole list because it's too long, but let me just compute the number of all the reduction types, and it does it on the fly now in Genus 3, and which is this Ashikage and Ishizaka classification. And you see, it takes four seconds to compute. There's 2,000 of them. And the reason it's so fast, it's sort of very easy combinatorial problem. You take a look at an arbitrary graph, small number of vertices, you decide which one of them is going to have which Euler characteristic, which is not. Have which Euler characteristic, which is non-negative, or you can quickly reduce it to positive, and that adds up to a given number, which is controlled by the genus here. And then you ask yourself, what are possible components I could put in as vertices in there? And you loop through them and you get the number of these reduction types quite quickly. And as I said, pushing it to six wasn't very hard. So it takes about four seconds for genus. It takes about four seconds for genus three. It takes, I think, a couple of minutes, maybe five minutes for genus four, and an hour or two for genus five, and about a day for genus six. And it's already a time when just saving them in a file, you know, because there's 50 million of them, is already become sort of cumbersome enough. So, in any case, what I would like to do next, I think, apart from To do next, I think, apart from releasing the paper and the package in question, so that everybody can access it and ideally have it available in other computer algorithms. I would like to merge the database of these reduction types and genomes, let's say two, three, four, five, and six, with other places like LMRDB, for example, our database maybe, which will be presented here, I think, on Friday. So if anybody is interested in having these reduction types for their geometric databases, I will be very happy to talk. I will be very happy to talk to them because I can also generate these things in HTML if you want them on web pages. I mean, the special fibers or whatever else maybe that would be considered useful. Okay, I think that's really all I had to say. So thank you all very much. Well, any questions? So, one comment you asked about labeling graphs. The one convention I know is called the sparse six representation or undirected graphs. It does come with a particular ordering of the vertices. So, that might be enough for you. Most of the time, your graphs are fairly simple. So, I don't know that you need it, but It but uh, that's what I know for graphs. So, can you say it again? Can you give me the name again? Sorry, six, so sparse, and then the number six. Okay. I can send you an email. Oh, that would be great. Yeah, that would be great because I just, you know, I don't want to reinvent the wheel and be nice to sort of be compatible with what other people are doing. Thanks. Yeah. Tim, a quick question. So you're writing the Codiro symbol, dash, collider symbol dash. Diarrh symbol dash to diagram dash. So is there a way where this would be ambiguous? So that's a very good question. So certainly, yeah, well, okay, it won't be because, oh, sorry, because I only use it. So it's the same with lengths. Okay, maybe let me pick one where, yeah, let me just, okay, right, let me just try to do this on the spot. So let's do a reduction type to two, see if it's. Two, two, see if it's happy about this. Yeah, and show all. So let's first look at this one. So here is two reduction type cadaver types, which is six with two, three, and one sticking at one another. And I said, I want to glue them together and decided that by default, it's going to glue them together by a component of multiplicity one. So the reason for that. So, the reason for that, so, well, I mean, the reason for that is you could just decide that that's what you're going to do. You could say that I'm going to order my multiplicities first by the greatest common divisor with M, and then just by the number. And then if I don't specify anything over the edge, I'm going to take the minimal multiplicities in this list. And it turns out to be a very nice convention, because if you look, for example, at the genus 2 curves, For example, at the genus 2 curves, you won't see any numbers there. They're all glued in this minimal canonical way, except I think one. Which I just saw, and then I removed. And the reason for that, there's one type where you have to specify that there's a loop on it, and the loop is not the one you would think of as minimal. So the reason for that is that, so what I'm showing you here on this picture is a genus two curve. You here on this picture is a genus 2 curve. If I glued it together by a different edge, so if I glued the same two types by, let's say, edge of multiplicity 2, let me do this here, and even give it a length maybe. You see that the genus went up, and the reason the genus went up is that the Euler characteristic formula, which I told you before, it had this correction term. Maybe I should show you rather than just talk through it. You rather than just talk through it. There was this Euler characteristic formula here, this one, which says that the Euler characteristic that the vertex contributes has this minus GCD of M with di for an open chain. So if you convert an open chain An open chain into a link one. In other words, if you decide you're not just taking a genus one type with chi equals zero and another one genus one type with chi equals zero, but you glue them together, in other words, you converted two open chains to a link one, you're going to lose, if you want, these GCDs. So your chi will go up and it go up by twice that GCD. So the bigger Twice that GCD. So the bigger the GCD is, the larger your genus will be. So in other words, this type where you don't glue in this minimal way, you will only see for the first time in genus 3. But because in genus 3 you have thousand or 2,000 of types, this ones will be lost. And again, the majority of them will still have this property that they are minimal in this sense. So it turns out that there is a quite an easy Turns out that there is a quite an easy way to decide what would be the canonical, what this minus means in a default way. So you could always specify, you know, you could always specify it anyway. But if you ask to print the type, well, not this one, but let me do it again. If I said, if I do this type and I glue it by, what was it glue? By five. Glue it by, what was it? Glue by five with one another. No, sorry, one. So I'm doing two and a two. And then I ask what it is, it will suppress this one, one. So in other words, it's always unambiguous. It's just that when these numbers are as small as possible, and that is both about the lengths and both about the chains by which they are glued, then these numbers are surprised. But it's a very good question. I'm very happy you asked it. Any other questions? Any other questions? One more thing, sorry. Can you also say if someone has given you the curve, which, and a point on the curve, which component it specializes? Yes, so these algorithms that I mentioned, let me just see, they all come with, so this one comes with, so this one comes with charts, this one, actually. So, this one comes with charts. This one actually also comes with charts, and this one comes with charts.