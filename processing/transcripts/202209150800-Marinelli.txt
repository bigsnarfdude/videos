So it's my pleasure to introduce the next speaker, Carlo Marinelli. Carlo is a professor at the University College in London and he got his PhD from Columbia University in New York. And he has worked on a variety of topics including applications to finance. Applications to finance, also control problems. And in the field of SPDs, he's known for his very fine and general results on SPDs driven by monotone operators. So today he will talk about the similar perturbations and asymptotic expansions for SPD. Expansions for SPDs with an application to term structure models, and this is also finance. So, please. Somehow, thank you very much. Thanks very much for the kind, actually too kind introduction. So, I will actually talk about some rather elementary things with a little bit of a stretched application to finance. Finance. So let's see what the problem is. So we consider a stochastic evolution equation of this form where for simplicity, the operators A and G are both supposed to be linear maximal monotone. They could be assumed a little bit more general, but that's really not the point. And also we assume that their sums is maximal monotony. Uh, maximum monotone. We could assume that just the closure of the sum and so on, but let us forget about this slightly technical issues for the moment. And the functions f and b are lip sheet in the appropriate sense, and w is a cylindrical linear process, and u0 is just an initial condition which can have some summability or also no summability, actually. Actually, although I will just present all results for P strictly larger than zero, and you can guess easily that all results can be extended to p equal to zero just by appropriate truncation of the initial condition and stopping time argument and exhaustion of the whole probability space. Actually, all the space omega times are plus by the usual techniques, so not a big deal. So, the questions are whether there is continuity, so whether the function with the So, whether the solution u epsilon, the mild solution u epsilon, is continuous when epsilon goes to zero. So, whether u epsilon converges to u, which is just a solution of the same stochastic differential equation without this term epsilon g in the drift. And moreover, we would also like to know whether it is possible to construct the most possible simple-minded expansions of U epsilon. Of u epsilon in terms of epsilon, so like Taylor-like expansion. So, for this, we would need to have that u epsilon as a function of epsilon as differentiable in a neighborhood of zero, so in a right neighborhood of zero. And this will lead to serial expansion, actually, also for functionals of u epsilon around the solution u. So, problems of convergence actually are essentially solved at least. At least in terms of having a rather general sufficient condition, which is this one: that if we know that A plus epsilon G converges to A in the strong resolvent sense, I will say in the next slide what all this means, then we have that we have strong convergence of U epsilon to U in a very nice space or in this space. So the supremum norm in time with values in H and then the pth moment of the difference between U epsilon and U tend to. Between u epsilon and u tend to zero. This problem actually perturbation, singular perturbation of semi-groups, has so without stochastic terms has a rather long history, but very short-lived actually, because apart from a couple of papers by the Japanese school around Kato, I don't know very much more. Of course, there is a large literature in Of course, there is a large literature in PDEs, which is very specific, so the vanishing viscosity limit and so on, but not the general abstract theory in terms of semi-groups, at least not as I am aware. So just to recall what is this result that I mentioned here, so that the question one is essentially solved. Let me just remember that if you consider even slightly more general case or Say slightly more general case, or of a family of stochastic evolution equations, always interpreted in the mild form. Sorry, Carlo, can I ask another stupid question? Why do you call this a singular perturbation? Ah, yes, because it will come in the second, but you're right. I should have said it right now. The reason is that we generally the interest is that when A is hyperbolic first order and G is First order and G is parabolic of second order. So, but if you want to see it more abstractly, you can just say that the domain of G is strictly contained in the domain of A. So, for this reason, it's called. So, this is actually a rather classical old terminology that is used in this area. So, it does not have any relation to singular stochastic PDF. Relation to singular stochastic PDEs and so on, really nothing. It is just singular perturbations of leading terms, generator of semi-groups in the classical semi-group setting. Okay, so I just wanted to mention that if you consider a family of stochastic evolution equations of this type where you have that a n, f and b n satisfy all the nice usual conditions are part of the fact that here Conditions are part of the fact that here I want that a n are maximal monotone operators. They could also be quasi-monotons, but this is really rather minor generalization. Well, we all know that there exists a solution of this type, so living in the best possible space. And the result is the following: that if A n converges to A in a strong resolvent sense, which I recall here what it means, it means that the resolvent of A n It means that the resolvent of a n converges to the resolvent of a in the strong operator topology, which is exactly like saying that it converges pointwise. Okay, so this is the meaning of strong resolvent convergence. So if we have strong resolvent convergence of the generator to the generator A, and the coefficients Fn, Bn are uniformly Lipschitz and converge pointwise. And converge point-wise, then we have this nice convergence result. Okay, so let's say under less general assumptions on one hand, but probably more general on the other hand, because they didn't assume that the AN were maximal monotone. Probably one of the first results is in the book, or maybe a paper of one or two years ago. Maybe a paper of one or two years before by the Prato Draccik. And there they use the so-called factorization lemma. They need more assumptions. So they gain on one side, they lose on the other side. This is really doesn't matter. Then there is a very nice, very general result by Kuntz and Fanieffen in 2011, where they also consider the possibility that this equation is taken in UMD Bank spaces, but the Spaces, but the AN instead of using macro monotonicity, they use analyticity. So the result is slightly different. So then there is a paper by De Persi, Dilio and myself in 2013 where we considered the situation with actually more general noise, but the ideas are the same, let's say, also in this case. So I mentioned this fact because, for instance, the factorization lemma cannot be used with. Lemma cannot be used with semi-martingales. While the method that we used in this paper is very simple-minded, and the funny thing is that it is inspired by non-linear analysis, whether here is while here it is, everything is linear. All right, so this is what I mentioned by the fact that point one, then let's say point one is solved as soon as we have sufficient condition for this strong resolvent convergence. And so it reduces everything to. And so it reduces everything to the deterministic problem, rather classical perhaps. And in terms of the stochastic problem that at hand that we are considering here, there are, well, the first approach that we tried in a joint paper with Alberti and Mastro Giacomo, which is going to appear hopefully this year, maybe next year, we did something say that was very problematic. Uh, was very problematic. So, we use a Taylor-like formula for well, forget the epsilon for S of G that I will show later. And this implied that we needed to make very strong assumptions. We needed to assume that the semi-groups generated by ENG commuted and that the coefficients F and B were just random, time dependent, but could not depend on U and it was very, let's say, an unpleasant result. An unpleasant result. Well, let's say maybe a first approach, but one could hope for much more than that. And then after that, I tried a rather rather, again, very simple-minded idea, which was just to formally differentiate the equation with respect to epsilon and hope that these families of linearized equations would admit a solution, and then to prove that, in fact, these solutions to the formally differentiated equations are, in fact. formally differentiated equations are in fact the solutions, are in fact the derivatives of the solutions of the equation itself. And for this approach, it turned out that, well, there are one still needs to assume rather strong conditions on A and G, but there is no need to assume that A and G generates community semi-group, and there is no need to assume that F and B are just additive terms. They can be Additive terms, they can be real coefficients depending on you, and actually they can even depend on epsilon, which is could be useful, let's say. And just a very minor remark. One will think, well, okay, this idea B is not an idea, it's just a full, complete triviality, which I would agree on. But normally, stochastic evolution equations, when one looks at even continuous or differentiable dependence on the initial condition. Or differential dependence on the initial condition, you look in old papers, and essentially everyone simply writes the equation like this: where this phi is the fixed point operator, and then they try to get theorem, the regularity theorems on the implicit function theorem depending on a parameter. This is very often, it is mostly the case that this approach is taken. But this approach is too involved, and the implicit function theorem requires too much regularity, and it's not really necessary to do this. And a kind of motivation comes from a part of the theoretical interest by itself, let's say, but we were kind of motivated by this by a circle of ideas around the so-called Muselas SPD, which. The so-called Muselas SPDE, which is an SPDE representing the time evolution for instantaneous forward rates, which are basic objects in the term structure of interest rates. So you don't need to know anything about this topic, by the way. You can just think about, just look at this equation and believe about a few trivial things that I'm going to tell you. So that if you want this equation to be, let's say, feasible. Be, let's say, feasible from the financial perspective, which means that the corresponding bond prices will be local martingales, then there is a structural or say rigidity on this equation in the sense that alpha zero will be a function of sigma, and the alpha zero will be exactly this. Okay, and this is just first-order derivative in X. So it turns out that with this, let's say, rigidity construction. With this, let's say rigidity constraint on alpha zero, this is sufficient and necessary condition for the market to make sense. Okay, essentially, this is what it is, and in other words, for as I said, for implied bond prices to be local martingals with respect to the reference measure. On the other hand, empirical observations suggest that it could That it looks more likely that in the physical measure, so not in the pricing measure, this equation should be of second order. So, there are plenty of issues here that I'm not going to touch upon, but a rather, let's say, first simple step that one could try would be to look at a parabolic regularization of this Mozilla SPDE and try to see whether, since we know that adding this term will Adding this term will imply arbitrage, and it will be interesting to see whether we can find at least a bounce between the real bond prices, which are the ones without the epsilon term, and the fake bond prices, if you like, the approximated bond prices with the added term epsilon. Okay. So, for this term, may I ask you a question? For this term, this actual epsilon term is just due to the regularization, right? The regularization, right? Or are there any like a real interpretation for this epsilon? So, yes, so this is just a regularization, as you said, yes, but the thing is, the one that I just said, that there are some papers by Kant, El Carwilli, and some other people in the 90s that suggest that in the physical measure, we should have a parabolic equation, not a hyperbolic equation. A hyperbolic equation. So that's why we tried this approximation here. But of course, if one wants to be precise, there is a mix up here because the physical measure and the Martigan measure are not the same. So yes, that's why I'm saying that this is just it is just a first step, but not necessarily the best possible thing to do. Possible thing to do. Okay? All right. Okay. Thank you. All right. So here come these heavy assumptions that I was mentioning before, which is still better than the commutativity thing. So first is something that I just said, that we assume that the closure of this sun is maximum monotone in a certain interval, and we just assume that this interval is one. And we just assume that this interval is one. Okay, so it's all right. So this just means that the range of this operator is tense in h for every strictly positive lambda. And then we have a kind of, let's say, regularity-preserving condition of S alpha, which can be of SA, which is the semi-group generated by A, which is expressed by this assignment. This assumption here, which yes, is relatively heavy, of course, but it is not that bad, probably. So I would just like to mention that since A plus epsilon G is monotone, then it is automatically closable, and I will not distinguish between A plus A G and A and the closure of A plus A G in the notation. Okay. Okay, so existence and uniqueness. So, for the developments that we will see, we need a bit more than just the existence and uniqueness of H-valued processes. We would need to have processes taking values in appropriate domains of powers of g. So that's why we take this, we consider this family, let's say, of assumptions and we give a name to. Assumptions and we give a name to assumptions of this type on H. So we call it HMP for natural M and positive P. So, where we assume that a part of the usual measurability conditions and Lipschitzianity, so by this term I just mean less or equal module constant. And we need, of course, existence of at least one element in H where One element in H where we have this integrability conditions for F and B. This will simply imply, together with this uniform Lipschitz property, that whenever you apply F to an element of H, these two conditions will always be satisfied. So, the idea is to just apply the theorem that I mentioned before. That I mentioned before. So, this one here. So, the fact that if we take this equation and we have that converges to A in the strong resolvent sense, then we should have convergence of the solutions. Of course, here there is a little bit of a technical problem, let's say, that one would see immediately, because here, since we want convergence with state space DGM, we need to check that all these conditions. Check that all these conditions, so convergence of strong result, the convergence of A plus epsilon G and so on, they all remain true if we pass from H to D G M as state space. So once we check that this is true, then this proposition will be proved essentially. So and what do we need for that? So first of all, First of all, I would just like to give here a more general result that is interesting in its own right. If one just wants to have strong result of convergence, one needs a lot less than this strong condition that I mentioned here. So this strong condition that I mentioned here is fine, will guarantee strong resolvent convergence. But if one is not interested in asynchronous, In asymptotic expansions, and one just wants to have convergence of the solutions. This theorem, which is a let's say a combination of results do by Okazava and Cato in the 70s, says that essentially you need an inequality of this type. Okay, so if you have an inequality of this type, then you will have a lot of very nice things. Lot of very nice things. So, forget about these points A and B that are a little bit technical. And so, just assume from the very beginning that A is itself maximal monotone. Then we have this very nice fact that the domain of G is actually a core of A. Here I wrote the closure of A, but ignore this for a moment. And then it is actually relatively easy to prove. It is, I would say, it is almost a classical fact that if DG is a core of A, then this can. G is a core of A, then this convergence is quite immediate action. Okay. Yes. So maybe just one word about why one needs an equation of this type. So this comes from calculations and it is needed in order to prove that not only u epsilon, let's say, if you look at the equation for the resolvens, not only u epsilon would be. Solvents, not only U epsilon will be bounded, but also AU epsilon will be bounded. Then you find the weak convergence of U epsilon and AU epsilon, then you have to try to identify the weak limits. And in order to do this, you use monotonicity techniques. Okay, so this is vaguely the idea. So in order to check that, we can apply our theorem to the situation where we replace H with this DGM. This DGM. We need some estimates, some results that are, let's say, not really hard at all. They are quite natural, actually. So this thing says that once we have the condition without this term, so that is our hypothesis, then that condition extends also to the case where SA is replaced by SA plus epsilon G. So whenever I write S of something, it means semi-group generated. Is semi-group generated by that operator. I should have written, I should say whose negative generator is that operator, but forget about it. It's not important. And the proof of this result, as you can kind of imagine, probably, is that you split, you try to reduce the computation to the case where A plus epsilon G is replaced by A. And there is a very nice formula to do this, which is the. Formula to do this, which is the trouble product formula, and one uses exactly that. And then, by some monotonicity and weak compactness argument, one can actually show that this is true. Then, in fact, remember that we would like, we need to prove that A epsilon G converges to A in the strong resolvent sense. Here we prove that directly that it works. It works on the whole scale of DGM and actually, in this sense, that if you take the resolvent of this perturbed semi-group, and then you take the resolvent of A, and we use just this notation for simplicity, then we have that at any point, well, I should have said at any point such that epsilon plus H is in 0, 1, but it's not. H is in 0, 1, but it's not important. We have this convergence. Okay, so this is true for every H and actually can be extended for every so it is trivial extended actually to DGM actually. So and the way that this is done is just by using the so-called second resolvent identity and the characterization of the resolvent in terms of the Laplace transform of the semi-group itself. Laplace transform of the semigroup itself, and by doing computations on DG, and then by the fact that these two semigroups resolvent, sorry, are uniformly bounded in the space of bounded operator on H. And since we have convergence on a dense subset, we have convergence on the whole set. Okay, so this is a rather simple idea as well. And the final thing that we And the final thing that we need is that also the semi-groups themselves, when restricted to DGK for all the scale of domains of powers of G, they are strongly continuous. And the idea to do this is just to prove first weak continuity and then recalling that for strongly for linear semi-groups, weak continuity implies strong continuity. And as a matter of fact, And as a matter of fact, as I said, we have also this convergence on DGM. So we have that this convergence holds in every DG K. So this convergence is not only in H, but also in the norm of this space, of these domains. Of course, also, I didn't say this, but the domain of these spaces are, sorry, these domains can always be interpreted as Hilbert. always can always be interpreted as Hilbert spaces with the graph norm. Okay, so it's a simple thing. Okay, so the and then let us see what would be the uh the the uh the idea that the second idea that I mentioned before that if I can ask a question. Yeah, yes, certainly. Did you use this uh lower bound on the inner product AUGU that you mentioned? The lower bound on, yeah, you had the general result, a few slides. Yeah, this one, the no, actually, because I mentioned this to say that if you want only convergence of the perturbed semi-group to the original semi-group, this is already enough. But what I'm using is too much. I'm using this. This so if you use this convergence is very simple to prove actually so you get something simpler than uh the general this is simpler, but I'm asking too much. I'm asking very much. Okay, so what I'm asking here is saying that essentially is saying that if I measure the regularity of phi in terms of belonging to DGK, it means that S of A leaves that invariant, not only, but does not increase the noise. Not only, but does not increase the norm too much. Okay. So it's a bit too much, actually, this. But I haven't checked whether this condition implies this condition. All right. But maybe I think it does, actually. It's probably true that this is actually larger or equal than zero, but I'm not 100% sure. But you have tried to work under those standard conditions and you... Oh, no, no, no, it's impossible to work with this because. No, no, no, it's impossible to work with this because you don't get any completely insufficient in order to get higher regularity of the derivatives. So to get the differentiability of the function itself. Actually, one can prove that without assuming anything in terms of regularity of F and B, in terms of DGK, you get no expansion. Uh, you get no expansion, even at order one. So, yes, it's a little bit of a so actually. Yeah, sorry for the interruption. May I also ask you another question? Of course, of course. Can you say a few more words about the choices of alpha k those constants? So, by sorry, sorry, I cannot understand you very well. Can you talk slowly here? Yeah, okay, yeah. Uh, so and uh, can you say? So, and can you say a few more words about the constants of alpha k? So, in the proof, right? So, there exists a constant of alpha k. Can you tell us a little bit more about the properties of alpha k? The alpha k, in the proof, in the result, you see maybe a page nine. Torgo to the page nine, right? See, and this is the less than equal to e to the The less than equal to e to the alpha kt. Can you say a few words about the alpha k? No, alpha k. Alpha k is alpha, you know, if you don't like alpha k, just put it equal to zero. This is something entirely trivial because this is just to allow the operators A or G not to be exactly monotone, but to be, let's say, a little bit less than monotone. So quasi-monotone or so, in the sense that instead of A being monotone, So, in the sense that instead of a being monotone, then a plus a certain constant plus alpha i is monotone, it will be something the alpha k can be like a bounded, right? Can be a uniform bounded, uniformly bounded number. So, each can be an uniform. I think every number is uniformly bounded by itself, right? But alpha k are just constants, nothing else than that. They are constants. All right, okay, they are just constants. All right, thank you. Just constants, all right. They are just there in order to uh, let's say, allow marginal, marginally more generality, but they are really not. So the point is that I cannot say that here, like I can put a constant capital M, let's say, or something like that. No, I need really this kind of growth. Okay. All right. Okay. I mean, the growth with respect to time. The growth with respect to time, right? You need the growth with respect, yeah, yeah, yeah, yeah, yeah. Yeah, the growth with respect to time needs to be bounded, let's say, at most by something like that. Okay, okay, thank you. Yeah, sure. Okay, so I was saying that we just compute to the derivatives, yeah, formally, we just formally differentiated the equation. So here, So, here I use this notation uk epsilon simply to like to take in the sense that I denote by this the object that is a completely formal object, which is obtained by taking the equation and formally differentiate. So, pretending that everything is differentiable. Okay, so I do this for n equal to one and then I do it for n larger or equal than one, where there are appearance of these terms that are, let's say, they can be obtained in close form, if you like. Obtained in closed form, if you like, they are related to the nth derivative of the composite function, which sometimes goes under the name of the Fadi-Bruno formula, but this is absolutely uninteresting. Okay, so what is important for me is simply that these terms, Vn and lowercase Vn and uppercase Vn, can be written in a certain form. So, in the sense that we can have form so in the sense that we can have a term of this type where we take the nth derivative and then other terms with derivatives of lower order okay and so in particular then if we look at the derivatives of the the terms involving f and b so here we should pretend that we have u instead of g but since i want to do the computation i want to have the computation to make Computation, I want to have the computation to make sense. I just take some g epsilon, which is C infinity. Okay, it doesn't matter. I just want to see the form of this object. And so what is relevant is that the rest, so if I isolated the highest order term, or the lowest order, actually, the order one term, so B prime, then what I have in the rest is higher order derivatives. So this will be maps in the multilinear form. Multilinear functionals, so J linear functionals, and they take these many elements as inputs, and the order of derivations, of course, are related by this identities. Okay, so everything is quite simple, as a matter of fact. I just need it in order to justify some estimates that I will obtain. That I will obtain. Okay, then in order to be able to say something about this equation for formal derivatives and then also for derivatives, proper derivatives, is that the coefficients of the drift and the diffusion coefficient need to be differentiable in some sense. Here, I take a little bit too much on what is needed, but in this case, there is. But in this case, there is actually no loss of generality. So I assume that they are C1. And notice that I don't take that they are C1 with values in GM, but with values in the domain of GM minus one, because every time I differentiate, I will lose one order of regularity. And just by Lipschitz continuity of F and B, actually, this hypothesis. Actually, this hypothesis immediately implies that these functions are actually of class C1B, so C1 bounded. I should have said better, actually. I should have said that they are C1 with bounded derivative, so not exactly C1B. Okay, so then we start with something which would be just considered an observation that the observation Considered an observation that the observation is that once we make this assumption and we look at this formal, formally obtained stochastic differential equation, we consider it as a proper stochastic evolution equation and we look for solutions U1 and the solution in fact does exist and it is it under the same assumption that guarantee existence we have that also u epsilon one That also u epsilon one exists, but it lives in a space with slightly with one order less regularity in terms of this belonging to domains of power of g and the proof is just essentially by by by inspection there is nothing more than that so the we just consider this auxiliary results that we that we mentioned before Results that we mentioned before: that the restriction of the semi-groups are still well-behaved semi-groups on all these domain spaces. And that since we assume existence, then we have automatically that G u epsilon belongs to the space. And then it is standard elementary well poseness for a very nicely behaved class of stochastic evolution equation because you see that both the one for first order and Both the one for first order and nth order are actually linear. They are linear. The problem is that the coefficients are random, they are time-dependent, they do not have very nice bounds in expectations. So there is a little bit of accounting to carry on, but otherwise it's not really hard. So then we do the same trick for nth formal derivatives. For nth formal derivatives, assuming that, let's say, we have at least proved that the first formal derivative is well posed. And in order for this to work, we actually do have to assume that the higher order derivatives are very well behaved. And the reason will appear quite soon. So, and once we make this And once we make this assumption, which is of course stronger, you see, then we have that also the equations, the nth formally derived, formally differentiated equations admit a solution. And the new fact with respect to the first order formal derivative is that we don't lose only in terms of regularity, we also lose in terms of integrability. Sorry for the interruption. Sorry for the interruption. Probably I misunderstood something. When you're taking the formal derivative, I guess the derivative is taken with respect to the epsilon. Is that correct? Yeah, yeah, yeah, of course. Completely correct. Okay. All right. So when we take the derivative with respect to epsilon, why we still have the epsilon appeared in the derivatives? Because I take the derivative on a whole interval. I said that I take derivatives. So for Derivatives so for all epsilon in an interval of in a right interval in a right neighborhood of zero oh okay yeah all right okay thank you uh yes all right so uh maybe i'll just show why there is a there is this loss of uh integrability and the loss of integrability is explained by the fact that we have this Is explained by the fact that we have these multilinear expressions here. Okay, so we have these multilinear expressions that, of course, can be estimated simply by saying that I take the operator norm of this guy, and then I have to take all the operator norm, all the norms of its arguments. So I take the norms of its arguments, and in order to have something And in order to have something finite, since I don't know anything specific, I will just use the Herder's inequality with these coefficients. And you see that the sum of all these guys will be n over P, and that's what I have here. So, this is the reason why I lose integrability. Okay, because, of course, I assume that I Because of course, I assume that I start from. So you see, u epsilon zero will be in P. So I cannot claim anything better than this, unfortunately. This is the point. Okay, so this is the reason why I said that, yes, these equations are easy in the sense that they are all linear, but the integrability of the coefficients plays against us, okay, because they are random and they depend. Random and they depend on all formal derivatives or derivatives of lower order. Okay, but anyway, it turns out that we have this term that so this is the term of the rests, let's say, following B, and then there will be a rest depending on lowercase F, but it is treated in exactly the same way. And the first order term instead, so remember. First order term instead. So remember that when we have the formal derivative here, you see that we have some first order term, rests, another first order term, and some rests. So these rests will only depend on order up to n minus one. Okay, so that's why I isolated them. And this term also satisfies this assumption. So in particular, then we can establish, we can claim, as I wrote here, we can claim the existence of this. Existence of this equation, of this solution in this space, applying just condition H M minus n P over n. Okay, and then in order to establish first order differentiability, we again do something which is entirely natural, which is simply to say, well, let us compare the four, let us prove that, in fact, the formal derivative coincides with the limits of incremental ratios. So we simply write when it comes to So we simply write an equation for the difference between incremental ratios and the formal derivative, and we play around with it, we get some estimates, and we show that it converges to zero. Essentially, this is what we do. So since this converges to zero, then it means that then u epsilon is differentiable, then its derivative is nothing else than the solution to the formula differentiated equation. And that's it. Equation, and that's it. And in order to prove higher order differentiability, we do exactly the same. So, assume that we have proved everything up to a certain order, let's up to order k. Let us prove that k plus 1 does the trick again. So, it is just an induction proof. And things get a bit more complicated. So, the manipulations require Require a little bit more effort, but the idea is exactly the same as before. So, the only issue here is to take into account all these multilinear terms that appear and to keep track of the integrability that we have from previous steps. And so it is a little bit of it's a kind of Sudoku, but nothing more than that, really. Okay, so. Uh okay, so uh actually once we have this we have all that is needed in order to write a Taylor expansion uh in a right neighborhood of zero, so which refines the just the convergence so we don't have just convergence but we can say something about the order of convergence of course assuming sufficient integrability sufficient regularity in terms of the coefficient In terms of the coefficient and of the initial condition. The other, I would like maybe to spend a couple of words about the other approach that we did at the beginning. So I write here also the type of results that one expects that comes also from the previous approach, not only from this. So there exists a formula which says that if you have a Says that if you have a strongly continuous semi-group which does not need to be contractive, so we don't need A to be dissipative. So, sorry, I'm switching from A to minus A here, but there is really no difference. So, you can imagine that you have a minus A everywhere, otherwise it will be the same. So, if you take an element phi in this space, so the domain of positive power of A, then you would have an expansion of Then you would have an expansion of this type. So you see, it is very similar to a Taylor expansion with an integral rest. So we showed that if we make the very strong assumption that A and G generate commuting semigroups, from which it follows in a rather trivial way that this convergence holds. Holds. Then we have an asymptotic expansion, or at least a serial expansion up to order m, m minus one, actually, with the rest of order, with the rest, which is infinitesimal of order m minus one, in a sense that I will clarify in a second. Then we have a corresponding Taylor-like expansion of U epsilon around U of this type, where all these processes V K and R M epsilon are actually obtained in this form. Actually, obtained in this form. So the process VK are obtained in this form. Now instead of writing A, instead of writing F here, I write alpha. So these are just random time-dependent functions, but we couldn't work out the case where they are functions of u itself. Okay, so we have this explicit expressions, if you like, for the functions vk. Expressions, if you like, for the functions vk. Of course, this vk can a posteriori be proved to be nothing else than the derivatives of u with all of order k. But let's say, okay, this also gives an expression for the rest, which is a rather ugly expression, if you like. So the only thing that maybe one could observe about this is that this can be seen as sort of non-linear stochastic convolutions. So you see that there is this term here. That there is this term here and t minus s. So we could write this whole integral here as an ordinary non-linear, if you like, stochastic ordinary convolution and this term as a kind of convolution with terms that involve only not only the semi-group, but also some powers of time. So, the whole thing that one needs to do once one has this kind of algebraic decomposition is to obtain estimates for all these terms. So, for, well, let us just look at the stochastic terms. They are more interesting. So, one would need to look at estimates for these terms. And what is the problem with these terms? Well, since they are not stochastic convolutions, one cannot use the usual results. One has to make up to something else. Up to something else. And by some tricks based on, let's say, freezing the time here and then unfreezing it and using reductions to estimates for ordinary stochastic integrals, we obtain relatively good estimates that are, let's say, that are comparable to the ones that you would obtain by blindly applying the Burkholder-Davis condition. The Burkholder-Davis-Kund inequality, which you could not apply. But it turns out that something entirely similar is available. And in particular, we get this convergence to zero. So this fact that the rest in this algebraic decomposition corresponds to, can lawfully be called a rest in the sense that it is infinitesimal of order higher than m minus one. Okay? Minus one. Okay, so this is what we could prove with this approach via the Taylor formula. Then to go back to, I still have a few, maybe. Sorry, before you proceed, may I ask you another question? Of course, of course. Yeah. So you formally compute the kth order derivative of u epsilon with respect to epsilon. And now you studied this and the T expansion with the And this is an attain expansion with the true and k-order derivative of VK. So, sorry, I studied what? Yeah, you formally calculated the formal derivative, right? The k-formal derivative of u epsilon, which you denoted as u epsilon k. And now you have this Taylor expansion for U epsilon in terms of epsilon, and you have this and the exact k-order derivative of VK, right? V k, right? So I was wondering: are there any connections between the k or the formal derivative of u epsilon k? Yeah, yeah, yeah, yeah, of course, of course, of course. Yeah, yeah, of course, this is just an alternative way, but this expression or an expression of this type is perfectly fine also in the more general approach that I've presented before. And this vk are nothing else than u to the power k evaluated at zero. Okay. Sorry, it's not power. Sorry, it's not power. Use superscript k, not yeah, that's right. Okay, so and but that case the formal derivative involves an epsilon, but here vk does not send epsilon at all, right? Yes, of course, because this is this is uh evaluated at zero. So I am, I am, so if you like, you can take any epsilon zero within the interval zero, one, and then you can expand around that epsilon zero. But since we are interested in expanding, Since we are interested in expansions around epsilon equal to zero, that's why I didn't dropped it here. So it's like saying that I'm doing a Taylor expansion around epsilon equal to zero. That's why there is no need for epsilon in this term. Right. So I was wondering if my understanding is correct or not. You have this u epsilon of the k, that's under k order formal derivative. Yeah. So for the kid order formal derivative, if we let epsilon Derivative: If we let epsilon be equal to zero, will the u epsilon k be equal to the b k? Absolutely, yes, yeah, yes, absolutely. All right, because actually, uh, actually, sorry, maybe I in some sense, point-wisely. No, no, no, no, no. In the best possible sense, they coincide as processes in LP with values in C0, C0T with values in LP. Okay, so I didn't stress it enough, but. So I didn't press it enough, but I meant here that we have that this is the true derivative. Okay. So the true derivative is the formal derivative. All right. Okay. Okay. So the limit is taken in any sense, right? You've taken the limit with respect to H. Yeah, yeah, yeah. But the limit is in the best possible sense. Everything here is very elementary. So I have taken limits only in the Taking limits only in the let's say in the best possible situations without there are no weak limits, stuff like that. No, no, no. Everything is very regular. All right. Okay. Thank you. Yeah. It's very regular. I mean, you know, maybe I did things in a very simple way because of my inherent limitations, but I believe that by dropping even a little bit of regularity, everything breaks down. Everything breaks down. All right. Okay. Thank you. And because actually, even though this issue is not really studied in the deterministic literature, but at least in terms of abstract semi-groups, but yes, even in the deterministic case, there are very severe limitations to going. To going beyond just convergence of order zero, which is just, let's say, convergence of the process themselves, without convergence of the derivatives. It is very hard, unfortunately. So I suspect that, in fact, even in the deterministic case, so in the sense of singular perturbations, it's not possible to do much better. But maybe I'm wrong. I don't know. I don't know. All right, thank you. Yeah, anyway. Thank you. Okay, in the last two minutes, maybe I would just like to mention then that so if we look at our initial motivation, things can be done choosing, let's say, a peculiar choice of ambient space, which is due to Filipovic. To Filipovic, and he suggested to look essentially at a kind of weighted homogeneous sobular space of order one on R plus. Why R plus? Because we only, because negative maturities do not make, negatives time to maturity do not make any sense. Okay, so this is the reason. This creates a lot of trouble, unfortunately. I don't go through all this. And a lot of trouble is that if you try to, let's say, even Let's say even take a zero square or maybe a second derivative on this space. The hypotheses are not, the hypothesis that we need in order to get the Taylor expansion do not work. This is due to the fact that since we are in a half space, boundary terms at zero appear and they trash the party completely. So in order to, let's say, To let's say avoid this problem, we did a trick which is to try to embed the whole thing in R where things would work much better. And so we look instead at a transport equation in a weighted solvolar space of order one with this weight, where w is a strictly positive real number. Strictly positive real number, and in this case, it is rather direct to show that the generator of the same group of left translations, which is the derivative, is dissipative. And each square is not dissipative, but translation of its square is dissipative. Also, it is also maximally dissipative. So, now we can play our So we can now we can play our uh we can use our machinery. The problem is that this is not Musela's equation, right? So how are the two equations related? And the relation between the two equations, without going too much into the details, is possible thanks to the existence of a linear continuous extension operator, a result which is due to Stein, which says Stein, which says that if you take H, so these are the usual sublock spaces, okay, the of order modeled on L2, so of order two. So this sub-lock space admits not necessarily unique, but there is a linear continuous extension operator from this sublock space to this sublock space. So it turns out that the domains of these operators are very strictly related to this. Are very strictly related to this sobola spaces, as well as the domain of these spaces are very strictly related, very intimately related to this spaces. So, once we have this extension operator, we get another extension operator, a linear continuous extension operator. And roughly speaking, now the trick is to embed the Musselung equation into a transport equation, play all this machinery, this perturbation machinery on the transport equation, and to translate back the results to the To translate back the results to the Musella SPD by restriction, essentially. And the reason why this works is that thanks to the regularity that we need in order for the perturbation result to hold, the solutions are not only mild, but they are strong. Being strong, this allows this translation trick, so this restriction trick. And of course, this involves uniqueness, but this is rather evident. Evident. Okay, so sorry, I'm two minutes late. I stop here. Okay, so thank you. Thank you very much for the nice talk, Carlo. And now there is time for, well, very short time for a question. So Sami is raised his hand. So Sami, please. I was just trying to, that was not raised. That was that was not raising my hand, I was clapping my hands. So then are there other questions or questions? No? But yeah, I could ask one if you, I mean, just looking back at your equation for the derivatives. So you mentioned and you explained why there was a loss in irregularity. There was a loss in irregularity, but if you just look at the equation, this is just a linear equation. So where does if you look at the coefficients of the equation where it because of the presence of this term? All right, okay. So you see, this term is the first order derivative, the formal first order derivative of this term. First order derivative of this term, okay. So, and each time you kill one regular one regularity, you kill one order of regularity, okay? Yeah, that's simple enough. Yeah, it's it's very simple, really. Everything here is embarrassingly simple. No, no, no, I'm not saying that. No, no, no, you're not saying that, I'm saying that. Okay, all right, thank you. So, I have a very, very simple question. Very simple question. So, in the behavior, when you wrote the behavior of the remaining term with respect to epsilon, I suppose that it's uniform in T over this term, right? Okay, so I used an abbreviated notation here that I wrote somewhere, but I didn't explain. I'm really sorry for that. I should have. That I should have. Uh, it was probably somewhere where I went too fast. So, that's indeed, yes, that I uh, this is the this is the topology in which it converges, so it is very uniform. Okay, okay, yeah, yeah, well, yeah, yeah, sorry, yeah, no, no, no, it was my fault. I should have uh said explicitly, or maybe I should it would have it would have been better in that slides to write this, yeah, not necessary to because it was not clear, yeah. Okay, so. Okay, so I think that it's time to move to the next one and I pass the button to Sammy. Bye-bye. Thank you. Thank you very much again, Carlo. Thank you. Thank you also for the kind invitation. Thanks.