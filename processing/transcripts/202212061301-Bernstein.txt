Thanks for the invite, which I just remembered when I got the invite in like the end of 2021 or 20 some year, I forgot what you know, I thought it was going to be that year and I'm like, I almost booked flights and I, okay, I wasn't the only one. All right, all right. I was this close to booking flights in the wrong year, so I'm glad I'm glad I made it during the right year. Yeah, this has been a very interesting conference for me. So yeah, just where I'm coming from. Just where I'm coming from. So, my background is in algebraic statistics. So, I think about varieties, matroids, things like this, but from a much different kind of motivation and way of setting things up, I think, than most people here. So, I just want to get sort of my just commentation things out of the way real quick. So, E is always going to be a finite set. And I'm going to, so everything I do is going to be in the space, which I'm going to write C to E. This is just a complex vector space whose coordinates are in bijection with E. And then with and then for each subset of my coordinates, the I sub S to be the corresponding coordinate projection. Corresponding coordinate projection and then all varieties I talk about are going to be irreducible and perhaps somewhat controversial. And perhaps somewhat controversially, for me, varieties always live in CDE, and we have a fixed coordinate system. That's basically just D. Okay, so you know, I guess a lot of physics applications. A lot of physics applications motivate this sort of algebraic geometry approach where you think about everything in a coordinate independent way. My motivation for studying a lot of these things comes from statistics and other things where the parameters or where your organization actually matters a lot. So everything I'm going to talk about is heavily dependent on being parameterized in a specific way. Oh, but in this group, that's fine. As soon as you've chosen a torus. Okay. Okay. All right, so definition. The object I'm going to be interested in is the algebraic matrix of a variety. So I'm not going to find a matri generally yet. I'll just give you, so here, the depth, the algebraic matroid. Of V, which, you know, as I've said like three times now, sits in C of E. Which I'll denote M of V, going to write something that might offend some major theorists, is the set of subsets of D such that Such that the dimension of the projection under the coordinates indexed by S of V is just the same as the dimension of V. V is a variety. Yes. Yeah, V is a variety. Whenever I write V, that is variety. Variety. And I guess, you know, if you know some atroid theory, these are expanding sense. Okay, so I'll give you an example, which should hopefully give you one reason to care about these things. Example, so let's define a map. map B from C to the two, the five to C to the edge set of the complete graph on N vertices defined as follows. It's going to take five points in R2, or C2, and it's just going to map it to It's just going to map it to the vector of all the pairwise distances among these five points. So just to write this explicitly: xi minus, sorry, yeah, I'll swear pairwise distances because then we have polynomials. Okay, and then I'm going to define the V to be the Zariski closure of the image of this map. Okay, so subsets of this coordinate set where my variety lives are just graphs, right? These are just edge subsets of the edges of the complete graph. So I can talk about the, for example, spanning sets of this algebraic matroid as just graphs. Break Matroid as just graphs. Okay, and I claim that the spanning sets of V are all graphs on five vertices with one of the following subgraphs. Uh we need one here is another one and then here's the last one. Okay. Okay. And these three graphs are, I guess the graphs containing one of these are the so-called rigid graphs, I guess 2D rigid, or if I'll say two rigid graphs on five vertices. On five vertices. Okay, so I just want to take a minute and unpack this example. So this map, it takes a set of five points. It just maps it to all the squared pairwise distances. Being a spanning set in this algebraic matrix means, right, when you project this variety onto those coordinates, you get something full-dimensional, which means that your fibers are finite. That your fibers are finite. And you can think about a coordinate projection here as you have, you know, your 10 pairwise distances among five points, and then you forget all the ones that don't correspond to edges. And being spanning means there are only finitely many ways to fill in the missing edges. Or there are only finitely many different ways you can fill in the missing distances. And practically, what this means is if you were to physically build any. Physically build any such graph in two dimensions. Assuming that your vertices are placed randomly, if you treat your edges as rigid struts or rigid bars that are free to move around the vertices, then these things can't be deformed. Right? In the sense that, for example, if I were to take, so I guess this is like a non-example. If I were to instead take like this graph on five vertices, this thing I can kind of move back and forth. I can kind of move back and forth without affecting any of the edge ways. So, this thing is not rigid. Okay, so this is one reason to care about algebraic matroids of a variety, given with the coordinator, which I guess I can stuff thank. And of course, this story generalizes. So we can replace. So actually, those graphs give me So, actually, those graphs you painted them literally on the plane. Yes, you are. I mean, literally constructed. Yeah. And okay, there's nothing special about five, there's nothing special about the plane. So we can replace, you know, five with N and two with D. We get a similar variety. You have to get a variety which is usually denoted CM. Is usually denoted CM to the D sub N. Right, and you can, so points in the real image, sorry, in the image of this map under the reels, these are just configurations of, or these are the parallelized distances among endpoints in d-dimensional space. And the same story goes through. Ones that are rigid in d-dimensions, using this intuitive definition, are exactly the spanning sets of the algebraic matroid of this variety. Of this variety. And a big part of rigidity theory, you know, historically has been to, I mean, you know, it wasn't phrased like this originally because matroids weren't around, but was to characterize the algebraic matroid of these varieties. So I'll tell you a little bit about what's known about these. Are these realizable? Matroids. Yes. So algebraic matroids from a variety over characteristic zero are all realizable over that same field. Realizable over that same field. Okay, so here's like a folklore proposition. You know, G is spanning in this in CM one and One and if and only FG is connected. All right, I can prove this to you right now, right? So assuming you're willing to accept that spanning sets of this variety are rigid graphs. If you put points in a line and you want to put enough edges in between them so that you can't like alter distances between points without just moving the whole Alter distances between points without just moving the whole thing. The only way to do that is have a connected graph. Things get interesting, but not unsolvable in two dimensions. So, and here's a story for that. So, and this is due to Hilda Geeringer. Actually, maybe some of the Actually, maybe some of the. I don't know where she. I think she was from Austria. Everyone says Gehringer, but how do I pronounce this? Is that Gehringer or Gehringer? Gehinder? Okay, all right, all right. Thought so. Okay. I can start correcting people. Good. I assume I recognize that it was true. Okay. So, oh, this was done in 1927. See? Was it? Definitely you don't pronounce like American. Okay. So, yeah, her theorem, which by the way, was, I guess, evidently forgotten or something until 1970, because there's this paper by this engineer who basically published one thing, which was this theorem, which was already discovered. So people call this Le Mans theorem. I think it was only in like a few years ago that someone like uncovered her original paper, which was in German, which I guess most mathematicians don't speak. Most mathematicians don't speak. So that's probably why, part of why it took so long for you to come up. Anyway, anyway. Well, she was a mathematician. I know, but the person who didn't read her work is an author. Yeah, yeah, they're good at that. Let's see. Yeah, so her theorem says, you know, the spanning sets. You know, the spanning sets, I guess I'll say the minimal spanning sets, also known as bases of the two-dimensional Helium variety are graphs with n vertices. Two n minus three edges where every subgraph on M vertices has at most two m minus three edges. Three edges. Okay, um, so I'm not going to prove this for you, but I'll tell you why it shouldn't be surprising. So one way to think about a graph being rigid is that you have enough, you put enough constraints onto your framework that you're building so that the only So, that the only way to move points around without changing any edge lengths is to just apply a Euclidean isometry. The Euclidean group in two dimensions has dimension three. So that's where this number comes from. And then this admost business, this is just saying they're sort of spread around the graph uniformly enough that you don't just have redundancy somewhere and then waste the constraint. Another reason why this shouldn't be surprising is this is a direct generalization of this. This is a direct generalization of this, where instead of two, I have one, and instead of three, I also have one. So there's sort of a natural kind of conjecture where you know you take D here and the dimension of the Euclidean group here, and then see if this generalizes completely. And it doesn't. As soon as you get to three dimensions, the graphs that satisfy this property for three and six don't form a matroid. So, and I mean, and So, and I mean, and the situation points in that. So, for, I mean, you know, at least like 150 years, people have been trying to find a theorem, you know, that's nice like this for three-dimensional rigidity. And like, there aren't even good conjectures. What will happen is like every now and then, someone will make a really complicated conjecture that they test for like, you know, up to like n equals 10. And then someone will come along, you know, a decade later and find a counterexample with like 40 vertices. This has happened many times. So this stuff is really hard. Is really hard. Okay. Algebraic matroids are useful and interesting outside of just rigidity theory. So two other examples, I guess I'll just assume. So one other example has to do with matrix completion. So you can ask exactly the same questions where instead of this, you pop in a determinantal variety. And then these questions have implications for whether or not certain low-ranked matrix completion problems. Or not certain low-ranked matrix completion problems can be solved. So, I'm not going to go into a whole lot of detail about that, but I'm happy to talk to people after if there's questions. I'm going to figure this is not really the crap that I'm going to sell with statistical applications. So, let's talk about how this relates to topple geometry and core generations. Oh, yeah, and I guess, by the way, my goal, I should say, for this talk is: I'm going to present you some stuff that's like, you know, I. You know, I've sort of been like throwing my tropical geometry tools at these for a while. And I think one sort of like big issue that I guess rigidity theory and algebraic matroys in general has is that there aren't really a lot of good general tools. Like, I mean, of course, you can compute spanning sets here by just computing ranks of the Jacobian of your projection maps. But that's basically the only general tool that exists. The only general tool that exists. So, you know, I'm going to talk about how to geometry, you know, has been useful to get some more results here. And my hope is that, so I know there is a way to think about this in terms of torque degenerations, but I don't know enough about that theory to like say what it is. So that's, so you know, if you want a research problem to think about, that's hopefully a good enough primer. Okay, so I want to talk a little bit about tropical geometry. Tropical geometry. All right. So let's let V be a variety defined by an ideal. Feel I in C adjoin E, which I'm just taking to mean you know adjoin variables in bijection with E. All right, then each omega in R to the opposite. Omega in R to the E defines a Grogner degeneration, which I'll define. As follows So one. So for each polynomial F C V E, and I'm going to express this explicitly like this. So alpha is J C alpha X V alpha. And I'm going to define the initial term. The initial term back to omega of f to be so sum over alpha and r max w alpha such that alpha is in j of c alpha x the alpha all right so in other words every element here puts a bunch of Element here puts a bunch of weights on my variables. So I can just take the dot product of that with every exponent vector, and then I'm just going to drop all of the monomials that don't maximize that quantity. All right, so this is just linear programming on the Newton polymer. Okay, with that in mind, then I will define in subwriting. In sub w of i to be the ideal generated by just these initial polynomials, you know, where f ranges over everything in the original ideal. Okay, um all right, and then here, you know, I guess the variety of this initial ideal is a rule of nerding generation. Of your original variety. And for me, this is the definition of a growner degeneration. Then drop of B. I'm just going to define. I'm just going to define to be the set of all weight vectors omega in R to be E such that in sub omega of the ideal of V has no monomials. Just pause for a second. Any questions? All right. So, okay, why would you do this? Well, it preserves a lot of useful information about the variety and makes things simpler. So, here's sort of the like, I guess, fundamental theorem of tropical geometry. And this, this, I mean, this is many authors across many papers. And, you know, this is all. And this is all written up in a, I guess, now not so recent anymore textbook by Baron Sternfels and Diane McGlagin. But the theorem says the following. I'm really paraphrasing here. Fraud is a highly structured Polyhedral fan of pure dimension D, where D is just the dimension of the original thriving. Okay. Um and the reason uh I care about um well yeah, so for me, you know, I mean, the tropicalization preserves a ton of information about gravity. Uh, you can, you know, I guess keeping like, you know, weights of cones and stuff, you can recover things like the degree. Recover things like the degree and probably a bunch of other stuff. For me, I only really care about the dimension because of the following corollary, which I think I guess was first noticed probably by Josephine Yu. And it says, so kind of informally, you know, this operator trap preserves. Preserves metroid structure. All right, and so formally speaking, what I mean is, you know, so in other words, S is spanning in V if and only if the dimension of the projection onto. Of the projection onto X of Schrock V is equal to the dimension of V. Okay. All right, so you know, on the face of this, this suggests. This suggests the following approach to solving figuring out what a lot of these algebraic makers look at: tropical highs of variety, and then study projections of tropicalization. So now the problem with that is tropicalizations are very non-trivial to compute. However, there are a few specific cases where they're completely understood, and leveraging that where it exists so far has been somewhat fruitful. So, I will give you one example, which is sort of the first one I stumbled upon. I guess back in 2017 or so. So it's not phrased in the paper like this because it's motivated by applications to matrix completion and not love of a Grossmanian. Love of a Grossmanian, but I'll phrase it in the love of the Grossmanian bike. I just hear new to Douglas and Cernbells, I think around 2008. All right, so let's let. Let's let Gr2N be the affine cone over the Rossmannian. So, secretly, this paper was about skew symmetric matrices, which they're Faufian is the fluker relation. So, sort of rank two. So, that's why I'm looking at the outline coding here. That's why I'm looking at the outline tone here. Okay. Then trot of this, which lives in R, you know, to the, I guess, yeah, edge set of KN. Has a polyhedral structure whose maximal cones are indexed by Um binary leaf labeled trees on MEVs and then modulo a common In n-dimensional lineality space, the generators of each cone are in or indexed. By the internal edges, right? So by the n minus three, the internal edges of the corresponding tree. Where that's a lot, I guess, all at once. Are you going to spoon Jesus? Yes, I'm going to give you an example. Example. So let's have a look at what this looks like in the n equals four case. So the maximal cones here are indexed by binary leaf-labeled trees on four leaves. There's three of those. And each one of them has a cone model of this four-dimensional lineality space, which I have. Linearity space, which I don't really need to go into details on, but here are the three. Um, three trees, and then I guess there's one non-maximal cone here, and this is actually going to correspond to the tree that's you know, kind of degenerately all of them, it's just the star tree. All of them, it's just a star dream. What is the bid? Uh, every internal vertex has degree three, so yeah, and I mean, the idea is like traveling, yeah. And binary comes from the fact that it's like, I mean, these things, at least as far as I know, come from evolution, where the idea is like at every sort of speciation event, there are two paths. Okay. Okay, so is the statement about what the tropicalization of the cross-mini looks like? All right, and then you know, there's sort of a whole long story here, but this was key to proving the following theorem. This one of mine from, I think, 2017. And it says that G is, yeah, I guess a basis or a maximal spanning set. Sorry, minimal spanning set. Of this Rosmanian if and only if G has an acyclic orientation with no alternating cycles. Cycles or start alternating closed trails. I will digest this. All right, so here's a graph. Yeah, so right, you know, the coordinates, of course, are indexed by. Coordinates, of course, are indexed by graph edges. You can talk about graphs being spanning. Oh, I'm sorry, but two n minus three edges. If you get rid of this, then that's just what it means to be independent in that matroid. Okay, so here's a graph. If I want to certify that this is spanning in this matroid, I first have to check. Yeah, in this matrix, I first have to check that it has seven edges: one, two, three, four, five, six, seven. Um, and then the second thing I have to do is I have to exhibit an encyclic orientation of it that doesn't have any alternating closed trails. And what I mean by that is something like the following. So this would be a bad thing. This would not tell me anything. Okay, so this does not certify that this is an spanning set in this matroid because here's an alternating closed trail. If I walk around the vertices like this, I'm going with the orientation and then against it, and then with it and then against it, and then with it and then against it. And that's the bad. And that's the bad thing. However, this does not certify that this fails to be spamming because I could have chosen a little bit better and gotten something and gotten something that doesn't have an alternating closed trail. So in particular, if I switch the orientation of this, I think I'm good. Oh, I'm sorry. I wish there was no alternating closed trail made. It's looking oriented. No direct cycle. All right, so is it theory clear? And okay, so and I'll just say one thing that I really like about tropical techniques when they work, which is very infrequently, but when they do work, like you don't even need a conjecture, right? Like this sort of just fell out from like, all right, I'm going to tropicalize this. I'm going to pay attention to like what the cones look like and like very carefully go. The cones look like, and like very carefully go through, like, you know, how do you certify that a certain projection like preserves rank? Um, and I mean, this just falls out. This was not a sort of thing where I had a conjecture and then I proved it. It was like the theorem just falls out. And this is not the first time that has happened for me using tropical geometry. Um, okay, so all right, and now here's my sort of like, you know, very quick page. If you make an addition now, you can take your trend job. Okay. Yeah. Yeah. Um so um here's here's here's why so here's where I guess you all come in as torque generations people. So I think of a way to get all of this using torque degeneration theory. I don't really know how, but okay, so if you have any variety and you say you care about its algebraic Matroid. Say you care about its algebraic Matroid. Then, if you have a degeneration of it where you know a certain set is spanning, then you know that's also a spanning set of the original variety. For the Grossmannian, there's a converse is true, which is that if you are spanning in the Grassmannian, then there exists a Grobner degeneration into a variety that is not contained in any union of the subspaces. Contained in any union of the subspaces that is toric where your set is spanning in that variety. So, I mean, and did this follows sort of from how like the proof went through and just this one as far as I know. Yeah, so and I yeah, so I would like to know how much that statement generalizes. And one other thing that's really nice about Toric stuff. Really nice about Toric stuff for algebraic matroid things is that Toric varieties have really easy to understand algebraic matroids. In particular, you know, I mean, for me, a Toric variety is just, you know, the Zariski closure of a monomial map, of the image of a monomial map. And right, you can express your torque variety as just, you know, a matrix that writes down that monomial map. And the algebraic matrix of your torque variety is exactly this linear matroid of that matrix. So from this Of that matrix. So, from this perspective, fork degenerations, especially if they capture like the whole picture of algebraic independence here, are potentially really useful. And I don't have the technical tools to like figure out even what a reasonable conjecture is. Could you just write down what it was? Okay, I'm trying not to be on the record for this. But yeah, I can. Yeah, yeah, yeah, yeah, yeah. Yeah, it was the thing that people were wondering whether it was. Think that you were wondering whether it was yeah, yeah, you're not happy with the statement again. You can tell us you can't listen, I'll just be very careful with my language here. Um, you can ask a vague question, yeah, yeah, yeah. Okay, so I'll start with a fact, right, which is um, you know, if W is a Grove Nerd degeneration. Of V and S and E spanning in the matroid for W then asks is spanning in the matroid. In the matroid of B. And then I'll say fact question mark.