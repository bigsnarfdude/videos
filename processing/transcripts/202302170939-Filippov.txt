Fortunately that otherwise uh I'm very happy to participate online and present some recent results related to actually Markovian embedding and also describe Tensor Networks a little bit and in connection with process tensor probably too. So let me start. So but first So, but first, I would simply kind of advertise a famous paper by J.S. C. Sarao. It's famous among the physics community, but not among mathematical sciences. So this paper actually introduced a so-called collision model, which is also called repeated interaction models in some papers. And the idea of that paper by Idea of that paper by Jay Sisa was to consider a situation when the system interacts with the environment that is repeatedly renewed. So there is a kind of stirring time tau through which the system is allowed to interact with the environment, but then the environment is renewed. So the system interacts with it again and again. And of course, this type of Of course, this type of dynamics is divisible, and we will see that there can be some limit in which we obtain GKSL equation. The idea is that the stirring time tau is much less than the decoherence and energy dissipation times for the system. So this paper is around sixty years old, but still we have inspiration from that. Have inspiration from that. And actually, this idea of stern hypothesis was kind of renewed in 2000 when many authors, including Skarani, Bujric Zieman, and others considered a simple case where the role of that environment is played by a small system, say a QB. So suppose now we have to. So, suppose now we have two systems, actually, the system in question and the environment composed of two-level systems. And we allow repeated interactions between row and elements of the environment, also called sub-environment. And if we consider this scenario where all the ancillary qubits are in maximally mixed state, and for example, consider a Heisenberg type. A Heisenberg type Hamiltonian, which is actually an exchange interaction, then we can find an analytical solution, and I present it just to give you intuition behind those repeated interaction models. So we can exactly find the representation of the qubit dynamics, find the corresponding matrix, and this solution is simply analytical. And then you can see. And then you can see that if cosine we actually use a Taylor expansion for that cosine function and use a specific kind of an assumption that gamma t, gamma tau goes to zero, where gamma was the interaction strength at the previous slide here. Then we get at the coherence time tau. And this model simply shows the And this model simply shows the polarization of the system qubit. And then you can ask questions: what would happen if we change the state ψ or we change the interaction type? And all these questions were analyzed in the middle of actually at the end of the 90s and the middle of 2000s. So, for example, if the state psi is fixed and the Hamiltonian is a swap time, then the people study so-called People studied so-called homogenization effect when the output state is close to the state ψ. Then the pure dephasing dynamics is possible when the unitaries that govern the evolution have the controlled unitary type. So there is a controlling part and controlled one. Also, amplitude damping could be described in these terms easily when the Hamiltonian has preserves the number of excitations. Citations and many more generalizations. And from that viewpoint, we could actually consider the general case. So suppose we have general Hamiltonian H and we consider a so-called stroboscopic limit. I usually call it this way, but it's not a common name for that. So when the interaction strength gamma times that stirring interval goes to zero, That stirring interval goes to zero, but gamma squared times tau is constant. And yeah, in this specific limit, we can derive many equations and actually to derive GKSL equation. So here are the two references where this limit was considered, for example, but these are not the only ones, of course. And recently, there appeared reviews on collision models where they can be used. Models, where they can be used, or what kind of physical systems can be described this way, and where they can be used also and where they can give inspiration to. But the subject of this meeting is non-Markovianity, so I would stick to non-Markovian collision models and the physics related to them, and mathematical description in terms of tensor networks related to non-Markovian models. Non-Markovian models. For example, in this review paper, there were four general non-Markovian generalizations presented. So one of them assumes that the uncellers, so sub-environments, interact with each other in between the situations when the system interacts with them. So say the system interacts with ancillary one, then ancilla one interacts. Ancilla one, then ancilla one interacts with ancilla two, and then the system interacts with ancilla two, and so on. Um, yeah, this is one of the possibilities, but it is a little bit artificial from the physics viewpoint. Although, for example, if we consider micromasers, then this situation can be in principle achievable. So, another scenario is Scenario is exactly what Anton mentioned before. It is the situation when the system and some kind of memory all together form a Markovian core that undergoes Markovian evolution, but the system as a part of that experience non-Markovian dynamics. So the third possibility is that the initial state of The initial state of all the environment particles is correlated. This could be either classical or quantum correlations, but these correlations actually enable information to propagate in time. So once the system interacted with the first ancilla, actually the total system plus environment become correlated. And it's not surprising that those correlations can come back. Correlations can come back in the system after some time. And finally, the fourth situation actually describes micromaster in a very well fashion. When several atoms pass through the cavity, say, then the system can interact with several atoms at the same time. And this is how correlations can propagate in time too. So in my talk, I will. So, in my talk, I will focus on that third scenario, as there are many physical applications where the environment is actually correlated or can be considered as correlated one. And these are the physical examples I have in mind. For example, we have a system that interacts with structured electromagnetic light. So, say any electromagnetic light light. Any electromagnetic field can be actually divided into spatiotemporal time bins. And if we look at the number of excitations in those time beams, and if there are correlations between those time bins, then we have structured light, and the interaction with such a structured light will induce a non-trivial dynamics for a system. For example, several photons. For example, several photon wave packets or more complicated light states can induce such dynamics. The other example could be the transport phenomenon when the carrier of information or charge or spin interacts with many atoms in one-dimensional line when it passes from source. From source to drain. And the general description of such physical phenomena could be as follows. So we have a collision model where the system interacts with sub-environments, individual ones, sequentially, but those sub-environments are in correlated state. And that correlated state is given by some either state vector. State vector or the density operator. And the problem is how to find the system dynamics. And of course, if we just naively write the equation for the density operator after k collisions, then this would be a difficult problem to solve because this state rho from one to k contains all the correlations. So we need exponentially. So, we need exponentially large memory to solve this problem, say classically. And then, okay, just to give an idea how this model is related with the process tensor. So this is a representation of this. So, these unitary interactions show how the system interacts with ancillary particles. And the all complexity of And the all complexity of this problem is now reduced to that state of n ancillas. So you see that vertical line here, it represents the which connects all these parts. It represents the bond dimension that actually describes the complexity of this tensor. So, and for example, this could be an output of a quantum computer, and then you see the immediate relation with the result. Immediate relation with the results presented by Gregory White yesterday. All right. So there are some exactly solvable models. For example, I'm presented in the scenario when specific states are chosen and specific controlled unitary interactions are chosen, or when we have many qubits also in correlated states. U-bits also in correlated states, but also under specific assumption about those unitaries. More physical results are related with interaction of the system with single photon wave packet or two photon wave packet. And these are the papers by Dabrovska, Khrushchinsky, Chakraborty, Sabrinsky. This is one of them I signed. And the physical scenario where the spin transport occurs in The spin transport occurs in such problems, it is given in this paper, although they used another approach to describe the spin current. All right, so my idea is to simplify this problem by representing the environment in the so-called tensor network formalism. And to give you the idea of this tensor network, let's consider one photon. Let's consider one photon wave packet first, and then we will generalize it to more complicated scenarios. So, say we have a one-photon wave packet in time being quantum optics, where one represents the excitation of the field in the first mode and vacuum in others, then the excitation in the second time bin and vacuum in the others, and so on. So, coefficient C1, C2, and so on, Cn can be arbitrary. And so on, Cn can be arbitrary. It is a generalization of the W state, in a sense. So, if we consider a modification of the usual product, where this dot now represents the tensor product for matrices A and so on, then we can really describe that state vector as a product of two matrices. So, say C11 is a cat vector. A cat vector it plays the role of matrix A, zero cat vector plays the role of matrix B and so on. So zero plays the role of C and C to one plays the role of D. Then we obtain the one photon excitation in two modes. If we extend it to product of three matrices, then we obtain the state vector for three modes. Three modes, and you can easily see that we can by extending this line of reasoning, we can obtain an arbitrary state of arbitrary many modes. So, and you see that here we deal with product of matrices, so it's not surprising that we come to the matrix product state representation. So, this is a matrix product state representation for one photon waste packet. Photon wave packet. And in general, not only this state, but many other states actually allow such a representation. And here where the tensor networks come into play. So those matrices that we use, they are now represented by tensors because one physical dimension actually is pointing up and the auxiliary. The auxiliary virtual indices are used as rows and columns for those matrices. So we deal actually with rank tensors in this case. And the state of the environment in the MPS form can be written in this way. I must note that any state can be written in this form. Simply, the bond dimension grows exponentially for arbitrary state. But if we consider many physics. Consider many physical relevant situations, then this bond dimension is rather small and it captures many important situations. And these are the examples of those situations. So here are the experimental works where people created photonic matrix product states in labs. And yeah, many interesting. Many interesting states like cluster states can be created this way. So, and now we will exploit Tensor Network formalism to derive the corresponding master equation and to find the dynamical map for the system. Here in panel A, we have a description of the pure state. Panel B shows both. Both the cat vector and the bra vector, so it's a density operator of a pure state. In principle, we could generalize it by introducing here an auxiliary yellow box like here in panel D. Then we would have a general density operator, or we could have connections between those tensors here, and then we would have so-called matrix product density operator. So these are possible extensions for this panel. Extensions for this panel B. And as you remember, there is a density operator of the subsystems row one, so on K. And to obtain that, we should take partial trace. So we should take partial trace over the subsystems we haven't interacted yet with. So this partial trace in tensor diagrams is represented by connecting physical lines. So cat and brown. And physical lines, so cat and brow lines are merged, so it means that we take partial trace of those degrees of freedom. And you see that if the chain is long, then this procedure could be difficult in principle. But one simplification comes from the fact that the tensor network, like MPS, can be reduced to the right canonical form. This is always possible, and the paper by Schoberg explains why this review paper. This review paper. So it's always possible to define those B tensors in such a way that this yellow truncation would actually be simply connecting line like that. So using this right canonical form, the reduced density operator of the environment could be written this way. And chi zero here gives a flexibility to consider mixed states, not only the pure states. Only the pure states for the environment. And now the tensor network representation for the dynamics in that collisional repeated interaction picture would be we have the system density operator. We have representation of the environment in terms of tensor network in the right canonical form. Now the unitary operators for CAT components and U daggers for BRAC components. And U-daggers for brackomponents, merge. And then here the upper part shows that we take trace of the particle we already interacted with. So this is a tensor diagram for finding the state of the system after K collisions. And the important thing here is that we can change the paradigm. And if you change the way you look at this picture, you can see how it could be done. You can see how it could be done. So, say now that you turned your head 90 degrees in one direction, and then you can see that actually you propagate from left to right. And those virtual degrees of freedom that we introduced in the environment actually play the role of cat and bra components. So, it's like evolution inside the environment that happens. Happens thanks to those right canonized tensors in green here. So you see that the repeated block is that map E, and that map E is actually a completely positive map because it's composed of two of Kraus operators of this form. And this completely positive map is actually trace-preserving thanks to the right canonical properties. Thanks to the right canonical property we imposed on green tensors. And thanks to this observation, we found a Markovian embedding. So, chi-zero plays the role of the initial state of the fictitious environment in the embedding picture. So, and this is the result. So, the system density operator dynamics is given by taking trace. Given by taking trace over extended operator. This extended operator corresponds to the system plus virtual degrees of freedom. Initial state is rho s tensor chi zero. And the map E is given by the unitary operators coming from the collision model and the green operators coming from the representation of the environment and in the right current. And in the right canonical form. And each map E is a quantum channel and has grace operators and this is a formula for them. Sorry, I will check chat because okay, it's not a question regarding my sound, so I will try to answer later. All right, so. All right. So these are the examples we can consider. Say we have an interaction with a two-mode wave packet, two photon wave packets, sorry, two photon wave packet and specific interactions and so on. I just want to give you the idea how this method works. So then we can find the blue curve which corresponds to that correlated dynamics and excitation probability. And excitation probability for the qubit. And if we disregard all the correlations, then we have that blue curve or that black curve. Sorry, so here correlations actually create a big impact in the dynamics. If on the other hand we consider cluster state on the right panel, then we can see that the blue curves and black curves, so with correlations and without correlations, they are almost. Without correlations, they are almost identical. You may ask the question: why is it so? And the answer is in the correlations inside the environment. So, the nature of correlations inside the environment doesn't appear in this theorem, but it does affect how the two solutions deviate, so how much the correlations in the environment contribute to the dynamics. And to study this effect, we actually considered one second discrete time. In a cashmere, it's one second discrete time equation. It's possible to derive it in a usual fashion, like it's described, for example, in Petro Cioni and Breuer book, chapter 9. And then if we find such an discrete time master equation and look at the kernel relating different time moments, then we would see. Different time moments, then we would see that this kernel is closely related to the Waldenfeld cumulants. So those correlators of the environment I showed to first, okay, second order, third order correlator. They contribute to those memory kernels. And in case of the first example, here, the correlator, the two-point correlator, was not zero. This is why we had so big. This is why we had so big deviation between the two solutions. And in the second case, the correlator was actually zero. And this is why we had a contribution of the third correlator in the dynamics, which had a smaller impact, of course, because the contribution of those cumulants is proportional to the gamma tau in the corresponding power. And finally, I think I have only a few minutes left. Have only a few minutes left. So, in this streboscopic limit, it's possible also to find a transition from non-Markovian to Markovian regime. Say we have a translationally invariant state of the environment, and then when the stirring time tau goes to zero, it means that we effectively fly over that environment. So, we have a ballistic. So we have a ballistic regime. And in this regime, what we actually feel, what the system feels, the system feels averaged state of the environment, but it comes from a rigorous mathematical consideration. So in this averaged state of the environment, in this limit, has a corresponding correlation length which is specified. Which is specified from the environment that we use. And these correlations actually modify GKSL generator. So in addition to the local term, the AP is non-local term. And this non-local term can be either with plus or minus sign, depending on the nature of these correlations. And there exists an example. And they exist an example where such correlations actually detard the decoherence. So they prolong the coherence time. And this happens, for example, if the environment in the acyl tear state, afflict the elliptic correlates its state of cutriates. So this example actually shows that correlations in the environment can contribute significantly to the dynamics of the system. system in this stroboscopic limit. So in the stroboscopic limit we come back to the Markovian realm, but correlations are still affecting the system dynamics. Okay, with this I would stop and simply say that higher order stroboscopic limits could be introduced in the similar fashion. And there are examples where they are needed actually because you see here the power G. Here, the power g is to the power 4, tau is to the power of 3. This is the actual inverse time at which the dynamics happens. All right, so the summary of my talk. So, I tried to present a general solution to quantum collision model with correlated environment and specified some physical system where that happens. And in this case, using Tensor Networks, we Case using Tensor Networks, we can find actually Markovian embedding. But the Markovian embedding doesn't say anything how correlations contribute to the dynamics. And the answer to that second question is given by the memory kernel in Nakajomitzwante equation. And that memory kernel is closely related with Waldenfeld's cumulants. And when And when we consider the stroboscopic limit, then we again can reproduce the Girjeke cell master equation. And in this case, correlations in the environment contribute non-trivially to the generator. So with that, I would finish. Thank you for your attention. Questions or remarks in the audience here? So it seems very strongly related to the transfer tensor formalism. Yes, yes. Please continue. Okay, don't think because at least unless I missed it, it didn't match it. We didn't match it, so it seems like a very similar idea. Yeah, I totally agree. And you see that actually this simple model introduced 60 years ago, it gives still kind of useful models to consider. So, and tensor networks actually and matrix product states, matrix product density. Matrix product states, matrix product density operators also give a kind of better understanding how we can represent structured environments in this case. All right. Are there questions from the online audience? Remarks? If I may, I just have a question concerning the correlation in your NCIDAS, the classical case. I'm wondering about the type of correlations that you assume or that you can infer from the physical models that you considered between these ancillas. Can I think of these correlations as, say, Markovian, classically Markovian correlated? Or is that completely different in the setup that you consider? In the setup that you consider? I think my setup relies on the density operator for those ancillas. So here, for example, rho from 1 to k represents the density operator for the environment. And you see that it can be arbitrarily large, but finite dimension of the environment. And now this density operator as n partite density operator can be either Operator can be either quantumly correlated or it can contain only classical correlations when we have some of factorized states, so-called separable states. So all scenarios are possible. Every state can be written in the form of the tensor network, but some of the states require small bond dimensions. And these are usually the states that correspond to the ground state of gap Camille. Of gap Hamiltonians in multipartite systems with local Hamiltonians, or they correspond to thermal states of such systems. So, in principle, the functionality of tensor networks is very flexible. So, we can consider arbitrary states in principle. But to do that efficiently on a class. To do that efficiently on a classical computer, we need to have a small bond dimension. And that small bond dimension is only appears in so-called slightly correlated states introduced by Vidal in 2000. So the state shouldn't be strongly correlated in the sense of the entanglement entropy. Entanglement entropy. But correlated states like GHZ, W states are perfectly okay. Thank you. No other questions or comments? To be the case, so it's time for us to thank Sergei again. Before we run to the coffee break, we can also thank. Coffee break. We can also thank our organizers. We'll probably see that online for a great week, at least from my perspective. But I think I'm speaking for everyone here. And with that, we close the session, the workshop, and see you next time in pass, maybe. Bye-bye, thank you. 