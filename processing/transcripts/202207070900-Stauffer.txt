Okay, so today I'm going to change a bit here because I want to reserve this last lecture to talk about some new ideas that appeared recently to try to tackle both scales with examples where you do not have stationary. Naturally, I'm going to look at a very strong non-stationary process, but it's a growing process. It's really non-stationary. But this also. But just one quick reminder for an observation before we start with this topic. You may be wondering, in the first lecture, we did the FROG model, which was quite simple to analyze. You just do oriented percolation, compared with oriented percolations. Then we did the SI, which we had to go through all these mode scale approaches to analyze it. It took us two lectures to do it. So, why we can't do that? To do it, so why can't we do simple comparison to oriented population for that? One could ask, right? It's very simple. We can just prove it's impossible. It can prove that it's impossible to stochastically dominate the construction of one scale box in the SI by oriented perpellation, just because it does not have exponential degree of correlations. Let's say that if I want if I have a time zero here this space is horizontal and I take the region space of size and if I just go with probability exponentially now enough to be We get that this whole region here is integral particles at zero. But if this happens, it will take an inner deep region here, say of size r over two. So this whole region, and this right about r squared, this whole region here is likely to be empty. It has Is likely to be empty, it has a possibility of being empty, wants to know that this is empty. So this means that the price that I have this whole region is spacetime empty, which has volume after the t plus 2, is just stretch exponent. So we cannot have exponential decay of correlation in this model if you just simply do the same approach. Simply do the same approach as in the fraud model. So that's one of my thoughts to mention. But yeah, so today we're going to look at something slightly more evolved. I'm not going to be able to go through the whole details, but the point is not to go through the whole details, but to give you the idea of what else we did beyond the standard food scale approach that we have seen in the last lectures. Have seen in the last lectures to solve a model without stationary. So, this model is a competition, is a competing first faster percolation model, but it's just a picture of the simulation. Let me define the model first. So, we are working on Zd as usual, and there will be two types. There will be a process with two types. Type one, which will be the nodes by Fb1, and second type, which will be the nodes by FBI lambda. Be lambda. Lambda will be a parameter in this process. F and zero start with fb1 combined only the origin. That's this point. Only the origin and no other side. Then for each of the other sites, besides the origin, I flip a coin independently and with probability p, I place this special guy here that I call a seed. It's a seed of the second type of F pilot. Of the second type of FPLAM, just but just see that a special role, and the other sites I'm just going to put enough of it slated. That's the standard configuration, and then the process starts. It starts at time zero with FP1 growing in time as a first passage calculation at the rate one. This means that each edge along the boundary of the FFP1 Of the FAP1 cluster has an exponential for some clock of rate one. When the clock rings, the clock of this edge rings, then it occupies the other endpoint. Okay, and I just have more than one. So it would occupy the other endpoint. And it continues like this. It starts occupying more and more vertices of Z until it gets to a point where it tries to occupy a vertex that is occupied. This vertex that is occupied by a seed. At this point, it does not occupy this vertex, but this seed gets activated. So seeds do not do anything. They just wait to be activated. And activated means someone tries to occupy its location. Once the seed is activated, then it also starts to grow as a first passage population, but of a different rate. That's what I call it. That's what I call it FPP like that. And the red FPP cannot occupy a black one. Cannot occupy a black one, yes. So each site remains occupied by the first type that gets split and never switched types. So this process continues like this. Other cities will get eventually activated. And it notes that the cities can be activated either by a Be activated either by XP1 or FP number. If it was this one that would go around the XP, it would activate that seat. It doesn't matter. So if lambda was one, we just have FPP. If lambda was one, we just have FPP. Yes. But still have two types. But if you need no types, just there. The process clear. So that's a growing process there. So that's a growing process. There is a strong competition between the two types. And which type of questions do we consider? There's more simulation going on here. So let me peace for the notation. There are two parameters, P, which is the density of C, and lambda, which is the rate of growth on the Q lambda. What are the questions we're going to look at? What are the questions we're going to look at? Oh, especially there, mostly it's going to be interesting which types survive. And survive here does not simply mean produce an infinite set of occupied sites, but actually produce an infinite cluster. I'm just requiring the occupation to produce an infinite connected component in ZD because the seeds already are an infinite set. Otherwise, type two. otherwise type door to the loader would immediately survive so if forcing to be a concept and you can also ask whether there will be quick systems that both types simultaneously can give rise to a different cost now for seat check if p is large i have more seats i should favor every p lambda F p p lambda, no, the red type, the silk type. If lambda is large, I increase the speed of FP lambda, so I should favor FP lambda. So either of the parameters, if I increase, I should favor Fp lambda. If I decrease, I should favor FP1. Send it check. Another standard check is that we're just going to look at the case where P is not too large, because otherwise the process is trivial, because if P, if this is going to divide what you need, because if we reorganize By what you need, because if you reorganize this, you get that one MSP has to be different, the critical probability for size population. If it's not, then one MSP is a dense of non-seeds. The site's not occupied by seeds. So if it's not supercritical, then the origin will be surrounded by seeds. I'm not sure this look can unfold. So I just say the P to this point. Okay. Now, as I said, increasing. As I said, increasing the parameter should save FP1, then decreasing should save FP1, but life's not that easy. So if you try to do a seller coupling to show, for example, take two initial configurations, and in one of them identical, and in one of them I add a seat. For example, I take the configuration I have here, I copy it, and in one I address it, and the other I want the process evolved without it. I want the process to evolve without that seed. Then, what happens up to the point where the seed is activated, both processes can cut on them so that they evolve and enter. But the moment that seed is reached by one of the two processes, the seed is activated, and that process has to go around the seed. While in the other case, it just passes through. There's no seed. So it has to go around. So suppose that's active one that gets sent to go around. That's FP1 as it gets S. So FP1 gets a delay as it has to go around. But this delay can defer the activation of other seeds that hang out at the same direction. Because it just has to go around. So it may take more time for you to activate this. Knowing activating this seed sooner can be beneficial at P1. So in the beginning, it sounds a little bit counterintuitive. It sounds a little bit counterintuitive, but adding acid can help FP1 to grow faster, but it could be more beneficial and exactly so standard cutting do not give monotonic. We still don't know whether ECB is molotone or not. It's a fair question to do. But actually, we know that there are graphs for which it's not molotone at all. There are graphs for which the probability. Graphs for which the probability that FP will survive is not a monotonous function of the learning. And these graphs, okay, they are hooked up for this to work, but you know, they're not really super weird because they are even positive transit. Not super strange. And there we can prove multiple phase transitions. And actually, we can prove as multiple phase transitions as you want. Phase transition has the ones. If you ask me, produce me an example with 10-phase transition, I produce you a graph that's fast transitive and has 10-phase transition. So there are issues. I still believe it's more concentrated, but we cannot prove it. So we have to work around by proving something without using rotors. Okay, let's yes, maybe I show a simulation, actual simulation kind of a picture. That should be great. So this is going to be an actual simulation. With P is a very small number, you cannot read. It's zero it's zero twenty seven. So P is tiny, so essentially you'll see no Cs. So essentially you'll see no seeds, very little seeds. And the speed of a lambda is 0.7. So Fp lambda is slower than FP1. It's 0.7, not too close to. So we expect that FP1 has a very good advantage for growing. And it does seem to grow. So this picture shows these colored regions are FP1 growing. The white regions inside are regions that are kept. A region that occurred by the other type, like the outside of this boundary here, is the region that I'm not showing you, but Scarpa yet occupies. And what I like about this picture, even though it does confirm that FP1 does grow, you see quite big regions that end up being occupied by FP1, even if it has such mild parameters for FPLON. And the reason is even. And the reason is, even though the seeds are so rare, whenever seeds, by random fluctuations, grow very quickly upon activation, this is felt for a long time in the process. So it takes a long time, but you want to go around and slowly deconfining this growing process to finite features. So this just indicates this sign of dependence we have to deal with. If you look If you look at the other processes. These white bubbles are occupied by the other processor. That's right. So let me see if I can get this. Ah, this, yes. So just change color and just print everything that's occupied by the other process, yellow. What is lambda here? London is 0.7. So there's pretty huge dependence in this layer. You can also try to do the opposite. They could be very large now, very close to a mine species site. You stress up the system with lots of seeds. But then you take London very small, otherwise you don't see anything because you have so many seeds that London has to be small if you want to hope, if you want to survive. So you got a picture that's completely. You get a picture that's completely different. So, FP1 now tends to occupy much more regions. I mean, it looks thinner in colors because it has to dribble, go around a lot of seas. So each, if you zoom in, you're going to see very small rays of FP1 going, but another picture will see more solid rays. So that's why you see a lighter colour. But FP1 seems to grow. But then FP1 seems to grow very less than the other case, but you still see another type of dependence that's quite curious, and that you can use this colour that I paste here, which shows you the epochs of the simulation. Because the C regions are very close in space, for example, here and here. They are very close in space, but they have been occupied by the process completely different times. So you have to have place in your space that the process arrives in failed between the catchbox, even though they are closed. So this is another type of dependence that in this other regime you can see. Why? With these parameters, it should come back to some regions. I don't know. It's full of seeds. So FD1 is able to ignore the seeds. Only seeds, right? Perhaps it can go far and start to but then maybe it activates a seed that by random fluctuations just grow a little bit the other side, it blocks that side because it's so full of seeds that it requires very little to block percolation locally. And if the blocks percolation locally, you are blocked here, so there's something going around, and then you get blocked again, and then later you come back. You can find a way. What's the lambda here? Lambda is zero point zero zero five let me get back to this line. So this essentially similar pictures. Okay, so this process I introduced with others. process I introduced with Vlades in 2019. We introduced it to another process and I'll comment a bit about this later because that's another reason why I'm telling about this process because also this process can be used as a tool of analysis. We'll talk about this at the end. But I introduced it in Flanner in 2019 and we showed the following result except for us maybe just the first one. One is enough. So we show that for any number is more than one. So as long as Fp lambda is lower than Fp1, there exists a value of this here. If P is small enough, then F1 survives. For any enough, I can take P is small enough so that F1 survives with positive. This is in all dimensions. This is not one. Not one, but two and another. And we can show that it's a positive speed of growth. You can show a kind of not a shade clearly, but a bulky behavior. You can show that the growth of this process, this process is not a solid region, it's not a ball in some sense, because it has holes inside of the other type. But if you fill in these holes, then Filling these holes, then the aggregate of time t, the set of sites occupied by FP1 plus the holes at time t will contain a ball of this followed by positive cognitive values. This always dies out with positive cognitive. So that's how the group here is just a graphical representation of how to prove that the horizontal axis lambda. Lambda in the vertical axis, and we show that for any lambda fb is small enough, that is the blue region where fb1 survives. Yes, that's what we should so it's easy to see that if we're above one, fp number kills fp1. How much true? That follows for from a sample result zone. From sample results on transpassion period. Just that FP1 is faster. While FP1 is not really, it grows at rate one, but still has to triple the C's. So effectively, it has a rate slightly smaller than one. So everyone with a rate of one or higher can eventually find a space where it grows upwards and capsules every and also the FPP lander has to do. Also, the FPP lander has to triple, but they can jump on the other one. That's right, but for them, it doesn't make a difference. Because if they hit a seed, the seed gets activated by a pilot. So from the point of view... It doesn't change. From the point of view of that pilot process, it doesn't change. That's why you prove it in LSQ lambda equals one. Also, it's also true if the lambda is equal to one. Also, it's also true if lambda is equal to one. For any you can even push a little bit low. P greater than one max specific common text. No chance right to be what's happening. Okay, this is the norm. So, what we expect, of course, is that this blue region, the region. Is that this blue region, the region where one survives could be pushed all the way to one of my species size? And of course, I left a grey region here because this claim in its own details survived here, only FB doesn't survive, and then we can ask whether the LP will exist in this process. This hasn't been addressed in our work. Okay, so that's the first result. There's a second result that Results that I can put now, 22 was accepted on Sunday. I was in the airport. So with my ex-student now, Tom Finn, we show that the opposite, the change of quantifiers. Essentially, we show that for any peace between zero and one society, there exists. species site they exist a lambda small enough such they are different small enough and they have positive probability of survival so that's uh seems like uh just put the two theorems one side by side here for you to see that really it's just a change of the way the order of set in the parameter it sounds that's not just like that but actually has a funny consequence There is a simple remark that the probability for size calculation, the critical probability site propulsion, is more than a half when the dimension is three and a half years. If it's strictly smaller than a half, then the interval, this is side, one minus the c is non-empty. So I can take p in between. And if I take p in between, since p is more than one minus pc side, our table says there is a regime left to also. Is a regime left, it all survives. But this CCP is also a bit of an exercise. Obviously, the seeds survive because the seeds at time zero have an infinite cluster in the all-dimensional part of the layer. It's an instance of coexistence, it's a very ridiculous one. Of course, if you learn this guaranteed survival time zero, but that's all you know about existence in this model. Okay, so this will coexistence on these cycle months. We see dimensions three and high. Of course, they don't say anything dimension two, because this interval is empty. Okay, so the picture in the picture I show you of what we expect should be slightly different because dimensional 3D is a special gene where we know there is coexistence. We know that it's coexistence, and the open question whether we can push this real act of the society or whether we can prove it. This is measured. The main question is not being at this moment for this. The gray region is that you prove it. No, the gray region is a fuzzy region. I don't know if that this really doesn't exist, it was direct. Doesn't exist, it goes directly white and blue. I don't know coexistence of it. There is some regime of coexistence here, and even if there is, I don't know to it extends if it does go to the whole of this range of functions of B or not. It's really ah, yeah, maybe this is also good to comment: that the kind of question. Comments that the kind of coexistence that we're dating this process is quite strong. It's not only both producing clusters, but both types produce influence clusters of positive case. So the seeds are obvious, but for FP1, you get a positive intensity of population. And this is false in other models of tag measure model, so that it's impossible to. Model shows that it's impossible to have possible density of quick resources of both types. But coexistence means a finite connected cluster, right? Coexistence is an infinite connected cluster. I think I'm just like forgetting degraded three percolation. So there are infinite clusters of closed sites, even if you're super critical. You can have. Non-dimensional super close. Non-dimensional. Okay, we're pretty good. Okay. Okay, so what I want to my interest in talk about this here is most about the proof. Actually, the pay contribution, my opinion of the paper is the proof. And this is this work, the previous work was valid. Previous work with VARS, we did a quite difficult modestianalis from this model in that regime. It was a very hands-on, so we had to do lots of things specific for this model. And in this setting, where P can be closed on our specific sites, that analysis really breaks down and they have to do something else. And to do something else, we did again a Motsky analysis, but we introduced one ingredient that's very simple, you see. It's very simple, you see, but actually help us not only control things, but also write down all the screen lines that I believe is readable. Even though I don't know how many people read between us two, maybe the left will try it. So, what is it? So, first, let's try to do a standard Mautic analysis. So, now we are excited in this data, so deconate, and it's usually. And it's really the same tessellation as we have been doing since today. I tessellate, I partition space. I don't need tessellating time. Each box participates only once in the process, whether it's a growing process or the box once occupied, doesn't matter anymore. So just as a space in box of size L1 number 3, if this is Z2, it's a picture. And a box for us would be a row. A box of size L1 center at one of these boxes of the package. That's a box for us. So that's a box whose center is this guy here. Then we have to call box good or bad. So first we have to look at what we want to prove. We want to prove that FP1 survives. So we need good box to So we need good blocks to let us make FIM survive. Particularly, if all blocks were good, the definition of good should imply that FIM survives. So what do we need? Well, first, that we want must have space to survive. Fuel can only grow the sites that are not occupied by seeds. So we just ask for percolative properties of the known seeds. It's exactly what you would expect. If I don't tell you this and ask you to guess, you'd guess correctly. So, no, no seeds, once you have a large cluster, the second large cluster of no seeds should be small. The same thing with X and Lax to touch all faces. This space where you want to survive. And then we need something more specific for the first passage population process to run. First, we needed the distance between sites and non-seeds. So my thoughts, suppose I want to show that no seeds, which the drawings I write here. So these are the no seeds, they have to percolate. That's the first two bubbles. So they have to have a large cluster that is of the order of the volume of the bottom. Is of the order of the volume of the box, and this smaller, it may be some other smaller cluster, but we have a small here. And then I need these two other properties specific to cluster fibrillation. The first one is if I take two vertices sides inside this cluster, then the distance within the cluster of most sites. Has to have the same order of their multitudes. That's what I ask. So uniformly in the uniformly in the seats, in the non-set I think for every poster, right? And for every two sides in the most seats, I need that the distance between them is that the move. Game is that the movements are constant, they have no distance, and you have to play a lot, right? Because if the sites are too close, if the sites are really, really close like this, then they may have a bit too side block. But if they are if as long as they are further away to each other, they lock, they should be the only stuff. Then that's not enough. I also need that at first passage population only such paths are fast. Fast means at the order of the same distance. That's the fourth bullet. So the distance are not too big. And then if I run first class extrapolation on this cluster, the time it takes to go from here to that is also of the order of the order. That is also of the order of the L. So I know that if this guy gets FP1, there is no FP1 in my world, he just gets there in the time. And last event I needed with these five events. The last one is just ask, since London now is going to be small, the first four events don't look at London. They just look at P and reports. They just look at P and the quality structure. So if I box my L large enough, so that these holds. Then once I fix L, I can look at my fifth event, and I set lambda small enough so that the passage time of the lambda through each edge of the box is large, that at least one volume. Lambda square root. And if I can do that, well, L1 is now fixed and then lambda goes to see it possible. And then I'm lumped in most of zero function. I can take it small enough and guarantee that this happens. Okay, in particular, and that's why I am defining this event like this. If I know, I'm new, for example, that FP1 enters this box first from outside, not FP1, but FP1 is the first one to enter, just as I didn't put a foot in this vertex there. What I get is by the old definition, F1 who conquer, assuming that this vertex is part of this cluster of non-seeds, FP1 gets the whole cluster of non-seeds before FP1 or FP lambda can step inside. Before the resin can step inside. Why? Just by choosing lambda so small. Lambda so small that this value, the time it takes my spin lambda to traverse any edge, is larger than the estimate I got in the first polygon. This line with this pulse and the time is the overall event I need because obviously the box has still had the origin, scientist property. So if I had all box good, So if I had all boxes good, I would be in great shape. Oh, because they overlap. They overlap. Yeah, yeah, so they, yeah. Right, right. That's a good point that problems. The box that seems here has a huge overlap. The problem is, of course, that what is it? You know, quick. Ah, okay. The problem, of course, is that. The problem, of course, is that these effects. Because I said that if everyone enters the box first, then it does occupy everything it came occupy from the box. It was needed with the box and so on. Great. But this event is not local. It depends on the whole history of the process. And that's the problem to recognize. So let's now start ending in the novelty part of the program. So far, the question So, what we'll do now, we're going to add ingredients to treat this event. So, the idea is simple. We're going to take boot boxes and further classify them. So, further classify the boot boxes. Classify the good boxes. They will be classified two types. It will be either of what we call positive feedback or negative feedback. And bad boxes are not further classified. Bad boxes are spent. Don't touch them. And how do we define what does it mean for a good box to give positive feedback? Feedback. That's the definition we gave. Don't read it. I think I have a picture. Yes. So, a positive feedback box is a box such that if I look at the first time it's entered, at some point, this box suppose it's not the one with the origin inside, otherwise it's entered time series. At some point, one of the two types you come and enter. You become an enter. This is the entrance time of the box, and let's suppose we call it power. Then the box will be of positive feedback if FPP1, the first type, enters in the volume of the box in a time that is tau, that telescope, plus not much. Something that's possible times our lot. The point is like. The voice is like the void, like yes. So you probably have another constant times electron. There are too many constants in this paper, so I'm trying to avoid a little bit strange. But this the idea is we will call a box of positive effect if FP1 enters the box in the book, a distance of order L1 from the path plane, in a time that is of order L1 after the first time someone enters this box. If this happens, I'm going to call this box positive detect. It's very simple. The final box is to be of positive analogy detect. It's very similar to what I was writing before, that I needed to monitor ice first. And it's like First, and it's like F drawn the ID first, but this is not robust enough for what I will do later. So, I don't even need it to arrive first, it would have been none of the to arrive first, but I just need that it arrives in the bug within a reasonable time of the first time the box was entered. And I call this positive regret. So, at this moment, you should all look a little bit disappointed. Why? Why? Because it looks like this renames the problem. I had a problem, which is this non-local event, and I said I can't handle it. And then I said, okay, I'll take the good box and reclassify them. And I now probably positive feedback, something that's like the same non-local events. This is also non-local. The main reason here is that we are going to do differently. Good box, non-look. Good box, we go dissect the box and look and see whether the box is good or bad. We estimate the probability that it's good, we estimate the probability that it's bad. Positive feedback box, we do not do that. We will never estimate the probability that it's a good or bad positive or negative feedback box. The idea here is to define things in such a way that deterministically I can get consequences. Consequence. That's the thing. I'm going to assess. I'm going to take for granted. I can say these boxes are positive feedback, this one's positive, this is negative, and so on. I can choose a way to define which ones are better, positive or negative. And then I want to look at where my bad boxes are. And I want to be able to say whether this is possible. Be able to say whether this is possible or not. That's the thing. We're going to deterministically juice out consequences from the definition of this possible feedback. And this is why we call it the feedback. It's not an information that we make an effort to get, but it's an information that we take for granted, as if it was given to us, and we just assess the consequence, whether it's feasible or not. I know. Hey, sounds magic, but maybe a little bit more steps to see why this works. Let me say, and that's the common strategy here. And we kind of split the proof into two parts. The first part is a standard Mootsky analysis where I'm only handling local events, but everything describes. So everything described those high events are local. Actually, even nicer than the Moon scale as I did last time, they are even bound independent. These joint bounds are really independent, these joint boxes. So that's very easy. You can solve that via comparison with percolation, but even into the most canals. But that's not enough. And the resolved parts you handle differently. And I think many models fall into this category. You have some graphical representation, some structure that is stationary. And that you can solve with a standard word programs. But then we need this another ingredient, which for us will be this positive and negative feedback, which will help get the result we want. Let's see if this makes sense. So then once I define positive feedback, I'm going to get three components. Feedback, I'm going to get three properties out of the definition. The first property is a positive feedback box. So, if I have my box here and I know it's positive feedback, then I know that FP1 spreads quickly to neighboring box. Actually, it takes the code of the box and goes to neighboring boxes. Why? Let's see. Bobo, just set the common size. The box has entered. So, FP1 entered in the bowl. So FP1 enters in the bulk in this time. If FP1 enters in the bulk, because the remote always have positive feedback is always wood. This means there is a large cluster of non-Cs. If everyone has in the book, it must be inside this cluster of non-C's. Cannot be anywhere else because it cannot go through seeds. So then the end development must be in a plus of no seeds. So from this moment on, it can spread everywhere. If I made my R small enough, then it doesn't give time for F-Pelon to step inside. F-Pelon can arrive at the boundary, but will stay stopped there, because it doesn't have time to translate. It's similar to what I was describing before, but a little bit more slow. So I get this. So I get this positive variety, it's what I want. And if you want quick load by the fit and spread to the neighbor due to the intersection of the loss. You choose this lambda in order that with the condition of goodness, in time L1, the FPP lambda cannot come. You can do better. Lambda does. Because the lambda, you fix L1 first, and then lambda choose. Then number two. And as I said, at the time to occupy a box to traverse an edge is one over root of lambda. So we can put tape lambda to be even something like one over L1 to the 10. Okay. The first scale is easy for this part because we have the longest. For this part, because we have the longitude. I mean, this time it's depending on the dimension. Which time? Ah, 10 depends on dimension, but because you want that every edger at this ah, yes. Yes, yes, that's first is easy. The second property, that's the main property. Property, that's the main property. I think that when I realized this property, then I was confident to do work. Then it should take some months. But this property was very important. It's the following thing. So let me draw the picture. It's a problem of negative feedback box. So suppose someone tells me this box of negative feedback. By definition, it's wood, because it's negative feedback, it's also wood. Because it's 100% also. Then they look at the entrance side of the box. So at the first side that's empty, what does this one be? Now, this side is, of course, not at the center of the box, but the centers partitions. So there is a box for which these sides are the center. I call this box the parent of that box. It's the parent. Why it's the parent? Why is the parent? Because it's just the entrance moment of this box of birth. And notice that the entrance of the parent is before the entrance of the child. This is the entrance of which one? This side is the entrance of this box, the top box. But of which process? The first slot to get is the first time that box sees action. The first time it sees action and it is in the center of a sound box, and that this box, this bottom box, is the parent of the top box. The thing is, if I know this box, this negative feedback of box, then the parent cannot be of positive feedback. That's really a crucial property that we choose out for the definition. Because if it were of positive feedback, what it means. Feedback: What it means? It means that FP1 would have entered inside at that time that translated. But if it enters inside, FP1 gets everything quickly before FP lambda can do anything inside this box. In particular, it gets something in the bulk of the box, of the top box. So it makes the top box positive to play. So the bottom box, the parents. So the bottom box, the parent, can be either of negative feedback or a red box. If it is of negative feedback, then you take it, because it has its own parent. And that parent has to be negative or bad. And you keep it in this until you reach a bad box, because this has to end. It cannot call a cycle because each time I'm going. Because each time I'm going to a box whose entrance time is strictly small, right? This one, this side is in the center of the bottom box. So the bottom box was entered before. So each time you are moving back in time, this is directions. So it has to end. And that ends in a bad box. It's an abolition. So this is important, but it makes you say that any negative feedback box can be associated to a bad box. But bad box will. Bad box, but bad box will know where they are. But bad box are look for events. We can do the boots, we don't need even the boots stay over here for controlling where the bad box are. So you have these negative in the bed box, which are non-local events, but you kind of know that they have to be associated with bad box. The parent of this uniquely defined site? Yes, it's unique about the point in the weight of the best. Or the location of it, or what was the definition of parent? You look at the enter site, which is unique, and then there is a unique center, where centers form the partition positive. Okay, so this is important, but there's another third property that's also. That's also crucial, which is to say that negative feedback logs that have a negative feedback parent cannot be entered quickly from one another. Let's see, I think I may have a pick of this. So if I have a box that has negative feedback, I look at its panel, and I assume that it also has negative feedback, then the time this total box is entered cannot be sooner after. Cannot be sooner after the time the parent is entitled. They must be a girl. And why? Imagine it was very close, and they were entering very close to each other. You just need to look at who entered the dollar box. If it's ent lambda, then you're done because FP lambda, it's a negative feedback, so it's a good box. So FP lambda will take one over root lambda to traverse a single edge. So this is already the time. So, this is already the time you put in your definition of what it means to be separated. If it's FPP1, then you're in good shape because FP1 means there is FP1 inside here going on. If there is FPP1 inside here, since it's in the center, it must be in the large cluster of this box. But if it's in the large cluster of this box, it has several ways to go to this guy. But if there are several ways, But if there are several ways, it would have entered quickly. But it didn't. So these several ways have to be blocked by FPL. But if they are blocked by F-Lambda, it means FPL traversed an edge. That's it. It takes time. If Afghanow has to traverse an edge, it takes time at least one of the languages. So these are very important. So I can rephrase these three properties. I think that's the key. These three properties, I think that's the key to maybe think about applying this standard to other models. We just need positive box with spread script to neighbors. If the first entrance is FPP1, isn't it automatically positive feedback? Or do you need the second positive feedback? No. Okay, so FP enters within time top lose RL1 means again. First, you put enter in a bad side, a side that's. A bad side, a site that's not connected to the cluster of the box, and then you get trapped. But even if you enter in the good side, then it's going to be unavoidable. If you enter in the bad side, it's unavoidable. So let me try to rephrase these three properties so that you get the feeling of what you mean at least in my head. At least in my head. The first property is that you spread positive feedback to neighbors quickly. If you get a positive feedback box, you express these two neighbors quickly. So their neighbors should be quickly entered by the process. If you have a negative with the bad box, then you can find a bad box nearby or nearby. Let's see. If you have a negative with the bad box, Have a negative feedback box, then I should be able to associate it to a bad box. That's crucial. And then, since a path of two concepts with negative feedback box, negative feedback and a negative feedback parent must have a delayed transfer from one another. This path of parents that we find for negative feedback, for negative feedback, for negative feedback, grandparents, and so on, can also be too long. Because each time you pay a different. Each time you pair the interest time gap between these two. So, why didn't the process go through other regions? That's the thing. That's the main three properties. And then, of course, I have to do this in higher state. I'm not going to go into the details of the higher scale, but just try to do the same. But try, just try to do the same. Actually, the only thing that really changes is the definition of positive. No, it doesn't change, but it just doesn't have an equivalent exact match of dimension one at scale one. We just define at scale a box to be of positive feedback if it contains in the book a k-minus one box of positive feedback. That's entered in type. A positive time is okay from the interest time of the box. It's exactly the same, but instead of asking if you want to be inside, you ask for a positive feedback box to be inside. Okay. Puzzles faces odds, but it's actually the higher at least the scale. Higher at least the scale one dynamics looks a lot like the scale zero dynamics, right? What scale zero dynamics? The original ah, you can you can imagine that wood defines your scale zero as the sites, right? Scale zero boxes, and you can say a positive feedback means of pipe by few one. And then you get the same definition. Why do you only need one interior water? only need one interior box or smaller scale box that's positive feedback well but it's it's yeah it's similar and i'll try to draw a picture that kind of summarizes those scale goals but we do it by the same reason as in the first scale it's just that if you get to one side in the pub occupied by p1 then you know for example there's a path that goes out and this F that goes out, and these implies you've got Figliv, you can get that. You see, don't need more. You just do some consequence from that. Let me see what's there. Okay. I had a picture show. But that's the same thing as before. This is just the definition of the positive feedback box I wrote about. So again, in the book, a positive feedback box on smaller scale. Back box on smaller scale, that end and the back of this should be allowed. And the crucial thing is that again, we'll have to cascade these properties. So these three properties that I showed, we have to prove in all directions, essentially. But I'm not going to prove the properties. I'm going to do the following. I will draw a picture of what this process looks like. It's clearer than So, what's really happening is the following. So, suppose this is a box, it's a good box, and it's of positive feedback. It's a good box. I have the same definition of this case here. This is a higher scale. It's a K-box. So it has smaller boxes inside. And I have a fixed number of them that can be bad, but it's a wood box. So I have this. In our example, just look at one in this model. I have to have D plus one, allow D plus one bad box in a good box. So these are the bad box. Then, one did say that each negative bad box that I find inside here has to be associated to a bad box. It can be a bad box inside or outside, but actually, because of this. But actually, because of this delay in the entrance, you get that in a small unclosed idea where all the negative feedback boxes associated with this box are inside. This box could be closed together so that the colours are not going to be able This box could be closed together so that these two guys can actually merge. There's no problem, but you find a small region around each bed box which contains the navigative bed box. And since by definition wood, you have few of them, they cannot really disconnect. Sorry, this is because K is good. K is good. Because positive and negative in the back box applies only to good box. Better box, I do not classify them further. But this is a good, it's a good box. Boot of positive effect. But this is it. That's why this works. That you can associate to each pet box and it has to be close by. But how long do you need to define some of the time that you allow? Need to define some of the time that you're allowed to wait. Some of the time. You say that it's a small region, but only if you wait up to time, I don't know, something. Only if you wait up to time something. You say that there is a delayed. Yes, but it's because of the delay entrance that this negative feedback box cannot propagate further away from the bed box. But why can't they just take more time and propagate further away? Take more time and propagate further away. No, because you assume it's positive feedback. So have positive feedback here, pass into the neighborhood. Okay, so it blocks it before they manage to propagate. The problem here is that we have it's all about the definition. You have to put the definition so that you can prove what it's in that direction. Look at that at scale k the three properties are satisfied because they are satisfied scale k minus one then you put scrolls one okay but then why this procedure works is because of this picture manage to concentrate just on the affinity negative feedback box around the band box so you you do or you don't have that picture on scale one You don't have that picture at scale one at scale one, it uh and okay, at scale two I have at scale one you don't have the box inside, you have the sides and you have the previous picture with the percolating cluster of loot seats. Because I wonder why do we need to do a multi-scale analysis? Why don't you stop at C2, for example? Why did I stop at C2? Good point, let me think if I can. I think if I can. My problem is we don't know what to do if I have more bed box in the same box. So I know that if the number of bed boxes inside had most some constant, then I can draw this neighboring areas around each bed box. Around each bed box, they do not block the whole thing inside, but if there will be some regions where I have just too many bad blocks, and maybe if I put this picture, it will work everything. But actually, the actual theorems that put this picture do not work, but they require to have a bit less box, less bad box in the big box. And in this case, I just call this bad. This becomes a bad box, but too many bad boxes inside, and that's when the highest stereotyped with zone negative feedback has this hour of negative feedback is around, but still it feels fast a lot more than I show you there. Doing this is a little bit vague, I agree. Bit vague, I agree. But the message I want to pass to you is how you apply this to, or how I measure applying or think about applying this kind of idea to other models. Just the proof is by two parts. There's really a standard mode scanalis, like two previous lectures, where you control good and bad box, which are defined as local events. These local events These local events can be also stationary events. For example, imagine that we let us try this exercise. Imagine we want to apply this strategy to analyze SIR, where particles after getting infected, they die. Then if I keep moving removed particles, I keep letting them move and then look at the particle system without distinguishing the attack. system without distinguishing their type they are stationary so i can define events on what particles do inside the box based on that without regarding them whether they are infected susceptible or not justifying are there enough particles there do they behave such that they spread they they get infected through a pass of infections that exactly that we did to the previous two lectures um so if you do it as i r So if you do it as IR, then you do a space-time argument. You can do it spacetime argument. Try to do the same thing, but just ignore the presence of removed sites. Just regard them as any other removed particle, just regard them as any other particle, and do the analysis of two lectures. We managed to do it. So we can do a Mutsky analysis, study the Mutsky analysis, control those, and then we get. Those and then we get where there is bed in boots, box, and then I had a need to introduce a new a way to control the non-local events, which for us in SPR would be to distinguish between removed particles and non-removed part. And this is what we can use this positive negative feedback framework. We can say a box of positive feedback now in space-time if it has enough. If it has enough non-removed particles, or maybe actually also well distributed with a dense paper. This positive is negative. But then you have to choose some consequence. If I do not have too many, if I have a negative in the bad box, you have to choose some consequence of the definition that tells you that you have to associate this with a bad box. But you can do, of course, in some sense, they remove. In some sense, the removed particles, at some point in the past, they were infected. Either they were infected in a good part of the environment where this factor spreads quickly and that's it, or they were infected in a bad part of the environment. But if it's a bad part of the environment, you have a bad loss. So, of course, we haven't implemented this for SIR because they don't really work of Adam in terms of. The work of Alan and Derrington, but that's the fun philosophy. To split your lines into two, I start with scale and some extra way to control the local events, such that by defining these new gradients properly, you can use half the consequence to control where the negative feedback works. They use that for different speeds, SI, also. You could imagine this also for the The manageabilities also for the discussion. Okay. Is it any more questions on this? Let me just finish with five minutes, so I'll finish with one comment. This mode of competition, as I said, was used itself as a method of analysis. So we invented it to analyze MDLA. I'm not going to explain this here, but R and D uses to analyze SIR. So they model SIR as this model of competition. How? It's very similar to how we did with MDLA, the following. You want to grow the infection and you see it as a competition process. You think about a vessel. And you know, if your effective particle is passing through a good portion of the environment, so if this Of the environment. So, if this box around the original M0 is good, then as we saw, the infection will spread to several other particles, and you move to the neighbors. He calls these moving to the neighbors as they spread of FP1. He says, if I'm in a lot part of the environment, you know, we guarantee that after some time, I went to the neighbors. So at some rate, I went to the neighbors. At some rate, I managed to get. At some rate, I managed to get here. At some rate, maybe I managed to get here. Maybe once I get here, at some rate, I bounce up. And so on. At some point, you're going to run into bad parts of the environment. Bad parts of the environment are modeled by C's. So you can place them randomly at time zero. And you know that at this I know that at this, when the process gets to here, I'll see ahead part of the environment. At this moment, we need to assess the consequence of finding this part, this part. And the consequence is upper bounded in some sense by the spread of epilambda for the city. So, what's the consequence in Nesayah? In Nesaya, is that maybe particles die too quickly, so the infection may not spread. This effect is felt by neighbors, but it's felt diffusively. Because now you're not spreading removed particles. You are just saying, okay, I don't have particles who spread infection, so this guy maybe will also become bad. So it's broken by F. B. London. And it's spread. And they spread, not spread sufficiently, while these guys are spreading faster because they have speed, global. So you can model SIR, as I did, and often delay, in a way in which FP1 spreads, it models the typical spread of your process, or the typical move of a front of infection. While FP1 models the bad regions of your environments. Use the bad regions of the environment which delay the spread of infection. If you show that the spread of the land is lower, sufficiently slower than the one of the one, and has less six possible the bad size of a red, then you can be more general. That's the idea that has been this two idea that has been used to analyze the process that I know of recently. So I finished. I think I'll go back to the next one.