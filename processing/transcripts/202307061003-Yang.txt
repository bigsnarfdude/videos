I was a host of Hong Yes Lab. I'm from Hong Kong. I would like to take this opportunity to introduce our university because I want to make it more visible to overseas friends. Our university is Hong Kong UST. Compared to Hong Kong U, we have more science and technology. Or you can integrate it like And you have also integrated like a winner. Yeah, we all our university is also known as Compound University of Strength and Tension. So that's okay. So overseas friends can remember our university. This is a joint work with our PhD students and collaborator Andrew Woolf. I'm going to introduce this work when I talk about the paper. The paper. First, I'm going to talk about this spatial transcriptional data analysis. Thank Raffa for a very nice introduction about the data structure here. So the data structure I showed here is just a table transpose of this. So it should be clear, right? Each row is just a pixel or very small area we call it sports, and then we measured thousands of gene days. Well, the limitation of this 10x besides is about the low resolution. Just like this. You have the overall measurements of multiple cells. But we really want to know individual cells' behavior. For example, their individual gene expression. So, what we want to do is like we try to make this low resolution to be the high resolution. I think like this for each sports. Yeah, there are a lot of works done for this topic. We have the benchmark paper from Natural Methods, and from this paper, and RCTD from Rafa's group, is ranked as the top performance methods for the self-haptic evolution. Well, for Xiang's methods, a card was not compared in this benchmark paper, yeah, because the card paper is quite new, okay. Is quite new. Well, basically, the cell type decomposition is trying to output for each spot the cell type proportion, just like Rafa mentioned. And second, for each cell, it's going to assign the average expression level for that cell type. Basically, that's the output. So here, we want to do something more. We just want to do one step ahead. One step ahead. Say, given this sport, we have the overall measurement. We want to have such kind of decomposition. We don't want the mean of the cell type. We want to decompose it into individual expression levels. Okay, so we want to do this. I hope this question makes sense to Rafa. I thought this is really a challenge. So in summary, we want to have transcript on what. We want to have transcription wide expression levels at single cell resolution for 10x business data. Of course, I'm trying to extend this framework to Murphys to try to do the imputation part. Oh, look, it's here. It's very low resolution. Okay, now we have our methods uh for the uh spatial scope. For the special scope. The first two students are my students, Xiaom and Xiao Shun. And Cindy is from Angela's group. They work jointly to have this nice paper. And Angela made a huge contribution to reshape the manuscript such that the biologists can understand what we are doing. I really appreciate Andy's efforts. Now, today I'm going to introduce. Now, today I'm going to introduce the main idea because there are too many technical details. So, what is the main idea? We have the overall mixture measurements and we want to decompose into individual components. Here I just take two cells as an example. So, the overall is like this: we want to decompose into individual components. We know this is impossible, just like the number 10, right? We can decompose into 10, right? We can decompose into 2 plus 8, 5 plus 5. So there exists an identifiability issue. Well, the question is that if we have some prior knowledge, for example, from single cell atlas, we know the distribution. For that year, we know this is a horse, this is a dog, and we know the prior distribution for horse and dog, then can we do this kind of decomposition? So that that's the main idea. So that's the main idea, right? Okay, now the answer will be yes. We can do that. Let me see. How to do that? We need a few mathematics, right? So if we want to take a sample from the desired distribution PS, this is an alternative way instead of doing MCMC. This is called long-term dynamics. As long as we Dynamics, as long as we have this term, this is called a score function, anyway, in the AI diffusion model, score function. And then we run this stochastic differential equation, we can eventually take samples from Px. We run this Langement dynamics. That part is just an illustration. And here, the big idea is that if we model the The likelihood and prior term. So basically, suppose we have the overall measurement. This is the individual gene expression with some measurements noise. And then if we want to get the individual gene expression levels, and then we want to write down the posterior rails here, and then run the Langevin dynamics. As simple as this, that's a big idea. And then when we work on the And then when we work on the posterior distribution, posterior distribution, then we just use Bayes' rule to rewrite this posterior. The nice thing is that the normalization term, here, this is a normalization term, will gone because here we put this gradient with respect to x. Then we don't need to consider the normalization term. So what remains is the likelihood term. The likelihood term and the prior term. Luckily, we can have used single-cell data to estimate the prior term. For example, this is the distribution for cell type 1. This is the distribution for cell type 2. As long as we can learn this part from single cell atlas data, then we can simply run this long-term dynamics to get the posterior inference. That's in parts. The big idea would be like this. The big idea would be like this. And of course, when we, well, we already have a lot of single-cell athletes. And for example, if we have the spatial data for human heart, and then we can have this type of single-cell data as the reference, we learn the prior distribution and then run the Dodgement dynamics. So basically, the big ideas, spatial scope is. The big idea, spatial scope is like this. For this image data, we can do the decomposition because we know the prior distribution from public data. And that's the similar set. We have this individual cell transcription-wide expression. That's because we can learn the distribution from single-cell data. Yeah, that's the main idea here. Of course, there are some other issues of this big idea. That is, for each sports, typically we don't know how many cells are there. So, we are going to use nuclear segmentation to the H and E standing image to count how many nucleus are there so we know the number of cells in each spot. Okay, so that's the first step. So that's the first step. The second step, we don't. I mean, you have HE and the spatial. Yeah, yeah, yeah. The second part, suppose we have five cells identified in that sports, we don't know the cell types. And then we learn from Rafa RCTV model. The only difference is that for Rafa's RCTV model, the cell type proportion is a continuous number. Here, Number. Here, because we already know there are five cells, I just modified the contingence model to be the discretized model and add some kind of spatial smoothness term. And then I can identify the cell types. So this should be attributed to rafa. And the third step is that how to learn the distribution, the prior distribution from the single-cell reference, and how to correct the battery batteries. Indeed, when we do the second step, When we do the second step, we again learn from RCTD, we already correct those platform differences when we do the cell type part. And I know this part I cannot explain in five minutes, so I will leave that part in discussion. Basically, we have three steps. The input data will be the spatial expression data and the image data and the single-cell reference data. The single-cell reference data, that's an input. The first step is to apply the New Kinear segmentation, which is different from cell segmentation. New Kinea segmentation is much easier. We have the count of number of cells, and then we identify the cell types, and then use those long-term dynamics to get the individual expression level for cells. So, this will be quite different from So, this will be quite different from just assign the mean, cell type mean for each individual cell. So, we will have individuals. This is how we learn this score function from single cell parts. I will leave this part in the discussion. Many technical details are here. Okay, this is just a demonstration. Just a demonstration. Say we have a single cell reference data, we can use this deep generating model, train it, and then gradually approximate the desired distribution. So we have the prior distribution and then run the management dynamics. In the paper, we have many examples, but I can just use one example. This is false-level transcription data, and this is the step. After step two, we identified each Each sports, how many cells, and what are the cell types, and for the three steps. The third step, we do the decomposition. This is original Vesium data for some macro gene, and this is the high super resolution obtained by SpatialScope. Okay, so we have individual gene transcription-wide expression. We can also attain this framework to Murphich data. The idea is pretty simple because we just need to modify the likelihood term. Here, we have a mask. We only observe, for example, 100 expression, but this is one hundred expression. But indeed, we want to take like thousands of gene expression. So we only need to modify the likelihood term. Likelihood term just like this. So, given data like this, I want to impute something like this. Why I can do this? Because I know the correlation between this part and the observed part based on the learned deep generating model. So, here we did some experiment and compared to, for example, some tank RAM methods. So, we try to demonstrate the deep generating model is really good at capturing the flux. Capture the flexible distribution in a single cell. And then we have the collaborator from Hong Kong, right? Rio, already applied this new techniques to embryo autonomous spatial data analysis. This paper has been accepted. Let me summarize. So, spatial scope offers a unified framework by Unified framework by leverage the deep generated model to learn the distribution from single-cell reference. And then we can do the decomposition for 10x besidium and the imputation for like Murphich data. That's all the software wells, and we have all those examples. All of them are reproducible because Jane is particularly interested in 3D. Particularly interesting in 3D. Then I have some results for 3D reconstruction based on spatial transformment data. That's about our stitch 3D. Again, Andrea is standing there. And the Girlfriend Andrea do all the technical work. And they are my PhD students. They are going to be the postdoc of the Inhong staff. And Yen Yan, a biologist, she is responsible for. She is responsible for the interpretation of the fly data parts, fly envelope data. Okay, so we can do this stitch 3D. What is the goal of this guy? We want to have this 3D reconstruction based on the multiple slides. What do we mean by reconstruction? We want to simultaneously do domain, spatial domain detection, and the cell type deconvolution in 3D space. Conclusion is 3D space. And why we can do this? Because we do the modeling using graphic neural nets and correction platform effects. And we write down it into the unified probabilistic model. And I try to show you in depth. We can combine the strengths from AI and the statistical modeling into the unified framework. And I believe this is a good approach for us to do. This is a good approach for us to do spatial data. And here I just try to demonstrate using this is a data, stabilizing data. We have this multiple size for the larver ample. And this is the reconstruction result in 3D space based on multiple size. And indeed, we can do this based on the stereotype in different resolution. For example, this. Resolution, for example, this low resolution, higher resolution, the highest resolution for different resolution. And then after we have those results, we can even improve that part for single cell resolution in 3D space. And then we compare this result with 10-gram and cell chunk. Of course, if you are interested in, we can talk more about this, how we achieve this. More about this, how we achieve this kind of performance. Again, all the softwares are available, and we have all those example data publicly available for you to run. All the code are there. In the end, I want to summarize my talk. Because I'm from Mass Permanent, I want to show you the take-home messages that AI is not magic. It is a computational It is a computationally efficient method. Try to incorporate different kinds of information in a flexible way into the statistical model part. And then try to build in the rich information in the data. So I think if you use correctly, it can dramatically improve the performance by computing. Yeah, thank you. Okay, question for the audience, which one? Ten. Very nice one. Very nice work. So I have a technical question on the first part. So I guess in Tuiter, we have five cells in the feature. And you want to, I say in the reference, you have all sorts of cells. You intuitively want to pick up the cell that's similar to that, as that cell type specific expression. But how do you do that exactly? Do you need to describe the assaltent cell representation for the assalm cell similar to the recovery one? Or do you like using quantiles of a certain summary specific? You mean the reference part or the methods? No, we simply do this. So in the reference part, we assume all those kind of cells, single cell has been correctly annotated, and then we do some kind of log transformation and then directly apply the generating model to model this distribution. As long as we have the distribution, I know the cell types, I know. I know the cell types, I know. For example, for one sports, if I have two cells, one cell with this cell type A, another with cell type B, we directly run the Langement Dynamics, try to use the learned score function. We don't know which is which, but for the trials, five cells are not five, you know, for cell type, I mean the different colour for each cell. I already know the cell types, for example, this A, this is B, this C. I already know that by spatial information. I already know. I know the specific cell types for this because I modify the start part of the CTB stuff. Yeah, it's a discretized version. Oh, yes. Yeah, discretization. So sometimes I think if you use the like AI model, so basically you just regenerate the pattern, you don't know what is the distribution for the probability between the platform. So you want to use single-cell RNA reference. Yes. So for us, we want to derive a X-ray model to kind of to To kind of to model the probability between single-cell assays with the spectral technique, special technology. So I would just wonder, you just use the count and then use some block transformation and all the data after removing the batch with that. So have you tried something like a bank? I wouldn't I I'm I'm I'm thinking whether you can get back even better performance. Get by even better performance? I didn't try rank, but I think I can say a few words more about the details. For the step two, since the RCTD model, in there we model the batch effects here and try to get rid of the batch effects when we do cell type identification. And then when we have the deep generated part, we learn the deep generated generation We learn the deep generative model in the log space, but then we convert it to the counter space when we do this decomposition. Yeah, two details, sorry. I didn't mention that part before. Last question before. Does the panel assume that you've seen all the other things? Uh the beta and the cell type are complete in reference. In the STI conclusion. Yeah, yeah, on the reference. We are assuming that. Because if without that apart, it's really hard to tell if one cell type in the spatial data are highly correlated in the reference, but not the cell type are not in the reference. So I think there is a challenge there because it's a question like yesterday about there have been issues with The issues with immunity cell types, too big, too small, too much oil, that kind of thing. And so I think that is what that's going to be. Yes, it's about the rare cell type, all those things are misannotated. While I would like to say that depends on the quality of single-cell reference data, I think in RCTE model, also the rough scroof. Rafa school also tested if some cell types are missed in the spatial part, in the reference part, if you have some highly correlated one, you are likely to have a correlated one. I think in RCTD supplementary or really demonstrate that part. So I didn't repeat that part. So look how Some of the things that